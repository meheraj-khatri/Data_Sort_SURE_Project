Document Title,Authors,Publication Title,Publication Year,Abstract,DOI,PDF Link
"Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutors",,Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2,2023,"Generative AI and large language models hold great promise in enhancing computing education by powering next-generation educational technologies. State-of-the-art models like OpenAI’s ChatGPT&nbsp;[8] and GPT-4&nbsp;[9] could enhance programming education in various roles, e.g., by acting as a personalized digital tutor for a student, a digital assistant for an educator, and a digital peer for collaborative learning&nbsp;[1, 2, 7]. In our work, we seek to comprehensively evaluate and benchmark state-of-the-art large language models for various scenarios in programming education. Recent works have evaluated several large language models in the context of programming education&nbsp;[4, 6, 10, 11, 12]. However, these works are limited for several reasons: they have typically focused on evaluating a specific model for a specific education scenario (e.g., generating explanations), or have considered models that are already outdated (e.g., OpenAI’s Codex&nbsp;[3] is no longer publicly available since March 2023). Consequently, there is a lack of systematic study that benchmarks state-of-the-art models for a comprehensive set of programming education scenarios. In our work, we systematically evaluate two models, ChatGPT (based on GPT-3.5) and GPT-4, and compare their performance with human tutors for a variety of scenarios in programming education. These scenarios are designed to capture distinct roles these models could play, namely digital tutors, assistants, and peers, as discussed above. More concretely, we consider the following six scenarios: (1) program repair, i.e., fixing a student’s buggy program; (2) hint generation, i.e., providing a natural language hint to the student to help resolve current issues; (3) grading feedback, i.e., grading a student’s program w.r.t. a given rubric; (4) peer programming, i.e., completing a partially written program or generating a sketch for the solution program; (5) task creation, i.e., generating new tasks that exercise specific types of concepts or bugs; (6) contextualized explanation, i.e., explaining specific concepts or functions in the context of a given program. Our study uses a mix of quantitative and qualitative evaluation to compare the performance of these models with the performance of human tutors. We conduct our evaluation based on 5 introductory Python programming problems with a diverse set of input/output specifications. For each of these problems, we consider 5 buggy programs based on publicly accessible submissions from geeksforgeeks.org &nbsp;[5] (see Figure&nbsp;1); these buggy programs are picked to capture different types of bugs for each problem. We will provide a detailed analysis of the data and results in a longer version of this poster. Our preliminary results show that GPT-4 drastically outperforms ChatGPT (based on GPT-3.5) and comes close to human tutors’ performance for several scenarios.",10.1145/3568812.3603476,https://doi.org/10.1145/3568812.3603476
Generative AI in Computer Science Education,"Hazzan, Orit and Erez, Yael",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"Generative AI has the potential to become disruptive technology for computer science education. Therefore, computer science educators must be familiar with the threats they should deal with and with the opportunities that generative-AI opens for the computer science education community. In the workshop, we explore the integration of several generative-AI tools and applications in computer science education. Activities include lesson design, code development, test design and assessment. We address the students' and the educators' perspectives. In addition, we explore computer science practices and soft skills to be applied with these tools as well as immediate and future applications and implications for computer science education and for the society. AT the end of the workshop, the participants will be able to use these generative AI tools in their daily educational computer science activities and beyond.",10.1145/3626253.3633409,https://doi.org/10.1145/3626253.3633409
Multimodal Analogy Generation in Programming Education,"Noviello, Yuri and Birillo, Anastasiia and Migut, Gosia",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 2,2025,"Engaging students with effective learning materials continues to be a significant challenge in programming education. Analogies are commonly used to simplify complex topics, enabling learners to relate unfamiliar concepts to familiar ones. Additionally, visual representations of these analogies can enhance engagement and improve the overall learning experience. This work presents a prototype of a novel AI tool that generates analogy-based explanations and corresponding video animations for programming education. The tool leverages Large Language Models (LLMs) for analogy generation and a structured animation workflow for visualization. This poster invites discussion on the effectiveness of AI-generated educational content and its implications for programming education.",10.1145/3724389.3730781,https://doi.org/10.1145/3724389.3730781
Generative AI for Programming Education: Can ChatGPT Facilitate the Acquisition of Fundamental Programming Skills for Novices?,"Sadat Shanto, Shakib and Ahmed, Zishan and Jony, Akinul Islam",Proceedings of the 3rd International Conference on Computing Advancements,2025,"Modern Generative AI (GAI) systems like ChatGPT have sparked much interest in their potential to revolutionize programming education, especially for beginners. However, the existing empirical data regarding the effectiveness of technologies like ChatGPT as autonomous programming tutors is presently limited. The present study investigates the capacity of ChatGPT to facilitate the acquisition of fundamental programming skills for novice programmers without human assistance. This study puts forth a conceptual framework (APEC - Adaptive Programming Education via ChatGPT) that integrates both bottom-up and top-down approaches, incorporating ChatGPT as the principal instructor for the study of programming. An empirical study was undertaken to assess the usefulness of ChatGPT as a tool for teaching novice programmers a new programming language. This empirical study was conducted on 20 undergraduate students. To provide an expert assessment of the quality of the responses, a survey was conducted with three programming experts proficient in Python. The survey findings indicate that ChatGPT is proficient in explaining core principles such as variables, data types, and control statements through conversational exchanges, adopting an intelligent and logical methodology. Nevertheless, certain constraints arise when dealing with increasingly complex topics.",10.1145/3723178.3723268,https://doi.org/10.1145/3723178.3723268
A Comparative Study of AI-Generated (GPT-4) and Human-crafted MCQs in Programming Education,"Doughty, Jacob and Wan, Zipiao and Bompelli, Anishka and Qayum, Jubahed and Wang, Taozhi and Zhang, Juran and Zheng, Yujia and Doyle, Aidan and Sridhar, Pragnya and Agarwal, Arav and Bogart, Christopher and Keylor, Eric and Kultur, Can and Savelka, Jaromir and Sakr, Majd",Proceedings of the 26th Australasian Computing Education Conference,2024,"There is a constant need for educators to develop and maintain effective up-to-date assessments. While there is a growing body of research in computing education on utilizing large language models&nbsp;(LLMs) in generation and engagement with coding exercises, the use of LLMs for generating programming MCQs has not been extensively explored. We analyzed the capability of GPT-4 to produce multiple-choice questions (MCQs) aligned with specific learning objectives (LOs) from Python programming classes in higher education. Specifically, we developed an LLM-powered (GPT-4) system for generation of MCQs from high-level course context and module-level LOs. We evaluated 651 LLM-generated and 449 human-crafted MCQs aligned to 246 LOs from 6 Python courses. We found that GPT-4 was capable of producing MCQs with clear language, a single correct choice, and high-quality distractors. We also observed that the generated MCQs appeared to be well-aligned with the LOs. Our findings can be leveraged by educators wishing to take advantage of the state-of-the-art generative models to support MCQ authoring efforts.",10.1145/3636243.3636256,https://doi.org/10.1145/3636243.3636256
A Systematic Literature Mapping of Early Generative AI Research is CS Education,"Harrington, Brian and Alnoor, Ahmad Zubair and Haqiqi, Pedram and Hoseininia, Zahra and Lin, Kai and Lodi, Maliha and Mirza, Asad and Wolfe, Leah and Zhang, Kevin",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"The widespread release of generative AI tools has led to a rapid rise in publications evaluating their impact on CS education. While there is no doubt that the area is new and rapidly evolving, it is important to begin to catalogue and map the literature at this early stage. In this work, we systematically search and map 82 papers evaluating the impact of generative AI tools on CS education. We then build a literature map of these papers using the axes of population, use of generative AI, and method of evaluation. This work will serve as both a snapshot of the first generation of generative AI papers in the field, and a road-map for further classification and literature review as the field develops.",10.1145/3641555.3705121,https://doi.org/10.1145/3641555.3705121
Supporting Teaching and Learning Computational Thinking Skills with Generative AI in Computing Education,"Benedetti, Enrico",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 2,2025,"Computational thinking (CT) skills allow us to achieve goals in a computation-driven world. Activities such as programming both benefit from and help improve CT skills, like abstraction and decomposition. Generative AI (GenAI) could be useful in developing CT skills. However, it could also change how we learn to program and which skills are more important. We aim to understand how GenAI can support the learning of CT skills in the context of computing education.",10.1145/3724389.3731294,https://doi.org/10.1145/3724389.3731294
"Assessing Risks, Challenges and Opportunities of Generative AI in Computer Programming Education --- Lightning Talk","Liu, Sa and Grey, Brian and Watkins, Ryan and Chu, Chad and Grim, Phillip and McManus, Thomas",J. Comput. Sci. Coll.,2024,"Artificial Intelligence (AI) has the potential to transform the education sector by enhancing teaching and learning experiences. According to Sal Khan, founder of Khan Academy, AI is about to start",,
Implementing the AI-Lab Framework: Enhancing Introductory Programming Education for CS Majors,"Bejarano, Andres and Dickey, Ethan and Setsma, Rhianna",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"The advent of generative AI tools presents novel opportunities and challenges in computer science education, particularly in introductory programming courses. This study explores the implementation of AI-Lab, a framework designed to guide students in the effective and ethical use of generative AI, in this case ChatGPT, in academic settings without compromising skill development. Conducted during Spring 2024, our use of the intervention targeted over 500 Computer Science and Data Science majors enrolled in their major-specific Data Structures and Algorithms courses. The AI-Lab framework enabled students to develop both conceptual questions and c++ and Python programs by interacting with ChatGPT and iteratively correcting its errors. Focus groups and post-intervention surveys revealed a generally positive experience. Students appreciated the ability to leverage AI for tasks outside their major, recognizing the value of understanding correct solutions through AI-assisted programming. Moreover, the guided use of generative AI by professors alleviated concerns regarding academic dishonesty, fostering a supportive learning environment. Despite these benefits, students expressed awareness of the potential drawbacks of over-reliance on AI, noting the risk of impeding their professional growth. Nevertheless, they acknowledged the practical utility of AI for non-major related tasks. This study highlights the importance of incorporating structured AI training in curricula to balance skill development and ethical AI usage, offering insights for broader applications in higher education.",10.1145/3641555.3705201,https://doi.org/10.1145/3641555.3705201
Exploring the Adoption of Generative AI Tools in Computer Science Education: A Student Survey,"Schefer-Wenzl, Sigrid and Vogl, Christoph and Peiris, Sahani and Miladinovic, Igor",Proceedings of the 2024 16th International Conference on Education Technology and Computers,2025,"The integration of generative AI tools into education has the potential to revolutionize learning experiences, particularly in computer science. This paper explores the adoption and utilization of generative AI tools among computer science students at the University of Applied Sciences Campus Vienna in Austria through a comprehensive survey. The study aims to understand the extent to which AI tools like ChatGPT are integrated into students' academic routines, their perceptions of these tools, and the challenges and opportunities they present. The survey results indicate a high level of acceptance and frequent use of AI tools for tasks such as programming, exam preparation, and generating simplified explanations. However, concerns about the accuracy of AI-generated content and the potential impact on critical thinking skills were also highlighted. The findings underscore the need for clear institutional guidelines and ethical considerations in the use of AI tools in education. This paper contributes to the growing body of literature on AI in education and provides insights for educators and policymakers to enhance the responsible integration of AI technologies in computer science curricula.",10.1145/3702163.3702188,https://doi.org/10.1145/3702163.3702188
Improving Introductory Java Programming Education Through ChatGPT,"Xie, Jingnan",J. Comput. Sci. Coll.,2024,"The realm of introductory computer science (CS) education is swiftly changing, as educators actively pursue inventive strategies to captivate and empower students. This manuscript introduces a fresh methodology for teaching CS1 or CS2 courses, concentrating specifically on the fundamental principles of Java programming. Harnessing the capabilities of ChatGPT, an AI language model, we delve into how integrating conversational AI into the classroom milieu can foster a more dynamic and tailored learning journey. By furnishing a platform for students to pose inquiries, seek elucidation, and promptly receive feedback, ChatGPT functions as a virtual mentor, complementing conventional teaching methodologies. We scrutinize the potential repercussions of this approach on student learning outcomes (SLOs) and juxtapose it with traditional classroom paradigms. Furthermore, we deliberate on the ramifications of employing AI in education and its contribution to molding the trajectory of introductory programming courses.",,
Generative AI and CS Education,"Johnson, Maggie",Commun. ACM,2024,Increasing knowledge sharing between industry and academia.,10.1145/3632523,https://doi.org/10.1145/3632523
The Robots Are Here: Navigating the Generative AI Revolution in Computing Education,"Prather, James and Denny, Paul and Leinonen, Juho and Becker, Brett A. and Albluwi, Ibrahim and Craig, Michelle and Keuning, Hieke and Kiesler, Natalie and Kohn, Tobias and Luxton-Reilly, Andrew and MacNeil, Stephen and Petersen, Andrew and Pettit, Raymond and Reeves, Brent N. and Savelka, Jaromir",Proceedings of the 2023 Working Group Reports on Innovation and Technology in Computer Science Education,2023,"Recent advancements in artificial intelligence (AI) and specifically generative AI (GenAI) are threatening to fundamentally reshape computing and society. Largely driven by large language models (LLMs), many tools are now able to interpret and generate both natural language instructions and source code. These capabilities have sparked urgent questions in the computing education community around how educators should adapt their pedagogy to address the challenges and to leverage the opportunities presented by this new technology. In this working group report, we undertake a comprehensive exploration of generative AI in the context of computing education and make five significant contributions. First, we provide a detailed review of the literature on LLMs in computing education and synthesise findings from 71 primary articles, nearly 80% of which have been published in the first 8 months of 2023. Second, we report the findings of a survey of computing students and instructors from across 20 countries, capturing prevailing attitudes towards GenAI/LLMs and their use in computing education contexts. Third, to understand how pedagogy is already changing, we offer insights collected from in-depth interviews with 22 computing educators from five continents. Fourth, we use the ACM Code of Ethics to frame a discussion of ethical issues raised by the use of large language models in computing education, and we provide concrete advice for policy makers, educators, and students. Finally, we benchmark the performance of several current GenAI models/tools on various computing education datasets, and highlight the extent to which the capabilities of current models are rapidly improving.There is little doubt that LLMs and other forms of GenAI will have a profound impact on computing education over the coming years. However, just as the technology will continue to improve, so will our collective knowledge about how to leverage these new models and tools in educational settings. We expect many important conversations around this topic will emerge as the community explores how to provide more effective, inclusive, and personalised learning experiences. Our aim is that this report will serve as a focal point for both researchers and practitioners who are exploring, adapting, using, and evaluating GenAI and LLM-based tools in computing classrooms.",10.1145/3623762.3633499,https://doi.org/10.1145/3623762.3633499
Student's Use of Generative AI as a Support Tool in an Advanced Web Development Course,"Alpizar-Chacon, Isaac and Keuning, Hieke",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"Various studies have studied the impact of Generative AI on Computing Education. However, they have focused on the implications for novice programmers. In this experience report, we analyze the use of GenAI as a support tool for learning, creativity, and productivity in a web development course for undergraduate students with extensive programming experience. We collected diverse data (assignments, reflections, logs, and a survey) and found that students used GenAI on different tasks (code generation, idea generation, etc.) with a reported increase in learning and productivity. However, they are concerned about over-reliance and incorrect solutions and want more training in prompting strategies.",10.1145/3724363.3729106,https://doi.org/10.1145/3724363.3729106
Discussing the Changing Landscape of Generative AI in Computing Education,"MacNeil, Stephen and Leinonen, Juho and Denny, Paul and Kiesler, Natalie and Hellas, Arto and Prather, James and Becker, Brett A. and Wermelinger, Michel and Reid, Karen",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"In a previous Birds of a Feather discussion, we delved into the nascent applications of generative AI, contemplating its potential and speculating on future trajectories. Since then, the landscape has continued to evolve revealing the capabilities and limitations of these models. Despite this progress, the computing education research community still faces uncertainty around pivotal aspects such as (1) academic integrity and assessments, (2) curricular adaptations, (3) pedagogical strategies, and (4) the competencies students require to instill responsible use of these tools. The goal of this Birds of a Feather discussion is to unravel these pressing and persistent issues with computing educators and researchers, fostering a collaborative exploration of strategies to navigate the educational implications of advancing generative AI technologies. Aligned with this goal of building an inclusive learning community, our BoF is led by globally distributed leaders to facilitate multiple coordinated discussions that can lead to a broader conversation about the role of LLMs in CS education.",10.1145/3626253.3635369,https://doi.org/10.1145/3626253.3635369
A Plan for an ACM Task Force Working Group into the Ethical and Societal Impacts of Generative AI in Higher Computing Education,"Mak, Janice and Nakatumba-Nabende, Joyce and Clear, Alison and Clear, Tony and Sanusi, Ismaila and Sheard, Judy and Angeli, Lorenzo and Rattigan, Matthew Hale and Andrei, Oana and Mann, Samuel and Oyelere, Solomon Sunday and MacNeil, Stephen and Zhu, Tingting",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 2,2025,"Generative AI (GenAI) presents societal and ethical challenges related to equity, academic integrity, bias, and data provenance. This working group will consider the ethical and societal impacts of GenAI in higher computing education. In this paper, we outline the goals, methodology and expected deliverables of the working group. In particular, we will carry out a systematic literature review to address a wide set of issues and topics covering the rapidly emerging technology of GenAI from the perspective of its ethical and social impacts, we will provide an evaluation of university policies on the adoption and guidelines for use of GenAI for computing education and develop a framework to outline the ethical and societal impacts of GenAI in computing education. This work synthesizes existing research and considers the implications for educational and professional codes of ethics.",10.1145/3724389.3731282,https://doi.org/10.1145/3724389.3731282
Enhancing Computer Programming Education using ChatGPT- A Mini Review,"Deriba, Fitsum Gizachew and Sanusi, Ismaila Temitayo and Sunday, Amos Oyelere",Proceedings of the 23rd Koli Calling International Conference on Computing Education Research,2024,"This paper aims to provide insights into how ChatGPT enhances computer programming education by synthesizing existing studies using rapid review. We analysed 13 articles published in 2023, where studies focused on different aspects of basic programming education. The results indicate that 21% of these studies demonstrate that ChatGPT served as a tool for code explanation and handling complex topics. However, 36% show that ChatGPT had difficulty answering non-text-based and code-related questions, revealing reliability and accuracy issues with these tools. Another 36% of the studies showed that blindly over-reliance on ChatGPT affected critical thinking, student creativity, and problem-solving skills in programming education. 46% of the studies indicated the need to provide clear guidelines and employ plagiarism-detection tools to instruct students effectively. We suggest that educators should adopt diverse approaches to integrating ChatGPT as an educational tool while highlighting ethical considerations and model limitations.",10.1145/3631802.3631848,https://doi.org/10.1145/3631802.3631848
A Benchmark for Testing the Capabilities of LLMs in Assessing the Quality of Multiple-choice Questions in Introductory Programming Education,"Ramesh, Aninditha and Agarwal, Arav and Doughty, Jacob Arthur and Ramaneti, Ketan and Savelka, Jaromir and Sakr, Majd",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1,2024,"There has been a growing interest in utilizing large language models (LLMs) for numerous educational applications. Recent studies have focused on the use of LLMs for generating various educational artifacts for programming education, such as programming exercises, model solutions, or multiple-choice questions (MCQs). The ability to efficiently and reliably assess the quality of such artifacts, both automatically and human generated, has become of paramount importance. Hence, there is a pressing need to develop and make available robust benchmarks. In this paper, we investigate an example use case of assessing the quality of programming MCQs. To that end, we carefully curated a data set of 192 MCQs annotated with quality scores based on a rubric that evaluates crucial aspects such as, e.g., their clarity, the presence of a single correct answer, and the quality of distractors. The results show that the task presents a considerable challenge even to the state-of-the-art LLMs and, hence, further research is needed. To further such research efforts in this important area we release the dataset as well as the extensible evaluation pipeline to the public.",10.1145/3649165.3690123,https://doi.org/10.1145/3649165.3690123
Generative AI in CS Education: Literature Review through a SWOT Lens,"Roberts, Jordan and Mohamed, Abdallah",Proceedings of the 26th Western Canadian Conference on Computing Education,2024,"The rapid growth of generative artificial intelligence (AI) models introduced challenges for educators, students and administrators across the academic sphere related to how to manage and regulate these tools. While some oppose their use, many researchers have begun to approach the topic of educational AI use from a different perspective. Despite being in its early stages; this field of research has produced notable insights into the capabilities and limitations of models like ChatGPT. This paper utilizes a SWOT analysis framework to analyze and consolidate existing literature, with a specific focus on Computer Science education. Through the analysis of this literature, we have created a set of use cases and guidelines to aid in the future development of strategies and tools within this field. Our findings indicate that while some concerns are valid, such as AI's ability to generate plagiarized work, we identified several promising avenues and opportunities for careful integration of this technology into education.",10.1145/3660650.3660657,https://doi.org/10.1145/3660650.3660657
Evaluating ChatGPT and GPT-4 for Visual Programming,"Singla, Adish",Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2,2023,"Generative AI has the potential to drastically improve the landscape of computing education by automatically generating personalized feedback and content. In particular, this potential lies in the advanced capabilities of state-of-the-art deep generative and large language models such as OpenAI’s Codex&nbsp;[7], ChatGPT&nbsp;[11], and GPT-4&nbsp;[12]. In our work, we seek to investigate the capabilities of these models in visual programming domains popularly used for K-8 programming education, including domains like Scratch&nbsp;[17], Hour of Code: Maze Challenge by Code.org&nbsp;[4, 5], and Karel&nbsp;[13]. Recent works have shown us sparks of advanced capabilities of such models for various education scenarios in introductory Python programming&nbsp;[2, 14, 18, 20]. In fact, a study in 2022 had ranked Codex in the top quartile w.r.t students in a large Python programming course&nbsp;[8]. However, all these works consider only text-based Python programming and leave open the question of how well these models would perform for visual programming. The main research question is: Do state-of-the-art neural generative models show advanced capabilities for visual programming on par with their capabilities on text-based Python programming?In our work, we evaluate these models for visual programming based on the following three settings designed to capture various generative and problem-solving capabilities: We conduct our evaluation based on 10 representative tasks from two visual programming domains: Hour of Code: Maze Challenge by Code.org&nbsp;[4, 5] and Intro to Programming with Karel course by CodeHS.com&nbsp;[3, 13]. As illustrative examples, Figures&nbsp;1,&nbsp;2,&nbsp;and&nbsp;3 show the output of GPT-4 in three settings for Maze18 task. We will provide the detailed analysis and prompts used in a longer version of this poster. Our preliminary results for ChatGPT (based on GPT-3.5) and GPT-4 show that these models perform poorly and produce incorrect output the majority of the time. These results highlight that state-of-the-art neural generative models like GPT-4 still struggle to combine spatial, logical, and programming skills crucial for visual programming. As the next step, it would be important to curate novel benchmarks that the research community can use to evaluate improvements in future versions of these models for visual programming.",10.1145/3568812.3603474,https://doi.org/10.1145/3568812.3603474
"StoryStudio: Enhancing Data Science Education with Explainable, Narrative-Driven Storytelling","Henry, Ryan and Hassan, Taha and Gong, Jiaqi",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 2,2025,"Data storytelling is essential in data science education but often lacks structured guidance. While students learn visualization and modeling, existing AI tools primarily generate stories automatically rather than teaching narrative construction. Few tools integrate storytelling with Jupyter Notebooks, and those that do focus on code generation rather than user-driven storytelling. StoryStudio bridges this gap by integrating with JupyterHub, allowing users to export figures and code into an interactive storytelling interface. It supports figure organization, AI-assisted insight extraction, and structured narrative generation using seven storytelling patterns. Unlike automated tools, Story Studio emphasizes active learning, helping students craft and refine their own data narratives. This poster will showcase Story Studio's role in enhancing visual literacy and data communication in data science education.",10.1145/3724389.3730811,https://doi.org/10.1145/3724389.3730811
Desirable Characteristics for AI Teaching Assistants in Programming Education,"Denny, Paul and MacNeil, Stephen and Savelka, Jaromir and Porter, Leo and Luxton-Reilly, Andrew",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"Providing timely and personalized feedback to large numbers of students is a long-standing challenge in programming courses. Relying on human teaching assistants (TAs) has been extensively studied, revealing a number of potential shortcomings. These include inequitable access for students with low confidence when needing support, as well as situations where TAs provide direct solutions without helping students to develop their own problem-solving skills. With the advent of powerful large language models (LLMs), digital teaching assistants configured for programming contexts have emerged as an appealing and scalable way to provide instant, equitable, round-the-clock support. Although digital TAs can provide a variety of help for programming tasks, from high-level problem solving advice to direct solution generation, the effectiveness of such tools depends on their ability to promote meaningful learning experiences. If students find the guardrails implemented in digital TAs too constraining, or if other expectations are not met, they may seek assistance in ways that do not help them learn. Thus, it is essential to identify the features that students believe make digital teaching assistants valuable. We deployed an LLM-powered digital assistant in an introductory programming course and collected student feedback (n=813) on the characteristics of the tool they perceived to be most important. Our results highlight that students value such tools for their ability to provide instant, engaging support, particularly during peak times such as before assessment deadlines. They also expressed a strong preference for features that enable them to retain autonomy in their learning journey, such as scaffolding that helps to guide them through problem-solving steps rather than simply being shown direct solutions.",10.1145/3649217.3653574,https://doi.org/10.1145/3649217.3653574
Feedback-Generation for Programming Exercises With GPT-4,"Azaiz, Imen and Kiesler, Natalie and Strickroth, Sven",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"Ever since Large Language Models (LLMs) and related applications have become broadly available, several studies investigated their potential for assisting educators and supporting students in higher education. LLMs such as Codex, GPT-3.5, and GPT 4 have shown promising results in the context of large programming courses, where students can benefit from feedback and hints if provided timely and at scale. This paper explores the quality of GPT-4 Turbo's generated output for prompts containing both the programming task specification and a student's submission as input. Two assignments from an introductory programming course were selected, and GPT-4 was asked to generate feedback for 55 randomly chosen, authentic student programming submissions. The output was qualitatively analyzed regarding correctness, personalization, fault localization, and other features identified in the material. Compared to prior work and analyses of GPT-3.5, GPT-4 Turbo shows notable improvements. For example, the output is more structured and consistent. GPT-4 Turbo can also accurately identify invalid casing in student programs' output. In some cases, the feedback also includes the output of the student program. At the same time, inconsistent feedback was noted such as stating that the submission is correct but an error needs to be fixed. The present work increases our understanding of LLMs' potential, limitations, and how to integrate them into e-assessment systems, pedagogical scenarios, and instructing students who are using applications based on GPT-4.",10.1145/3649217.3653594,https://doi.org/10.1145/3649217.3653594
Prompt-Engineering Strategies for Minimizing Bias in Large Language Model Outputs: Applications in Computing Education,"Morales, Jamie and Raman, Preeti",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"As large language models (LLMs) increasingly permeate educational applications, concerns about the perpetuation of bias persist. We present our preliminary work on developing prompt-engineering strategies to mitigate bias in content generated by LLMs in computer science (CS) education. This work investigates both empirical insights into fairness-aware prompt formulation and actionable takeaways for educators. We focus on an initial list of prompting strategies for mitigating bias and explore their impact on educational content generation. Recent research has shown the efficacy of prompt-base debiasing [1] as well as the potential disadvantages of using prompts that have not been mitigated for bias, from user dissatisfaction [2] to unsafe outputs [5, 6]. Additionally, a growing body of empirical work points to the idea that certain properties of in-context examples such as flow [7], illustration [3], and order [4] could either improve or derail LLM performance. Our study leverages these findings in the context of generating educational content. The goal is to promote fairness-aware approaches which can be applied to the automated generation of learning materials and the development of LLM-based educational tools. This work also contributes practical insights on prompt-engineering to the evolving curriculum of Ethics in Artificial Intelligence (AI).",10.1145/3641555.3705080,https://doi.org/10.1145/3641555.3705080
Personalised Programming Education with Knowledge Tracing,"Shaka, Martha and Carraro, Diego and Brown, Kenneth N.",Proceedings of the 2023 Conference on Human Centered Artificial Intelligence: Education and Practice,2023,"In traditional programming education, addressing diverse student needs and providing effective and scalable learning experiences is challenging. Conventional methods struggle to adapt to varying learning styles and offer personalised feedback. AI-based Programming Tools (AIPTs) have shown promise in automating feedback, simplifying programming concepts, and guiding students. Their widespread adoption is hindered by limitations related to accuracy, explanation, and personalisation. Conversely, AIPTs tailored for expert programmers, such as ChatGPT and Copilot, have gained popularity for their productivity-enhancing capabilities, but they still fall short in terms of personalisation, neglecting individual students’ unique knowledge and skills. Our research aims to leverage AI to create AIPTs that offer personalised feedback through adaptive learning, accommodating diverse student backgrounds and proficiency levels. In particular, we explore using Knowledge Tracing (KT) to anticipate specific syntax errors in programming assignments, addressing the challenges novices face in acquiring syntactical knowledge. The findings suggest the KT’s potential to transform programming education by enabling timely interventions for students dealing with specific errors or misconceptions, automating personalised feedback, and informing tailored instructional strategies.",10.1145/3633083.3633220,https://doi.org/10.1145/3633083.3633220
How ChatGPT Will Change Software Engineering Education,"Daun, Marian and Brings, Jennifer",Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1,2023,"This position paper discusses the potential for using generative AIs like ChatGPT in software engineering education. Currently, discussions center around potential threats emerging from student's use of ChatGPT. For instance, generative AI will limit the usefulness of graded homework dramatically. However, there exist potential opportunities as well. For example, ChatGPT's ability to understand and generate human language allows providing personalized feedback to students, and can thus accompany current software engineering education approaches. This paper highlights the potential for enhancing software engineering education. The availability of generative AI will improve the individualization of education approaches. In addition, we discuss the need to adapt software engineering curricula to the changed profiles of software engineers. Moreover, we point out why it is important to provide guidance for using generative AI and, thus, integrate it in courses rather than accepting the unsupervised use by students, which can negatively impact the students' learning.",10.1145/3587102.3588815,https://doi.org/10.1145/3587102.3588815
Towards Robust Plagiarism Detection in Programming Education: Introducing Tolerant Token Matching Techniques to Counter Novel Obfuscation Methods,"Maisch, Robin and Hagel, Nathan and Bartel, Alexander",Proceedings of the 6th European Conference on Software Engineering Education,2025,"With the rise of AI-generated code, programming courses face new challenges in detecting code plagiarism. Traditional methods struggle against obfuscation techniques that modify code structure through statement insertion and deletion. To address this, we propose a novel approach based on tolerant token matching designed to enhance resilience against such attacks. We evaluate our method through three experiments on a real-life dataset with AI-obfuscated plagiarisms. The results show that our approach increased the median similarity gap between originals and plagiarisms by 1 to 6 percentage points.",10.1145/3723010.3723019,https://doi.org/10.1145/3723010.3723019
When People Come First: A Human-Centered Approach to Computer Science Education,"Zakharov, Ilya and Piatnitckaia, Liudmila and Birillo, Anastasiia and Sergeyuk, Agnia and Izadi, Maliheh",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 2,2025,"The rise of AI tools is reshaping computer science education, shifting the focus from coding skills to teaching students how to effectively use these technologies. Understanding students' mental models and fostering computational and metacognitive skills are now essential, as over-reliance on AI can weaken critical thinking. This panel explores how a human-centered approach can balance these challenges, sharing strategies to optimize learning while addressing the risks of cognitive offloading in an AI-driven world.",10.1145/3724389.3730766,https://doi.org/10.1145/3724389.3730766
Software Engineering Education Must Adapt and Evolve for an LLM Environment,"Kirova, Vassilka D. and Ku, Cyril S. and Laracy, Joseph R. and Marlowe, Thomas J.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"In the era of artificial intelligence (AI), generative AI, and Large Language Models (LLMs) in particular, have become increasingly significant in various sectors. LLMs such as GPT expand their applications, from content creation to advanced code completion. They offer unmatched opportunities but pose unique challenges to the software engineering domain. This paper discusses the necessity and urgency for software engineering education to adapt and evolve to prepare software engineers for the emerging LLM environment. While existing literature and social media have investigated AI's integration into various educational spheres, there is a conspicuous gap in examining the specifics of LLMs' implications for software engineering education. We explore the goals of software engineering education, and changes to software engineering, software engineering education, course pedagogy, and ethics. We argue that a holistic approach is needed, combining technical skills, ethical awareness, and adaptable learning strategies. This paper seeks to contribute to the ongoing conversation about the future of software engineering education, emphasizing the importance of adapting and evolving to remain in sync with rapid advancements in AI and LLMs. It is hoped that this exploration will provide valuable insights for educators, curriculum developers, and policymakers in software engineering.",10.1145/3626252.3630927,https://doi.org/10.1145/3626252.3630927
CourseAssist: Pedagogically Appropriate AI Tutor for Computer Science Education,"Feng, Ty and Liu, Sa and Ghosal, Dipak",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2,2024,"The growing enrollments in computer science courses and increase in class sizes necessitate scalable, automated tutoring solutions to adequately support student learning. While Large Language Models (LLMs) like GPT-4 have demonstrated potential in assisting students through question-answering, educators express concerns over student overreliance, miscomprehension of generated code, and the risk of inaccurate answers. Rather than banning these tools outright, we advocate for a constructive approach that harnesses the capabilities of AI while mitigating potential risks. This poster introduces CourseAssist, a novel LLM-based tutoring system tailored for computer science education. Unlike generic LLM systems, CourseAssist uses retrieval-augmented generation, user intent classification, and question decomposition to align AI responses with specific course materials and learning objectives, thereby ensuring pedagogical appropriateness of LLMs in educational settings. We evaluated CourseAssist against a baseline of GPT-4 using a dataset of 50 question-answer pairs from a programming languages course, focusing on the criteria of usefulness, accuracy, and pedagogical appropriateness. Evaluation results show that CourseAssist significantly outperforms the baseline, demonstrating its potential to serve as an effective learning assistant. We have also deployed CourseAssist in 6 computer science courses at a large public R1 research university reaching over 500 students. Interviews with 20 student users show that CourseAssist improves computer science instruction by increasing the accessibility of course-specific tutoring help and shortening the feedback loop on their programming assignments. Future work will include extensive pilot testing at more universities and exploring better collaborative relationships between students, educators, and AI that improve computer science learning experiences.",10.1145/3649409.3691094,https://doi.org/10.1145/3649409.3691094
Exploring the Potential of GPT-4 in Automated Mentoring for Programming Courses,"Balse, Rishabh and Prasad, Prajish and Warriem, Jayakrishnan Madathil",Proceedings of the ACM Conference on Global Computing Education Vol 2,2023,"This research proposes an AI-assisted mentoring system for programming education, leveraging the advanced capabilities of OpenAI's GPT-4. We aim to validate students' pseudocode or algorithmic approaches to Python programming problems within the context of a Tier-1 institution in India, where the high student-to-mentor ratio presents unique challenges. The proposed system aspires to alleviate the pressures of the current mentoring system, providing a more accessible, responsive, and effective educational support system.",10.1145/3617650.3624946,https://doi.org/10.1145/3617650.3624946
VisOpt - Visualization of Compiler Optimizations for Computer Science Education,"Koitz-Hristov, Roxane and Mandl, Franz and Wotawa, Franz",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Visualizations in teaching have become a common practice as they effectively convey theoretical concepts. Compiler construction, a heavily theory-based subject in computer science education, is particularly challenging for students to understand. While many tools simulate a compiler's front end, or analysis phase, applications that focus on the back end, or synthesis phase, are scarce. This paper describes VisOpt, a web-based visualization tool designed for a master's level Compiler Construction course. VisOptfocuses on the synthesis phase, i.e., code optimization and code generation. Its primary objective is to help students comprehend various local compiler optimizations, which can be visualized on the original code, an intermediate representation, or an assembler-like target code. A quasi-experiment with a pre-test-post-test design revealed that students who used VisOpt reported higher self-efficacy compared to those who did not. Although no significant improvement in learning outcomes was observed overall, we propose VisOpt as an engaging pedagogical tool that effectively complements traditional methods for teaching the synthesis phase of compilers.",10.1145/3641554.3701832,https://doi.org/10.1145/3641554.3701832
Automated Grading and Feedback Tools for Programming Education: A Systematic Review,"Messer, Marcus and Brown, Neil C. C. and K\",ACM Trans. Comput. Educ.,2024,"We conducted a systematic literature review on automated grading and feedback tools for programming education. We analysed 121 research papers from 2017 to 2021 inclusive and categorised them based on skills assessed, approach, language paradigm, degree of automation, and evaluation techniques. Most papers assess the correctness of assignments in object-oriented languages. Typically, these tools use a dynamic technique, primarily unit testing, to provide grades and feedback to the students or static analysis techniques to compare a submission with a reference solution or with a set of correct student submissions. However, these techniques’ feedback is often limited to whether the unit tests have passed or failed, the expected and actual output, or how they differ from the reference solution. Furthermore, few tools assess the maintainability, readability, or documentation of the source code, with most using static analysis techniques, such as code quality metrics, in conjunction with grading correctness. Additionally, we found that most tools offered fully automated assessment to allow for near-instantaneous feedback and multiple resubmissions, which can increase student satisfaction and provide them with more opportunities to succeed. In terms of techniques used to evaluate the tools’ performance, most papers primarily use student surveys or compare the automatic assessment tools to grades or feedback provided by human graders. However, because the evaluation dataset is frequently unavailable, it is more difficult to reproduce results and compare tools to a collection of common assignments.",10.1145/3636515,https://doi.org/10.1145/3636515
Leveraging Large Language Models for Automated Program Repair in Programming Education,"Murali, Pavithra Sripathanallur",XRDS,2025,,10.1145/3703408,https://doi.org/10.1145/3703408
KOGI: A Seamless Integration of ChatGPT into Jupyter Environments for Programming Education,"Kuramitsu, Kimio and Obara, Yui and Sato, Miyu and Obara, Momoka",Proceedings of the 2023 ACM SIGPLAN International Symposium on SPLASH-E,2023,"The impact of ChatGPT has brought both anxiety and anticipation to schools and universities. Exploring a positive method to improve programming skills with ChatGPT is a new and pressing challenge.   In pursuit of this goal, we have developed KOGI, a learning support system that integrates ChatGPT into the Jupyter environment. This paper demonstrates how KOGI enables students to receive timely advice from ChatGPT in response to errors and other questions they encounter.    We immediately introduced KOGI in our two introductory courses: Algorithms and Data Science. The introduction of KOGI resulted in a significant decrease in the number of unresolved student errors. In addition, we report on student trends observed in the classroom regarding the type and frequency of help requested. Although our findings are preliminary, they are informative for programming instructors interested in using ChatGPT.",10.1145/3622780.3623648,https://doi.org/10.1145/3622780.3623648
Rethinking Computer Science Education in the Age of GenAI,"Hazzan, Orit and Erez, Yael",ACM Trans. Comput. Educ.,2025,"In this opinion piece, we explore the idea that GenAI has the potential to fundamentally disrupt computer science education (CSE) by drawing insights from 10 pedagogical and cognitive theories and models. We highlight how GenAI improves CSE by making educational practices more effective and requires less effort and time, and all at a lower cost, properties that have the potential to make GenAI a disruptive technology for CSE.Each of the 10 theories and models examined serves as a lens through which we observe and interpret the impact of GenAI on CSE. The 10 theories and models are grouped into 3 categories: Learning (Constructivism, Cognitive Load, and Motivation), Pedagogy (Bloom’s Taxonomy, Assessment, Personalization/Diversity/Equity, and Didactic Transposition), and Competencies (the KSA Model, Computational Thinking, and Metacognition).",10.1145/3732792,https://doi.org/10.1145/3732792
Developing a Computer Science Curriculum for Two-Year Programs: From Concepts to Implementation,,J. Comput. Sci. Coll.,2025,"Two-year institutions in the United States, commonly known as Community and Technical Colleges, play a vital role in computing education by offering a range of programs that awards credentials and degrees. These programs address regional workforce needs, support socioeconomic development, and provide pathways for students to transition to four-year institutions. The Computer Science Transfer Associate degree, a widely recognized award, requires alignment with four-year programs through Memoranda of Understanding (MOUs) and adherence to established curriculum guidelines, such as those provided by ACM/IEEE-CS. In 2023, the ACM, IEEE-CS, and AAAI released the CS2023 Curricula, a comprehensive framework defining 17 Knowledge Areas for computer science education. The ACM Committee for Computing Education in Community Colleges (CCECC) builds on this foundation through the",,
The Role of Virtual Reality in Enhancing Computer Science Education,"Zabir, Zubair and Tisha, Sirazum Munira",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"This paper examines the application of Virtual Reality (VR) in com- puter science education through a review of 28 academic papers. The study investigates VR's effectiveness in teaching complex topics such as finite state machines, computational thinking, and algo- rithms. The authors highlight VR's advantages, including immersive learning experiences and intuitive visualization of abstract concepts, while also noting challenges such as high costs and limited acces- sibility. The analysis reveals critical research gaps, including the need to evaluate VR's cost-effectiveness, scalability, integration with AI for adaptive learning, and support for diverse learners. To address these gaps, the paper proposes research questions for future investigations. While underscoring VR's potential to revolutionize computer science education, the study emphasizes the need for further research to optimize its implementation and effectiveness.",10.1145/3641555.3705267,https://doi.org/10.1145/3641555.3705267
"Using GPT-4 to Provide Tiered, Formative Code Feedback","Nguyen, Ha and Allan, Vicki",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"Large language models (LLMs) have shown promise in generating sensible code explanation and feedback in programming exercises. In this experience report, we discuss the process of using one of these models (OpenAI's GPT-4) to generate individualized feedback for students' Java code and pseudocode. We instructed GPT-4 to generate feedback for 113 submissions to four programming problems in an Algorithms and Data Structures class. We prompted the model with example feedback (few-shot learning) and instruction to (1) give feedback on conceptual understanding, syntax, and time complexity, and (2) suggest follow-up actions based on students' code or provide guiding questions. Overall, GPT-4 provided accurate feedback and successfully built on students' ideas in most submissions. Human evaluators (computer science instructors and tutors) rated GPT-4's hints as useful in guiding students' next steps. Model performance varied with programming problems but not submission quality. We reflect on where the model performed well and fell short, and discuss the potential of integrating LLM-generated, individualized feedback into computer science instruction.",10.1145/3626252.3630960,https://doi.org/10.1145/3626252.3630960
How Do Programming Students Use Generative AI?,"Rahe, Christian and Maalej, Walid",Proc. ACM Softw. Eng.,2025,"Programming students have a widespread access to powerful Generative AI tools like ChatGPT.     While this can help understand the learning material and assist with exercises, educators are voicing more and more concerns about an overreliance on generated outputs and lack of critical thinking skills.     It is thus important to understand how students actually use generative AI and what impact this could have on their learning behavior.     To this end, we conducted a study including an exploratory experiment with 37 programming students, giving them monitored access to ChatGPT while solving a code authoring exercise.     The task was not directly solvable by ChatGPT and required code comprehension and reasoning.    While only 23 of the students actually opted to use the chatbot, the majority of those eventually prompted it to simply generate a full solution.    We observed two prevalent usage strategies: to seek knowledge about general concepts and to directly generate solutions.    Instead of using the bot to comprehend the code and their own mistakes, students often got trapped in a vicious cycle of submitting wrong generated code and then asking the bot for a fix.    Those who self-reported using generative AI regularly were more likely to prompt the bot to generate a solution.    Our findings indicate that concerns about potential decrease in programmers' agency and productivity with Generative AI are justified.    We discuss how researchers and educators can respond to the potential risk of students uncritically over-relying on Generative AI.    We also discuss potential modifications to our study design for large-scale replications.",10.1145/3715762,https://doi.org/10.1145/3715762
Large Language Models in Computer Science Education: A Systematic Literature Review,"Raihan, Nishat and Siddiq, Mohammed Latif and Santos, Joanna C.S. and Zampieri, Marcos",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Large language models (LLMs) are becoming increasingly better at a wide range of Natural Language Processing tasks (NLP), such as text generation and understanding. Recently, these models have extended their capabilities to coding tasks, bridging the gap between natural languages (NL) and programming languages (PL). Foundational models such as the Generative Pre-trained Transformer (GPT) and LLaMA series have set strong baseline performances in various NL and PL tasks. Additionally, several models have been fine-tuned specifically for code generation, showing significant improvements in code-related applications. Both foundational and fine-tuned models are increasingly used in education, helping students write, debug, and understand code. We present a comprehensive systematic literature review to examine the impact of LLMs in computer science and computer engineering education. We analyze their effectiveness in enhancing the learning experience, supporting personalized education, and aiding educators in curriculum development. We address five research questions to uncover insights into how LLMs contribute to educational outcomes, identify challenges, and suggest directions for future research.",10.1145/3641554.3701863,https://doi.org/10.1145/3641554.3701863
Oral Exams in Computer Science Education Amidst ChatGPT Dependency,"Novak, Ed and Ohmann, Peter and Reckinger, Scott and Reckinger, Shanon",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"Oral exams provide a compelling alternative to traditional evaluation methods, expanding or replacing traditional written work. Interest in oral exams is growing rapidly in computer science (CS) education due to shifts to remote learning and concerns around AI-supported programming. This Birds of a Feather (BoF) session is broadly applicable to many in the CS education community, whether they have previously tried oral exams, have concerns about the use of oral exams in CS education, or are curious to hear more about how oral exams might work. The BoF session will provide a forum to discover and discuss previous approaches to oral exams, dive into common themes of interest in small groups, and collectively identify promising future directions for oral exams in CS courses.",10.1145/3641555.3705102,https://doi.org/10.1145/3641555.3705102
Computing Education in the Era of Generative AI,"Denny, Paul and Prather, James and Becker, Brett A. and Finnie-Ansley, James and Hellas, Arto and Leinonen, Juho and Luxton-Reilly, Andrew and Reeves, Brent N. and Santos, Eddie Antonio and Sarsa, Sami",Commun. ACM,2024,Challenges and opportunities faced by computing educators and students adapting to LLMs capable of generating accurate source code from natural-language problem descriptions.,10.1145/3624720,https://doi.org/10.1145/3624720
AI-Tutoring in Software Engineering Education,"Frankford, Eduard and Sauerwein, Clemens and Bassner, Patrick and Krusche, Stephan and Breu, Ruth",Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training,2024,"With the rapid advancement of artificial intelligence (AI) in various domains, the education sector is set for transformation. The potential of AI-driven tools in enhancing the learning experience, especially in programming, is immense. However, the scientific evaluation of Large Language Models (LLMs) used in Automated Programming Assessment Systems (APASs) as an AI-Tutor remains largely unexplored. Therefore, there is a need to understand how students interact with such AI-Tutors and to analyze their experiences.In this paper, we conducted an exploratory case study by integrating the GPT-3.5-Turbo model as an AI-Tutor within the APAS Artemis. Through a combination of empirical data collection and an exploratory survey, we identified different user types based on their interaction patterns with the AI-Tutor. Additionally, the findings highlight advantages, such as timely feedback and scalability. However, challenges like generic responses and students' concerns about a learning progress inhibition when using the AI-Tutor were also evident. This research adds to the discourse on AI's role in education.",10.1145/3639474.3640061,https://doi.org/10.1145/3639474.3640061
Implications of ChatGPT for Data Science Education,"Shen, Yiyin and Ai, Xinyi and Soosai Raj, Adalbert Gerald and Leo John, Rogers Jeffrey and Syamkumar, Meenakshi",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"ChatGPT is a conversational AI platform that can produce code to solve problems when provided with a natural language prompt. Prior work on similar AI models has shown that they perform well on typical intro-level Computer Science problems. However, little is known about the performance of such tools on Data Science (DS) problems. In this work, we assess the performance of ChatGPT on assignments from three DS courses with varying difficulty levels. First, we apply the raw assignment prompts provided to the students and find that ChatGPT performs well on assignments with dataset(s) descriptions and progressive question prompts, which divide the programming requirements into sub-problems. Then, we perform prompt engineering on the assignments for which ChatGPT had low performance. We find that the following prompt engineering techniques significantly increased ChatGPT's performance: breaking down abstract questions into steps, breaking down steps into multiple prompts, providing descriptions of the dataset(s), including algorithmic details, adding specific instructions to entice specific actions, and removing extraneous information. Finally, we discuss how our findings suggest potential changes to curriculum design of DS courses.",10.1145/3626252.3630874,https://doi.org/10.1145/3626252.3630874
The Role of Generative AI in Software Student CollaborAItion,"Kiesler, Natalie and Smith, Jacqueline and Leinonen, Juho and Fox, Armando and MacNeil, Stephen and Ihantola, Petri",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"Collaboration is a crucial part of computing education. The increase in AI capabilities over the last couple of years is bound to profoundly affect all aspects of systems and software engineering, including collaboration. In this position paper, we consider a scenario where AI agents would be able to take on any role in collaborative processes in computing education. We outline these roles, the activities and group dynamics that software development currently include, and discuss if and in what way AI could facilitate these roles and activities. The goal of our work is to envision and critically examine potential futures. We present scenarios suggesting how AI can be integrated into existing collaborations. These are contrasted by design fictions that help demonstrate the new possibilities and challenges for computing education in the AI era.",10.1145/3724363.3729040,https://doi.org/10.1145/3724363.3729040
ECSEE '25: Proceedings of the 6th European Conference on Software Engineering Education,,,2025,,,
Open Source Language Models Can Provide Feedback: Evaluating LLMs' Ability to Help Students Using GPT-4-As-A-Judge,"Koutcheme, Charles and Dainese, Nicola and Sarsa, Sami and Hellas, Arto and Leinonen, Juho and Denny, Paul",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"Large language models (LLMs) have shown great potential for the automatic generation of feedback in a wide range of computing contexts. However, concerns have been voiced around the privacy and ethical implications of sending student work to proprietary models. This has sparked considerable interest in the use of open source LLMs in education, but the quality of the feedback that such open models can produce remains understudied. This is a concern as providing flawed or misleading generated feedback could be detrimental to student learning. Inspired by recent work that has utilised very powerful LLMs, such as GPT-4, to evaluate the outputs produced by less powerful models, we conduct an automated analysis of the quality of the feedback produced by several open source models using a dataset from an introductory programming course. First, we investigate the viability of employing GPT-4 as an automated evaluator by comparing its evaluations with those of a human expert. We observe that GPT-4 demonstrates a bias toward positively rating feedback while exhibiting moderate agreement with human raters, showcasing its potential as a feedback evaluator. Second, we explore the quality of feedback generated by several leading open-source LLMs by using GPT-4 to evaluate the feedback. We find that some models offer competitive performance with popular proprietary LLMs, such as ChatGPT, indicating opportunities for their responsible use in educational settings.",10.1145/3649217.3653612,https://doi.org/10.1145/3649217.3653612
SIGCSETS 2025: Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,,,2025,"Welcome to the 56th annual SIGCSE Technical Symposium on Computer Science Education (SIGCSE TS 2025)! For the first time since 1978, our symposium is being held in the",,
"Unlocking Potential with Generative AI Instruction: Investigating Mid-level Software Development Student Perceptions, Behavior, and Adoption","Gorson Benario, Jamie and Marroquin, Jenn and Chan, Monica M. and Holmes, Ernest D.V. and Mejia, Daniel",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Generative AI tools are rapidly evolving and impacting many domains, including programming. Computer Science (CS) instructors must address student access to these tools. While some advocate to ban the tools entirely, others suggest embracing them so that students develop the skills for utilizing the tools safely and responsibly. Studies indicate positive impacts, as well as cautions, on student outcomes when these tools are integrated into courses. We studied the impact of incorporating instruction on industry-standard generative AI tools into a mid-level software development course with students from 16 Minority Serving Institutions. 89% of student participants used generative AI tools prior to the course without any formal instruction. After formal instruction, students most frequently used generative AI tools for explaining concepts and learning new things. Students generally reported positive viewpoints on their ability to learn to program and learn problem-solving skills while using generative AI tools. Finally, we found that students: reported to understand their code when they work with generative AI tools, are critical about the outputs that generative AI tools provide, and check outputs of generative AI tools to ensure accuracy.",10.1145/3641554.3701859,https://doi.org/10.1145/3641554.3701859
Experiences from Integrating Large Language Model Chatbots into the Classroom,"Hellas, Arto and Leinonen, Juho and Lepp\",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1,2024,"We provided students access to a state-of-the-art large language model (LLM) chatbot through the online materials of three university-level courses. One of the courses focused on software engineering with LLMs, while the two other courses were not directly related to LLMs. The chatbot used OpenAI GPT-4 without additional filters or system prompts.  Our results suggest that only a minority of students engage with the chatbot in the courses that do not relate to LLMs. At the same time, unsurprisingly, nearly all students in the LLM-focused course leveraged the chatbot. In all courses, the majority of the chatbot usage came from a few superusers, whereas the majority of the students did not heavily use the chatbot even though it effectively provided free access to OpenAI's GPT-4 model (which would have otherwise required a paid subscription at the time of the study). We observe that in addition to students using the chatbot for course-specific purposes, many use the chatbot for their own purposes.  Overall, our results suggest that the worst fears of educators -- all students overrelying on chatbots -- did not materialize. Finally, we discuss potential reasons for low usage, including the need for more tailored and scaffolded chatbot experiences targeted for specific types of use cases.",10.1145/3649165.3690101,https://doi.org/10.1145/3649165.3690101
Evaluating ChatGPT to Answer Multi-Modal Exercises in Computer Science Education,"Ouh, Eng Lieh and Tan, Kar Way and Lo, Siaw Ling and Gan, Benjamin Kok Siew",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"This study investigates ChatGPT-4o's ability to answer multi-modal assessment exercises in computer science (CS) courses. While the use of large language models (LLMs) to answer text-based exercises are extensively researched, their ability to answer exercises involving artifacts of other modalities remains underexplored. To close this gap, we evaluate ChatGPT-4o's answers to 120 multi-modal CS exercises in programming, software design, human-computer interaction, statistical analysis, process analysis, and simulation. The multi-modal artifacts in these exercises include class diagrams, sequence diagrams, user interface images, analytical charts, workflow diagrams and object-flow diagrams. Our comparisons to the expected answers of these exercises show that ChatGPT-4o performs well for exercises with class and sequence diagrams possibly due to the availability of more data for training. The potential for misuse by students highlights these exercises are better suited for closed-book exams or as scaffolding activities. ChatGPT-4o answers better for those multi-modal exercises designed to assess students at the lower levels of Bloom's taxonomy than the higher levels. This discrepancy is possibly due to ChatGPT-4o's lack of understanding underlying design concepts and limited ability to generate new multi-modal artifacts, making exercises requiring higher order of cognitive thinking suitable for take-home assignment. We hope the insights from this study provide a foundation to develop effective multi-modal assessments.",10.1145/3724363.3729056,https://doi.org/10.1145/3724363.3729056
"Investigating AI in Programming Education: Self-Reported AI Usage, Individual Traits, and Learning Outcomes","Kamberovic, Mubina and Delic, Amra and Krivic, Senka","Adjunct Proceedings of the 33rd ACM Conference on User Modeling, Adaptation and Personalization",2025,"Understanding how students perceive and utilize Large Language Models (LLMs) and how these interactions relate to their learning behavior and individual differences is crucial for optimizing educational process and outcomes. This paper introduces a novel dataset comprising weekly self-reported data from students in an introductory programming course, i.e., students’ AI tool usage, perceived difficulty of weekly subject areas, personality traits, preferred learning styles, and general attitudes toward AI. We present a descriptive overview of the collected data and conduct a correlation analysis to gain first insights into the students’ individual differences and their learning outcomes, frequency of AI tools usage, as well as their attitudes toward AI. The findings reveal that while individual student characteristics did not show significant correlations with final performance or frequency of AI tool usage, the combination of students’ expectations for success and their perceived value of the task (constructs of expectancy theory) were significantly associated with both course outcomes and how often they used the AI tool. Additionally, motivational factors may be the key to fostering positive attitudes toward AI, while personality traits, particularly those related to negative emotionality, may play a more significant role in shaping resistance. This initial analysis lays the groundwork for future investigations on the prospects of AI in support of the students’ learning process.",10.1145/3708319.3733692,https://doi.org/10.1145/3708319.3733692
Automating Human Tutor-Style Programming Feedback: Leveraging GPT-4 Tutor Model for Hint Generation and GPT-3.5 Student Model for Hint Validation,,Proceedings of the 14th Learning Analytics and Knowledge Conference,2024,"Generative AI and large language models hold great promise in enhancing programming education by automatically generating individualized feedback for students. We investigate the role of generative AI models in providing human tutor-style programming hints to help students resolve errors in their buggy programs. Recent works have benchmarked state-of-the-art models for various feedback generation scenarios; however, their overall quality is still inferior to human tutors and not yet ready for real-world deployment. In this paper, we seek to push the limits of generative AI models toward providing high-quality programming hints and develop a novel technique, GPT4HINTS-GPT3.5VAL. As a first step, our technique leverages GPT-4 as a “tutor” model to generate hints – it boosts the generative quality by using symbolic information of failing test cases and fixes in prompts. As a next step, our technique leverages GPT-3.5, a weaker model, as a “student” model to further validate the hint quality – it performs an automatic quality validation by simulating the potential utility of providing this feedback. We show the efficacy of our technique via extensive evaluation using three real-world datasets of Python programs covering a variety of concepts ranging from basic algorithms to regular expressions and data analysis using pandas library.",10.1145/3636555.3636846,https://doi.org/10.1145/3636555.3636846
Generative AI Literacy: Twelve Defining Competencies,"Annapureddy, Ravinithesh and Fornaroli, Alessandro and Gatica-Perez, Daniel",Digit. Gov.: Res. Pract.,2025,"This article introduces a competency-based model for generative artificial intelligence (AI) literacy covering essential skills and knowledge areas necessary to interact with generative AI. The competencies range from foundational AI literacy to prompt engineering and programming skills, including ethical and legal considerations. These 12 competencies offer a framework for individuals, policymakers, government officials, and educators looking to navigate and take advantage of the potential of generative AI responsibly. Embedding these competencies into educational programs and professional training initiatives can equip individuals to become responsible and informed users and creators of generative AI. The competencies follow a logical progression and serve as a roadmap for individuals seeking to become familiar with generative AI and for researchers and policymakers to develop assessments, educational programs, guidelines, and regulations.",10.1145/3685680,https://doi.org/10.1145/3685680
From Automation to Cognition: Redefining the Roles of Educators and Generative AI in Computing Education,"Feng, Tony Haoran and Luxton-Reilly, Andrew and W\",Proceedings of the 27th Australasian Computing Education Conference,2025,"Generative Artificial Intelligence (GenAI) offers numerous opportunities to revolutionise teaching and learning in Computing Education (CE). However, educators have expressed concerns that students may over-rely on GenAI and use these tools to generate solutions without engaging in the learning process. While substantial research has explored GenAI use in CE, and many Computer Science (CS) educators have expressed their opinions and suggestions on the subject, there remains little consensus on implementing curricula and assessment changes.In this paper, we describe our experiences with using GenAI in CS-focused educational settings and the changes we have implemented accordingly in our teaching in recent years since the popularisation of GenAI. From our experiences, we propose two primary actions for the CE community: 1) redesign take-home assignments to incorporate GenAI use and assess students on their process of using GenAI to solve a task rather than simply on the final product; 2) redefine the role of educators to emphasise metacognitive aspects of learning, such as critical thinking and self-evaluation. This paper presents and discusses these stances and outlines several practical methods to implement these strategies in CS classrooms. Then, we advocate for more research addressing the concrete impacts of GenAI on CE, especially those evaluating the validity and effectiveness of new teaching practices.",10.1145/3716640.3716658,https://doi.org/10.1145/3716640.3716658
"Investigating the Capabilities of Generative AI in Solving Data Structures, Algorithms, and Computability Problems","Li, Nero and Broner, Shahar and Kim, Yubin and Mizuo, Katrina and Sauder, Elijah and To, Claire and Wang, Albert and Gila, Ofek and Shindler, Michael",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"There is both great hope and concern about the future of Computer Science practice and education concerning the recent advent of large language models (LLMs).We present the first study to extensively evaluate the ability of such a model to solve problems in Computer Science Theory. Specifically, we tested 165 exam-level problems across 16 specific topics related to computer science theory, ranging from preliminary data structures to algorithm design paradigms to theory of computation (automata and complexity). Our results use the recent popular models (GPT-4 and GPT-4o). This is a rapidly evolving field, with model performance continuously improving. We present our results primarily as an indication of what they can already achieve-equivalently how they can already be useful-today, fully expecting them to improve even further in the near future. Our results show that what was very recently a state-of-the-art model (GPT-4) can solve 77% of free-response problems in data structures and algorithms with little to no guidance. The latest model, GPT-4o, can solve around 46% of the Theory of Computation problems we posed, with predictable categories for which problems it could not solve. When broken down by topic, the model can solve 80% of problems in 4 out of the 15 topics and at least half in 8 other topics. Other problems, namely more visual problems, either require more substantial coaching or seem to still be beyond the capabilities of the language model--for now. By understanding the strengths and limitations of these models for solving theory problems, we can open the door to future work, ranging from human educational assessment on the topic to automated tutors for learners of the subject.",10.1145/3641554.3701946,https://doi.org/10.1145/3641554.3701946
SIGCSETS 2025: Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,,,2025,"Welcome to the 56th annual SIGCSE Technical Symposium on Computer Science Education (SIGCSE TS 2025)! For the first time since 1978, our symposium is being held in the",,
Quantitative Evaluation of Using Large Language Models and Retrieval-Augmented Generation in Computer Science Education,"Wang, Kevin Shukang and Lawrence, Ramon",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Generative artificial intelligence (GenAI) is transforming Computer Science education, and every instructor is reflecting on how AI will impact their courses. Instructors must determine how students may use AI for course activities and what AI systems they will support and encourage students to use. This task is challenging with the proliferation of large language models (LLMs) and related AI systems. The contribution of this work is an experimental evaluation of the performance of multiple open-source and commercial LLMs utilizing retrieval-augmented generation in answering questions for computer science courses and a cost-benefit analysis for instructors when determining what systems to use. A key factor is the time an instructor has to maintain their supported AI systems and the most effective activities for improving their performance. The paper offers recommendations for deploying, using, and enhancing AI in educational settings.",10.1145/3641554.3701917,https://doi.org/10.1145/3641554.3701917
"Ecosystems That Build Equitable, K-5 Sustainable Computer Science Education","Levitt, Diane and Ray, Meg",Proceedings of the 2024 on RESPECT Annual Conference,2024,"The rollout of computer science education has been dependent on a patchwork of uncoordinated professional learning experiences. This has left some schools serving students from underrepresented groups without an articulated, rigorous, joyful K-12 CS education. Based on our work with four urban schools serving such students, we propose that an ecosystem of support that prepares every administrator and teacher to include CS in every student's education with a whole school approach and sustained professional learning, is one way to assure an equitable, sustainable CS education. We propose changes in policy to scaffold such an ecosystem.",10.1145/3653666.3656092,https://doi.org/10.1145/3653666.3656092
ITiCSE 2024: 2024 Working Group Reports on Innovation and Technology in Computer Science Education,,,2025,,,
Bridging Academia and Industry: Leveraging Generative AI in a Software Engineering Course for Practical Industry Experiences,"Mejia, Daniel and Holmes, Ernest D.V. and Marroquin, Jenn and Gorson Benario, Jamie",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"The rapid adoption of generative AI across the tech industry demands a corresponding evolution in educational practices. By proactively incorporating generative AI, educational institutions can ensure their programs remain relevant and continue to provide students with the skills necessary for career success. This work presents an intro Software Engineering course, Software Development Studio (SDS), designed and implemented by Google in collaboration with faculty, to ensure students acquire industry-relevant skills. The course focuses on integrating generative AI tools into software engineering practices, mirroring the evolving methodologies used by professionals in the field. The curriculum emphasizes practical, real-world projects, providing early undergraduate computer science students hands-on experience using generative AI tools. Data collected during the Spring 2024 semester from students and faculty reveals a positive experience and enhancement of software engineering learning through the integration of generative AI.",10.1145/3724363.3729036,https://doi.org/10.1145/3724363.3729036
Iris: An AI-Driven Virtual Tutor for Computer Science Education,"Bassner, Patrick and Frankford, Eduard and Krusche, Stephan",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"Integrating AI-driven tools in higher education is an emerging area with transformative potential. This paper introduces Iris, a chat-based virtual tutor integrated into the interactive learning platform Artemis that offers personalized, context-aware assistance in large-scale educational settings. Iris supports computer science students by guiding them through programming exercises and is designed to act as a tutor in a didactically meaningful way. Its calibrated assistance avoids revealing complete solutions, offering subtle hints or counter-questions to foster independent problem-solving skills. For each question, it issues multiple prompts in a Chain-of-Thought to GPT-3.5-Turbo. The prompts include a tutor role description and examples of meaningful answers through few-shot learning. Iris employs contextual awareness by accessing the problem statement, student code, and automated feedback to provide tailored advice. An empirical evaluation shows that students perceive Iris as effective because it understands their questions, provides relevant support, and contributes to the learning process. While students consider Iris a valuable tool for programming exercises and homework, they also feel confident solving programming tasks in computer-based exams without Iris. The findings underscore students' appreciation for Iris' immediate and personalized support, though students predominantly view it as a complement to, rather than a replacement for, human tutors. Nevertheless, Iris creates a space for students to ask questions without being judged by others.",10.1145/3649217.3653543,https://doi.org/10.1145/3649217.3653543
Novice Learners of Programming and Generative AI - Prior Knowledge Matters,"Kiesler, Natalie and Scholz, Ingo and Albrecht, Jens and Stappert, Friedhelm and Wienkop, Uwe",Proceedings of the 24th Koli Calling International Conference on Computing Education Research,2024,"With the broad availability of Generative AI (GenAI), introductory programming education is starting to change. At Nuremberg Tech, we observed the doubling of failure rates to approximately 50% in the first semester course “Procedural Programming” across students of all study programs. Due to these exam results in winter 2023/24, we conducted a pilot study to gather students’ use of GenAI tools, their exam results, and prior programming education and experience. The results imply significant differences of students’ use of GenAI tools depending on their prior programming education. We will therefore extend the investigation in winter term 2024/25.",10.1145/3699538.3699580,https://doi.org/10.1145/3699538.3699580
Understanding the Role of Temperature in Diverse Question Generation by GPT-4,"Agarwal, Arav and Mittal, Karthik and Doyle, Aidan and Sridhar, Pragnya and Wan, Zipiao and Doughty, Jacob Arthur and Savelka, Jaromir and Sakr, Majd",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"We conduct a preliminary study of the effect of GPT's temperature parameter on the diversity of GPT4-generated questions. We find that using higher temperature values leads to significantly higher diversity, with different temperatures exposing different types of similarity between generated sets of questions. We also demonstrate that diverse question generation is especially difficult for questions targeting lower levels of Bloom's Taxonomy.",10.1145/3626253.3635608,https://doi.org/10.1145/3626253.3635608
ITiCSE 2025: Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 2,,,2025,"Welcome to the 30th annual conference on Innovation and Technology in Computer Science Education (ITiCSE 2025), hosted by Radboud University in Nijmegen, The Netherlands.ITiCSE 2025 will take place from Friday, 27 June to Wednesday, 2 July. The conference program includes plenary lectures, paper sessions, panels, tips, techniques &amp; courseware demonstrations, posters, a doctoral consortium, and working group presentations. Working groups meet from 27 to 29 June and will submit draft reports before the conference begins on 30 June.The program includes two keynote talks by scholars from neighbouring disciplines, to help the community explore new challenges and reflect on scientific progress in the field. Our opening speaker, Inge Molenaar, will present her views about 'Human-AI Collaboration in Education: The Hybrid Future'. At the end of the conference, Danny Beckers will address the conference in a plenary session with a talk entitled 'On the Connection between Blind Dates and Teaching Programming'.Reviewing of submissions for ITiCSE 2025 involved 323 researchers and practitioners from computing education and related fields, including 38 programme committee members. Thanks to their outstanding effort and commitment, every submission received a metareview and most received at least three reviews, providing authors of all submissions with constructive feedback. Although no review process is flawless, we are confident that this effort led to a vibrant conference program, capturing multiple voices and perspectives in the field.We received 354 full paper submissions for the conference. The programme committee worked very hard to select 99 papers to be presented at ITiCSE 2025 and published in the proceedings. The proceedings also include the opening keynote abstract, 23 tips, techniques, &amp; courseware submissions, and abstracts for 9 working groups, 3 panels, 45 posters, and 16 doctoral consortium participants.",,
Ethical Implications of Gen-AI and LLMs in Computing Education,"Zarb, Mark and Brown, John N.A. and Goodfellow, Martin and Liaskos, Konstantinos and Young, Tiffany",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2,2024,"The panel convenes five educators to discuss the ethical implications of utilising Generative AI (Gen-AI) and Large Language Models (LLMs) in computing education. Their expertise spans various domains, including organising national workshops on the implications of generative AI tools, conducting surveys on their use within curricula, implementing institutional policies related to technology use, and engaging with students directly in the classroom. They reflect on the evolution of Gen-AI and LLMs from challenging-to-use technologies to indispensable tools for users of all levels. Furthermore, they examine the ethical dilemmas arising from the widespread adoption of these technologies in educational contexts, particularly regarding issues of originality, integrity, and responsible use. In addition, they explore practical strategies for integrating ethics education into computing curriculum design and classroom practices. This includes discussions on the role of educators in guiding students towards ethical technology usage, addressing uncertainties surrounding Gen-AI tools, and fostering a culture of responsible innovation within educational institutions. Through their collective insights and experiences, the panel aims to provide recommendations for navigating the ethical complexities inherent in the integration of Gen-AI technologies into computing education curricula.",10.1145/3649409.3691074,https://doi.org/10.1145/3649409.3691074
'All Roads Lead to ChatGPT': How Generative AI is Eroding Social Interactions and Student Learning Communities,"Hou, Irene and Man, Owen and Hamilton, Kate and Muthusekaran, Srishty and Johnykutty, Jeffin and Zadeh, Leili and MacNeil, Stephen",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"The widespread adoption of generative AI is already impacting learning and help-seeking. While the benefits of generative AI are well-understood, recent studies have also raised concerns about increased potential for cheating and negative impacts on students' metacognition and critical thinking. However, the potential impacts on social interactions, peer learning, and classroom dynamics are not yet well understood. To investigate these aspects, we conducted 17 semi-structured interviews with undergraduate computing students across seven R1 universities in North America. Our findings suggest that help-seeking requests are now often mediated by generative AI. For example, students often redirected questions from their peers to generative AI instead of providing assistance themselves, undermining peer interaction. Students also reported feeling increasingly isolated and demotivated as the social support systems they rely on begin to break down. These findings are concerning given the important role that social interactions play in students' learning and sense of belonging.",10.1145/3724363.3729024,https://doi.org/10.1145/3724363.3729024
Leveraging Conceptual Change regarding Artificial Intelligence in Computer Science Education,"Kreinsen, Moritz and Rabe, Anna and Grospietsch, Finja and Schulz, Sandra",Proceedings of the 24th Koli Calling International Conference on Computing Education Research,2024,"Various research studies have been conducted on the topic of students’ conceptions of artificial intelligence (AI), but there is insufficient research into how these conceptions can be changed. In computer science education, there is a need to empirically research solutions or activities for conceptions that have already been discovered in order to make them usable in terms of educational reconstruction and integrate them into instruction. However, this is hardly ever done yet. Our work addresses this issue and can be transferred as a prototype study to other areas of conceptions research in computer science education. To this end, a teaching intervention was conducted with 10th and 11th grade secondary school students in Germany in order to measure the change in their agreement to specific conceptions with the help of pre- and post-tests. This study was conducted with N = 76&nbsp;students who were divided into an experimental and control group. The results of the study show that conceptual change texts are a promising teaching method for expanding students’ conceptions of AI. This is indicated by the results of the post-test, in which students who worked with the conceptual change text were able to demonstrate greater agreement to the conception presented. However, the results of the study needs to be critically discussed in terms of validity and future perspectives.",10.1145/3699538.3699542,https://doi.org/10.1145/3699538.3699542
SPHERE: Supporting Personalized Feedback at Scale in Programming Classrooms with Structured Review of Generative AI Outputs,"Tang, Xiaohang and Wong, Sam and Huynh, Marcus and He, Zicheng and Yang, Yalong and Chen, Yan",Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems,2025,"This paper introduces SPHERE, a system that enables instructors to effectively create and review personalized feedback for in-class coding activities. Comprehensive personalized feedback is crucial for programming learning. However, providing such feedback in large programming classrooms poses significant challenges for instructors. While Large Language Models (LLMs) offer potential assistance, how to efficiently ensure the quality of LLM-generated feedback remains an open question. SPHERE guides instructors’ attention to critical students’ issues, empowers them with guided control over LLM-generated feedback, and provides visual scaffolding to facilitate verification of feedback quality. Our between-subject study with 20 participants demonstrates SPHERE’s effectiveness in creating more high-quality feedback while not increasing the time spent on the overall review process compared to a baseline system. This work contributes a synergistic approach to scaling personalized feedback in programming education, addressing the challenges of real-time response, issue prioritization, and large-scale personalization.",10.1145/3706599.3720203,https://doi.org/10.1145/3706599.3720203
Building AI-Powered Responsible Workforce by Integrating Large Language Models into Computer Science Curriculum,"Hare, Brian K. and Gladbach, Joan and Shah, S. Jawad and Xu, Dianxiang",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"Software development is undergoing a revolutionary transformation, fueled by remarkable advancements in Large Language Models (LLMs). This wave of innovation is reshaping the entire landscape and holds the promise of streamlining the development process, leading to increased productivity and efficiency. By providing text prompts, developers can now receive entirely generated code outputs, representing a fundamental shift in how software is built. This paradigm change can accelerate development cycles and unlock new levels of creativity and ingenuity, resulting in the realization of novel applications and business outcomes. However, this paradigm shift also brings new challenges and necessitates acquiring additional skills for software developers to fully harness the capabilities of LLM-powered tools. These skills include prompt engineering for software development, structural complexity management, debugging of AI errors, and compliance with ethical guidelines and principles.The special session will introduce our NSF-sponsored 3-year project, which aims to integrate LLMs into the standard CS curriculum. To the best of our knowledge, this project is among the first department-level initiatives to renovate CS curriculum, rather than individual courses, with the new developments of LLMs. Our project focuses on (a) enhancing students' problem-solving and programming skills by leveraging LLMs as a learning tool in core programming courses, (b) improving students' software development skills by integrating LLM-powered tools into the software engineering course sequence, and (c) educating students on ethical and responsible AI practices. The special session will discuss the objectives and methods of our project, as well as the current results and lessons learned.This NSF-supported project aims to integrate LLMs into the standard CS curriculum. The revolutionized computer science education will cultivate a new generation of AI-powered responsible developers. The objectives are to enhance student programming, software development, and problem-solving skills; educate students on ethical and responsible AI practices; and develop faculty development materials and workshops. Our presentation will discuss the objectives and methods of our project, currently in year 1 of a 3-year timeline.",10.1145/3641555.3704749,https://doi.org/10.1145/3641555.3704749
Optimizing Prompt Engineering for Automated Text Summarization of Student Reflections: A Comparative Study Using GPT-4 LLM,"Wiktor, Nicole",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"In the educational domain, extracting insights from student-written text has shown to be valuable for instructors. Efficiently summarizing students' reflections in a course offers instructors valuable insights to enhance students' learning experience. Therefore, quickly understanding students' impressions about the course could be very helpful to instructors for in-time and/or personalized one-on-one discussions. Achieving this often involves using natural language processing (NLP) techniques Understanding capabilities of LLMs through a series of comparative experiments involving prompt engineering is the goal of this work. We compare the summarization outputs of GPT-4 with an experimentally optimized temperature of 0.75 through a variety of experiments that include different levels of prompts, starting with base level and proceeding to increase context in the prompt. We evaluate and compare the outputs of these summaries based on a rubric from literature, evaluated by human annotators. Our findings suggest that providing more detailed context prompts help LLMs uncover less frequent and obvious student challenges and provide more detailed explanations. One notable finding showed how sensitive the LLM approach is to the distribution of the challenge types in students' reflections. In other words, all prompts regardless of their contextual details faced issues due to this misrepresenting of student challenges distributions, sometimes overstating their occurrence frequency. Therefore, further study is required to refine the data distribution impact. Despite this, the approach shows much potential to extract useful knowledge quickly. It offers valuable insights to instructors and could help in supporting students more effectively.",10.1145/3641555.3705044,https://doi.org/10.1145/3641555.3705044
"Beyond the Hype: A Comprehensive Review of Current Trends in Generative AI Research, Teaching Practices, and Tools","Prather, James and Leinonen, Juho and Kiesler, Natalie and Gorson Benario, Jamie and Lau, Sam and MacNeil, Stephen and Norouzi, Narges and Opel, Simone and Pettit, Vee and Porter, Leo and Reeves, Brent N. and Savelka, Jaromir and Smith, David H. and Strickroth, Sven and Zingaro, Daniel",2024 Working Group Reports on Innovation and Technology in Computer Science Education,2025,"Generative AI (GenAI) is advancing rapidly, and the literature in computing education is expanding almost as quickly. Initial responses to GenAI tools were mixed between panic and utopian optimism. Many were fast to point out the opportunities and challenges of GenAI. Researchers reported that these new tools are capable of solving most introductory programming tasks and are causing disruptions throughout the curriculum. These tools can write and explain code, enhance error messages, create resources for instructors, and even provide feedback and help for students like a traditional teaching assistant. In 2024, new research started to emerge on the effects of GenAI usage in the computing classroom. These new data involve the use of GenAI to support classroom instruction at scale and to teach students how to code with GenAI. In support of the former, a new class of tools is emerging that can provide personalized feedback to students on their programming assignments or teach both programming and prompting skills at the same time. With the literature expanding so rapidly, this report aims to summarize and explain what is happening on the ground in computing classrooms. We provide a systematic literature review; a survey of educators and industry professionals; and interviews with educators using GenAI in their courses, educators studying GenAI, and researchers who create GenAI tools to support computing education. The triangulation of these methods and data sources expands the understanding of GenAI usage and perceptions at this critical moment for our community.",10.1145/3689187.3709614,https://doi.org/10.1145/3689187.3709614
Active Repos: Integrating Generative AI Workflows into GitHub,"Glassey, Richard and Baltatzis, Alexander",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2,2024,"The aim of this work is to describe a simple and cost effective way to integrate generative AI into GitHub to support course specific scenarios. We are motivated by helping teachers realise their creative AI use cases in spite of technical barriers and also to ensure that students have a blessed and fair way to access AI services without needing to sign-up, prompt or pay. First we will describe a scenario that we have implemented for our own CS1 course, then we will describe the technical requirements for implementation. We finish off with our early thoughts on where these types of scenarios might be heading in terms of supporting computing education.",10.1145/3649405.3659517,https://doi.org/10.1145/3649405.3659517
Experience Report: Adopting AI-Usage Policy in Software Engineering Education,"Rajabi, Parsa",Proceedings of the 26th Western Canadian Conference on Computing Education,2024,"This report examines the introduction of an AI-usage policy within a Software Engineering course, aiming to overcome the challenges of incorporating generative AI (genAI) tools in academic settings. As the debate around the impact of technologies like ChatGPT in education continues, this policy represents a proactive stance, addressing both the opportunities and risks associated with AI tool usage. With N=86 students, this course implemented a policy that promotes responsible AI use through guidelines and an",10.1145/3660650.3660668,https://doi.org/10.1145/3660650.3660668
Experiences with Remote Examination Formats in Light of GPT-4,"Dobslaw, Felix and Bergh, Peter",Proceedings of the 5th European Conference on Software Engineering Education,2023,"Sudden access to the rapidly improving large language model GPT by OpenAI forces educational institutions worldwide to revisit their exam procedures. In the pre-GPT era, we successfully applied oral and open-book home exams for two courses in the third year of our predominantly remote Software Engineering BSc program. We ask in this paper whether our current open-book exams are still viable or whether a move back to a legally compliant but less scalable oral exam is the only workable alternative. We further compare work-effort estimates between oral and open-book exams and report on differences in throughput and grade distribution over eight years to better understand the impact of examination format on the outcome. Examining GPT-4 on the most recent open-book exams showed that our current Artificial Intelligence and Reactive Programming exams are not GPT v4 proof. Three potential weaknesses of GPT are outlined. We also found that grade distributions have largely been unaffected by the examination format, opening up for a move to oral examinations only if needed. Throughput was higher for open-book exam course instances (73% vs 64%), while fail rates were too (12% vs 7%), with teacher workload increasing even for smaller classes. We also report on our experience regarding effort. Oral examinations are efficient for smaller groups but come with caveats regarding intensity and stress.",10.1145/3593663.3593695,https://doi.org/10.1145/3593663.3593695
Traversing New Horizons: An Exploration of Educational Policies on Generative AI,"Hooper, Kerrie and Lunn, Stephanie Jill",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"Understanding how tertiary academic institutions approach the integration of generative AI (GAI) into their course policies is crucial since AI technologies are rapidly transforming society. AI is being used and applied across sectors and industries, and it is important to do so with regard to ethics. This exploratory study sought to examine how GAI policies were discussed across academic institutions. The policies were analyzed using NLP techniques and utilized existing publicly available datasets, which consisted of a collection of over 100 university policies and syllabi policies. Unsupervised clustering techniques were applied to analyze patterns in how different institutions may express their policies and best practices. These findings illuminate how universities and colleges may approach topics and challenges around AI, and specifically GAI.",10.1145/3641555.3705272,https://doi.org/10.1145/3641555.3705272
ITiCSE 2025: Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,,,2025,"Welcome to the 30th annual conference on Innovation and Technology in Computer Science Education (ITiCSE 2025), hosted by Radboud University in Nijmegen, The Netherlands.ITiCSE 2025 will take place from Friday, 27 June to Wednesday, 2 July. The conference program includes plenary lectures, paper sessions, panels, tips, techniques &amp; courseware demonstrations, posters, a doctoral consortium, and working group presentations. Working groups meet from 27 to 29 June and will submit draft reports before the conference begins on 30 June.The program includes two keynote talks by scholars from neighbouring disciplines, to help the community explore new challenges and reflect on scientific progress in the field. Our opening speaker, Inge Molenaar, will present her views about 'Human-AI Collaboration in Education: The Hybrid Future'. At the end of the conference, Danny Beckers will address the conference in a plenary session with a talk entitled 'On the Connection between Blind Dates and Teaching Programming'.Reviewing of submissions for ITiCSE 2025 involved 323 researchers and practitioners from computing education and related fields, including 38 programme committee members. Thanks to their outstanding effort and commitment, every submission received a metareview and most received at least three reviews, providing authors of all submissions with constructive feedback. Although no review process is flawless, we are confident that this effort led to a vibrant conference program, capturing multiple voices and perspectives in the field.We received 354 full paper submissions for the conference. The programme committee worked very hard to select 99 papers to be presented at ITiCSE 2025 and published in the proceedings. The proceedings also include the opening keynote abstract, 23 tips, techniques, &amp; courseware submissions, and abstracts for 9 working groups, 3 panels, 45 posters, and 16 doctoral consortium participants.",,
Prompt Programming: A Platform for Dialogue-based Computational Problem Solving with Generative AI Models,,Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"Computing students increasingly rely on generative AI tools for programming assistance, often without formal instruction or guidance. This highlights a need to teach students how to effectively interact with AI models, particularly through natural language prompts, to generate and critically evaluate code for solving computational tasks. To address this, we developed a novel platform for prompt programming that enables authentic dialogue-based interactions, supports problems involving multiple interdependent functions, and offers on-request execution of generated code. Data analysis from over 900 students in an introductory programming course revealed high engagement, with the majority of prompts occurring within multi-turn dialogues. Problems with multiple interdependent functions encouraged iterative refinement, with progression graphs highlighting several common strategies. Students were highly selective about the code they chose to test, suggesting that on-request execution of generated code promoted critical thinking. Given the growing importance of learning dialogue-based programming with AI, we provide this tool as a publicly accessible resource, accompanied by a corpus of programming problems for educational use.",10.1145/3724363.3729094,https://doi.org/10.1145/3724363.3729094
Guidelines for the Evolving Role of Generative AI in Introductory Programming Based on Emerging Practice,"Mahon, Joyce and Mac Namee, Brian and Becker, Brett A.",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"In the rapidly evolving Generative AI (GenAI) landscape, source code and natural language are being mixed and used in new ways. This presents opportunities for rethinking teaching practice in Introductory Programming (CS1) courses that includes, but goes beyond, assessment. In this paper we examine the reasons why and how instructors who are early adopters of GenAI are using it in their teaching, and why others are not. We also explore the changes and adaptations that are currently being made to practice. This is achieved by synthesizing insights from several recent studies that have collected primary data from introductory programming instructors who are teaching with, considering teaching with, or actively not teaching with GenAI.Due to the fast pace of GenAI development and adoption, the fixed-pace and cyclical nature of education, and the relatively slow pace of research (including ethical approvals) and publication cycles, research with primary data from instructors is only being published relatively recently. In computing education, there is not yet enough published research with primary data from CS1 instructors to warrant a systematic literature review, although in the next year this will likely be possible. Based on an analysis of the nascent research that has been published, we propose emerging and flexible guidelines on how CS1 instructors could adapt their practice based on what others have done so far. These guidelines highlight important factors to consider when integrating GenAI in CS1 courses, which for many is only beginning.",10.1145/3649217.3653602,https://doi.org/10.1145/3649217.3653602
Leveraging Generative AI for Personalized Learning Experiences,"Dzhumaliev, Mirbek and Musaev, Aibek and Pu, Calton",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"This demo presents KimBilet.com, an educational platform that utilizes generative AI to create personalized educational content on demand. Catering to high-school and college students, instructors, job seekers, and lifelong learners, the system generates customized courses based on user prompts, covering any topic of interest. Each course may include a sequence of AI-created lessons and quizzes, providing detailed feedback for every quiz option to enhance understanding. The platform supports intuitive navigation through keyboard shortcuts and allows users to jump between course items seamlessly. It also maintains a history of completed quizzes to help users track their learning progress. Future enhancements include topic suggestions based on past interests, support for coding exercises, and multilingual support. This demo will showcase how KimBilet.com leverages AI to offer adaptive learning experiences, engage attendees through interactive exploration, and discuss its potential applications in educational settings. Participants will gain insights into integrating AI-driven tools into teaching and learning processes to address diverse educational needs.",10.1145/3641555.3705038,https://doi.org/10.1145/3641555.3705038
Approachable Machine Learning Education: A Spiral Pedagogy Approach with Experiential Learning,"Qin, Meiying",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Machine learning (ML) is an important subject for computer science students to learn due to its broad applications. Introductory courses often present techniques in a linear sequence, resulting in a steep learning curve that can overwhelm students and limit the time for experiential learning through course projects. To address this, I restructured the course using a spiral approach, presenting concepts in three iterations. Each iteration delves deeper into the material and introduces complex computational topics progressively. This method includes a built-in repetition mechanism that reinforces learning and enhances understanding. Moreover, this approach allows time for hands-on projects that apply theory to real-world scenarios, helping students better understand the course materials. The spiral approach was implemented in an ML course at a local university, resulting in positive student feedback and improved course retention rates.",10.1145/3641554.3701783,https://doi.org/10.1145/3641554.3701783
Can AI Coding Assistants Enhance Secure Programming Education? A Comparative Analysis of AI-Based Programming Assistants for Code Optimization,"Das, Syaamantak and Batterywala, Husain",Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 2,2024,"Teaching secure programming, including concepts like buffer overflow, is challenging. Advanced AI Coding Assistants aim to help with programming instruction, but it’s unclear how effective they are at promoting secure code. This research compares different AI Coding Assistants to assess their ability to optimize code for secure coding education. The study offers insights into these tools’ capabilities and recommends their potential use for improving secure coding teaching in computer science education.",10.1145/3632621.3671421,https://doi.org/10.1145/3632621.3671421
Enhancing Learning Analytics: H5P Results for Personalized Software Engineering Education,"Bigler, Dimitri and Hagel, Georg and Becker, Matthias",Proceedings of the 6th European Conference on Software Engineering Education,2025,"Learning Management Systems have become fundamental in higher education for delivering and managing educational content. However, traditional implementations often lack the ability to provide personalized learning experiences and detailed insights into learner behavior. A new approach addresses these limitations by enabling more detailed Learning Analytics through the integration of interactive H5P content and the implementation of Moodle’s LogStore xAPI plugin to send Experience API-based statements within a Moodle Learning Management System. By extending this plugin, detailed user interactions, including activity outcomes, scores, durations and completion status, are captured as Learning Records and stored in a Learning Record Store for further analysis. The enriched Learning Records enable more advanced Learning Analytics that provide deeper insights into student behavior, such as identifying learning preferences, activity patterns, and knowledge levels. Future work will involve developing a recommendation system that uses the Learning Analytics data to identify the next activity best suited to fill learning gaps. The system should monitor learner preferences to maintain engagement, enable adaptive learning paths and offer personalized suggestions. Further efforts will focus on refining the system and evaluating its effectiveness in improving educational outcomes.",10.1145/3723010.3723014,https://doi.org/10.1145/3723010.3723014
Analysis of Generative AI Policies in Computing Course Syllabi,"Ali, Areej and Collier, Aayushi Hingle and Dewan, Umama and McDonald, Nora and Johri, Aditya",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Since the release of ChatGPT in 2022, Generative AI (GenAI) is increasingly being used in higher education computing classrooms across the United States. While scholars have looked at overall institutional guidance for the use of GenAI and reports have documented the response from schools in the form of broad guidance to instructors, we do not know what policies and practices instructors are actually adopting and how they are being communicated to students through course syllabi. To study instructors' policy guidance, we collected 98 computing course syllabi from 54 R1 institutions in the U.S. and studied the GenAI policies they adopted and the surrounding discourse. Our analysis shows that 1) most instructions related to GenAI use were as part of the academic integrity policy for the course and 2) most syllabi prohibited or restricted GenAI use, often warning students about the broader implications of using GenAI, e.g. lack of veracity, privacy risks, and hindering learning. Beyond this, there was wide variation in how instructors approached GenAI including a focus on how to cite GenAI use, conceptualizing GenAI as an assistant, often in an anthropomorphic manner, and mentioning specific GenAI tools for use. We discuss the implications of our findings and conclude with current best practices for instructors.",10.1145/3641554.3701823,https://doi.org/10.1145/3641554.3701823
Exploring the Impact of Generative AI for StandUp Report Recommendations in Software Capstone Project Development,"Neyem, Andres and Sandoval Alcocer, Juan Pablo and Mendoza, Marcelo and Centellas-Claros, Leonardo and Gonzalez, Luis A. and Paredes-Robles, Carlos",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"StandUp Reports play an important role in capstone software engineering courses, facilitating progress tracking, obstacle identification, and team collaboration. However, despite their significance, students often grapple with the challenge of creating StandUp Reports that are clear, concise, and actionable. This paper investigates the impact of the use of generative AI in producing StandUp report recommendations, aiming to assist students in enhancing the quality and effectiveness of their reports. In a semester-long capstone course, 179 students participated in 16 real-world software development projects. They submitted weekly StandUp Reports with the assistance of an AI-powered Slack, which analyzed their initial reports and provided suggestions for enhancing them using both GPT-3.5 and the early access GPT-4 API. After each submitted report, students voluntarily answered a survey about usability and suggestion preference. Furthermore, we conducted a linguistic analysis of the recommendations made by the algorithms to gauge reading ease and comprehension complexity. Our findings indicate that the AI-based recommendation system helped students improve the overall quality of their StandUp Reports throughout the semester. Students expressed a high level of satisfaction with the tool and exhibited a strong willingness to continue using it in the future. The survey reveals that students perceived a slight improvement when using GPT-4 compared to GPT-3.5. Finally, a computational linguistic analysis performed on the recommendations demonstrates that both algorithms significantly improve the alignment between the generated texts and the students' educational level, thereby improving the quality of the original texts.",10.1145/3626252.3630854,https://doi.org/10.1145/3626252.3630854
Short answer scoring with GPT-4,"Jiang, Lan and Bosch, Nigel",,2024,"Automatic short-answer scoring is a long-standing research problem in education. However, assessing short answers at human-level accuracy requires a deep understanding of natural language. Given the notable abilities of recent generative pre-trained transformer (GPT) models, we investigate gpt-4-1106-preview to automatically score student responses from the Automated Student Assessment Prize Short Answer Scoring dataset. We systematically varied information given to the model including possible correct answers and scoring examples, as well as the order of sub-tasks within short answer scoring (e.g., assigning a score vs. generating a rationale for an assigned score) to understand what affects short answer scoring. With the best configuration, GPT-4 yielded a quadratic weighted kappa of .677 across 10 questions. However, we observe that the performance differs across educational subjects (e.g., biology, English), the quality of scoring rubrics might affect the predictions, and the overall utility of rationales generated to explain scores is uncertain.",10.1145/3657604.3664685,https://doi.org/10.1145/3657604.3664685
Evaluating Student Performance and Interactions in Generative AI-Integrated SQL Practical Tests,"Ramakrishnan, Charanya and Cassidy, Steve and Bower, Matt",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 2,2025,"The growing use of Generative AI (GenAI) necessitates a re-evaluation of the design of programming assessments. This two-phase study examines the effects of GenAI integration into an introductory database unit, analysing student performance and problem-solving strategies through their interactions with GenAI during an SQL programming test. In the first phase of the study, 1,304 students participated in the practical test without prior integration of GenAI into the learning activities. The findings indicate that GenAI enhances performance for high-achieving students but is less effective for those struggling with fundamental concepts. The second phase will embed GenAI into lesson plans, allowing a direct comparison of its impact on student learning and assessment outcomes. This research aims to inform the best practices for GenAI-integrated assessments, with a focus on database education.",10.1145/3724389.3730785,https://doi.org/10.1145/3724389.3730785
Auto-grading in Computing Education: Perceptions and Use,"Ruth, Barrett and Hott, John R.",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Auto-grading technologies have become increasingly prevalent in computing education, driven by the need to handle growing class sizes and provide timely and effective feedback. We conducted a survey of 44 computer science instructors at various institutions in order to gather instructor experience and use of auto-graders, the features instructors value most, and the challenges and limitations faced when using these tools. We specifically asked about factors such as grading strategies and policies, opinions on existing tools, and other automated grading methods they employ. Our results indicated that instructors prefer tools that offer significant customizability and integration capabilities, with functionality and program output-based grading as the most commonly used approaches. They emphasized the need for integrated auto-grading solutions that include robust core features and prioritize extensibility to better align with pedagogical goals and to support instructors in managing the increasing demands of computer science education. Based on these findings, we conclude that existing solutions should be improved to address instructor-reported preferences and diverse educational needs.",10.1145/3641554.3701900,https://doi.org/10.1145/3641554.3701900
Teaching CS50 with AI: Leveraging Generative Artificial Intelligence in Computer Science Education,"Liu, Rongxin and Zenke, Carter and Liu, Charlie and Holmes, Andrew and Thornton, Patrick and Malan, David J.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"In Summer 2023, we developed and integrated a suite of AI-based software tools into CS50 at Harvard University. These tools were initially available to approximately 70 summer students, then to thousands of students online, and finally to several hundred on campus during Fall 2023. Per the course's own policy, we encouraged students to use these course-specific tools and limited the use of commercial AI software such as ChatGPT, GitHub Copilot, and the new Bing. Our goal was to approximate a 1:1 teacher-to-student ratio through software, thereby equipping students with a pedagogically-minded subject-matter expert by their side at all times, designed to guide students toward solutions rather than offer them outright. The tools were received positively by students, who noted that they felt like they had",10.1145/3626252.3630938,https://doi.org/10.1145/3626252.3630938
A Roadmap for Integrating Sustainability into Software Engineering Education,,ACM Trans. Softw. Eng. Methodol.,2025,"The world faces escalating crises: record-breaking temperatures, widespread fires, severe flooding, increased oceanic microplastics, and unequal resource distribution. Academia introduces courses around sustainability to meet the new demand, but software engineering education lags behind. While software systems contribute to environmental issues through high energy consumption, they also hold the potential for solutions, such as more efficient and equitable resource management. Yet, sustainability remains a low priority for many businesses, including those in the digital sector. Business as usual is no longer viable. A transformational change in software engineering education is urgently needed. We must move beyond traditional curriculum models and fully integrate sustainability into every aspect of software development. By embedding sustainability as a core competency, we can equip future engineers not only to minimise harm but also to innovate solutions that drive positive, sustainable change. Only with such a shift can software engineering education meet the demands of a world in crisis and prepare students to lead the next generation of sustainable technology. This article discusses a set of challenges and proposes a customisable education roadmap for integrating sustainability into the software engineering curricula. These challenges reflect our perspective on key considerations, stemming from regular, intensive discussions in regular workshops among the authors and the community, as well as our extensive research and teaching experience in the field.",10.1145/3708526,https://doi.org/10.1145/3708526
Bringing Industry-Grade Code Quality and Practices into Software Engineering Education (Doctoral Consortium),"Birillo, Anastasiia",Proceedings of the 24th Koli Calling International Conference on Computing Education Research,2024,"Using professional development tools and practices is an essential part of being a programmer. However, beginners often struggle with professional tools. In this work, we ask the question: “How can we adapt professional programming tools to improve software engineering education?” and aim to find efficient ways to solve this problem.",10.1145/3699538.3699571,https://doi.org/10.1145/3699538.3699571
Fostering Creativity: Student-Generative AI Teaming in an Open-Ended CS0 Assignment,"Filcik, Daniel and Sobiesk, Edward and Matthews, Suzanne J.",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"The increasing ubiquity of web-based generative artificial intelligence technologies necessitates that all students experience teaming with such technologies -- exploring their strengths and limitations and learning how to create synergy with them. To aid in this effort, we designed an open-ended generative AI project for the freshmen taking our general-education introduction to computing course. Students were required to team with generative AI to create something beyond what they alone (or the AI alone) could accomplish. Upon completion, students submitted a short written critical analysis documenting their experiences and presented a three-minute demonstration of their project in class. Despite limited course coverage of AI and generative AI prior to this project, we were impressed by the creativity and sophistication of the submitted final products as well as the breadth of generative AI tools explored. Student reflections on the experience illustrated numerous insights into the strengths and limitations of the tools they employed. Our results underscore that students can learn about the benefits and limitations of generative AI in as little as a single assignment and that covering such topics need not require extensive amounts of course time and resources.",10.1145/3641554.3701853,https://doi.org/10.1145/3641554.3701853
Differentiated Tasks by ChatGPT for Secondary Computer Science Education: Useful or not?,"Bahr, Tobias and Manzocco, Mario and Schuster, Dennis",Proceedings of the 19th WiPSCE Conference on Primary and Secondary Computing Education Research,2024,"In recent years, there has been a growing interest in exploring the capabilities of AI chatbots, such as ChatGPT. Studies have investigated diverse applications, including the response of AI chatbots to undergraduate exam questions and the generation of student exercises for programming. However, the question remains if AI chatbots provide adequate results for K-12 CS in different application scenarios. AI chatbots are increasingly integrated into K-12 education by both students and teachers. In this context, a tool using didactical parameters was created to differentiate tasks with ChatGPT-4 in an ongoing project. Preliminary findings from this work in progress reveal that teachers see a benefit using the tool. Future directions for using the tool are discussed.",10.1145/3677619.3678092,https://doi.org/10.1145/3677619.3678092
How Instructors Incorporate Generative AI into Teaching Computing,"Prather, James and Leinonen, Juho and Kiesler, Natalie and Benario, Jamie Gorson and Lau, Sam and MacNeil, Stephen and Norouzi, Narges and Opel, Simone and Pettit, Virginia and Porter, Leo and Reeves, Brent N. and Savelka, Jaromir and Smith, David H. and Strickroth, Sven and Zingaro, Daniel",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2,2024,"Generative AI (GenAI) has seen great advancements in the past two years and the conversation around adoption is increasing. Widely available GenAI tools are disrupting classroom practices as they can write and explain code with minimal student prompting. While most acknowledge that there is no way to stop students from using such tools, a consensus has yet to form on how students should use them if they choose to do so. At the same time, researchers have begun to introduce new pedagogical tools that integrate GenAI into computing curricula. These new tools offer students personalized help or attempt to teach prompting skills without undercutting code comprehension. This working group aims to detail the current landscape of education-focused GenAI tools and teaching approaches, present gaps where new tools or approaches could appear, identify good practice-examples, and provide a guide for instructors to utilize GenAI as they continue to adapt to this new era.",10.1145/3649405.3659534,https://doi.org/10.1145/3649405.3659534
Exploring Human-Centered Approaches in Generative AI and Introductory Programming Research: A Scoping Review,"Stone, Irene",Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research,2024,"Recent advancements in generative artificial intelligence are poised to reshape introductory programming education, challenging conventional teaching methodologies. This paper presents a scoping review that explores the current understanding of integrating generative artificial intelligence tools in the learning of introductory programming. Through an analysis of 28 selected studies, this review provides a snapshot of the landscape in mid-2024, presenting benefits, concerns, and recommendations surrounding the use of generative artificial intelligence within programming education. It finds insufficient guidance on how to implement recommended pedagogical strategies, limited consideration of student perceptions and experiences, and a predominance of short study time frames. Additionally, there is a significant research gap in second-level education, particularly in the United Kingdom and Ireland. The paper discusses how these gaps signal a need for more human-centered approaches in the current research. The paper concludes with recommendations for future research, aiming to inspire further inquiry and advance the understanding of generative artificial intelligence’s role in programming education from a human-centered perspective.",10.1145/3689535.3689553,https://doi.org/10.1145/3689535.3689553
ITiCSE 2024: Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,,,2024,,,
Generative AI in Student Software Development Projects: A User Study on Experiences and Self-Assessment,"Borghoff, Uwe M. and Minas, Mark and Schopp, Jannis",Proceedings of the 6th European Conference on Software Engineering Education,2025,"The way software is developed is changing rapidly due to the general availability of generative AI tools. As a result, the software engineering education that is part of every computer science program needs to change. Especially in software engineering courses, such AI tools need to be used and practiced in a meaningful and useful way. The programming project is one such course at our university, and the curriculum will be expanded accordingly in the future. In this paper we describe our approach and a user study among the participants of the last programming project, in which we collected experiences with the use of current AI tools, in particular highlighting their usefulness and limitations. Our study focuses on identifying which aspects of the course students used AI tools for, evaluating successful applications, and uncovering remaining challenges.",10.1145/3723010.3723012,https://doi.org/10.1145/3723010.3723012
Applications of Programming as Theory Building in Computer Science Education,"Tuson, Ella",Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 2,2023,The field of Computer Science has always been one of rapid growth and change. We propose the investigation of Peter Naur's framework of Programming as Theory building as a means to make CS education more resilient to emerging technology and to improve student outcomes by encouraging a focus on internal understanding over the external artifacts of programming.,10.1145/3587103.3594137,https://doi.org/10.1145/3587103.3594137
Evaluating Contextually Personalized Programming Exercises Created with Generative AI,"Logacheva, Evanfiya and Hellas, Arto and Prather, James and Sarsa, Sami and Leinonen, Juho",Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1,2024,"Programming skills are typically developed through completing various hands-on exercises. Such programming problems can be contextualized to students’ interests and cultural backgrounds. Prior research in educational psychology has demonstrated that context personalization of exercises stimulates learners’ situational interests and positively affects their engagement. However, creating a varied and comprehensive set of programming exercises for students to practice on is a time-consuming and laborious task for computer science educators. Previous studies have shown that large language models can generate conceptually and contextually relevant programming exercises. Thus, they offer a possibility to automatically produce personalized programming problems to fit students’ interests and needs. This article reports on a user study conducted in an elective introductory programming course that included contextually personalized programming exercises created with GPT-4. The quality of the exercises was evaluated by both the students and the authors. Additionally, this work investigated student attitudes towards the created exercises and their engagement with the system. The results demonstrate that the quality of exercises generated with GPT-4 was generally high. What is more, the course participants found them engaging and useful. This suggests that AI-generated programming problems can be a worthwhile addition to introductory programming courses, as they provide students with a practically unlimited pool of practice material tailored to their personal interests and educational needs.",10.1145/3632620.3671103,https://doi.org/10.1145/3632620.3671103
SIGCSE 2024: Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,,,2024,"Welcome to the 55th annual SIGCSE Technical Symposium on Computer Science Education (SIGCSE TS 2024)! This year, we have returned to Portland, Oregon. We hope that, like us, you are looking forward to a highly productive and engaging symposium that provides ample opportunity to renew old relationships, build new connections, and learn about the latest advances in our field. While we are sure that there will be a few surprises along the way, we hope and expect that we won't experience anything nearly as disruptive as the opening days of the pandemic, which occurred when we last tried to gather here in 2020.Our theme for this year's symposium is",,
ITiCSE 2024: Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2,,,2024,"Welcome to the 29th annual conference on Innovation and Technology in Computer Science Education (ITiCSE 2024), hosted by Universita degli Studi di Milano in Milan, Italy.ITiCSE 2024 will take place from Friday July 5 to Wednesday July 10. The conference program includes a keynote address, paper sessions, a panel, tips, techniques &amp; courseware demonstrations, posters, a doctoral consortium, and working group presentations. Working groups meet July 5-7 and will submit draft reports before the conference begins on July 8.The submissions to ITiCSE 2024 were reviewed by 446 researchers and practitioners from computing education and related fields, including 44 program committee members and 402 reviewers. Thanks to their outstanding effort and commitment, every submission received a metareview and most received at least three reviews, providing authors of all submissions with constructive feedback. Although no review process is flawless, we are confident that this effort led to a vibrant conference program, capturing multiple voices and perspectives in the field.",,
SQL Query Evaluation with Large Language Model and Abstract Syntax Trees,"Xiang, Lili",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"SQL stands as the foundational language for data analysis and manipulation, playing a pivotal role in the database learning process. Proficiency in SQL is essential for students seeking to excel in data-related fields. However, the conventional approaches to assessing SQL queries rely heavily on manual grading, and the automated assessment tools are usually producing only binary decisions for the submitted queries. Our primary research objective is to develop effective methods for evaluating the quality of the SQL queries. To meet this objective, we introduce two approaches: structure-based analysis and evaluation by an instruction tuned large language model (LLM). The first approach deconstructs queries into Abstract Syntax Trees (AST) and employs cosine similarity to assess student submissions. The second approach utilizes a pre-trained LLM: FLAN-T5, fine-tuned for predicting the quality of student submissions. These methodologies are tested on a SQL dataset, and our experimental findings evaluate against a grading rubric with categories ranging from",10.1145/3626253.3635408,https://doi.org/10.1145/3626253.3635408
More Than Meets the AI: Evaluating the performance of GPT-4 on Computer Graphics assessment questions,"Feng, Tony Haoran and Denny, Paul and Wuensche, Burkhard and Luxton-Reilly, Andrew and Hooper, Steffan",Proceedings of the 26th Australasian Computing Education Conference,2024,"Recent studies have showcased the exceptional performance of LLMs (Large Language Models) on assessment questions across various discipline areas. This can be helpful if used to support the learning process, for example by enabling students to quickly generate and contrast alternative solution approaches. However, concerns about student over-reliance and inappropriate use of LLMs in education are common. Understanding the capabilities of LLMs is essential for instructors to make informed decisions on question choices for learning and assessment tasks. In CS (Computer Science), previous evaluations of LLMs have focused on CS1 and CS2 questions, and little is known about how well LLMs perform for assessment questions in upper-level CS courses such as CG (Computer Graphics), which covers a wide variety of concepts and question types. To address this gap, we compiled a dataset of past assessment questions used in a final-year undergraduate course about introductory CG, and evaluated the performance of GPT-4 on this dataset. We also classified assessment questions and evaluated the performance of GPT-4 for different types of questions. We found that the performance tended to be best for simple mathematical questions, and worst for questions requiring creative thinking, and those with complex descriptions and/or images. We share our benchmark dataset with the community and provide new insights into the capabilities of GPT-4 in the context of CG courses. We highlight opportunities for teaching staff to improve student learning by guiding the use of LLMs for CG questions, and inform decisions around question choices for assessment tasks.",10.1145/3636243.3636263,https://doi.org/10.1145/3636243.3636263
Enhancing Programming Error Messages in Real Time with Generative AI,"Kimmel, Bailey and Geisert, Austin Lee and Yaro, Lily and Gipson, Brendan and Hotchkiss, Ronald Taylor and Osae-Asante, Sidney Kwame and Vaught, Hunter and Wininger, Grant and Yamaguchi, Chase",Extended Abstracts of the CHI Conference on Human Factors in Computing Systems,2024,"Generative AI is changing the way that many disciplines are taught, including computer science. Researchers have shown that generative AI tools are capable of solving programming problems, writing extensive blocks of code, and explaining complex code in simple terms. Particular promise has been shown in using generative AI to enhance programming error messages. Both students and instructors have complained for decades that these messages are often cryptic and difficult to understand. Yet recent work has shown that students make fewer repeated errors when enhanced via GPT-4. We extend this work by implementing feedback from ChatGPT for all programs submitted to our automated assessment tool, Athene, providing help for compiler, run-time, and logic errors. Our results indicate that adding generative AI to an automated assessment tool does not necessarily make it better and that design of the interface matters greatly to the usability of the feedback that GPT-4 provided.",10.1145/3613905.3647967,https://doi.org/10.1145/3613905.3647967
SIGCSE 2024: Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,,,2024,"Welcome to the 55th annual SIGCSE Technical Symposium on Computer Science Education (SIGCSE TS 2024)! This year, we have returned to Portland, Oregon. We hope that, like us, you are looking forward to a highly productive and engaging symposium that provides ample opportunity to renew old relationships, build new connections, and learn about the latest advances in our field. While we are sure that there will be a few surprises along the way, we hope and expect that we won't experience anything nearly as disruptive as the opening days of the pandemic, which occurred when we last tried to gather here in 2020.Our theme for this year's symposium is",,
Evaluating Large Language Model Code Generation as an Autograding Mechanism for,"Smith, David H. and Zilles, Craig",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"The ability of students to ''Explain in Plain English'' (EiPE) the purpose of code is a critical skill for students in introductory programming courses to develop. EiPE questions serve as both a mechanism for students to develop and demonstrate code comprehension skills. However, evaluating this skill has been challenging as manual grading is time consuming and not easily automated. The process of constructing a prompt for the purposes of code generation for a Large Language Model, such OpenAI's GPT-4, bears a striking resemblance to constructing EiPE responses. In this paper, we explore the potential of using test cases run on code generated by GPT-4 from students' EiPE responses as a grading mechanism for EiPE questions. We applied this proposed grading method to a corpus of EiPE responses collected from past exams, then measured agreement between the results of this grading method and human graders. Overall, we find moderate agreement between the human raters and the results of the unit tests run on the generated code. This appears to be attributable to GPT-4's code generation being more lenient than human graders on low-level descriptions of code.",10.1145/3626253.3635542,https://doi.org/10.1145/3626253.3635542
Trust in Generative AI among Students: An exploratory study,"Amoozadeh, Matin and Daniels, David and Nam, Daye and Kumar, Aayush and Chen, Stella and Hilton, Michael and Srinivasa Ragavan, Sruti and Alipour, Mohammad Amin",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"Generative Artificial Intelligence (GenAI) systems have experienced exponential growth in the last couple of years. These systems offer exciting capabilities for CS Education (CSEd), such as generating programs, that students can well utilize for their learning. Among the many dimensions that might affect the effective adoption of GenAI for CSEd, in this paper, we investigate students' trust. Trust in GenAI influences the extent to which students adopt GenAI, in turn affecting their learning. In this paper, we present results from a survey of 253 students at two large universities to understand how much they trust GenAI tools and their feedback on how GenAI impacts their performance in CS courses. Our results show that students have different levels of trust in GenAI. We also observe different levels of confidence and motivation, highlighting the need for further understanding of factors impacting trust.",10.1145/3626252.3630842,https://doi.org/10.1145/3626252.3630842
A Generative AI Tool to Foster and Assess Authentic Learning: A Case Study in Teaching SQL,"Sooriamurthi, Raja and Tu, Xiaoying and Pensky, Allison E. Connell",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"Authentic learning refers to a student's metacognition about what they have learned and not learned. Building students' authentic learning is a primary goal of instructors. Educators also want to be able to assess students' learning. One way to do this is to have a one-on-one conversation with students in which the instructor probes their understanding with a series of questions that require the students to explain why they did what they did, possible alternative approaches, and the implications of their learning. Scaling this type of high-impact 1-1, human-led dialogues with larger classes is a challenge. The present study built a custom generative AI tool and tested its ability to have such a conversation with students. In this paper we report on an experiment which aims to compare students' course performance and attitudes between conditions of instructor-led and AI-led dialogues. We found that regardless of condition, students significantly grew in their self efficacy from the beginning of the semester to the end of each of the two feedback sessions. Additionally, students receiving dialoguing with the AI were significantly less nervous than students dialoguing with the instructor with no differences in other attitude measures such as how deeply they believed they understood their assignments. As such, the intelligent assessor generative AI tool offers the potential to provide scalable feedback to students regardless of class size, likely with little to no detriment to students' growing confidence in their skills.",10.1145/3724363.3729022,https://doi.org/10.1145/3724363.3729022
Chat Overflow: Artificially Intelligent Models for Computing Education - renAIssance or apocAIypse?,"Denny, Paul and Becker, Brett A. and Leinonen, Juho and Prather, James",Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1,2023,"Recent breakthroughs in deep learning have led to the emergence of generative AI models that exhibit extraordinary performance at producing human-like outputs. Using only simple input prompts, it is possible to generate novel text, images, video, music, and source code, as well as tackle tasks such as answering questions and translating and summarising text.However, the potential for these models to impact computing education practice is only just beginning to be explored. For example, novices learning to code can now use free tools that automatically suggest solutions to programming exercises and assignments; yet these tools were not designed with novices in mind and little to nothing is known about how they will impact learning. Furthermore, much attention has focused on the immediate challenges these models present, such as academic integrity concerns. It seems that even in the AI-era a pending apocalypse sells better than a promising renaissance.Generative AI will likely play an increasing role in people's lives in the reasonably foreseeable future. Model performance seems set to continue accelerating while novel uses and new possibilities multiply. Given this, we should devote just as much effort to identifying and exploiting new opportunities as we do to identifying and mitigating challenges.In this talk, we begin by discussing several concrete and research-backed opportunities for computing educators. Many of these have already shown great promise in positively impacting current practice. We then discuss more short- to medium-term possibilities in areas such as student recruitment, and curricular changes. Finally - against our better judgement - we speculate over the longer-term, including rethinking the very fundamentals of the practice of teaching introductory and advanced computing courses. In these discussions we suggest potential research questions and directions. Although making remotely accurate predictions in such a fast-changing landscape is foolhardy, we believe that now is the time to explore and embrace opportunities to help make positive change in as many computing classrooms as possible.",10.1145/3587102.3588773,https://doi.org/10.1145/3587102.3588773
Undergraduate Computer Science Education in China,"Liu, Yutong and Xiang, Qiao and Chen, Juan and Zhang, Ming and Xu, Jingdong and Luo, Yuan",ACM Inroads,2024,,10.1145/3638563,https://doi.org/10.1145/3638563
Leveling up Learning: Serious Games for Computing Education - Long-Term Opportunities and Risks,W\,Proceedings of the 27th Australasian Computing Education Conference,2025,"Serious games are becoming an increasingly popular tool in education, including computing education, due to their potential to engage learners, practice skills development, stimulate creativity, promote active learning, and cultivate exploration. However, few researchers have discussed the potential long-term implications of using serious games for learning programming and how they can be addressed.This paper investigates opportunities and drawbacks arising from the wider use of serious games in computing education. We look beyond immediate effects, such as the risk of distraction and technological barriers, and consider prospects and risks caused by market forces and the economic realities of the game, education, and software industries. In particular, we discuss how technological advances can increase the benefits of serious games for programming education, but also that there is a risk that an increasing use of serious games might result in market dominance of a few vendors, lack of diversity, cultural bias, inequity, pressure on education funding, and reduced learning outcomes.",10.1145/3716640.3716655,https://doi.org/10.1145/3716640.3716655
'Can You Refactor This for Me?': Investigating How Students Use ChatGPT in Code Refactoring Exercises,"Carneiro Oliveira, Eduardo and Keuning, Hieke and Jeuring, Johan",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 2,2025,"LLMs are increasingly used in programming education. However, little research has explored their use in teaching and learning code refactoring. In this study, we use a grounded-theory approach to examine student-LLM conversations during code refactoring exercises. Our preliminary results show that students use LLM in various modes, such as requesting a refactoring for the entire program at once or discussing refactoring possibilities in long conversations.",10.1145/3724389.3730789,https://doi.org/10.1145/3724389.3730789
Teaching CS50 with AI: Leveraging Generative Artificial Intelligence in Computer Science Education,"Liu, Rongxin and Zenke, Carter and Liu, Charlie and Holmes, Andrew and Thornton, Patrick and Malan, David J.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"CS50.ai is an AI-based educational tool developed and integrated into CS50 at Harvard University using large language models (LLMs), supporting both in-person and online learners. CS50.ai encapsulates a variety of AI-based tools designed to enhance students' learning by approximating a 1:1 teacher-to-student ratio. We showcase:",10.1145/3626253.3635427,https://doi.org/10.1145/3626253.3635427
Determining the Scope of the Philosophy of Computing Education,,Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"There are a number of different approaches to the investigation of teaching and learning within the subject of Computing Education. Many of the advances in pedagogy that have taken place over the past thirty years have been due to careful statistical analysis of empirical data, enhancing the reputation of the subject within the broader Computing discipline. Empirical, qualitative methodologies, of the kinds used extensively in the Social Sciences, have also appeared in the Computing Education literature, often investigating the socio-cultural aspects of the subject. More recently, there has been a proposal to develop a role for philosophical inquiry in Computing Education, which mirrors similar historical developments in Engineering Education. Rather than focus on the quantitative or qualitative analysis of the student experience, philosophical investigation instead relies on the use of conceptual analysis to investigate the detailed semantic content of ideas raised in the practice of computing education, careful analysis of the methodologies used to do such work, and a critique of the assumptions that underlie the subject.In this paper, we investigate ways in which an understanding of the Philosophy of Computing Education can assist research within the subject. We consider how it emerges from basic questions about nature of the subject, its scope, and how it can be applied fruitfully within the discipline.",10.1145/3724363.3729049,https://doi.org/10.1145/3724363.3729049
Incorporating Generative AI into Software Development Education,"Petrovska, Olga and Clift, Lee and Moller, Faron and Pearsall, Rebecca",Proceedings of the 8th Conference on Computing Education Practice,2024,"This paper explores how Generative AI can be incorporated into software development education. We present examples of formative and summative assessments, which explore various aspects of ChatGPT, including its coding capabilities, its ability to construct arguments as well as ethical issues of using ChatGPT and similar tools in education and the workplace. Our work is inspired by the insights from surveys that show that the learners on our Degree Apprenticeship Programme have a great interest in learning about and exploiting emerging AI technology. Similarly, our industrial partners have a clear interest for their employees to be formally prepared to use GenAI in their software engineering roles. In this vein, it is proposed that embedding the use of GenAI tools in a careful and creative way - by developing assessments which encourage learners to critically evaluate AI output - can be beneficial in helping learners understand the subject material being taught without the risk of the AI tools “doing the homework”.",10.1145/3633053.3633057,https://doi.org/10.1145/3633053.3633057
Seventh Workshop on Emerging Software Engineering Education(WESEE 2025),"Rathore, Santosh Singh and Tiwari, Saurabh and Farooq, Sheikh Umar",Proceedings of the 18th Innovations in Software Engineering Conference,2025,"The seventh Workshop on Emerging Software Engineering Education (WESEE) aims to discuss and examine the development of learning environments that are influencing the pedagogical strategies for the education of software engineering courses in institutions, specifically through the adoption of Generative AI (GenAI) tools and techniques. Additionally, the workshop aims to examine how industries are utilizing GenAI tools and technologies for teaching software development methods and how the developers are utilizing the material for self-learning and skill acquisition. The report is an overview of the upcoming seventh edition of WESEE, which will be held on 20th February 2025 at NIT Kurukshetra. The workshop will be held alongside the 18th Innovations in Software Engineering Conference (ISEC 2025).",10.1145/3717383.3721236,https://doi.org/10.1145/3717383.3721236
Computing Education in African Countries: A Literature Review and Contextualised Learning Materials,"Hamouda, Sally and Marshall, Linda and Sanders, Kate and Tshukudu, Ethel and Adelakun-Adeyemo, Oluwatoyin and Becker, Brett A. and Dodoo, Emma R. and Korsah, G. Ayorkor and Luvhengo, Sandani and Ola, Oluwakemi and Parkinson, Jack and Sanusi, Ismaila Temitayo",2024 Working Group Reports on Innovation and Technology in Computer Science Education,2025,"This report begins with a literature review of computing education in Africa. We found a substantial body of work, scattered over more than 80 venues, which we have brought together here for the first time. Several important themes emerge in this dataset, including the need to contextualise computing education.In the second part of this report we investigate contextualisation further. We present a pilot study, grounded in the literature review, of the development of course materials, sample code, and programming assignments for introductory programming, contextualised for six African countries: Botswana, Egypt, Ghana, Nigeria, South Africa, and Zambia. We include the materials, report on a preliminary evaluation of the materials by fellow educators in African countries, and suggest a process by which other educators could develop materials for their local contexts.",10.1145/3689187.3709606,https://doi.org/10.1145/3689187.3709606
The Effects of Generative AI on Computing Students’ Help-Seeking Preferences,"Hou, Irene and Mettille, Sophia and Man, Owen and Li, Zhuo and Zastudil, Cynthia and MacNeil, Stephen",Proceedings of the 26th Australasian Computing Education Conference,2024,"Help-seeking is a critical way that students learn new concepts, acquire new skills, and get unstuck when problem-solving in their computing courses. The recent proliferation of generative AI tools, such as ChatGPT, offers students a new source of help that is always available on-demand. However, it is unclear how this new resource compares to existing help-seeking resources along dimensions of perceived quality, latency, and trustworthiness. In this paper, we investigate the help-seeking preferences and experiences of computing students now that generative AI tools are available to them. We collected survey data (n=47) and conducted interviews (n=8) with computing students. Our results suggest that although these models are being rapidly adopted, they have not yet fully eclipsed traditional help resources. The help-seeking resources that students rely on continue to vary depending on the task and other factors. Finally, we observed preliminary evidence about how help-seeking with generative AI is a skill that needs to be developed, with disproportionate benefits for those who are better able to harness the capabilities of LLMs. We discuss potential implications for integrating generative AI into computing classrooms and the future of help-seeking in the era of generative AI.",10.1145/3636243.3636248,https://doi.org/10.1145/3636243.3636248
AI in and for K-12 Informatics Education. Life after Generative AI.,"Barendsen, Erik and Lonati, Violetta and Quille, Keith and Altin, Rukiye and Divitini, Monica and Hooshangi, Sara and Karnalim, Oscar and Kiesler, Natalie and Melton, Madison and Suero Montero, Calkin and Morpurgo, Anna",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2,2024,"The use and adoption of Generative AI (GenAI) has revolutionised various sectors, including computing education. However, this narrow focus comes at a cost to the wider AI in and for educational research. This working group aims to explore current trends and explore multiple sources of information to identify areas of AI research in K-12 informatics education that are being underserved but needed in the post-GenAI AI era. Our research focuses on three areas: curriculum, teacher-professional learning and policy. The denouement of this aims to identify trends and shortfalls for AI in and for K-12 informatics education. We will systematically review the current literature to identify themes and emerging trends in AI education at K-12. This will be done under two facets, curricula and teacher-professional learning. In addition, we will conduct interviews and surveys with educators and AI experts. Next, we will examine the current policy (such as the European AI Act, and European Commission guidelines on the use of AI and data in education and training as well as international counterparts). Policies are often developed by both educators and experts in the domain, thus providing a source of topics or areas that may be added to our findings. Finally, by synthesising insights from educators, AI experts, and policymakers, as well as the literature and policy, our working group seeks to highlight possible future trends and shortfalls.",10.1145/3649409.3691073,https://doi.org/10.1145/3649409.3691073
Teach AI How to Code: Using Large Language Models as Teachable Agents for Programming Education,"Jin, Hyoungwook and Lee, Seonghee and Shin, Hyungyu and Kim, Juho",Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems,2024,"This work investigates large language models (LLMs) as teachable agents for learning by teaching (LBT). LBT with teachable agents helps learners identify knowledge gaps and discover new knowledge. However, teachable agents require expensive programming of subject-specific knowledge. While LLMs as teachable agents can reduce the cost, LLMs’ expansive knowledge as tutees discourages learners from teaching. We propose a prompting pipeline that restrains LLMs’ knowledge and makes them initiate “why” and “how” questions for effective knowledge-building. We combined these techniques into TeachYou, an LBT environment for algorithm learning, and AlgoBo, an LLM-based tutee chatbot that can simulate misconceptions and unawareness prescribed in its knowledge state. Our technical evaluation confirmed that our prompting pipeline can effectively configure AlgoBo’s problem-solving performance. Through a between-subject study with 40 algorithm novices, we also observed that AlgoBo’s questions led to knowledge-dense conversations (effect size=0.71). Lastly, we discuss design implications, cost-efficiency, and personalization of LLM-based teachable agents.",10.1145/3613904.3642349,https://doi.org/10.1145/3613904.3642349
Impact of COVID-19 on Live-Coding in First-Year Computer Science Education: A Literature Review,"Kulkarni, Sourabh and Attarwala, Abbas and Raigoza, Jaime",J. Comput. Sci. Coll.,2025,"The COVID pandemic has significantly influenced educational methodologies, leading to a shift towards more interactive and technology-integrated teaching approaches. Live-coding, which involves real-time coding demonstrations, has gained recognition as a valuable tool in computer science education. This study investigates the impact of the pandemic on the popularity and application of live-coding. By conducting a comprehensive literature review of 22 research papers, this study categorizes the papers based on their publication date relative to the pandemic: pre-COVID (2017 to 2019), during COVID (2020 to 2022), and post-COVID (2023 to 2024). The papers were selected using a specific search query for live-coding in introductory computer science education on Google Scholar. A systematic literature review was performed to determine their sentiment towards live-coding, categorizing the sentiments as positive, neutral, or negative. The sentiment data were then statistically analyzed using Fisher's Exact Test to assess significant differences across the three periods. Results from this manuscript indicate shifts in positive sentiment towards live-coding during and after the pandemic.",,
First Year CS Students Exploring And Identifying Biases and Social Injustices in Text-to-Image Generative AI,"Apiola, Mikko and Vartiainen, Henriikka and Tedre, Matti",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"Generative AI is a recent breakthrough in AI. While it has become a hot topic in computing education research (CER), much of the recent research has focused on e.g. issues of plagiarism or academic integrity. One problem spot with Generative AI is its susceptibility to various kinds of algorithmic bias. In this study, we collected data from an introductory computing course, where students experimented with text-to-image generative models and reflected on their generated image sets, in terms of biases, related harms, and possible fixes. Data were collected in Fall 2023 (pilot data in Fall 2022). Data included reports from 163 students. The results show (1) a variety of bias types observed by students related to gender, ethnicity, age, as well as a variety of bias types not observed by students, (2) two major types of attributions for the source of bias: bias caused by biases in the society and bias caused by data or algorithms, and (3) a number of potential harms associated with the biases, as well as attributions of those harms in specific contexts and use cases.",10.1145/3649217.3653596,https://doi.org/10.1145/3649217.3653596
LittleGenius: Co-Designing a GPT-4 Enhanced VR Pedagogical Framework with Teachers for Primary Education,,Proceedings of the 24th ACM International Conference on Intelligent Virtual Agents,2024,"This study introduces LittleGenius, a VR tool integrated with GPT-4 for primary education. Combining GPT-4’s advanced natural language processing with VR technology, LittleGenius creates an engaging learning environment. Users interact with an astronaut floating outside the International Space Station. A specialized GPT prompt was developed to foster deeper engagement through knowledge construction. The system enables natural speech interaction using Microsoft Azure’s Speech Cognitive Services. Nine in-service teachers evaluated the design, giving positive feedback, especially on the interactive astronaut agent’s engaging questions that could deepen student understanding. Future development will expand content and customize the system for diverse communication preferences and learning styles.",10.1145/3652988.3673941,https://doi.org/10.1145/3652988.3673941
Exploring Large Language Model-Powered Pedagogical Approaches to Cybersecurity Education,"Chhetri, Chola",Proceedings of the 25th Annual Conference on Information Technology Education,2024,"The adoption of artificial intelligence (AI) technologies by businesses and corporations is rising. AI technologies continue to be adopted in cybersecurity for both defensive and offensive strategies. However, threat actors also persist in utilizing these technologies to enhance the speed, accuracy, and sophistication of their attacks. Hence, it is essential to train the next generation of cybersecurity learners not only on how to use AI technology but also on how to leverage these technologies to enhance the efficiency of their work. This extended abstract describes our exploratory work on the use of generative AI-based pedagogical approaches in cybersecurity education. This extended abstract will describe some preliminary findings on large language model-powered pedagogical approaches to cybersecurity education and training. These approaches will help cybersecurity educators enhance their teaching methods to equip learners with the essential skills needed to succeed in the dynamic field of cybersecurity.",10.1145/3686852.3686887,https://doi.org/10.1145/3686852.3686887
"Integrating Small Language Models with Retrieval-Augmented Generation in Computing Education: Key Takeaways, Setup, and Practical Insights","Yu, Zezhu and Liu, Suqing and Denny, Paul and Bergen, Andreas and Liut, Michael",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Leveraging a Large Language Model (LLM) for personalized learning in computing education is promising, yet cloud-based LLMs pose risks around data security and privacy. To address these concerns, we developed and deployed a locally stored Small Language Model (SLM) utilizing Retrieval-Augmented Generation (RAG) methods to support computing students' learning. Previous work has demonstrated that SLMs can match or surpass popular LLMs (gpt-3.5-turbo and gpt-4-32k) in handling conversational data from a CS1 course. We deployed SLMs with RAG (SLM + RAG) in a large course with more than 250 active students, fielding nearly 2,000 student questions, while evaluating data privacy, scalability, and feasibility of local deployments. This paper provides a comprehensive guide for deploying SLM + RAG systems, detailing model selection, vector database choice, embedding methods, and pipeline frameworks. We share practical insights from our deployment, including scalability concerns, accuracy versus context length trade-offs, guardrails and hallucination reduction, as well as data privacy maintenance. We address the",10.1145/3641554.3701844,https://doi.org/10.1145/3641554.3701844
Understanding the Impact of Using Generative AI Tools in a Database Course,"Ramirez Osorio, Valeria and Zavaleta Bernuy, Angela and Simion, Bogdan and Liut, Michael",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs) have led to changes in educational practices by creating opportunities for personalized learning and immediate support. Computer science student perceptions and behaviors towards GenAI tools have been studied, but the effects of such tools on student learning have yet to be determined conclusively. We investigate the impact of GenAI tools on computing students' performance in a database course and aim to understand why students use GenAI tools in assignments. Our mixed-methods study (N=226) asked students to self-report whether they used a GenAI tool to complete a part of an assignment and why. Our results reveal that students utilizing GenAI tools performed better on the assignment part in which LLMs were permitted but did worse in other parts of the assignment and in the course overall. Also, those who did not use GenAI tools viewed more discussion board posts and participated more than those who used ChatGPT. This suggests that using GenAI tools may not lead to better skill development or mental models, at least not if the use of such tools is unsupervised, and that engagement with official course help supports may be affected. Further, our thematic analysis of reasons for using or not using GenAI tools, helps understand why students are drawn to these tools. Shedding light into such aspects empowers instructors to be proactive in how to encourage, supervise, and handle the use or integration of GenAI into courses, fostering good learning habits.",10.1145/3641554.3701785,https://doi.org/10.1145/3641554.3701785
A Self-Regulated Learning Framework using Generative AI and its Application in CS Educational Intervention Design,"Prasad, Prajish and Sane, Aamod",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"Self-regulation refers to the ability to plan, monitor, control and reflect on one's problem-solving process. Prior research has shown that self-regulated learning (SRL) strategies help improve novice performance in solving programming problems. However, with the advent of LLM tools like ChatGPT, novices can generate fairly accurate code by just providing the problem prompt, and hence may forego applying essential self-regulation strategies such as planning and reflection to solve the problem. In this position paper, we discuss challenges and opportunities that generative AI technologies pose for novices' self-regulation strategies in the context of programming problem solving. We believe that the key challenge facing educators is that such technologies may hamper novices' ability to regulate their programming problem solving process.On the other hand, these technologies also open up the possibility to design new interventions that promote better SRL strategies in learners. We draw on generic and domain-specific self-regulated learning theories as the basis of our work, and propose an SRL framework that incorporates use of generative AI tools in programming problem solving. We illustrate how the proposed framework guides exploration of the design space of interventions that integrate generative AI in CS education.",10.1145/3626252.3630828,https://doi.org/10.1145/3626252.3630828
The Influence of Generative AI on Pedagogy and Assessment in Computing Education,"Mehta, Jean and Becker, Brett A. and Hsin, Wen-Jung and Hummel, Joe and Kerney, Bill and Krupp, Brian",J. Comput. Sci. Coll.,2023,"Student access to Generative AI tools stands to alter the way we teach as well as the way we assess our student's learning. ChatGPT has only been available for a few months, but already instructors are concerned about its wide use and implications. Love it? Hate it? Embed it in your course? Ban its use? Will this change not just how we teach but what we teach, when we teach it and even who we teach? Most of us have been wrestling with these questions, and more. Panelists will speak of how they altered their pedagogy, and the results, in both in-person and online courses.",,
The Role of Formal Methods in Computer Science Education,"ter Beek, Maurice and Broy, Manfred and Dongol, Brijesh",ACM Inroads,2024,,10.1145/3702231,https://doi.org/10.1145/3702231
"In an Interdisciplinary World, Computer Science Education Must Adapt","Green, Karen",ACM Inroads,2024,,10.1145/3701622,https://doi.org/10.1145/3701622
Prompt Problems: A New Programming Exercise for the Generative AI Era,"Denny, Paul and Leinonen, Juho and Prather, James and Luxton-Reilly, Andrew and Amarouche, Thezyrie and Becker, Brett A. and Reeves, Brent N.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"Large language models (LLMs) are revolutionizing the field of computing education with their powerful code-generating capabilities. Traditional pedagogical practices have focused on code writing tasks, but there is now a shift in importance towards reading, comprehending and evaluating LLM-generated code. Alongside this shift, an important new skill is emerging -- the ability to solve programming tasks by constructing good prompts for code-generating models. In this work we introduce a new type of programming exercise to hone this nascent skill: 'Prompt Problems'. Prompt Problems are designed to help students learn how to write effective prompts for AI code generators. A student solves a Prompt Problem by crafting a natural language prompt which, when provided as input to an LLM, outputs code that successfully solves a specified programming task. We also present a new web-based tool called Promptly which hosts a repository of Prompt Problems and supports the automated evaluation of prompt-generated code. We deploy Promptly in one CS1 and one CS2 course and describe our experiences, which include student perceptions of this new type of activity and their interactions with the tool. We find that students are enthusiastic about Prompt Problems, and appreciate how the problems engage their computational thinking skills and expose them to new programming constructs. We discuss ideas for the future development of new variations of Prompt Problems, and the need to carefully study their integration into classroom practice.",10.1145/3626252.3630909,https://doi.org/10.1145/3626252.3630909
Proceedings of the 2024 on RESPECT Annual Conference,"Smith, Julie M.",Proceedings of the 2024 on RESPECT Annual Conference,2024,"Research Questions: (1) Is there a pattern of racial bias in student advising recommendations made by generative AI? (2) What safeguards can promote equity when using generative AI in high-stakes decision-making? Methodology: Using lists of names associated with various ethnic/racial groups, we asked ChatGPT and Claude AI for recommendations for colleges and majors for each student. Results: ChatGPT was more likely to recommend STEM majors to some student groups. ChatGPT did not show systematic bias in various metrics of school quality, but Claude AI did. There were also overall differences in the colleges recommended by Claude AI and ChatGPT. Implications: We provide cautions and recommendations for using generative AI in high-stakes tasks.",10.1145/3653666.3656065,https://doi.org/10.1145/3653666.3656065
Pedagogical Evaluation of Generative AI Course for Technologists,"Bandi, Ajay",J. Comput. Sci. Coll.,2025,"Generative AI is a transformative technology that impacts various fields, including software development, data analytics, and cybersecurity. To address this, we have designed and developed a Generative AI course for technologists, integrating foundational knowledge of various Gen AI architecture models with hands-on practical experience using Python libraries, including HuggingFace. This paper discusses the detailed course structure and assessments. A pedagogical evaluation approach is followed to identify the challenges encountered in the course and how to overcome them. The results demonstrate that the Generative AI Course for Technologists effectively equips students with technical expertise and critical thinking skills through a balanced combination of theoretical concepts and practical exercises, such as chatbot development and prompt engineering. The course addresses challenges like hardware limitations and API integration by proposing future improvements, including a dedicated Python module and access to cloud-based GPU tools, ensuring learners are well-prepared to navigate and ethically apply Generative AI in real-world contexts.",,
Teaching Ethics in Computing: A Systematic Literature Review of ACM Computer Science Education Publications,"Brown, Noelle and Xie, Benjamin and Sarder, Ella and Fiesler, Casey and Wiese, Eliane S.",ACM Trans. Comput. Educ.,2024,"The computing education research community now has at least 40 years of published research on teaching ethics in higher education. To examine the state of our field, we present a systematic literature review of papers in the Association for Computing Machinery computing education venues that describe teaching ethics in higher-education computing courses. Our review spans all papers published to SIGCSE, ICER, ITiCSE, CompEd, Koli Calling, and TOCE venues through 2022, with 100 papers fulfilling our inclusion criteria. Overall, we found a wide variety in content, teaching strategies, challenges, and recommendations. The majority of the papers did not articulate a conception of “ethics,” and those that did used many different conceptions, from broadly applicable ethical theories to social impact to specific computing application areas (e.g., data privacy and hacking). Instructors used many different pedagogical strategies (e.g., discussions, lectures, assignments) and formats (e.g., stand-alone courses, incorporated within a technical course). Many papers identified measuring student knowledge as a particular challenge, and 59% of papers included mention of assessments or grading. Of the 69% of papers that evaluated their ethics instruction, most used student self-report surveys, course evaluations, and instructor reflections. While many papers included calls for more ethics content in computing, specific recommendations were rarely broadly applicable, preventing a synthesis of guidelines. To continue building on the last 40 years of research and move toward a set of best practices for teaching ethics in computing, our community should delineate our varied conceptions of ethics, examine which teaching strategies are best suited for each, and explore how to measure student learning.",10.1145/3634685,https://doi.org/10.1145/3634685
Workshop Report on Emerging Software Engineering Education,"Rathore, Santosh Singh and Tiwari, Saurabh and Farooq, Sheikh Umar",Proceedings of the 17th Innovations in Software Engineering Conference,2024,"Software engineering is rapidly adapting to meet the demands of contemporary customers and the challenges posed by relentless technological advancements. A well-prepared and highly competent workforce is crucial to propel this evolution, making it a pivotal element for the successful future of software engineering. To instill the art and science of software engineering across diverse age groups, innovative teaching methods must be introduced at all levels of education dissemination. Software engineering stands out as one of the most dynamic subjects in computer science curricula, spanning both undergraduate and postgraduate levels, given the continuous emergence of new software development process models, methods, and tools. A comprehensive software engineering course should encompass various processes, methods, and tools necessary to support large-scale software systems’ development, operation, and maintenance. Moreover, these courses should significantly emphasize developing the interpersonal and communication skills essential for a well-rounded software engineer.",10.1145/3641399.3641436,https://doi.org/10.1145/3641399.3641436
Generative AI in Introductory Programming Instruction: Examining the Assistance Dilemma with LLM-Based Code Generators,"Poitras, Eric and Crane, Brent and Siegel, Angela",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1,2024,"Problem decomposition is an important skill in programming, allowing learners to break down complex tasks into manageable subgoals. However, translating these subgoals into executable code poses a significant challenge for novice programmers. In this study conducted in an introductory programming course, learners received instruction in stepwise refinement and integration of AI-generated code within their assignments. Throughout the course, learners were permitted to rely on AI code generators, following opportunities to receive feedback on their ability to read and write code without AI assistance.  Our findings show that learners frequently relied on AI-generated code when working on assignments outside the classroom, but that the frequency of reliance varied from one assignment to another. The reliance on AI-generated code was not correlated with the learners' year in their degree, nor whether they were enrolled in a CS degree or not. Instead, it was associated with their prior knowledge, as learners who were less proficient in reading and writing code were more likely to seek AI assistance.  AI tools were primarily used to translate subgoals into code, fix errors, and explain algorithmic concepts. Few learners encountered difficulties in understanding or integrating AI generated code into their solutions. Overall, learner performance in meeting assignment requirements was relatively high, regardless of their prior knowledge or reliance on AI code generators. We conclude that leveraging the capabilities of generative AI can effectively bridge the gap between problem-solving and implementation, enabling learners to engage in skills that might otherwise be beyond their reach.",10.1145/3649165.3690111,https://doi.org/10.1145/3649165.3690111
ITiCSE-WGR '23: Proceedings of the 2023 Working Group Reports on Innovation and Technology in Computer Science Education,,,2023,"In these proceedings, we present papers from the Working Groups that worked in the context of the 28th Annual Conference on Innovation &amp; Technology in Computer Science Education (ITiCSE), held in Turku Finland, and hosted by University of Turku from the 10th to the 12th of July 2023.The concept of Working Groups has been a unique feature of the ITiCSE conference series since its inception, with CompEd adopting the Working Group practice in 2019. A Working Group typically comprises 5 to 10 researchers who work together on a project related to computing education. Working Groups provide a wonderful opportunity to work intensively on a topic of interest with an international group of computing education researchers. This unique experience is one that, in our opinion, each Computer Science Educator should strive to participate in at least once.In 2023, 13 proposals for Working Groups were received and six Working Groups were selected by the Working Group chairs to recruit members and proceed for ITiCSE 2023. There were over 100 member applications to Working Groups, with 67 being accepted across the six Working Groups.",,
Early Adoption of Custom Generative AI Bots in Online Forums for CS Courses,"Chen, Matt",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"This lightning talk presents insights from a pilot program in an IT Faculty, where custom generative AI bots were integrated into online forums across 20 courses over two semesters in 2024. The AI bots were trained on specific course content and past student questions to provide tailored responses to student inquiries, with all responses reviewed by teaching staff before being released to students.This approach, distinct from the direct use of large language models (LLMs) like ChatGPT or Claude, offers targeted information aligned with course material and ensures accuracy while preventing the disclosure of assignment answers. The mechanism is designed to support large computer science courses, including first-year courses with over 1,000 students, where timely and comprehensive staff responses can be challenging.This talk will explore the benefits and drawbacks of using generative AI bots in the CS context. It will also examine the factors influencing staff acceptance and trust in chatbot responses and how AI impacts the types and quality of student questions in forums. Key lessons learned and challenges encountered during the program's implementation will also be shared.",10.1145/3641555.3705076,https://doi.org/10.1145/3641555.3705076
Large Language Model-Supported Software Testing with the CS Matrix Taxonomy,"Crandall, Johannah L. and Crandall, Aaron S.",J. Comput. Sci. Coll.,2024,"New breakthroughs in code synthesis from Generative Pre-Trained Transformers (GPT) and Large Language Model (LLM) algorithms are driving significant changes to software engineering education. Having algorithms able to generate components of a software project means that software developers will need stronger skills in requirements specification to guide code generation as well as stronger skills in code review, testing, and integration to incorporate AI-generated code into projects. Shifts in industry and classroom practices are already occurring with the availability of inline code generation tools like GitHub's Copilot, which makes discussion of pedagogical strategies in this area a timely topic. Of immediate concern in computer science education is the potential for LLM-generated code and code help to undermine the learning of CS students. In order to avoid such undermining in even intentional uses of LLM-enhanced learning supports, it is necessary to clarify the roles such supports need to play in the pedagogical process. The Computer Science Matrix Taxonomy provides a strong framework for organizing software testing learning outcomes as well as delineating the operational space in which LLM-based feedback tools should operate to support those learning outcomes. In this paper, the authors operationalize the CS Matrix Taxonomy for software testing learning outcomes and illustrate the integration of LLM-generated test strategy suggestions as an extension of the peer coding/testing model. The work includes examples of AI-generated code testing suggestions that students would use to help guide their own code synthesis for assignments or projects.",,
"Integrating Ethics into Computer Science Education: Multi-, Inter-, and Transdisciplinary Approaches","Goetze, Trystan S.",Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1,2023,"While calls to integrate ethics into computer science education go back decades, recent high-profile ethical failures related to computing technology by large technology companies, governments, and academic institutions have accelerated the adoption of computer ethics education at all levels of instruction. Discussions of how to integrate ethics into existing computer science programmes often focus on the structure of the intervention---embedded modules or dedicated courses, humanists or computer scientists as ethics instructors---or on the specific content to be included---lists of case studies and essential topics to cover. While proponents of computer ethics education often emphasize the importance of closely connecting ethical and technical content in these initiatives, most do not reflect in depth on the variety of ways in which the disciplines can be combined. In this paper, I deploy a framework from cross-disciplinary studies that categorizes academic projects that work across disciplines as multidisciplinary, interdisciplinary, or transdisciplinary, depending on the degree of integration. When applied to computer ethics education, this framework is orthogonal to the structure and content of the initiative, as I illustrate using examples of dedicated ethics courses and embedded modules. It therefore highlights additional features of cross-disciplinary teaching that need to be considered when planning a computer ethics programme. I argue that computer ethics education should aim to be at least interdisciplinary-multidisciplinary initiatives are less aligned with the pedagogical aims of computer ethics-and that computer ethics educators should experiment with fully transdisciplinary education that could transform computer science as a whole for the better.",10.1145/3545945.3569792,https://doi.org/10.1145/3545945.3569792
Integrating Small-scale Autonomous Vehicles in CS Education: An Experience Report,"Silvis-Cividjian, Natalia and Kenyon, Joshua and Gallup, Maximilian and Groot, Elias and Wezenbeek, Hugo van and Lira-Cossio, Eduardo and Althuisius, Niels",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"Teaching software systems engineering is neither effective, nor inspiring if students cannot practice the conveyed theory. We report on a hands-on approach that closes the gap by means of off-the-shelf and in-house realistic miniature models of autonomous vehicles. It is innovative that the infrastructure extends beyond the widely-used solutions, to digitally controlled cars and trains, with open hardware and extendable sensory/actuating capabilities (cameras, opto-sensors, proximity sensors, LEDs, displays) operating in realistic mini-environments, including line-marked roads, railways, traffic-lights and -signs, tunnels and railroad switches. For many years already, we have been using these vehicles to structurally teach physical computing (300 undergraduates yearly) and systems testing (12 graduates yearly), and for incidental individual research projects. Recently, we started two initiatives that stimulate a more dynamic know-how transfer across generations. The first is a better scalable undergraduate capstone project, where groups of students work on a 'hot' research topic in autonomous driving. The second motivates student teams to go the extra mile in an international intelligent car race competition. Evaluations showed that although unusual for a non-engineering curriculum, 'playing' with autonomous vehicles is an excellent strategy to discover the interaction of software with hardware and environment, to better consolidate existing knowledge on programming and testing, and to explore new fields, such as AI-based computer vision, navigation and safety, adding in all cases more fun and motivation. We share the design of the scaffolding and teaching initiatives, together with lessons learned which will hopefully inspire other educators in shaping engaging and future-proof CS curricula.",10.1145/3724363.3729078,https://doi.org/10.1145/3724363.3729078
Student Perspectives on Using a Large Language Model (LLM) for an Assignment on Professional Ethics,,Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"The advent of Large Language Models (LLMs) started a serious discussion among educators on how LLMs would affect, e.g., curricula, assessments, and students' competencies. Generative AI and LLMs also raised ethical questions and concerns for computing educators and professionals.This experience report presents an assignment within a course on professional competencies, including some related to ethics, that computing master's students need in their careers. For the assignment, student groups discussed the ethical process by Lennerfors et al. by analyzing a case: a fictional researcher considers whether to attend the real CHI 2024 conference in Hawaii. The tasks were (1) to participate in in-class discussions on the case, (2) to use an LLM of their choice as a discussion partner for said case, and (3) to document both discussions, reflecting on their use of the LLM.Students reported positive experiences with the LLM as a way to increase their knowledge and understanding, although some identified limitations. The LLM provided a wider set of options for action in the studied case, including unfeasible ones. The LLM would not select a course of action, so students had to choose themselves, which they saw as coherent.From the educators' perspective, there is a need for more instruction for students using LLMs: some students did not perceive the tools as such but rather as an authoritative knowledge base. Therefore, this work has implications for educators considering the use of LLMs as discussion partners or tools to practice critical thinking, especially in computing ethics education.",10.1145/3649217.3653624,https://doi.org/10.1145/3649217.3653624
Assessing Software Engineering Students' Analytical Skills in the Era of Generative AI,"Petrovska, Olga and Pearsall, Rebecca and Clift, Lee",Proceedings of the 9th Conference on Computing Education Practice,2025,This poster showcases an assessment designed to develop and evaluate software engineering students’ code analysis skills. We demonstrate how students approached code analysis tasks when given multiple code samples created by a human and various AI tools.,10.1145/3702212.3702223,https://doi.org/10.1145/3702212.3702223
Models of Mastery Learning for Computing Education,"Szabo, Claudia and Parker, Miranda C. and Friend, Michelle and Jeuring, Johan and Kohn, Tobias and Malmi, Lauri and Sheard, Judithe",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"The application of mastery learning, where students progress through their learning in a self-paced manner until they have mastered specific concepts, is considered appealing for teaching introductory programming courses. Despite its growing popularity in computing and its extensive use in other disciplines, there is no overview of the design of courses that use mastery learning. In this position paper, we present an overview of five mastery learning models and discuss examples of how these can be applied in practice, both in foundational programming as well as more advanced courses. Our analysis focuses on the student progression through the course, the assessment structure, and the support for self-paced learning, including for struggling students. This work provides a greater understanding of mastery learning and its application in a computing education context.",10.1145/3641554.3701868,https://doi.org/10.1145/3641554.3701868
What We Talk About When We Talk About K-12 Computing Education,"Schulte, Carsten and Sentance, Sue and Sparmann, S\",2024 Working Group Reports on Innovation and Technology in Computer Science Education,2025,"K-12 computing education research is a rapidly growing field of research, both driven by and driving the implementation of computing as a school and extra-curricular subject globally. In the context of discipline-based education research, it is a new and emerging field, drawing on areas such as mathematics and science education research for inspiration and theoretical bases. The urgency around investigating effective teaching and learning in computing in school alongside broadening participation has led to much of the field being focused on empirical research. Less attention has been paid to the underlying philosophical assumptions informing the discipline, which might include a critical examination of the rationale for K-12 computing education, its goals and perspectives, and associated inherent values and beliefs. In this working group, we conducted an analysis of the implicit and hidden values, perspectives and goals underpinning computing education at school in order to shed light on the question of what we are talking about when we talk about K-12 computing education. To do this we used a multi-faceted approach to identify implicit rationales for K-12 computing education and examine what these might mean for the implemented curriculum. Methods used include both traditional and natural language processing techniques for examining relevant literature, alongside an examination of the theoretical literature relating to education theory. As a result we identified four traditions for K-12 computing education: algorithmic, design-making, scientific and societal. From this we have developed a framework for the exemplification of these traditions, alongside several potential use cases. We suggest that while this work may provoke some discussion and debate, it will help researchers and others to identify and express the rationales they draw on with respect to computing education.",10.1145/3689187.3709612,https://doi.org/10.1145/3689187.3709612
Non-Expert Programmers in the Generative AI Future,"Feldman, Molly Q and Anderson, Carolyn Jane",Proceedings of the 3rd Annual Meeting of the Symposium on Human-Computer Interaction for Work,2024,"Generative AI is rapidly transforming the practice of programming. At the same time, our understanding of who writes programs, for what purposes, and how they program, has been evolving. By facilitating natural-language-to-code interactions, large language models for code have the potential to open up programming work to a broader range of workers. While existing work finds productivity benefits for expert programmers, interactions with non-experts are less well-studied. In this paper, we consider the future of programming for non-experts through a controlled study of 67 non-programmers. Our study reveals multiple barriers to effective use of large language models of code for non-experts, including several aspects of technical communication. Comparing our results to a prior study of beginning programmers illuminates the ways in which a traditional introductory programming class does and does not equip students to effectively work with generative AI. Drawing on our empirical findings, we lay out a vision for how to empower non-expert programmers to leverage generative AI for a more equitable future of programming.",10.1145/3663384.3663393,https://doi.org/10.1145/3663384.3663393
Students' Perceptions and Use of Generative AI Tools for Programming Across Different Computing Courses,"Keuning, Hieke and Alpizar-Chacon, Isaac and Lykourentzou, Ioanna and Beehler, Lauren and K\",Proceedings of the 24th Koli Calling International Conference on Computing Education Research,2024,"Investigation of students’ perceptions and opinions on the use of generative artificial intelligence (GenAI) in education is a topic gaining much interest. Studies addressing this are typically conducted with large heterogeneous groups, at one moment in time. However, how students perceive and use GenAI tools can potentially depend on many factors, including their background knowledge, familiarity with the tools, and the learning goals and policies of the courses they are taking. In this study we explore how students following computing courses use GenAI for programming-related tasks across different programs and courses: Bachelor and Master, in courses in which learning programming is the learning goal, courses that require programming as a means to achieve another goal, and in courses in which programming is optional, but can be useful. We are also interested in changes over time, since GenAI capabilities are changing at a fast pace, and users are adopting GenAI increasingly. We conducted three consecutive surveys (fall ‘23, winter ‘23, and spring ‘24) among students of all computing programs of a large European research university. We asked questions on the use in education, ethics, and job prospects, and we included specific questions on the (dis)allowed use of GenAI tools in the courses they were taking at the time. We received 264 responses, which we quantitatively and qualitatively analyzed, to find out how students have employed GenAI tools across 59 different computing courses, and whether the opinion of an average student about these tools evolves over time. Our study contributes to the emerging discussion of how to differentiate GenAI use across different courses, and how to align its use with the learning goals of a computing course.",10.1145/3699538.3699546,https://doi.org/10.1145/3699538.3699546
Using Generative AI to Scaffold the Teaching of Software Engineering Team Skills,,Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"Most of the attention on GenAI in computing education has focused on programming-centric tasks, such as code generation, giving feedback on code, or providing synthetic programming partners. Yet in advanced software engineering and project courses, interpersonal skills such as team meetings or customer interviews are equally important but difficult and instructor-intensive to teach realistically. GenAI presents the possibility of scaffolding the teaching of some of these practices by enabling exercises in which students develop the ability to investigate a topic by iteratively asking questions to find a solution. The goal is to create scenarios in which students train to interact with humans in real-world situations, simulating these interactions in a controlled, guided environment. These simulations could help students practice and refine ''soft skills,'' such as teamwork and interviewing, by mimicking the types of exchanges and problem-solving they would encounter in professional environments. This approach allows learners to engage in realistic communication exercises, improving their ability to handle complex, interpersonal tasks through repeated practice with AI-guided feedback. As an example, we envision examples that include requirements elicitation with customers, development team meetings, and discussion with potential investors, to name just a few.",10.1145/3641555.3705107,https://doi.org/10.1145/3641555.3705107
CS1 with a Side of AI: Teaching Software Verification for Secure Code in the Era of Generative AI,"Fernandez, Amanda S. and Cornell, Kimberly A.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"As AI-generated code promises to become an increasingly relied upon tool for software developers, there is a temptation to call for significant changes to early computer science curricula. A move from syntax-focused topics in CS1 toward abstraction and high-level application design seems motivated by the new large language models (LLMs) recently made available. In this position paper however, we advocate for an approach more informed by the AI itself - teaching early CS learners not only how to use the tools but also how to better understand them. Novice programmers leveraging AI-code-generation without proper understanding of syntax or logic can create",10.1145/3626252.3630817,https://doi.org/10.1145/3626252.3630817
Teaching Programming in the Age of Generative AI,"Martini, Simone",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,Programming has been considered the,10.1145/3649217.3653527,https://doi.org/10.1145/3649217.3653527
ChatGPT for Teaching and Learning: An Experience from Data Science Education,"Zheng, Yong",Proceedings of the 24th Annual Conference on Information Technology Education,2023,"ChatGPT, an implementation and application of large language models, has gained significant popularity since its initial release. Researchers have been exploring ways to harness the practical benefits of ChatGPT in real-world scenarios. Educational researchers have investigated its potential in various subjects, e.g., programming, mathematics, finance, clinical decision support, etc. However, there has been limited attention given to its application in data science education. This paper aims to bridge that gap by utilizing ChatGPT in a data science course, gathering perspectives from students, and presenting our experiences and feedback on using ChatGPT for teaching and learning in data science education. The findings not only distinguish data science education from other disciplines but also uncover new opportunities and challenges associated with incorporating ChatGPT into the data science curriculum.",10.1145/3585059.3611431,https://doi.org/10.1145/3585059.3611431
The Impact of AI on Computer Science Education,"Shein, Esther",Commun. ACM,2024,Understanding why “working hard and struggling is … an important way of learning.”,10.1145/3673428,https://doi.org/10.1145/3673428
Evolution of Students' Attitudes Towards the Use of Generative AI Tools in a CS1 Course: Implications for Instructors,"Erez, Yael and Ayali, Lilach and Hazzan, Orit",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"Recent advancements in large language model-based generative artificial intelligence (GenAI) tools have transformed computer science education, presenting both opportunities and challenges. A study investigating students' attitudes toward these tools was conducted during an Introduction to Computer Science course. The target of the study was to gauge students' evolving attitudes toward using GenAI tools in the course, before, during and after ChatGPT was gradually assimilated into homework assignments. The study refers to three phases: preliminary phase, assimilation phase, and calibration stage, which currently takes place. Findings show that, in the preliminary phase, students appreciated the efficiency of GenAI tools offered but were concerned about developing a dependency on these tools and about ''cheating''. Findings from the assimilation phase indicate that consistent, guided exposure to GenAI tools positively shifted students' views, alleviating initial concerns and promoting a positive attitude toward using GenAI tools in the course. The targets of the calibration phase are: a) to examine how to leverage independent learning by formulating clear guidelines that can build trust in the technology and help overcome concerns regarding reliability and credibility; b) to check how GenAI can help students in a Introduction to Computer Science course acquire skills such as critical thinking and code comprehension. The study offers insights for educators on the integration of GenAI tools into computer science courses to enhance learning while maintaining academic integrity.",10.1145/3641555.3705064,https://doi.org/10.1145/3641555.3705064
Generative AI as a Resource for Creativity in Computational Physics,"Hamerski, Patti C.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"Generative artificial intelligence (gen-AI) has become ubiquitous in daily life, including classroom environments where students are using it to assist them on their coursework. Given the widespread use of this tool and the lack of knowledge over how it can support learning, there is a need for educators to have a framework for using it in the classroom and teaching their students usage strategies that are beneficial for learning. One pathway forward is through creativity, a process crucial for learning and also connected to the act of using gen-AI. This poster demonstrates the results of a study designed to provide an in-depth view on how creativity intersects with gen-AI usage in a computational physics course. In the course, students learn about computing tools during group-based, open-ended computational physics activities. Students are often tasked with using gen-AI to explore and help make decisions. The findings demonstrate a connection between using gen-AI and engaging in creative processes, and the implications point to strategies for supporting student usage of gen-AI.",10.1145/3626253.3635595,https://doi.org/10.1145/3626253.3635595
The Widening Gap: The Benefits and Harms of Generative AI for Novice Programmers,"Prather, James and Reeves, Brent N and Leinonen, Juho and MacNeil, Stephen and Randrianasolo, Arisoa S and Becker, Brett A. and Kimmel, Bailey and Wright, Jared and Briggs, Ben",Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1,2024,"Novice programmers often struggle through programming problem solving due to a lack of metacognitive awareness and strategies. Previous research has shown that novices can encounter multiple metacognitive difficulties while programming, such as forming incorrect conceptual models of the problem or having a false sense of progress after testing their solution. Novices are typically unaware of how these difficulties are hindering their progress. Meanwhile, many novices are now programming with generative AI (GenAI), which can provide complete solutions to most introductory programming problems, code suggestions, hints for next steps when stuck, and explain cryptic error messages. Its impact on novice metacognition has only started to be explored. Here we replicate a previous study that examined novice programming problem solving behavior and extend it by incorporating GenAI tools. Through 21 lab sessions consisting of participant observation, interview, and eye tracking, we explore how novices are coding with GenAI tools. Although 20 of 21 students completed the assigned programming problem, our findings show an unfortunate divide in the use of GenAI tools between students who did and did not struggle. Some students who did not struggle were able to use GenAI to accelerate, creating code they already intended to make, and were able to ignore unhelpful or incorrect inline code suggestions. But for students who struggled, our findings indicate that previously known metacognitive difficulties persist, and that GenAI unfortunately can compound them and even introduce new metacognitive difficulties. Furthermore, struggling students often expressed cognitive dissonance about their problem solving ability, thought they performed better than they did, and finished with an illusion of competence. Based on our observations from both groups, we propose ways to scaffold the novice GenAI experience and make suggestions for future work.",10.1145/3632620.3671116,https://doi.org/10.1145/3632620.3671116
Computer Science Education in Latin America and the Caribbean,"Pias, Marcelo and Cuadros-Vargas, Ernesto and Duran, Rodrigo",ACM Inroads,2024,,10.1145/3643646,https://doi.org/10.1145/3643646
Generative AI in Rural High Schools: Challenges and Opportunities,"Michel, Shira",Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing,2025,"Recent advancements in Artificial Intelligence (AI) and more recently, Generative AI (GenAI) approaches have introduced both new challenges and opportunities in educational settings; yet, its effect on rural schools, which already face educational inequities, remains unclear. This study employs a mixed-methods approach using surveys and interviews to explore the current and potential roles of GenAI in rural high school classrooms across three U.S. regions. Preliminary findings reveal mixed perceptions: rural teachers value GenAI's ability to personalize learning but worry about encountering misinformation and feel unprepared to mitigate these risks due to their current level of AI literacy. While GenAI offers potential to enhance students' tech skills and reduce resource disparities, barriers like unreliable internet access and a lack of students owning personal devices still hinder its effectiveness, leaving both teachers and students under-supported in fully leveraging the technology. Overall, this study aims to explore rural teachers' experiences with GenAI to help develop strategies for fair and effective integration that address their unique challenges.",,https://doi.org/10.1145/3672608.3707992
SIGCSE Virtual 2024: Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2,,,2024,"On behalf of SIGCSE Virtual 2024 Steering, Organization, and Program Committees, we would like to welcome you to this wonderful event. SIGCSE Virtual 2024, 1st ACM Virtual Global Computing Education Conference is now a reality after over a year of work by all the committee members. We like to send our special thanks to the SIGCSE Board and ACM for their continued support, encouragement and facilitation.One of the major goals of SIGCSE Virtual is to promote an inclusive and easily accessible conference to all interested in CS education research and practice. The hope is to allow those who are not able to easily travel to SIGCSE conferences to participate virtually from around the world. For this reason, the core of the conference follows all other SIGCSE conferences by providing papers, panels, posters/lightning talks, working groups, and doctoral consortium sessions dedicated to CS education research and practice.The conference has different themes based on the global aspects of CS education while considering regional circumstances. The sessions are offered considering time-zone constraints. The online program adjusts to time zones.Several different activities are provided besides the technical sessions by conference sponsors as well as for social engagements. All these activities are included in the program.",,
Exploring the Potential of Artificial Intelligence Program Generators in Computer Programming Education for Students,"Philbin, Carrie Anne",ACM Inroads,2023,,10.1145/3610406,https://doi.org/10.1145/3610406
Investigating Students' Perspectives on the Value of Help-Seeking Resources in CS Education,"Zahn, Matthew and Heckman, Sarah and Battestilli, Lina",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1,2024,"The accessibility and effectiveness of help-seeking resources plays a pivotal role in contributing to the success of students in Computer Science courses. However, students do not always choose to utilize these resources, and when they do, their experiences can vary. While some students commend help-seeking resources for effectively providing clarification on assignment instructions, debugging code, and addressing questions about course concepts, others share instances where their problems were not resolved, or, in some cases, they did not receive any meaningful guidance from these resources. In this study, we examine the experiences of students enrolled in a CS2 course, all of whom had access to the course's help-seeking resources. These experiences were gathered through qualitative interviews at three time points within a semester. Our findings, derived from emergent coding, reveal thematic patterns in student encounters with help-seeking resources and contribute to a broader theme regarding help-seeking resource utilization at different phases of the semester. The findings of this investigation contribute to the wider conversation on student success and help-seeking resource utilization in Computer Science education.",10.1145/3649165.3690130,https://doi.org/10.1145/3649165.3690130
Handwritten Code Recognition for Pen-and-Paper CS Education,"Islam, Md Sazzad and Doumbouya, Moussa Koulako Bala and Manning, Christopher D. and Piech, Chris",,2024,Teaching Computer Science (CS) by having students write programs by hand on paper has key pedagogical advantages: It allows focused learning and requires careful thinking compared to the use of Integrated Development Environments (IDEs) with intelligent support tools or,10.1145/3657604.3662027,https://doi.org/10.1145/3657604.3662027
No More Pencils No More Books: Capabilities of Generative AI on Irish and UK Computer Science School Leaving Examinations,"Mahon, Joyce and Mac Namee, Brian and Becker, Brett A.",Proceedings of the 2023 Conference on United Kingdom &amp; Ireland Computing Education Research,2023,"We investigate the capabilities of ChatGPT (GPT-4) on second-level (high-school) computer science examinations: the UK A-Level and Irish Leaving Certificate. Both are national, government-set / approved, and centrally assessed examinations. We also evaluate performance differences in exams made publicly available before and after the ChatGPT knowledge cutoff date, and investigate what types of question ChatGPT struggles with. We find that ChatGPT is capable of achieving very high marks on both exams and that the performance difference before and after the knowledge cutoff date are minimal. We also observe that ChatGPT struggles with questions involving symbols or images, which can be mitigated when in-text information ‘fills in the gaps’. Additionally, GPT-4 performance can be negatively impacted when an initial inaccurate answer leads to further inaccuracies in subsequent parts of the same question. Finally, the element of choice on the Leaving Certificate is a significant advantage in achieving a high grade. Notably, there are minimal occurrences of hallucinations in answers and few errors in solutions not involving images. These results reveal several strengths and weaknesses of these exams in terms of how generative AI performs on them and have implications for exam design, the construction of marking schemes, and could also shift the focus of what is examined and how.",10.1145/3610969.3610982,https://doi.org/10.1145/3610969.3610982
ACE '25: Proceedings of the 27th Australasian Computing Education Conference,,,2025,,,
Learning without Limits: Analysing the Usage of Generative AI in a Summative Assessment,"Clift, Lee and Petrovska, Olga",Proceedings of the 9th Conference on Computing Education Practice,2025,"This paper explores how Generative AI (GenAI) can be introduced within summative assessment components in software engineering education. We present an example of an assessment which allows learners to use GenAI in a freeform, constructionist manner, as part of a large, software development project. This work is inspired by previously executed AI-focused assessments and surveys, which explicitly indicate that learners on an Applied Software Engineering Degree Apprenticeship Programme want to formally learn how to use GenAI tools when programming and their employers want to see these skills from graduates. The learning outcome of the assignment was for learners to explore a typical developmental pipeline as a solo developer, moving from design to development to finished product. Learners were marked exclusively on their end product and understanding of application components, not the written code itself, resulting in an assessment where the end product and project were prioritised over foundational code (which was adequately assessed in other components). The results show that all learners used GenAI to some extent during their project, and in all cases, they found it beneficial for large programming tasks. Learners were generally able to produce a larger, more comprehensive and more ambitious project, compared to previous years. It is proposed that removing the barrier to GenAI - and demystifying it - can encourage a constructionist approach to its use, and normalise it as a potential tool for programming.",10.1145/3702212.3702214,https://doi.org/10.1145/3702212.3702214
SIGCSE Virtual 2024: Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1,,,2024,"On behalf of SIGCSE Virtual 2024 Steering, Organization, and Program Committees, we would like to welcome you to this wonderful event. SIGCSE Virtual 2024, 1st ACM Virtual Global Computing Education Conference is now a reality after over a year of work by all the committee members. We like to send our special thanks to the SIGCSE Board and ACM for their continued support, encouragement and facilitation.One of the major goals of SIGCSE Virtual is to promote an inclusive and easily accessible conference to all interested in CS education research and practice. The hope is to allow those who are not able to easily travel to SIGCSE conferences to participate virtually from around the world. For this reason, the core of the conference follows all other SIGCSE conferences by providing papers, panels, posters/lightning talks, working groups, and doctoral consortium sessions dedicated to CS education research and practice.The conference has different themes based on the global aspects of CS education while considering regional circumstances. The sessions are offered considering time-zone constraints. The online program adjusts to time zones.Several different activities are provided besides the technical sessions by conference sponsors as well as for social engagements. All these activities are included in the program.",,
I-Card: A Generative AI-Supported Intelligent Design Method Card Deck,"Chen, Liuqing and Cheang, Wengteng and Jiang, Zhaojun and Xu, Yuan and Cai, Zebin and Sun, Lingyun and Childs, Peter and Han, Ji and Hansen, Preben and Zuo, Haoyu",Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems,2025,"A design method card deck helps designers understand and provoke thinking by presenting each method in a simple format and allow designers to switch between methods seamlessly by maintaining the same simple format across the deck. However, recent observations have shown designers hesitate to use a card deck due to the lack of support, while other tools have provided identified support with generative AI. Through a formative study, we identified the specific support designers need when applying the design method cards and intentions in integrating generative AI. Accordingly, we developed the intelligent design method card deck, I-Card, which integrates generative AI to provide applicable design methods, design knowledge and data support, and interactive and dynamic support. A user study demonstrates that I-Card improved the design efficiency and applicability by offering personalized guidance, enhanced decision-making with comprehensive data generation and provided more design inspiration via interactive support.",10.1145/3706598.3713934,https://doi.org/10.1145/3706598.3713934
ChatGPT as an Assembly Language Interpreter for Computing Education,"Zuo, Fei and Tompkins, Cody and Qian, Gang and Rhee, Junghwan and Qu, Xianshan and Yang, Bokai",J. Comput. Sci. Coll.,2024,"Assembly language is a low-level programming language useful for a number of important computing areas, such as hardware and embedded systems programming, computer architecture, reverse engineering, and malware analysis. In recent years, generative AI, enhanced by GPT technology, has been widely adopted in the IT industry as well as computing education. However, little work has been done to investigate the applicability of GPT to teaching assembly language. In this paper, we fill in the gap by providing an empirical study of GPT's ability to interpret assembly instructions. In particular, we manually evaluated GPT-4's per-instruction explanations of code segments for four different computer architectures, namely x86, x86-64, ARM, and AArch64. Our study shows that, while inconsistencies and rare errors do exist, GPT's interpretations are highly accurate in general, demonstrating a great potential for such tools to be applied in pedagogical practices for tutoring assembly language.",,
LLM-itation is the Sincerest Form of Data: Generating Synthetic Buggy Code Submissions for Computing Education,"Leinonen, Juho and Denny, Paul and Kiljunen, Olli and MacNeil, Stephen and Sarsa, Sami and Hellas, Arto",Proceedings of the 27th Australasian Computing Education Conference,2025,"There is a great need for data in computing education research. Data is needed to understand how students behave, to train models of student behavior to optimally support students, and to develop and validate new assessment tools and learning analytics techniques. However, relatively few computing education datasets are shared openly, often due to privacy regulations and issues in making sure the data is anonymous. Large language models (LLMs) offer a promising approach to create large-scale, privacy-preserving synthetic data, which can be used to explore various aspects of student learning, develop and test educational technologies, and support research in areas where collecting real student data may be challenging or impractical. This work explores generating synthetic buggy code submissions for introductory programming exercises using GPT-4o. We compare the distribution of test case failures between synthetic and real student data from two courses to analyze the accuracy of the synthetic data in mimicking real student data. Our findings suggest that LLMs can be used to generate synthetic incorrect submissions that are not significantly different from real student data with regard to test case failure distributions. Our research contributes to the development of reliable synthetic datasets for computing education research and teaching, potentially accelerating progress in the field while preserving student privacy.",10.1145/3716640.3716647,https://doi.org/10.1145/3716640.3716647
Promoting Ethical Use of Generative AI in Education,"Deng, Xuefei (Nancy) and Joshi, K.D.",SIGMIS Database,2024,"Generative artificial intelligence (AI) represents a crucial subset of AI models characterized by their ability to generate new content based on user input, showing vast potential to transform learning and teaching. However, educators have raised ethical concerns, particularly regarding the adverse effect on students' learning if students simply parrot generative AI-generated content without engaging in critical analysis or original thought. Moreover, there exists the potential of generative AI to perpetuate existing biases in training data. This editorial discusses three major concerns in generative AI use in education and proposes questions (on task-AI fit and people-AI fit) and approaches to address the ethical considerations by adopting five principles of AI ethics. The editorial also discusses developing a classroom AI use policy as one governance mechanism for promoting ethical use of AI. As generative AI technology continues to evolve, so must our educational practices. The editorial ends with a call for readers (educators) to collaboratively define the terms of engagement with generative AI in educational settings and to begin this discourse by sharing insights and experiences with promoting ethical use of generative AI.",10.1145/3685235.3685237,https://doi.org/10.1145/3685235.3685237
AI in Computing Education from Research to Practice,"Akram, Bita and Leinonen, Juho and Norouzi, Narges and Prather, James and Zhang, Lisa",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"The panel comprises a diverse set of Computing educators working on AI in education. The panelists will address four areas of AI in Computing education: 1) AI for introductory CS classrooms, 2) Investigating opportunities presented by LLMs, 3) LLM-based tool development, and 4) Ethics and inclusion in AI curriculum. The panel will share experiences and discuss opportunities and challenges in AI education with the community.",10.1145/3626253.3631657,https://doi.org/10.1145/3626253.3631657
"LLMs Still Can't Avoid Instanceof: An Investigation Into GPT-3.5, GPT-4 and Bard's Capacity to Handle Object-Oriented Programming Assignments","Cipriano, Bruno Pereira and Alves, Pedro",Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training,2024,"Large Language Models (LLMs) have emerged as promising tools to assist students while solving programming assignments. However, object-oriented programming (OOP), with its inherent complexity involving the identification of entities, relationships, and responsibilities, is not yet mastered by these tools. Contrary to introductory programming exercises, there exists a research gap with regard to the behavior of LLMs in OOP contexts. In this study, we experimented with three prominent LLMs - GPT-3.5, GPT-4, and Bard - to solve real-world OOP exercises used in educational settings, subsequently validating their solutions using an Automatic Assessment Tool (AAT). The findings revealed that while the models frequently achieved mostly working solutions to the exercises, they often overlooked the best practices of OOP. GPT-4 stood out as the most proficient, followed by GPT-3.5, with Bard trailing last. We advocate for a renewed emphasis on code quality when employing these models and explore the potential of pairing LLMs with AATs in pedagogical settings. In conclusion, while GPT-4 showcases promise, the deployment of these models in OOP education still mandates supervision.",10.1145/3639474.3640052,https://doi.org/10.1145/3639474.3640052
Using Generative AI to Support PK-12 Teaching and Learning: Developing Sample Lessons and More,"Ruiz, Pati and Rangel, Alessandra and Coenraad, Merijke",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"North Salem Central School District (North Salem) has worked with researchers as part of a larger Research Practice Partnership (RPP) to design and implement an inclusive PK-12 computing pathway in their district. This poster describes how teachers used Generative AI (GenAI) tools in three areas: (1) the development of sample computational thinking (CT) lesson plans; (2) initial brainstorming; and (3) professional learning.As North Salem reflected on their use of GenAI tools, they named two AI tools specifically: OpenAI's ChatGPT-4 and Bing's Image Creator. Teachers also describe ethical dilemmas that they faced when integrating GenAI tools as well as other concerns that will be described below. This work builds on the growing literature on the use of Generative AI tools to support the day-to-day work of teachers.",10.1145/3626253.3635522,https://doi.org/10.1145/3626253.3635522
Software Engineering Education for the Next Generation:SEENG 2023 Workshop Report,"Krusche, Stephan and Bell, Jonathan and Tenbergen, Bastian",SIGSOFT Softw. Eng. Notes,2023,"The 5th International Workshop on Software Engineering Education for the Next Generation was held on May 16, 2023 in Melbourne, Australia. The workshop was part of the 45th International Conference on Software Engineering. It specifically supported the general theme of",10.1145/3617946.3617959,https://doi.org/10.1145/3617946.3617959
Exploring Multimodal Generative AI for Education through Co-design Workshops with Students,"Prasad, Prajish and Balse, Rishabh and Balchandani, Dhwani",Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems,2025,"Multimodal large language models (MLLMs) are Generative AI models that take different modalities such as text, audio, and video as input and generate appropriate multimodal output. Since such models will be integrated into future educational tools, a human-centered design approach that takes students’ perspectives into account is essential while designing such applications.This paper describes two co-design workshops which were conducted with 79 student groups to examine how they design and prototype future educational tools integrated with MLLMs. Through various activities in the workshops, students discussed relevant educational problems, created journey maps, storyboards and low fidelity prototypes for their applications, and evaluated their applications based on relevant design principles. We found that students’ applications used MLLMs for important learning environment design features such as multimodal content creation, personalization, and feedback. Based on these findings, we discuss future research directions for the design of multimodality in generative AI educational applications.",10.1145/3706598.3714146,https://doi.org/10.1145/3706598.3714146
Enhancing Undergraduate Computing Education with LMMs and ChatGPT-4o,"Liao, Weidong and Guzide, Osman",J. Comput. Sci. Coll.,2024,"Large Language Models (LLMs) and ChatGPT have significantly impacted programming practices and computer science education. The rapid advancements in natural language processing, recurrent neural networks, and Transformer architectures have captured the attention of students and educators alike. These tools aid students in brainstorming, coding, analyzing code, and writing reports. Although concerns about cheating and plagiarism persist, these tools also provide educators with novel ways to create and assess assignments. Despite some hesitancy among educators to integrate these AI tools into the classroom, the advert and development of Large MultiModal Models (LMMs), the enhancement of LLMs that can deal with multimedia inputs and outputs, illustrates a significant evolution in generative AI capabilities.",,
Generative AI Integrated Educational Model for User-Centered Design,"Wu, Yanan and Zeng, Xiaoping and Lin, Qibei",Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education,2025,"The advent of artificial intelligence (AI) has profoundly transformed the educational landscape. Many educators are exploring how AI tools can enhance learning instructional programs. However, there is less focus on how its application within design education—particularly when teaching user-centered design. This study developed an educational model utilizing AI for user-centered design curriculum. Based on design thinking theory, this model integrates ChatGPT and Midjourney into the divergent and convergent design phases to facilitate the workflow. The empirical research showed that educational model can foster students’ creativity and problem-solving skills. The findings highlight the efficacy of AI integration in curricula design and instructional practices.",10.1145/3722237.3722260,https://doi.org/10.1145/3722237.3722260
Enhancing Pedagogy with Generative AI: Video Production from Course Descriptions,"Weerakoon, Oshani and Lepp\",Proceedings of the International Conference on Computer Systems and Technologies 2024,2024,"This paper explores a novel workflow that integrates Generative AI tools, ChatGPT and DALL·E, into educational use, aiming to improve the traditional teaching methods in university education. Our workflow is focused on creating short introductory videos for university courses, using primary course descriptions available in the university’s study guide with the idea of introducing courses visually. This approach was deliberately selected for experimentation, and we believe that it could be further enhanced to generate course videos on specific course topics. This will minimize the efforts of teachers who are required to produce detailed course videos as a part of their teaching. As the first part of our workflow, we present a tool that utilizes ChatGPT-4 and DALL·E 2 to autonomously generate a script and background graphics for videos, using primary course descriptions extracted through a given course web URL. As the second part of the workflow, we combine those generated artefacts into videos using Narakeet, a Text-to-Speech software service that is available online. To analyze the feasibility of this workflow, we then conducted a field survey where university teachers participated in reviewing introductory course videos of their courses generated through our workflow. We employed only engineering courses that are English-taught in this field survey. The results demonstrate the potential of AI-generated content to increase the efficiency of teachers when creating video materials. However, challenges such as the uncanny valley effect in text-to-speech narration and the propensity for AI-generated misinformation highlight the need for careful review by humans on such content before setting it for wider use. This paper argues for the strategic integration of AI in university education, focusing on the benefits, while acknowledging the limitations owned by generative AI tools.",10.1145/3674912.3674922,https://doi.org/10.1145/3674912.3674922
Generative AI and its Impact on the CS Classroom and Programmers,"Lindoo, Ed and Lotfy, Mohamed",J. Comput. Sci. Coll.,2024,"As the integration of generative artificial intelligence (AI) in educational settings becomes more widespread, students, teachers, and educational institutions face the challenge of utilizing these technologies in a responsible manner. The responsible use of generative AI can help CS and IT students develop critical thinking, enhance their learning experience, facilitate the learning process, can assist in understanding code concepts, programming skills, and/or enhancing the programming knowledge. The aim of this investigation is on how students might utilize, and potentially abuse, generative AI. In this paper we provide examples of how generative AI can be used to generate code modules. We discuss the use of generative AI in programming classes as well as its impact on the future of programming and programmers.",,
Where's the Data? Finding and Reusing Datasets in Computing Education,"Kiesler, Natalie and Impagliazzo, John and Biernacka, Katarzyna and Kapoor, Amanpreet and Kazmi, Zain and Ramagoni, Sujeeth Goud and Sane, Aamod and Tran, Keith and Taneja, Shubbhi and Wu, Zihan",Working Group Reports on 2023 ACM Conference on Global Computing Education,2024,"Computing education research (CER) is a rapidly advancing discipline, offering vast potential for data-driven, secondary research or replication studies. Although gathering and analyzing data for research seem straightforward, making research data publicly available to the community remains a challenge. Likewise, finding and reusing high-quality, prominent, and well-documented research data proves to be a daunting task. In this working group paper, the authors present their search for available datasets in the CER context (e.g., in databases and repositories). The available datasets are further analyzed using a newly developed metadata scheme and presented to the community as a resource. The second component of this work is a summary of the community's perspective and concerns on publishing their research data, which has been gathered through a survey among 52 computing education researchers. Based on this status quo, this report presents recommendations for measures and future steps for the community to become more accessible and establish open data practices. We thus emphasize the potential of making research data available to enhance productivity, transparency, and reproducibility in the CER community.",10.1145/3598579.3689378,https://doi.org/10.1145/3598579.3689378
ChatGPT in Computer Science Curriculum Assessment: An analysis of Its Successes and Shortcomings,"Qureshi, Basit","Proceedings of the 2023 9th International Conference on E-Society, e-Learning and e-Technologies",2023,"The application of Artificial intelligence for teaching and learning in the academic sphere is a trending subject of interest in computing education. ChatGPT, as an AI-based tool, provides various advantages, such as heightened student involvement, cooperation, accessibility, and availability. This paper addresses the prospects and obstacles associated with utilizing ChatGPT as a tool for learning and assessment in undergraduate Computer Science curriculum in particular to teaching and learning fundamental programming courses. Students having completed the course work for a Data Structures and Algorithms (a sophomore-level course) participated in this study. Two groups of students were given programming challenges to solve within a short period of time. The control group (group A) had access to textbooks and notes of programming courses, however, no Internet access was provided. Group B students were given access to ChatGPT and were encouraged to use it to help solve the programming challenges. The challenge was conducted in a computer lab environment using Programming Contest Control (PC2) environment which is widely used in ACM International Collegiate Programming Contest (ICPC). Each team of students addresses the problem by writing executable code that satisfies a certain number of test cases. Student teams were scored based on their performance in terms of the number of successfully passed test cases. Results show that students using ChatGPT had an advantage in terms of earned scores, however, there were inconsistencies and inaccuracies in the submitted code consequently affecting the overall performance. After a thorough analysis, the paper’s findings indicate that incorporating AI in higher education brings about various opportunities and challenges. Nonetheless, universities can efficiently manage these apprehensions by adopting a proactive and ethical stance toward the implementation of such tools.",10.1145/3613944.3613946,https://doi.org/10.1145/3613944.3613946
Generative AI Tools in Higher Education: A Meta-Analysis of Cognitive Impact,"Qu, Xiaodong and Sherwood, Joshua and Liu, Peiyan and Aleisa, Nawwaf",Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems,2025,"This meta-analysis examines the cognitive impact of Generative Artificial Intelligence (GenAI) tools on college students, focusing on various levels of Bloom’s taxonomy. As GenAI integration in higher education grows, understanding its influence on critical thinking, problem-solving, and creativity is essential. Using a mixed-effects model, we synthesized data from quantitative studies to explore two moderators: cognitive skill level (e.g., understanding, applying, analyzing) and instructional context (instructed vs. unguided use). Our findings indicate that GenAI tools significantly enhance lower-order cognitive outcomes, particularly in understanding and applying concepts, with instructed use producing stronger positive effects than unguided use. However, their impact on higher-order cognitive skills, such as creating and evaluating, was minimal. These results highlight the importance of tailoring GenAI integration to task complexity and underscore the value of guided instruction in maximizing its educational benefits. Educators should prioritize instructional strategies that encourage active engagement with GenAI tools, particularly for fostering critical thinking and creativity.",10.1145/3706599.3719841,https://doi.org/10.1145/3706599.3719841
"AI in CS Education: Opportunities, Challenges, and Pitfalls to Avoid","Vahid, Frank",ACM Inroads,2024,,10.1145/3679205,https://doi.org/10.1145/3679205
The Metacognitive Demands and Opportunities of Generative AI,"Tankelevitch, Lev and Kewenig, Viktor and Simkute, Auste and Scott, Ava Elizabeth and Sarkar, Advait and Sellen, Abigail and Rintel, Sean",Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems,2024,"Generative AI (GenAI) systems offer unprecedented opportunities for transforming professional and personal work, yet present challenges around prompting, evaluating and relying on outputs, and optimizing workflows. We argue that metacognition—the psychological ability to monitor and control one’s thoughts and behavior—offers a valuable lens to understand and design for these usability challenges. Drawing on research in psychology and cognitive science, and recent GenAI user studies, we illustrate how GenAI systems impose metacognitive demands on users, requiring a high degree of metacognitive monitoring and control. We propose these demands could be addressed by integrating metacognitive support strategies into GenAI systems, and by designing GenAI systems to reduce their metacognitive demand by targeting explainability and customizability. Metacognition offers a coherent framework for understanding the usability challenges posed by GenAI, and provides novel research and design directions to advance human-AI interaction.",10.1145/3613904.3642902,https://doi.org/10.1145/3613904.3642902
Scaling Up Mastery Learning with Generative AI: Exploring How Generative AI Can Assist in the Generation and Evaluation of Mastery Quiz Questions,"Hutt, Stephen and Hieb, Grayson",,2024,"Generative AI has the potential to scale a number of educational practices, previously limited by resources. One such instructional approach is mastery learning, a pedagogy emphasizing proficiency before progression that is highly resource (teacher time, materials) intensive. The rise of computer-based instruction offered partial solutions, tailoring student progression and automating some facets of the mastery learning process. This work in progress considers the application of large language models for content generation tailored to mastery learning. We present a paired framework for analyzing and evaluating the generated content relative to rubrics designed by the teacher. Recognizing the potential of large language models, we critically assess the potential of improving mastery-based instruction. We close our discussion by considering the applications and limitations of this approach.",10.1145/3657604.3664699,https://doi.org/10.1145/3657604.3664699
Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1,"Ravi, Prerna and Parks, Robert and Masla, John and Abelson, Hal and Breazeal, Cynthia",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1,2024,"Data science is emerging as a crucial 21st-century competence, influencing professional practices from citing evidence when advocating for social change to developing artificial intelligence (AI) models. For middle and high school students, data science can put formerly decontextualized subjects into real-world scenarios. Many existing curricula, however, lack authenticity and personal relevance for students. A critique of data science courseware cites the lack of",10.1145/3649165.3703623,https://doi.org/10.1145/3649165.3703623
CEP '25: Proceedings of the 9th Conference on Computing Education Practice,,,2025,,,
ECSEE '23: Proceedings of the 5th European Conference on Software Engineering Education,,,2023,,,
Use of Generative AI for Fictional Field Studies in Design Courses,R\,Adjunct Proceedings of the 2024 Nordic Conference on Human-Computer Interaction,2024,"In this paper, we present how we used generative AI (GenAI) as a pedagogical tool for students taking a course in tangible interaction design. In this course, the students design different physical-digital objects (PDOs) to learn designing, sketching and prototyping with code and hardware. However, due to the short course duration these PDOs are not evaluated or explored with any kind of field or user study. Therefore we gave the students the exercise of doing user interviews with GenAI to explore their design ideas further. With this paper, we contribute a description and the outcomes of this approach, and highlight the pedagogical implications for student learning.",10.1145/3677045.3685439,https://doi.org/10.1145/3677045.3685439
Cracking the code: Co-coding with AI in creative programming education,"Jonsson, Martin and Tholander, Jakob",Proceedings of the 14th Conference on Creativity and Cognition,2022,"This paper presents a study of a group of university students using generative machine learning to translate from natural language to computer code. The study explores how the use of the AI tool can be understood in terms of co-creation, focusing on the one hand on how the tool may serve as a resource for understanding and learning, and on the other hand how the tool affects the creative processes. Findings show how the participants search for a ’correct’ syntax in their instructions to the machine learning tool, and how the inconsistent and erroneous behavior can work as a way to generate clues and inspiration for generating creative expressions. The notion of friction is used to describe how systems like this can serve to both lower thresholds for programming, and also interfere with the creative processes, encouraging reflection and exploration of alternative solutions.",10.1145/3527927.3532801,https://doi.org/10.1145/3527927.3532801
Evaluating the Effectiveness of LLMs in Introductory Computer Science Education: A Semester-Long Field Study,"Lyu, Wenhan and Wang, Yimeng and Chung, Tingting (Rachel) and Sun, Yifan and Zhang, Yixuan",,2024,"The integration of AI assistants, especially through the development of Large Language Models (LLMs), into computer science education has sparked significant debate, highlighting both their potential to augment student learning and the risks associated with their misuse. An emerging body of work has looked into using LLMs in education, primarily focusing on evaluating the performance of existing models or conducting short-term human subject studies. However, very little work has examined the impacts of LLM-powered assistants on students in entry-level programming courses, particularly in real-world contexts and over extended periods. To address this research gap, we conducted a semester-long, between-subjects study with 50 students using CodeTutor, an LLM-powered assistant developed by our research team. Our study results show that students who used CodeTutor (the",10.1145/3657604.3662036,https://doi.org/10.1145/3657604.3662036
Thrilled by Your Progress! Large Language Models (GPT-4) No Longer Struggle to Pass Assessments in Higher Education Programming Courses,"Savelka, Jaromir and Agarwal, Arav and An, Marshall and Bogart, Chris and Sakr, Majd",Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1,2023,"This paper studies recent developments in large language models’ (LLM) abilities to pass assessments in introductory and intermediate Python programming courses at the postsecondary level. The emergence of ChatGPT resulted in heated debates of its potential uses (e.g., exercise generation, code explanation) as well as misuses in programming classes (e.g., cheating). Recent studies show that while the technology performs surprisingly well on diverse sets of assessment instruments employed in typical programming classes the performance is usually not sufficient to pass the courses. The release of GPT-4 largely emphasized notable improvements in the capabilities related to handling assessments originally designed for human test-takers. This study is the necessary analysis in the context of this ongoing transition towards mature generative AI systems. Specifically, we report the performance of GPT-4, comparing it to the previous generations of GPT models, on three Python courses with assessments ranging from simple multiple-choice questions (no code involved) to complex programming projects with code bases distributed into multiple files (599 exercises overall). Additionally, we analyze the assessments that were not handled well by GPT-4 to understand the current limitations of the model, as well as its capabilities to leverage feedback provided by an auto-grader. We found that the GPT models evolved from completely failing the typical programming class’ assessments (the original GPT-3) to confidently passing the courses with no human involvement (GPT-4). While we identified certain limitations in GPT-4’s handling of MCQs and coding exercises, the rate of improvement across the recent generations of GPT models strongly suggests their potential to handle almost any type of assessment widely used in higher education programming courses. These findings could be leveraged by educators and institutions to adapt the design of programming assessments as well as to fuel the necessary discussions into how programming classes should be updated to reflect the recent technological developments. This study provides evidence that programming instructors need to prepare for a world in which there is an easy-to-use widely accessible technology that can be utilized by learners to collect passing scores, with no effort whatsoever, on what today counts as viable programming knowledge and skills assessments.",10.1145/3568813.3600142,https://doi.org/10.1145/3568813.3600142
CompEd 2023: Working Group Reports on 2023 ACM Conference on Global Computing Education,,,2024,"Welcome to the Working Group proceedings of the ACM Global Computing Education Conference (CompEd), held in Hyderabad, India, hosted by IIIT Hyderabad, from 6th December to the 9th December 2023.As stated in previous Working Group proceedings",,
Empowering Creativity with Generative AI in Digital Art Education,"Kicklighter, Caleb and Seo, Jinsil Hwaryoung and Andreassen, Mayet and Bujnoch, Emily",ACM SIGGRAPH 2024 Educator's Forum,2024,"Artificial intelligence is dramatically changing the creative process for many practices. We see this as an opportunity to enrich student projects within our classroom. We created educational materials and conducted an initial study in the Fall of 2023. The study focuses on the impact that image-based generative AI tools could have on the creative process for students in the 3D Animation classroom. We found that, within our class, most students found AI useful for their productivity, but further work was needed to educate students and to create a safe space for students to explore how these tools can enhance their creative work.",10.1145/3641235.3664438,https://doi.org/10.1145/3641235.3664438
Exploring Students Solutions to Concurrent and Parallel Programming Exercises – Impact of Generative AI,"Mozgovoy, Maxim and Suero Montero, Calkin",Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 2,2024,"Background. Concurrent and parallel programming is difficult to teach and learn as the understanding of complex and abstract concepts such as nondeterminism, semaphore, and rare conditions, among others, is required [1, 2, 9], having as a core issue the synchronisation of processes to achieve a common goal [4]. It is well-acknowledged that concurrent and parallel programming skills are fundamental since, nowadays, computing is increasingly handled in a parallel manner [7].Problem and Motivation. Therefore, identifying students’ pitfalls and successes when solving practical concurrent and parallel programming exercises could shed light on the best approaches and strategies that they use [3]. In addition, the advent of large language models, and generative AI applications such as ChatGPT, has prompted intensive research on their use in several areas including programming teaching and learning [8]. Yet, the studies in the literature have focused on issues related to learning to program by novice students in introductory courses (e.g., CS1, CS2) [6]. Less work, however, has been presented on the impact of generative AI tools in advanced programming practices such as concurrent and parallel programming.Methodology. To investigate whether generative AI has had an impact on the submitted concurrent and parallel programming exercises solutions at the University of Aizu, Japan, we performed a comparison analysis of the students’ submissions over 2020–2023. The analysis included five different exercises covering the basis of concurrency through various tasks and scenarios where the implementation of parallel processes is needed as solution. For instance, exercises 2.3 and 2.4 required to create parallel processes and perform independent computations; exercises 3.2 and 3.3, required synchronisation of the parallel processes; and in exercise 3.5 a code template was given for modification. We analysed the submissions of 72 undergraduate 3rd year students (avg. 18 students/year) and labelled the solutions using the following nomenclature: OK, indicating a good solution; OKFeat, a good solution but with unusual features; AdvLib, use of unnecessary advanced library or functionality; BadTool, use of an inappropriate tool when the task definition explicitly required a different tool; CodeErr, general coding error; SyncErr, concurrent programming specific error; N/A, solution not submitted or incomplete.Results and Analysis. Results show a substantial increase in the incidence of use of advance libraries (AdvLib) and the wrong tools (BadTool) among students in 2023 for three out of the five analysed exercises. At the same time the concurrency programming-specific errors (SyncErr) also see a reduction in all the exercises. (Figure 1). This coincides with the availability of generative AI tools such as ChatGPT [5], which warrants further investigations to understand how students, teachers and instructors could harness the affordances of large language models in their concurrent programming learning, teaching, and practice.Contribution and Impact. This paper presents an initial step towards investigating the impact of generative AI on advanced programming topics. This research will continue to uncover strategies for the lecturers and instructors to identify the affordances and use of generative AI and to design exercises that harness these affordances to support students learning of difficult programming concepts.",10.1145/3632621.3671424,https://doi.org/10.1145/3632621.3671424
Generative AI in Software Development Education: Insights from a Degree Apprenticeship Programme,"Petrovska, Olga and Clift, Lee and Moller, Faron",Proceedings of the 2023 Conference on United Kingdom &amp; Ireland Computing Education Research,2023,"We describe insights gained from incorporating ChatGPT into assignments for our Software Engineering Degree Apprenticeship programme, including attitudes expressed by the learners and their employers regarding our approach.",10.1145/3610969.3611132,https://doi.org/10.1145/3610969.3611132
The Potential and Implications of Generative AI on HCI Education,"Kharrufa, Ahmed and Johnson, Ian",Proceedings of the 6th Annual Symposium on HCI Education,2024,"Generative AI (GAI) is impacting teaching and learning directly or indirectly across a range of subjects and disciplines. As educators, we need to understand the potential and limitations of AI in HCI education and ensure our graduating HCI students are aware of the potential and limitations of AI in HCI. In this paper, we report on the main pedagogical insights gained from the inclusion of generative AI into a 10-week undergraduate module. We designed the module to encourage student experimentation with GAI models as part of the design brief requirement and planned practical sessions and discussions. Our insights are based on replies to a survey sent out to the students after completing the module. Our key findings, for HCI educators, report on the use of AI as a persona for developing project ideas and creating resources for design, and AI as a mirror for reflecting students’ understanding of key concepts and ideas and highlighting knowledge gaps. We also discuss potential pitfalls that should be considered and the need to assess students’ literacies and assumptions of GAIs as pedagogical tools. Finally, we put forward the case for educators to take the opportunities GAI presents as an educational tool and be experimental, creative, and courageous in their practice. We end with a discussion of our findings in relation to the TPACK framework in HCI.",10.1145/3658619.3658627,https://doi.org/10.1145/3658619.3658627
Patterns of Student Help-Seeking When Using a Large Language Model-Powered Programming Assistant,"Sheese, Brad and Liffiton, Mark and Savelka, Jaromir and Denny, Paul",Proceedings of the 26th Australasian Computing Education Conference,2024,"Providing personalized assistance at scale is a long-standing challenge for computing educators, but a new generation of tools powered by large language models (LLMs) offers immense promise. Such tools can, in theory, provide on-demand help in large class settings and be configured with appropriate guardrails to prevent misuse and mitigate common concerns around learner over-reliance. However, the deployment of LLM-powered tools in authentic classroom settings is still rare, and very little is currently known about how students will use them in practice and what type of help they will seek. To address this, we examine students’ use of an innovative LLM-powered tool that provides on-demand programming assistance without revealing solutions directly. We deployed the tool for 12 weeks in an introductory computer and data science course&nbsp;(n = 52), collecting more than 2,500 queries submitted by students throughout the term. We manually categorized all student queries based on the type of assistance sought, and we automatically analyzed several additional query characteristics. We found that most queries requested immediate help with programming assignments, whereas fewer requests asked for help on related concepts or for deepening conceptual understanding. Furthermore, students often provided minimal information to the tool, suggesting this is an area in which targeted instruction would be beneficial. We also found that students who achieved more success in the course tended to have used the tool more frequently overall. Lessons from this research can be leveraged by programming educators and institutions who plan to augment their teaching with emerging LLM-powered tools.",10.1145/3636243.3636249,https://doi.org/10.1145/3636243.3636249
ICSE-SEET '24: Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training,,,2024,,,
How CO2STLY Is CHI? The Carbon Footprint of Generative AI in HCI Research and What We Should Do About It,"Inie, Nanna and Falk, Jeanette and Selvan, Raghavendra",Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems,2025,"The energy cost of developing and deploying Generative AI (GenAI) models has exploded with their mass adoption, as has the ensuing carbon emissions. The climate impact of this is currently unknown. In Human-Computer Interaction, GenAI models are rarely trained but often used. Based on detailed review of 282 papers, we estimate this footprint from energy consumption of the total use of GenAI for CHI 2024 research as between 10,769.63 and 10,925.12 kg CO2e — equal to driving a car for more than 100,000 km. We show that in CHI research, GenAI is most often used for Prototyping, Evaluation &amp; User studies, and that Data Collection and Fine-tuning models incurs the highest CO2st.1 We find that CHI submissions are unlikely to report GenAI use transparently, which makes precise calculations difficult. By measuring the usage of a subset of the papers on local hardware, we obtain estimations of the energy consumption and carbon footprint. Based on this evidence, we discuss and demonstrate ways to mitigate the issues of GenAI carbon footprint and lack of transparency.",10.1145/3706598.3714227,https://doi.org/10.1145/3706598.3714227
Generative Co-Learners: Enhancing Cognitive and Social Presence of Students in Asynchronous Learning with Generative AI,"Wang, Tianjia and Wu, Tong and Liu, Huayi and Brown, Chris and Chen, Yan",Proc. ACM Hum.-Comput. Interact.,2025,"Cognitive presence and social presence are crucial for a comprehensive learning experience. Despite the flexibility of asynchronous learning environments to accommodate individual schedules, the inherent constraints of asynchronous environments make augmenting cognitive and social presence particularly challenging. Students often face challenges such as a lack of timely feedback and support, an absence of non-verbal cues in communication, and a sense of isolation. To address this challenge, this paper introduces Generative Co-Learners, a system designed to leverage generative AI-powered agents, simulating co-learners supporting multimodal interactions, to improve cognitive and social presence in asynchronous learning environments. We conducted a study involving 12 student participants who used our system to engage with online programming tutorials to assess the system's effectiveness. The results show that by implementing features to support textual and visual communication and simulate an interactive learning environment with generative agents, our system enhances the cognitive and social presence in the asynchronous learning environment. These results suggest the potential to use generative AI to support student learning and transform asynchronous learning into a more inclusive, engaging, and efficacious educational approach.",10.1145/3701198,https://doi.org/10.1145/3701198
Design of An Eye-Tracking Study Towards Assessing the Impact of Generative AI Use on Code Summarization,"Mohamed, Suad and Ismail, Najma and Amaya Hernandez, Kimberly and Parvin, Abdullah and Oliver, Michael and Parra, Esteban",Proceedings of the 2025 Symposium on Eye Tracking Research and Applications,2025,"As large language models (LLMs) become more integrated into software engineering and computer science education, it is crucial to understand their impact on student learning. While recent research has explored student perceptions of generative AI, little is known about how these tools influence students’ cognitive processes during programming tasks, such as code comprehension, a valuable skill in software development and maintenance. This paper presents the design of a study that aims to investigate how computer science students interact with LLMs, such as Google’s Gemini, in the context of code summarization using eye-tracking. This study will examine differences in visual attention, fixation behaviors, and performance of students engaged in code summarization with and without AI assistance across varying experience levels.",10.1145/3715669.3725868,https://doi.org/10.1145/3715669.3725868
Arguments for and Approaches to Computing Education in Undergraduate Computer Science Programmes,"Cutts, Quintin and Kallia, Maria and Anderson, Ruth and Crick, Tom and Devlin, Marie and Farghally, Mohammed and Mirolo, Claudio and Runde, Ragnhild Kobro and Sepp\",Proceedings of the 2023 Working Group Reports on Innovation and Technology in Computer Science Education,2023,"Computing education (CE), the scientific foundation of the teaching and learning of subject matter specific to computing, has matured into a field with its own research journals and conferences as well as graduate programmes. Yet, and unlike other mature subfields of computer science (CS), it is rarely taught as part of undergraduate CS programmes. In this report, we present a gap analysis resulting from semi-structured interviews with various types of stakeholders and derive a set of arguments for teaching CE courses in undergraduate CS programmes. This analysis and the arguments highlight a number of opportunities for the discipline of CS at large, in academia, in industry, and in school education, that would be opened up with undergraduate CE courses, as well as potential barriers to implementation that will need to be overcome. We also report on the results of a Delphi process performed to elicit topics for such a course with various audiences in mind. The Delphi process yielded 19 high-level categories that encompass the subject matter CE courses should incorporate, tailored to the specific needs of their intended student audiences. This outcome underscores the extensive range of content that can be integrated into a comprehensive CE programme. Based on these two stakeholder interactions as well as a systematic literature review aiming to explore the current practices in teaching CE to undergraduate students, we develop two prototypical outlines of such a course, keeping in mind that departments may have different preferences and affordances resulting in different kinds of CE offerings. Overall, input from external stakeholders underscores the clear significance of undergraduate CE courses. We anticipate leveraging this valuable feedback to actively promote these courses on a broader scale.",10.1145/3623762.3633494,https://doi.org/10.1145/3623762.3633494
Impact of Generative AI on K-12 Students’ Perceptions of Computing: A Research Proposal,"Philbin, Carrie Anne",Proceedings of the 18th WiPSCE Conference on Primary and Secondary Computing Education Research,2023,"The rapid progress of generative artificial intelligence (AI) is fundamentally reshaping traditional perspectives on knowledge and skills, with profound implications for computing education. This necessitates a thorough examination of the relevance and timeliness of computing as a subject, especially for K-12 students who are making critical decisions about their future qualifications. This abstract proposes an empirical research study that aims to explore the effects of integrating generative AI in the creation of digital artefacts on K-12 students’ perceptions of the value of computing, as well as their understanding of ownership and achievement. Constructive discussions regarding the outlined approach are encouraged.",10.1145/3605468.3609775,https://doi.org/10.1145/3605468.3609775
Generative AI and News Consumption: Design Fictions and Critical Analysis,"Kiskola, Joel and Rydenfelt, Henrik and Olsson, Thomas and Haapanen, Lauri and V\",Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems,2025,"The emergence of Generative AI features in news applications may radically change news consumption and challenge journalistic practices. To explore the future potentials and risks of this understudied area, we created six design fictions depicting scenarios such as virtual companions delivering news summaries to the user, AI providing context to news topics, and content being transformed into other formats on demand. The fictions, discussed with a multi-disciplinary group of experts, enabled a critical examination of the diverse ethical, societal, and journalistic implications of AI shaping this everyday activity. The discussions raised several concerns, suggesting that such consumer-oriented AI applications can clash with journalistic values and processes. These include fears that neither consumers nor AI could successfully balance engagement, objectivity, and truth, leading to growing detachment from shared understanding. We offer critical insights into the potential long-term effects to guide design efforts in this emerging application area of GenAI.",10.1145/3706598.3713804,https://doi.org/10.1145/3706598.3713804
CompEd 2023: Proceedings of the ACM Conference on Global Computing Education Vol 2,,,2023,"It is our great pleasure to welcome participants to the 2nd ACM Global Conference on Computing Education (ACM CompEd 2023) being held in Hyderabad, India, 7th-9th December, 2023 with the Working Groups meetings being held on 5th and 6th December 2023.ACM CompEd is a recent addition to the list of ACM sponsored conferences devoted to research in all aspects of computing education, including education at the school and college levels. The Hyderabad edition is only the second in this promising series. The long hiatus due to Covid-19 pushed this conference by two years, but we are glad that it is finally here!This edition of ACM CompEd partly overlaps with COMPUTE 2023, ACM India's flagship conference on Computing Education. Having the two conferences adjacent to each other is a great way to build synergy between the Indian computing education community and the global community of computing education researchers.",,
New Perspectives on the Future of Computing Education: Teaching and Learning Explanatory Models,H\,Proceedings of the 24th Koli Calling International Conference on Computing Education Research,2024,"This paper introduces the explanatory model approach to address challenges in computing education arising from rapid technological developments and paradigm shifts, particularly regarding artificial intelligence and machine learning. Traditional approaches in computing education aim to teach basic concepts derived from the computer science discipline as they are in order to support students’ understanding of these concepts and digital technologies that implement these concepts. This approach is challenged in topics like machine learning, where the ground truth of the inner workings and the behaviors of these technologies is not so clear, making rethinking approaches in computing education necessary. The explanatory model approach suggests that students learn models about computational concepts and digital artifacts that help them understand, explain, and reason about digital technologies. While drawing on the notion of models in science and science education, this approach emphasizes learning and using explanatory models as a focal point in computing classes. Doing so may help students make use of these models as tools and enable them to reflect on and critique different models in various contexts. Additionally, this paper discusses how making explanatory models explicit in research can enrich computing education research and our discourses and describes avenues for researching explanatory models as different perspectives on computational concepts.",10.1145/3699538.3699558,https://doi.org/10.1145/3699538.3699558
Is GPT-4 Alone Sufficient for Automated Essay Scoring?: A Comparative Judgment Approach Based on Rater Cognition,"Kim, Seungju and Jo, Meounggun",,2024,"Large Language Models (LLMs) have shown promise in Automated Essay Scoring (AES), but their zero-shot and few-shot performance often falls short compared to state-of-the-art models and human raters. However, fine-tuning LLMs for each specific task is impractical due to the variety of essay prompts and rubrics used in real-world educational contexts. This study proposes a novel approach combining LLMs and Comparative Judgment (CJ) for AES, using zero-shot prompting to choose between two essays. We demonstrate that a CJ method surpasses traditional rubric-based scoring in essay scoring using LLMs.",10.1145/3657604.3664703,https://doi.org/10.1145/3657604.3664703
Investigating the Use of Generative AI in M&amp;S Education,"Leathrum, James F. and Shen, Yuzhong and Sosonkina, Masha",Proceedings of the Winter Simulation Conference,2025,"Large Language Models (LLMs) are rapidly creating a place for themselves in society. There are numerous reports, both good and bad, of their use in business, academia, government and society. While some organizations are trying to limit, or eliminate, their use, it appears that it is inevitable they will become a common",,
Enhancing Code Tracing Question Generation with Refined Prompts in Large Language Models,"Fan, Aysa X. and Hendrawan, Rully A. and Shi, Yang and Ma, Qianou",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"This study refines Large Language Models (LLMs) prompts to enhance the generation of code tracing questions, where the new expert-guided prompts consider features identified from prior research. Expert evaluations compared new LLM-generated questions against previously preferred ones, revealing improved quality in aspects like complexity and concept coverage. While providing insights into effective question generation and affirming LLMs' potential in educational content creation, the study also contributes an expert-evaluated question dataset to the computing education community. However, generating high-quality reverse tracing questions remains a nuanced challenge, indicating a need for further LLM prompting refinement.",10.1145/3626253.3635624,https://doi.org/10.1145/3626253.3635624
Overcoming Barriers in Scaling Computing Education Research Programming Tools: A Developer's Perspective,"Tran, Keith and Bacher, John and Shi, Yang and Skripchuk, James and Price, Thomas",Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1,2024,"Background and Context. Research software in the Computing Education Research (CER) domain frequently encounters issues with scalability and sustained adoption, which limits its educational impact. Despite the development of numerous CER programming (CER-P) tools designed to enhance learning and instruction, many fail to see widespread use or remain relevant over time. Previous research has primarily examined the challenges educators face in adopting and reusing CER tools, with few focusing on understanding the barriers to scaling and adoption practices from the tool developers’ perspective. Objectives. To address this, we conducted semi-structured interviews with 16 tool developers within the computing education community, focusing on the challenges they encounter and the practices they employ in scaling their CER-P tools. Method. Our study employs thematic analysis of the semi-structured interviews conducted with developers of CER-P tools. Findings. Our analysis revealed several barriers to scaling highlighted by participants, including funding issues, maintenance burdens, and the challenge of ensuring tool interoperability for a broader user base. Despite these challenges, developers shared various practices and strategies that facilitated some degree of success in scaling their tools. These strategies include the development of teaching materials and units of curriculum, active marketing within the academic community, and the adoption of flexible design principles to facilitate easier adaptation and use by educators and students. Implications. Our findings lay the foundation for further discussion on potential community action initiatives, such as the repository of CS tools and the community of tool developers, to allow educators to discover and integrate tools more easily in their classrooms and support tool developers by exchanging design practices to build high-quality education tools. Furthermore, our study suggests the potential benefits of exploring alternative funding models.",10.1145/3632620.3671113,https://doi.org/10.1145/3632620.3671113
Designing and Generating Lesson Plans combining Open Educational Content and Generative AI,,Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems,2024,"In this paper, we propose an approach for assisting educators in deriving lesson plans for complex learning subjects like Model-Driven Engineering (MDE) from existing educational materials, leveraging generative AI techniques. Our method focuses on guiding teachers in defining learning objectives and suggesting concrete learning activities for students. Central to our approach is the development of a metamodel that characterizes the methodology and serves as the foundation for implementing supporting tools. By utilizing available Open Educational Resources (OERs) and incorporating them into specific learning activities, our method provides a general framework for supporting educators in designing lesson plans. We present the methodology to generate lesson plans, the metamodel conceptualizing plans ingredients, and demonstrate their application through supporting tools, illustrating the potential of our approach in facilitating the development of MDE teaching materials.",10.1145/3652620.3687773,https://doi.org/10.1145/3652620.3687773
Early Adoption of Generative Artificial Intelligence in Computing Education: Emergent Student Use Cases and Perspectives in 2023,"Smith, C. Estelle and Shiekh, Kylee and Cooreman, Hayden and Rahman, Sharfi and Zhu, Yifei and Siam, Md Kamrul and Ivanitskiy, Michael and Ahmed, Ahmed M. and Hallinan, Michael and Grisak, Alexander and Fierro, Gabe",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"Because of the rapid development and increasing public availability of Generative Artificial Intelligence (GenAI) models and tools, educational institutions and educators must immediately reckon with the impact of students using GenAI. There is limited prior research on computing students' use and perceptions of GenAI. In anticipation of future advances and evolutions of GenAI, we capture a snapshot of student attitudes towards and uses of yet emerging GenAI, in a period of time before university policies had reacted to these technologies. We surveyed all computer science majors in a small engineering-focused R1 university in order to: (1) capture a baseline assessment of how GenAI has been immediately adopted by aspiring computer scientists; (2) describe computing students' GenAI-related needs and concerns for their education and careers; and (3) discuss GenAI influences on CS pedagogy, curriculum, culture, and policy. We present an exploratory qualitative analysis of this data and discuss the impact of our findings on the emerging conversation around GenAI and education.",10.1145/3649217.3653575,https://doi.org/10.1145/3649217.3653575
Generative AI-Enabled Conversational Interaction to Support Self-Directed Learning Experiences in Transversal Computational Thinking,"Ouaazki, Abdessalam and Bergram, Kristoffer and Farah, Juan Carlos and Gillet, Denis and Holzer, Adrian",Proceedings of the 6th ACM Conference on Conversational User Interfaces,2024,"As computational thinking (CT) becomes increasingly acknowledged as an important skill in education, self-directed learning (SDL) emerges as a key strategy for developing this capability. The advent of generative AI (GenAI) conversational agents has disrupted the landscape of SDL. However, many questions still arise about several user experience aspects of these agents. This paper focuses on two of these questions: personalization and long-term support. As such, the first part of this study explores the effectiveness of personalizing GenAI through prompt-tuning using a CT-based prompt for solving programming challenges. The second part focuses on identifying the strengths and weaknesses of a GenAI model in a semester-long programming project. Our findings indicate that while prompt-tuning could hinder ease of use and perceived learning assistance, it might lead to higher learning outcomes. Results from a thematic analysis also indicate that GenAI is useful for programming and debugging, but it presents challenges such as over-reliance and diminishing utility over time.",10.1145/3640794.3665542,https://doi.org/10.1145/3640794.3665542
CompEd 2023: Proceedings of the ACM Conference on Global Computing Education Vol 1,,,2023,"It is our great pleasure to welcome participants to the 2nd ACM Global Conference on Computing Education (ACM CompEd 2023) being held in Hyderabad, India, 7th-9th December, 2023 with the Working Groups meetings being held on 5th and 6th December 2023.ACM CompEd is a recent addition to the list of ACM sponsored conferences devoted to research in all aspects of computing education, including education at the school and college levels. The Hyderabad edition is only the second in this promising series. The long hiatus due to Covid-19 pushed this conference by two years, but we are glad that it is finally here!This edition of ACM CompEd partly overlaps with COMPUTE 2023, ACM India's flagship conference on Computing Education. Having the two conferences adjacent to each other is a great way to build synergy between the Indian computing education community and the global community of computing education researchers.",,
WCCCE '24: Proceedings of the 26th Western Canadian Conference on Computing Education,,,2024,,,
Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems,"Mhasakar, Manas and Baker-Ramos, Rachel and Carter, Benjamin and Helekahi-Kaiwi, Evyn-Bree and Hester, Josiah",Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems,2025,"As large language models (LLMs) become increasingly integrated into educational technology, their potential to assist in developing curricula has gained interest among educators. Despite this growing attention, their applicability in culturally responsive Indigenous educational settings like Hawai‘i’s public schools and Kaiapuni (immersion language) programs, remains understudied. Additionally, ‘undefinedlelo Hawai‘i, the Hawaiian language, as a low-resource language, poses unique challenges and concerns about cultural sensitivity and the reliability of generated content. Through surveys and interviews with kumu (educators), this study explores the perceived benefits and limitations of using LLMs for culturally revitalizing computer science (CS) education in Hawaiian public schools with Kaiapuni programs. Our findings highlight AI’s time-saving advantages while exposing challenges such as cultural misalignment and reliability concerns. We conclude with design recommendations for future AI tools to better align with Hawaiian cultural values and pedagogical practices, towards the broader goal of trustworthy, effective, and culturally grounded AI technologies.",10.1145/3706599.3720282,https://doi.org/10.1145/3706599.3720282
Adaptive Second Language Tutoring Using Generative AI and a Social Robot,"Verhelst, Eva and Janssens, Ruben and Demeester, Thomas and Belpaeme, Tony",Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction,2024,"The most effective second language learning occurs through extensive interpersonal interaction and tutoring. However, limited funding and a lack of language teachers often prevent students from engaging in individualised practice, a lack which can be addressed using AI and social robots. We present a system that leverages generative AI to provide customized educational content in real-time, adapting to students' skills through an engaging, visually-grounded game played alongside a social robot. To test effectiveness, we conducted a study in which Dutch high school students learned Spanish vocabulary either with or without the robot present. Results showed significant vocabulary gains regardless of robot presence, indicating the game itself, not the social embodiment, drove learning. While further refinements are needed, these findings highlight the potential for generative AI to deliver personalized language tutoring and circumvent the constraints posed by limited resources and staffing in schools. Ongoing work aims to enhance social presence and better align generative content with individuals' abilities and pacing.",10.1145/3610978.3640559,https://doi.org/10.1145/3610978.3640559
ICER '24: Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 2,,,2024,,,
ACE '24: Proceedings of the 26th Australasian Computing Education Conference,,,2024,,,
Generating Diverse Code Explanations using the GPT-3 Large Language Model,"MacNeil, Stephen and Tran, Andrew and Mogil, Dan and Bernstein, Seth and Ross, Erin and Huang, Ziheng",Proceedings of the 2022 ACM Conference on International Computing Education Research - Volume 2,2022,"Good explanations are essential to efficiently learning introductory programming concepts [10]. To provide high-quality explanations at scale, numerous systems automate the process by tracing the execution of code [8, 12], defining terms [9], giving hints [16], and providing error-specific feedback [10, 16]. However, these approaches often require manual effort to configure and only explain a single aspect of a given code segment. Large language models (LLMs) are also changing how students interact with code [7]. For example, Github's Copilot can generate code for programmers [4], leading researchers to raise concerns about cheating [7]. Instead, our work focuses on LLMs' potential to support learning by explaining numerous aspects of a given code snippet. This poster features a systematic analysis of the diverse natural language explanations that GPT-3 can generate automatically for a given code snippet. We present a subset of three use cases from our evolving design space of AI Explanations of Code.",10.1145/3501709.3544280,https://doi.org/10.1145/3501709.3544280
How Far Are We? The Triumphs and Trials of Generative AI in Learning Software Engineering,"Choudhuri, Rudrajit and Liu, Dylan and Steinmacher, Igor and Gerosa, Marco and Sarma, Anita",Proceedings of the IEEE/ACM 46th International Conference on Software Engineering,2024,"Conversational Generative AI (convo-genAI) is revolutionizing Software Engineering (SE) as engineers and academics embrace this technology in their work. However, there is a gap in understanding the current potential and pitfalls of this technology, specifically in supporting students in SE tasks. In this work, we evaluate through a between-subjects study (N=22) the effectiveness of ChatGPT, a convo-genAI platform, in assisting students in SE tasks. Our study did not find statistical differences in participants' productivity or self-efficacy when using ChatGPT as compared to traditional resources, but we found significantly increased frustration levels. Our study also revealed 5 distinct faults arising from violations of Human-AI interaction guidelines, which led to 7 different (negative) consequences on participants.",10.1145/3597503.3639201,https://doi.org/10.1145/3597503.3639201
Advancements and Challenges of Generative AI in Higher Educational Content Creation A Technical Perspective,"Faccia, Alessio and Ridon, Manjeet and Beebeejaun, Zeenat and Mosteanu, Narcisa Mosteanu Roxana",Proceedings of the 2023 8th International Conference on Information Systems Engineering,2024,"Generative Artificial Intelligence (AI) has witnessed remarkable advancements, igniting interest in various domains, including Higher Education. This research paper explores the impacts and challenges of integrating Generative AI in content creation within Higher Education. We utilise a literature review and case study approach to gain insights into the potential benefits and complexities of implementing Generative AI in educational settings. Specific research questions are formulated to investigate the influence of Generative AI on content creation efficiency, productivity, quality, and adaptability. The paper also highlights ethical considerations and the evolving role of educators in the AI-driven educational landscape. Furthermore, the research paper examines the practical applications of Generative AI tools such as OpenAI GPT, GPT-Neo, Hugging Face's Transformers Library, Cognii, MosaChat-AI, TeacherMatic, and OpenAI Codex in Higher Education content creation. This comprehensive analysis aims to provide educators, instructional designers, and policymakers with valuable insights and concrete examples of how Generative AI can be leveraged to create personalised learning materials, improve assessment strategies, and enhance the overall educational experience for students pursuing advanced technical subjects. The culmination of this research presents a vision for a future where Generative AI, thoughtfully implemented and ethically managed, empowers educational institutions to meet the diverse and evolving needs of learners in the digital era.",10.1145/3641032.3641055,https://doi.org/10.1145/3641032.3641055
UKICER '24: Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research,,,2024,,,
Koli Calling '24: Proceedings of the 24th Koli Calling International Conference on Computing Education Research,,,2024,,,
Plagiarism in the Age of Generative AI: Cheating Method Change and Learning Loss in an Intro to CS Course,"Chen, Binglin and Lewis, Colleen M. and West, Matthew and Zilles, Craig",,2024,"Background: ChatGPT became widespread in early 2023 and enabled the broader public to use powerful generative AI, creating a new means for students to complete course assessments.  Purpose: In this paper, we explored the degree to which generative AI impacted the frequency and nature of cheating in a large introductory programming course. We also estimate the learning impact of students choosing to submit plagiarized work rather than their own work.  Methods: We identified a collection of markers that we believe are indicative of plagiarism in this course. We compare the estimated prevalence of cheating in the semesters before and during which ChatGPT became widely available. We use linear regression to estimate the impact of students' patterns of cheating on their final exam performance. Findings: The patterns associated with these plagiarism markers suggest that the quantity of plagiarism increased with the advent of generative AI, and we see evidence of a shift from online plagiarism hubs (e.g., Chegg, CourseHero) to ChatGPT. In addition, we observe statistically significant learning losses proportional to the amount of presumed plagiarism, but there is no statistical difference on the proportionality between semesters.  Implications: Our findings suggest that unproctored exams become increasingly insecure and care needs to be taken to ensure the validity of summative assessments. More importantly, our results suggest that generative AI can be detrimental to students' learning. It seems necessary for educators to reduce the benefit of students using generative AI for counterproductive purposes.",10.1145/3657604.3662046,https://doi.org/10.1145/3657604.3662046
Personalized Parsons Puzzles as Scaffolding Enhance Practice Engagement Over Just Showing LLM-Powered Solutions,"Hou, Xinying and Wu, Zihan and Wang, Xu and Ericson, Barbara J.",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"As generative AI products could generate code and assist students with programming learning seamlessly, integrating AI into programming education contexts has driven much attention. However, one emerging concern is that students might get answers without learning from the LLM-generated content. In this work, we deployed the LLM-powered personalized Parsons puzzles as scaffolding to write-code practice in a Python learning classroom (PC condition) and conducted an 80-minute randomized between-subjects study. Both conditions received the same practice problems. The only difference was that when requesting help, the control condition showed students a complete solution (CC condition), simulating the most traditional LLM output. Results indicated that students who received personalized Parsons puzzles as scaffolding engaged in practicing significantly longer than those who received complete solutions when struggling.",10.1145/3641555.3705227,https://doi.org/10.1145/3641555.3705227
Using Transformer Models for Knowledge Graph Construction in Computer Science Education,"Katyshev, Alexander and Anikin, Anton and Sychev, Oleg",Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2,2023,"The volume of information that can be used in the development of knowledge bases that can be used in education is constantly increasing. Also, this amount of data is very difficult to process and store. When designing a knowledge base to optimize the educational process, it is important to use ontologies. At the moment, the creation of an ontological knowledge model is the most promising option for storing and processing information. The article describes effective approaches for generating an ontological model using machine learning models based on the Transformer model.",10.1145/3545947.3576365,https://doi.org/10.1145/3545947.3576365
Using Generative AI to Design Programming Assignments in Introduction to Computer Science,"Alrifai, Rad",J. Comput. Sci. Coll.,2024,"Programming stands as an essential requisite in computer science education. Recognizing the challenges students face in learning programming effectively, the proposed assignment aims to integrate generative artificial intelligence (AI) tools to teach students introductory programming constructs. Generative AI has gained an increasing popularity in recent years. Several available Generative AI implementations can now help students learn programming essentials and debugging skills.",,
SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model,"Fu, Lingyue and Guan, Hao and Du, Kounianhua and Lin, Jianghao and Xia, Wei and Zhang, Weinan and Tang, Ruiming and Wang, Yasheng and Yu, Yong",Proceedings of the 33rd ACM International Conference on Information and Knowledge Management,2024,"Knowledge Tracing (KT) aims to determine whether students will respond correctly to the next question, which is a crucial task in intelligent tutoring systems (ITS). In educational KT scenarios, transductive ID-based methods often face severe data sparsity and cold start problems, where interactions between individual students and questions are sparse, and new questions and concepts consistently arrive in the database. In addition, existing KT models only implicitly consider the correlation between concepts and questions, lacking direct modeling of the more complex relationships in the heterogeneous graph of concepts and questions. In this paper, we propose a &lt;u&gt;S&lt;/u&gt;tructure-aware &lt;u&gt;IN&lt;/u&gt;ductive &lt;u&gt;K&lt;/u&gt;nowledge &lt;u&gt;T&lt;/u&gt;racing model with large language model (dubbed SINKT), which, for the first time, introduces large language models (LLMs) and realizes inductive knowledge tracing. Firstly, SINKT utilizes LLMs to introduce structural relationships between concepts and constructs a hetero- geneous graph for concepts and questions. Secondly, by encoding concepts and questions with LLMs, SINKT incorporates semantic information to aid prediction. Finally, SINKT predicts the student's response to the target question by interacting with the student's knowledge state and the question representation. Experiments on four real-world datasets demonstrate that SINKT achieves state-of-the-art performance among 12 existing transductive KT models. Additionally, we explore the performance of SINKT on the inductive KT task and provide insights into various modules.",10.1145/3627673.3679760,https://doi.org/10.1145/3627673.3679760
CEP '24: Proceedings of the 8th Conference on Computing Education Practice,,,2024,,,
ICER '24: Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1,,,2024,,,
Automatic Feedback Generation on K-12 Students' Data Science Education by Prompting Cloud-based Large Language Models,"Fung, Sze Ching Evelyn and Wong, Man Fai and Tan, Chee Wei",,2024,"Since data science is traditionally an advanced field taught at the college or university level, introducing its concepts to K-12 students can present unique learning challenges. As educational environments increasingly adopt data science curricula for K-12 students, the need for scalable, personalized teaching tools becomes critical. While the integration of large language models (LLMs) in educational environments offers significant potential for scalability and automation, it is important to note that the generated language output may not always be highly suitable for K-12 students. In this paper, we introduce the DSRAG, a novel educational automatic feedback generation framework that leverages Retrieval-Augmented Generation (RAG) and cloud-based LLMs to provide automated and personalized feedback for K-12 students engaged in data science education. DSRAG employs Langchain question-answering and RAG systems to manage educational content and generate feedback on the top of GPT-4. We also demonstrate the framework's capability to simplify complex concepts and align its responses to be pedagogically appropriate and understandable for K-12 students.",10.1145/3657604.3664673,https://doi.org/10.1145/3657604.3664673
With Great Power Comes Great Responsibility - Integrating Data Ethics into Computing Education,"Kiesler, Natalie and Opel, Simone and Thorbr\",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"Most computing students enter the industry once they graduate. As future software engineers, they will be in powerful positions, making decisions that impact their personal lives, others, and society. Thus, preparing graduates for their careers is crucial by addressing ethical considerations, decision problems, and other concepts related to morals, values, and legal aspects (e.g., data protection, privacy, security, etc.) as part of computing curricula. In this paper, we propose the integration of data ethics into computing programs and provide a framework for an ethics module, including relevant competency-based learning objectives. The proposed module is based on a curricular analysis of all 71 German data science degree programs focusing on ethics courses. The course contents and competency goals were analyzed and classified based on their cognitive complexity. As the results proved the lack of competency-based learning outcomes, we designed observable competency goals, meaning knowledge, skills, and dispositions taken in the context of a task. In addition, we provide suggestions for contents, pedagogical instructions, and assessments in such a course. The proposed module serves as a first draft and resource to support other educators aiming to design such a course and who are willing to integrate it into computing curricula.",10.1145/3649217.3653637,https://doi.org/10.1145/3649217.3653637
Reacting to Generative AI: Insights from Student and Faculty Discussions on Reddit,"Wu, Chuhao and Wang, Xinyu and Carroll, John and Rajtmajer, Sarah",Proceedings of the 16th ACM Web Science Conference,2024,"Generative Artificial intelligence (GenAI) such as ChatGPT has elicited strong reactions from almost all stakeholders across the education system. Education-oriented and academic social media communities provide an important venue for these stakeholders to share experiences and exchange ideas about GenAI, which is constructive for developing human-centered policies. This study examines early user reactions to GenAI, consisting of 725 Reddit threads between 06/2022 and 05/2023. Through natural language processing (NLP) and content analysis, we observe an increasingly negative sentiment in the discussion and identify six main categories of student and faculty experiences of GenAI in education. These experiences reflect concerns about academic integrity and AI’s negative impact on the values of traditional education. Our analysis also highlights the tension and burden imposed by new technologies. Our findings suggest that dialogue between stakeholders in the education community is critical and can mitigate sources of tension between students and faculty.",10.1145/3614419.3644014,https://doi.org/10.1145/3614419.3644014
Panel: Using Generative AI in Teaching and Learning.,"Sumner, Mary and Van Slyke, Craig and Niederman, Fred and Galletta, Dennis",Proceedings of the 2024 Computers and People Research Conference,2024,,10.1145/3632634.3655868,https://doi.org/10.1145/3632634.3655868
Evaluating ChatGPT: Generative AI in UX Design and Web Development Pedagogy,"York, Eric",Proceedings of the 41st ACM International Conference on Design of Communication,2023,"The advent of widely-accessible generative AI tools and their rapid adoption across industry and education is necessitating large-scale revisions to user experience design and web development pedagogies and curricula, a process that will take some time. This report describes a series of initial experiments using generative AI tools as a student or junior designer or web developer might, sometimes na\",10.1145/3615335.3623035,https://doi.org/10.1145/3615335.3623035
Using a Low-Code Environment to Teach Programming in the Era of LLMs,"Potriasaeva, Anna and Dzialets, Katsiaryna and Golubev, Yaroslav and Birillo, Anastasiia",Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 2,2024,"LLMs change the landscape of software engineering, and the question arises: “How can we combine LLMs with traditional teaching approaches in computer science?”. In this work, we propose to teach students in a low-code environment of code generation, developing not only their coding but also decomposition and prompting skills.",10.1145/3632621.3671429,https://doi.org/10.1145/3632621.3671429
Large Language Models with Reasoning on Theory Course Exams,"Dougherty, Ryan E. and Golesteanu, Matei A. and Vowinkel, Garrett B.",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 2,2025,"Theory of Computing (ToC) courses are important in CS curricula as they promote formal reasoning and writing skills about computation. Large language models (LLMs) have recently upended standard pedagogy in CS courses, but ToC courses have so far been fairly resistant to LLMs as they generally have lacked reasoning abilities. Prior work showed that GPT-4 performed at an ''average'' student level, specifically with a B-/C+ average. Considerable advancements since that prior work have occurred with LLMs in that some now provide ''reasoning'' capabilities. In this poster we tested whether the ChatGPT o1 LLM can perform better than GPT-4 on our ToC course's exams. We found that o1 can solve ToC questions approximately two letter grades higher than GPT-4 could, specifically at an A+ level.",10.1145/3724389.3730783,https://doi.org/10.1145/3724389.3730783
LLM-KCI: Leveraging Large Language Models to Identify Programming Knowledge Components,"Niousha, Rose and O'Neill, Abigail and Chen, Ethan and Malhotra, Vedansh and Akram, Bita and Norouzi, Narges",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"Identifying Knowledge Components (KCs) in computer science education improves curriculum design and teaching strategies. We introduce a framework using Large Language Models to identify KCs from programming assignments automatically. Our framework helps educators align assignments with course objectives. GPT-4 identifies relevant KCs well, though there's a low match with expert-generated KCs at the course level. At the problem level, performance is lower, but key KCs are reasonably identified.",10.1145/3641555.3705215,https://doi.org/10.1145/3641555.3705215
"Ethics, Governance, and User Mental Models for Large Language Models in Computing Education","Zhou, Kyrie Zhixuan and Kilhoffer, Zachary and Sanfilippo, Madelyn Rose and Underwood, Ted and Gumusel, Ece and Wei, Mengyi and Choudhry, Abhinav and Xiong, Jinjun",XRDS,2024,"Large language models like ChatGPT are disrupting many industries, including computing education. How should policy evolve to improve learning outcomes?",10.1145/3688089,https://doi.org/10.1145/3688089
WiPSCE '24: Proceedings of the 19th WiPSCE Conference on Primary and Secondary Computing Education Research,,,2024,,,
Are LLMs Good at Answering Student Questions in CS1 Courses?,"Van Mullem, Thomas and Mesuere, Bart and Dawyndt, Peter",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 2,2025,"Educators often spend a significant amount of time answering student coding questions, which can lead to rushed or incomplete responses. Additionally, generative AI tools are starting to and will play an increasing role in students' careers. These tools are easy to use and can provide heaps of information almost instantly. However, they often generate answers that provide full assignment solutions rather than guiding students towards the correct solution, which can be detrimental to their learning process. To address this issue, we are exploring the potential of large language models (LLMs) in improving student support by generating draft responses. These drafts are designed to provide students with meaningful guidance without giving away direct solutions. To evaluate these drafts, an LLM-as-a-judge is employed to compare the generated answers from various LLMs, different prompts, and best available human answers against a ground truth dataset. We present the evaluation process using an LLM-as-a-judge based benchmark, discuss the results obtained by different models and prompts, and compare them to the best available human responses. These evaluations give an indication of how LLMs can aid in computer science education, by reducing the time needed to answer questions and increasing both the accuracy and effectiveness of responses.",10.1145/3724389.3730778,https://doi.org/10.1145/3724389.3730778
Generative AI-Powered Educational Alignment: A Framework for Matching Syllabus Course Topics with Web Description,"Liu, Liyuan and Mendoza, Ruben A. and Martin, Thomas R. and Miori, Virginia M.",Proceedings of the 2024 9th International Conference on Distance Education and Learning,2024,"The application of generative artificial intelligence (GAI) in the educational sector is increasingly gaining attention from researchers. This study explores the congruence between online course descriptions and actual course syllabi to improve course preparation and consistency for instructors. Alignment between course catalog descriptions and actual course content as detailed in the syllabus can lead to learning improvements, student satisfaction, and academic alignment in a program. Our research introduces a novel framework utilizing GAI to systematically evaluates and identifies mismatches and suggests content to close the gap between online course descriptions and syllabus content. We used OpenAI’s ChatGPT to extract key topics from course syllabi and assessed the congruence between results and course description content with embedding methods such as BERT, GPT-2, RoBERTa, and DistilBERT, coupled with cosine similarity metrics. Our framework also integrates an outlier detection algorithm to identify courses with significant misalignments and use GAI applications to refine and enhance course catalog descriptions. This approach helps higher education institutions update course offerings with cutting-edge technology and contributes to curriculum development, helping improve student learning efficiency and course design.",10.1145/3675812.3675874,https://doi.org/10.1145/3675812.3675874
Large language model augmented exercise retrieval for personalized language learning,"Xu, Austin and Monroe, Will and Bicknell, Klinton",Proceedings of the 14th Learning Analytics and Knowledge Conference,2024,"We study the problem of zero-shot exercise retrieval in the context of online language learning, to give learners the ability to explicitly request personalized exercises via natural language. Using real-world data collected from language learners, we observe that vector similarity approaches poorly capture the relationship between exercise content and the language that learners use to express what they want to learn. This semantic gap between queries and content dramatically reduces the effectiveness of general-purpose retrieval models pretrained on large scale information retrieval datasets like MS MARCO&nbsp;[2]. We leverage the generative capabilities of large language models to bridge the gap by synthesizing hypothetical exercises based on the learner’s input, which are then used to search for relevant exercises. Our approach, which we call mHyER, overcomes three challenges: (1) lack of relevance labels for training, (2) unrestricted learner input content, and (3) low semantic similarity between input and retrieval candidates. mHyER outperforms several strong baselines on two novel benchmarks created from crowdsourced data and publicly available data.",10.1145/3636555.3636883,https://doi.org/10.1145/3636555.3636883
Educator and Student Perspectives on the Impact of Generative AI on Assessments in Higher Education,"Smolansky, Adele and Cram, Andrew and Raduescu, Corina and Zeivots, Sandris and Huber, Elaine and Kizilcec, Rene F.",,2023,"The sudden popularity and availability of generative AI tools, such as ChatGPT that can write compelling essays on any topic, code in various programming languages, and ace standardized tests across domains, raises questions about the sustainability of traditional assessment practices. To seize this opportunity for innovation in assessment practice, we conducted a survey to understand both the educators' and students' perspectives on the issue. We measure and compare attitudes of both stakeholders across various assessment scenarios, building on an established framework for examining the quality of online assessments along six dimensions. Responses from 389 students and 36 educators across two universities indicate moderate usage of generative AI, consensus for which types of assessments are most impacted, and concerns about academic integrity. Educators prefer adapted assessments that assume AI will be used and encourage critical thinking, but students' reaction is mixed, in part due to concerns about a loss of creativity. The findings show the importance of engaging educators and students in assessment reform efforts to focus on the process of learning over its outputs, higher-order thinking, and authentic applications.",10.1145/3573051.3596191,https://doi.org/10.1145/3573051.3596191
ICER '23: Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2,,,2023,,,
UKICER '23: Proceedings of the 2023 Conference on United Kingdom &amp; Ireland Computing Education Research,,,2023,,,
Predicting challenge moments from students' discourse: A comparison of GPT-4 to two traditional natural language processing approaches,"Suraworachet, Wannapon and Seon, Jennifer and Cukurova, Mutlu",Proceedings of the 14th Learning Analytics and Knowledge Conference,2024,"Effective collaboration requires groups to strategically regulate themselves to overcome challenges. Research has shown that groups may fail to regulate due to differences in members’ perceptions of challenges which may benefit from external support. In this study, we investigated the potential of leveraging three distinct natural language processing models: an expert knowledge rule-based model, a supervised machine learning (ML) model and a Large Language model (LLM), in challenge detection and challenge dimension identification (cognitive, metacognitive, emotional and technical/other challenges) from student discourse, was investigated. The results show that the supervised ML and the LLM approaches performed considerably well in both tasks, in contrast to the rule-based approach, whose efficacy heavily relies on the engineered features by experts. The paper provides an extensive discussion of the three approaches’ performance for automated detection and support of students’ challenge moments in collaborative learning activities. It argues that, although LLMs provide many advantages, they are unlikely to be the panacea to issues of the detection and feedback provision of socially shared regulation of learning due to their lack of reliability, as well as issues of validity evaluation, privacy and confabulation. We conclude the paper with a discussion on additional considerations, including model transparency to explore feasible and meaningful analytical feedback for students and educators using LLMs.",10.1145/3636555.3636905,https://doi.org/10.1145/3636555.3636905
"Unlimited Practice Opportunities: Automated Generation of Comprehensive, Personalized Programming Tasks","Jacobs, Sven and Peters, Henning and Jaschke, Steffen and Kiesler, Natalie",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"Generative artificial intelligence (GenAI) offers new possibilities for generating personalized programming exercises, addressing the need for individual practice. However, the task quality along with the student perspective on such generated tasks remains largely unexplored. Therefore, this paper introduces and evaluates a new feature of the so-called Tutor Kai for generating comprehensive programming tasks, including problem descriptions, code skeletons, unit tests, and model solutions. The presented system allows students to freely choose programming concepts and contextual themes for their tasks. To evaluate the system, we conducted a two-phase mixed-methods study comprising (1) an expert rating of 200 automatically generated programming tasks w.r.t. task quality, and (2) a study with 26 computer science students who solved and rated the personalized programming tasks. Results show that experts classified 89.5% of the generated tasks as functional and 92.5% as solvable. However, the system's rate for implementing all requested programming concepts decreased from 94% for single-concept tasks to 40% for tasks addressing three concepts. The student evaluation further revealed high satisfaction with the personalization. Students also reported perceived benefits for learning. The results imply that the new feature has the potential to offer students individual tasks aligned with their context and need for exercise. Tool developers, educators, and, above all, students can benefit from these insights and the system itself.",10.1145/3724363.3729089,https://doi.org/10.1145/3724363.3729089
Duty vs. Consequence: Exploring Teachers' Assessment of the Ethical Dimensions of Generative AI Technologies,"Aguilar, Stephen J and Wang, Changzhao",Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing,2024,"This study examines how K-12 teachers (n=248) in the United States evaluated multiple ethical propositions grounded within classic philosophic distinction of deontology and consequentialism. Notably, we observed gender differences in ethical evaluations, with women scoring higher in several deontological propositions. Furthermore, teachers' attitudes significantly predicted their stances on consequentialist propositions, while self-efficacy and anxiety were related to both consequentialist and deontological perspectives.",10.1145/3605098.3636180,https://doi.org/10.1145/3605098.3636180
PromptTutor: Effects of an LLM-Based Chatbot on Learning Outcomes and Motivation in Flipped Classrooms,"Zhang, Yuhao and Ouh, Eng Lieh and Ho, Adam and Lo, Siaw Ling and Tan, Kar Way and Lin, Feng",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"This study explores the integration of a Large Language Model (LLM) based chatbot, PromptTutor, into flipped classrooms (FC) for undergraduate Computer Science (CS) education. PromptTutor is designed to provide personalized, immediate feedback to support student learning in FC by incorporating reflective learning and scaffolding strategies. The traditional FC typically lacks this immediate feedback during the pre-class learning phase, risking decreased student motivation according to existing literature. This study examines if students improve in learning outcomes and motivation after using PromptTutor. Through a controlled crossover experiment with 50 students, the study demonstrates statistically significant improvements in students' quiz performance and motivation compared to traditional FC. Our work underscores the potential of LLM-based tools in addressing FC challenges, offering actionable insights for educators and institutional leaders in technology-enhanced learning environments.",10.1145/3724363.3729095,https://doi.org/10.1145/3724363.3729095
The Evolving Usage of GenAI by Computing Students,"Hou, Irene and Nguyen, Hannah Vy and Man, Owen and MacNeil, Stephen",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"Help-seeking is a critical aspect of learning and problem-solving for computing students. Recent research has shown that many students are aware of generative AI (GenAI) tools; however, there are gaps in the extent and effectiveness of how students use them. With over two years of widespread GenAI usage, it is crucial to understand whether students' help-seeking behaviors with these tools have evolved and how. This paper presents findings from a repeated cross-sectional survey conducted among computing students across North American universities ( n=95 ). Our results indicate shifts in GenAI usage patterns. In 2023, 34.1% of students ( n=47 ) reported never using ChatGPT for help, ranking it fourth after online searches, peer support, and class forums. By 2024, this figure dropped sharply to 6.3% ( n=48 ), with ChatGPT nearly matching online search as the most commonly used help resource. Despite this growing prevalence, there has been a decline in students' hourly and daily usage of GenAI tools, which may be attributed to a common tendency to underestimate usage frequency. These findings offer new insights into the evolving role of GenAI in computing education, highlighting its increasing acceptance and solidifying its position as a key help resource.",10.1145/3641555.3705266,https://doi.org/10.1145/3641555.3705266
Identifying Competence Gaps and Student Struggle by Monitoring Testing Performance,B\,Proceedings of the 6th European Conference on Software Engineering Education,2025,"Creating sufficient motivation for unit testing is often a challenge in software engineering education. As well, it is often difficult for students to decide whether they have written sufficient tests. Classical coverage measures require thorough explanation and thus introduce great complexity, which risks to overwhelm programming novices. Instead, we started using mutation testing early on in programming courses, as mutations are an easy concept to understand. In addition, integrating mutation testing into projects is nowadays straightforward. Furthermore, hunting mutations can create a sense of gaming challenge, and thus, fun for novice programmers.In this paper, we describe experiences with mutation testing in the first and second semester of an introductory course on software development in a Bachelor’s degree program on Computer Science. In order to critically evaluate our approach, we analyze in detail the meta data on testing activities generated in the students’ repositories. Specifically, we analyze their work performance and identify typical performance patterns in terms of programming activities over time, as well as in terms of improvement of code quality during this process. Furthermore, we correlate these performance data to the exam performance.Finally, we classify leftover mutants in terms of skill levels according to Bloom’s revised taxonomy of learning objectives. This provides an insight into students’ abilities, and identifies where we need to adapt our teaching and exercises in the next iteration of teaching these courses, to better support our students along their learning path.",10.1145/3723010.3723033,https://doi.org/10.1145/3723010.3723033
BugSpotter: Automated Generation of Code Debugging Exercises,"P?durean, Victor-Alexandru and Denny, Paul and Singla, Adish",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Debugging is an essential skill when learning to program, yet its instruction and emphasis often vary widely across introductory courses. In the era of code-generating large language models (LLMs), the ability for students to reason about code and identify errors is increasingly important. However, students frequently resort to trial-and-error methods to resolve bugs without fully understanding the underlying issues. Developing the ability to identify and hypothesize the cause of bugs is crucial but can be time-consuming to teach effectively through traditional means. This paper introduces BugSpotter, an innovative tool that leverages an LLM to generate buggy code from a problem description and verify the synthesized bugs via a test suite. Students interact with BugSpotter by designing failing test cases, where the buggy code's output differs from the expected result as defined by the problem specification. This not only provides opportunities for students to enhance their debugging skills, but also to practice reading and understanding problem specifications. We deployed BugSpotter in a large classroom setting and compared the debugging exercises it generated to exercises hand-crafted by an instructor for the same problems. We found that the LLM-generated exercises produced by BugSpotter varied in difficulty and were well-matched to the problem specifications. Importantly, the LLM-generated exercises were comparable to those manually created by instructors with respect to student performance, suggesting that BugSpotter could be an effective and efficient aid for learning debugging.",10.1145/3641554.3701974,https://doi.org/10.1145/3641554.3701974
Does ChatGPT Help With Introductory Programming?An Experiment of Students Using ChatGPT in CS1,"Xue, Yuankai and Chen, Hanlin and Bai, Gina R. and Tairas, Robert and Huang, Yu",Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training,2024,"Generative AI, notably ChatGPT, has garnered attention in computer science education. This paper presents a controlled experiment that explores ChatGPT's role in CS1 in a classroom setting. Specifically, we aim to investigate the impact of ChatGPT on student learning outcomes and their behaviors when working on programming assignments. Participants were tasked with creating a UML diagram and subsequently implementing its design through programming, followed by a closed-book post-evaluation and a post-survey. All the participants were required to screen-record the whole process. In total, 56 participants were recruited, with 48 successful screen recordings. Participants in the Experimental Group can access ChatGPT 3.5 and other online resources, such as Google and Stack Overflow when creating the UML diagram and programming; however, participants in the Control Group can access all online resources except for ChatGPT (i.e., the only design variable is the access to ChatGPT). Finally, we measured and analyzed participants' learning outcomes through their UML diagram, programming, and post-evaluation scores. We also analyzed the time participants took to complete the tasks and their interactions with ChatGPT and other resources from the screen recordings. After finishing the tasks, student participants also provided their perceptions of using ChatGPT in CS1 through a post-survey.With rigorous quantitative and qualitative analysis, we found that (1) using ChatGPT does not present a significant impact on students' learning performance in the CS1 assignment-style tasks; (2) once using ChatGPT, students' tendency to explore other traditional educational resources is largely reduced (though available) and they tend to rely solely on ChatGPT, and this reliance on ChatGPT did not guarantee enhanced learning performance; (3) the majority of students hold neutral views on ChatGPT's role in CS1 programming but most of them raised concerns about its potential ethical issues and inconsistent performance across different tasks. We hope this study can help educators and students better understand the impact of ChatGPT in CS1 and inspire future work to provide proper guidelines for using ChatGPT in introductory programming classes.",10.1145/3639474.3640076,https://doi.org/10.1145/3639474.3640076
"An LLM-Based Framework for Simulating, Classifying, and Correcting Students' Programming Knowledge with the SOLO Taxonomy","Zhang, Shan and Meshram, Pragati Shuddhodhan and Ganapathy Prasad, Priyadharshini and Israel, Maya and Bhat, Suma",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"Novice programmers often face challenges in designing computational artifacts and fixing code errors, which can lead to task abandonment and over-reliance on external support. While research has explored effective meta-cognitive strategies to scaffold novice programmers' learning, it is essential to first understand and assess students' conceptual, procedural, and strategic/conditional programming knowledge at scale. To address this issue, we propose a three-model framework that leverages Large Language Models (LLMs) to simulate, classify, and correct student responses to programming questions based on the SOLO Taxonomy. The SOLO Taxonomy provides a structured approach for categorizing student understanding into four levels: Pre-structural, Uni-structural, Multi-structural, and Relational. Our results showed that GPT-4o achieved high accuracy in generating and classifying responses for the Relational category, with moderate accuracy in the Uni-structural and Pre-structural categories, but struggled with the Multi-structural category. The model successfully corrected responses to the Relational level. Although further refinement is needed, these findings suggest that LLMs hold significant potential for supporting computer science education by assessing programming knowledge and guiding students toward deeper cognitive engagement.",10.1145/3641555.3705125,https://doi.org/10.1145/3641555.3705125
ICSE-SEET '23: Proceedings of the 45th International Conference on Software Engineering: Software Engineering Education and Training,,,2023,,,
Current Challenges in Computing Education,"Conrad, Susan and Dimitoglou, George and Flinn, Michael B. and Morgan, Jacob and Gupta, Pranshu and Mengistu, Zelalem",J. Comput. Sci. Coll.,2023,Discussion about topics related to current issues in computing science education focusing on three themes:,,
Investigating the Impact of Generative AI on Students and Educators: Evidence and Insights from the Literature,"Clos, Jeremie and Chen, Yoke Yie",Proceedings of the Second International Symposium on Trustworthy Autonomous Systems,2024,"Generative artificial intelligence (AI) has become one of the main concerns of knowledge workers due to its ability to mimic realistic human reasoning and creativity. However, this integration raises critical concerns about trust and ethics, which are crucial in shaping both the acceptance and effective utilisation of these technologies. There are many reports, articles and papers currently exploring the opportunities and challenges of LLMs in higher education from the perspective of students and educators. However, these papers often focus on specific contexts like in the UK, US or a particular institutions. In this paper, we examine the problems of generative AI in higher education from educator and student perspectives using scientometrics and text analysis to provide an overview of the research landscape, followed by a narrative review and thematic analysis of selected literature. Some findings of this work are: (1) Students and educators found different ways to use generative AI. Students focus more on using it as an assistant (revising and preparing for lectures, helping with homework) and educators as a content production assistant (writing lecture notes, personalising content). Commonalities are that both students and educators use generative AI as an accessibility aid, e.g., to rephrase sentences or explain concepts. (2) The main concerns of higher education regarding generative AI are equity in access, clarity of rules regarding usage, and job displacement.",10.1145/3686038.3686063,https://doi.org/10.1145/3686038.3686063
Exploring the Research Gap: Generative AI and Learning of Python Programming among Post-Primary Students,"Stone, Irene",Proceedings of the 2023 Conference on Human Centered Artificial Intelligence: Education and Practice,2023,"The introduction of Leaving Certificate Computer Science (LCCS) in Ireland in 2018 signifies a notable advancement in post-primary education. Moreover, developments in generative Artificial Intelligence (GAI) in education, are gaining prominence, yet we do not understand its value or how best to implement it in post-primary educational settings. Despite a growing international body of research in this area, my scoping review highlights that many aspects of these topics have yet to be explored, particularly in the context of post-primary students in Ireland. My study will begin to bridge this gap by exploring how a purposeful sample of LCCS post-primary students in Ireland engage with GAI tools, such as ChatGPT, during their initial experiences learning Python programming. These findings, when approached through the lens of Human-Centred Artificial Intelligence (HCAI), can help enhance pedagogical strategies and lead to improved learning experiences for students.",10.1145/3633083.3633099,https://doi.org/10.1145/3633083.3633099
AI Debugging Assistant: Enhancing Debugging Skills With Intelligent Guidance,"Artser, Elizaveta and Karol, Daniil and Potriasaeva, Anna and Rostovskiy, Aleksey and Birillo, Anastasiia",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 2,2025,"Debugging is an essential skill in programming education. Current debugging approaches lack interactivity and personalization for students. To address this gap, we introduce an AI Debugging Assistant integrated into JetBrains IDEs. The tool analyzes the students' errors in real-time and guides them through the debugging process by recommending breakpoints and explaining them on each step. This poster invites discussion on the effectiveness of the AI Debugging Assistant and its implications for programming education.",10.1145/3724389.3730777,https://doi.org/10.1145/3724389.3730777
Exploring LLMs Impact on Student-Created User Stories and Acceptance Testing in Software Development,"Brockenbrough, Allan and Feild, Henry and Salinas, Dominic",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"In Agile software development methodology, a user story describes a new feature or functionality from an end user's perspective. The user story details may also incorporate acceptance testing criteria, which can be developed through negotiation with users. When creating stories from user feedback, the software engineer may maximize their usefulness by considering story attributes, including scope, independence, negotiability, and testability. This study investigates how LLMs (large language models), with guided instructions, affect undergraduate software engineering students' ability to transform user feedback into user stories. Students, working individually, were asked to analyze user feedback comments, appropriately group related items, and create user stories following the principles of INVEST, a framework for assessing user stories. We found that LLMs help students develop valuable stories with well-defined acceptance criteria. However, students tend to perform better without LLMs when creating user stories with an appropriate scope.",10.1145/3641555.3705183,https://doi.org/10.1145/3641555.3705183
Feedback on Feedback: Comparing Classic Natural Language Processing and Generative AI to Evaluate Peer Feedback,"Hutt, Stephen and DePiro, Allison and Wang, Joann and Rhodes, Sam and Baker, Ryan S and Hieb, Grayson and Sethuraman, Sheela and Ocumpaugh, Jaclyn and Mills, Caitlin",Proceedings of the 14th Learning Analytics and Knowledge Conference,2024,"Peer feedback can be a powerful tool as it presents learning opportunities for both the learner receiving feedback as well as the learner providing feedback. Despite its utility, it can be difficult to implement effectively, particularly for younger learners, who are often novices at providing feedback. It can be difficult for students to learn what constitutes “good” feedback – particularly in open-ended problem-solving contexts. To address this gap, we investigate both classical natural language processing techniques and large language models, specifically ChatGPT, as potential approaches to devise an automated detector of feedback quality (including both student progress towards goals and next steps needed). Our findings indicate that the classical detectors are highly accurate and, through feature analysis, we elucidate the pivotal elements influencing its decision process. We find that ChatGPT is less accurate than classical NLP but illustrate the potential of ChatGPT in evaluating feedback, by generating explanations for ratings, along with scores. We discuss how the detector can be used for automated feedback evaluation and to better scaffold peer feedback for younger learners.",10.1145/3636555.3636850,https://doi.org/10.1145/3636555.3636850
ACE '23: Proceedings of the 25th Australasian Computing Education Conference,,,2023,,,
Transformed by Transformers: Navigating the AI Coding Revolution for Computing Education: An ITiCSE Working Group Conducted by Humans,"Prather, James and Denny, Paul and Leinonen, Juho and Becker, Brett A. and Albluwi, Ibrahim and Caspersen, Michael E. and Craig, Michelle and Keuning, Hieke and Kiesler, Natalie and Kohn, Tobias and Luxton-Reilly, Andrew and MacNeil, Stephen and Petersen, Andrew and Pettit, Raymond and Reeves, Brent N. and Savelka, Jaromir",Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 2,2023,"The recent advent of highly accurate and scalable large language models (LLMs) has taken the world by storm. From art to essays to computer code, LLMs are producing novel content that until recently was thought only humans could produce. Recent work in computing education has sought to understand the capabilities of LLMs for solving tasks such as writing code, explaining code, creating novel coding assignments, interpreting programming error messages, and more. However, these technologies continue to evolve at an astonishing rate leaving educators little time to adapt. This working group seeks to document the state-of-the-art for code generation LLMs, detail current opportunities and challenges related to their use, and present actionable approaches to integrating them into computing curricula.",10.1145/3587103.3594206,https://doi.org/10.1145/3587103.3594206
Bridging Novice Programmers and LLMs with Interactivity,"Yeh, Thomas Y. and Tran, Karena and Gao, Ge and Yu, Tyler and Fong, Wai On and Chen, Tzu-Yi",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"While Large Language Models (LLMs) enable experienced programmers to increase their productivity, LLMs' impact on learning and productivity for novices is currently unclear. Recent work showed novice programmers struggle with prompting LLMs for code generation and suggested that the use of LLMs in CS education could exacerbate existing equity issues. Educators are now faced with the difficult question of whether and when to incorporate the use of LLMs into the CS curriculum without adversely impacting student learning and equity. To address these concerns, we study the effects of using an interactive LLM on code generation with novice programmers. We find that using our interactive LLM improves the accuracy of code generation over the baseline LLM. Additionally, after using the interactive LLM, novices write improved prompts even when using the baseline LLM. Based on our findings, we plan to create iGPTs, a set of customized, interactive LLMs spanning CS education learning goals as templates to facilitate LLM integration for improving student learning and retention.",10.1145/3641554.3701867,https://doi.org/10.1145/3641554.3701867
The Impact of Generative AI on Critical Thinking: Self-Reported Reductions in Cognitive Effort and Confidence Effects From a Survey of Knowledge Workers,"Lee, Hao-Ping (Hank) and Sarkar, Advait and Tankelevitch, Lev and Drosos, Ian and Rintel, Sean and Banks, Richard and Wilson, Nicholas",Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems,2025,"The rise of Generative AI (GenAI) in knowledge workflows raises questions about its impact on critical thinking skills and practices. We survey 319 knowledge workers to investigate 1) when and how they perceive the enaction of critical thinking when using GenAI, and 2) when and why GenAI affects their effort to do so. Participants shared 936 first-hand examples of using GenAI in work tasks. Quantitatively, when considering both task- and user-specific factors, a user’s task-specific self-confidence and confidence in GenAI are predictive of whether critical thinking is enacted and the effort of doing so in GenAI-assisted tasks. Specifically, higher confidence in GenAI is associated with less critical thinking, while higher self-confidence is associated with more critical thinking. Qualitatively, GenAI shifts the nature of critical thinking toward information verification, response integration, and task stewardship. Our insights reveal new design challenges and opportunities for developing GenAI tools for knowledge work.",10.1145/3706598.3713778,https://doi.org/10.1145/3706598.3713778
Koli Calling '23: Proceedings of the 23rd Koli Calling International Conference on Computing Education Research,,,2023,,,
WCCCE '23: Proceedings of the 25th Western Canadian Conference on Computing Education,,,2023,,,
Not the Silver Bullet: LLM-enhanced Programming Error Messages are Ineffective in Practice,"Santos, Eddie Antonio and Becker, Brett A.",Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research,2024,"The sudden emergence of large language models (LLMs) such as ChatGPT has had a disruptive impact throughout the computing education community. LLMs have been shown to excel at producing correct code to CS1 and CS2 problems, and can even act as friendly assistants to students learning how to code. Recent work shows that LLMs demonstrate unequivocally superior results in being able to explain and resolve compiler error messages—for decades, one of the most frustrating parts of learning how to code. However, LLM-generated error message explanations have only been assessed by expert programmers in artificial conditions. This work sought to understand how novice programmers resolve programming error messages (PEMs) in a more realistic scenario. We ran a within-subjects study with n = 106 participants in which students were tasked to fix six buggy C programs. For each program, participants were randomly assigned to fix the problem using either a stock compiler error message, an expert-handwritten error message, or an error message explanation generated by GPT-4. Despite promising evidence on synthetic benchmarks, we found that GPT-4 generated error messages outperformed conventional compiler error messages in only 1 of the 6 tasks, measured by students’ time-to-fix each problem. Handwritten explanations still outperform LLM and conventional error messages, both on objective and subjective measures.",10.1145/3689535.3689554,https://doi.org/10.1145/3689535.3689554
Scaffolding CS1 Courses with a Large Language Model-Powered Intelligent Tutoring System,"Cao, Chen",Companion Proceedings of the 28th International Conference on Intelligent User Interfaces,2023,"Programming skills are rapidly becoming essential for many educational paths and career opportunities. Yet, for many international students, the traditional approach to teaching introductory programming courses can be a significant challenge due to the complexities of the language, the lack of prior programming knowledge, and the language and cultural barriers. This study explores how large language models and gamification can scaffold coding learning and increase Chinese students’ sense of belonging in introductory programming courses. In this project, a gamification intelligent tutoring system was developed to adapt to Chinese international students’ learning needs and provides scaffolding to support their success in introductory computer programming courses. My research includes three studies: a formative study, a user study of an initial prototype, and a computer simulation study with a user study in progress. Both qualitative and quantitative data were collected through surveys, observations, focus group discussions and computer simulation. The preliminary findings suggest that GPT-3-enhanced gamification has great potential in scaffolding introductory programming learning by providing adaptive and personalised feedback, increasing students’ sense of belonging, and reducing their anxiety about learning programming.",10.1145/3581754.3584111,https://doi.org/10.1145/3581754.3584111
Enhancing Software Engineering Education through AI: An Empirical Study of Tree-Based Machine Learning for Defect Prediction,"Alhazeem, Ensaf and Alsobeh, Anas and Al-Ahmad, Bilal",Proceedings of the 25th Annual Conference on Information Technology Education,2024,"In the rapidly evolving field of information technology education,integrating artificial intelligence (AI) and machine learning (ML) techniques presents opportunities and challenges. This empirical study investigates the application of tree-based ML techniques, specifically Random Forest (RF) and Extreme Gradient Boosting (XGBoost), for software defect prediction in the context of IT education. We analyze nine publicly available NASA software defect datasets to compare the performance of these algorithms across multiple metrics, including accuracy, precision, recall, and ROC area. Our findings demonstrate that XGBoost consistently outperforms Random Forest, achieving near-perfect accuracy across most datasets. The paper explores how these advanced techniques can be responsibly integrated into software engineering (SE) education to enhance student learning while addressing concerns about potential over-reliance on AI tools. We discuss the implications of our results for IT education, emphasizing the need to balance the use of sophisticated AI technologies with the development of fundamental software assurance skills. Furthermore, we examine the role of AI in augmenting SE education, particularly in areas such as software assurance explanations, feature identification, and data augmentation.",10.1145/3686852.3686881,https://doi.org/10.1145/3686852.3686881
Solving Proof Block Problems Using Large Language Models,"Poulsen, Seth and Sarsa, Sami and Prather, James and Leinonen, Juho and Becker, Brett A. and Hellas, Arto and Denny, Paul and Reeves, Brent N.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"Large language models (LLMs) have recently taken many fields, including computer science, by storm. Most recent work on LLMs in computing education has shown that they are capable of solving most introductory programming (CS1) exercises, exam questions, Parsons problems, and several other types of exercises and questions. Some work has investigated the ability of LLMs to solve CS2 problems as well. However, it remains unclear how well LLMs fare against more advanced upper-division coursework, such as proofs in algorithms courses. After all, while known to be proficient in many programming tasks, LLMs have been shown to have more difficulties in forming mathematical proofs.In this paper, we investigate the ability of LLMs to solve mathematical proofs by using Proof Blocks, a tool previously shown to efficaciously teach proofs to students. Our results show that GPT-3.5 is almost completely unable to provide correct solutions (11.4%), while GPT-4 shows a significant increase in correctness (64.8%). However, even given this improvement, current models still struggle to correctly order lines in a proof. It remains an open question whether this is a temporary situation or if LLMs will continue to struggle to solve these types of exercises in the future.",10.1145/3626252.3630928,https://doi.org/10.1145/3626252.3630928
Automated Benchmarking Infrastructure: Moving Toward Robust Investigations of Gen AI in Computing Education,"Ali, Murtaza and Xie, Benjamin",ACM Inroads,2025,,10.1145/3734876,https://doi.org/10.1145/3734876
Making Ethics at Home in Global CS Education: Provoking Stories from the Souths,"Wong-Villacres, Marisol and Kutay, Cat and Lazem, Shaimaa and Ahmed, Nova and Abad, Cristina and Collazos, Cesar and Elbassuoni, Shady and Islam, Farzana and Singh, Deepa and Mayeesha, Tasmiah Tahsin and Ujakpa, Martin Mabeifam and Zaman, Tariq and Bidwell, Nicola J.",ACM J. Comput. Sustain. Soc.,2024,"Despite the increase in university courses and curricula on the ethics of computing there are few studies about how computer science (CS) programs should account for the diverse ways ethical dilemmas and approaches to ethics are situated in cultural, philosophical, and governance systems, religions, and languages. We draw on the experiences and insights of 46 university educators and practitioners in Latin America, South-Asia, Africa, the Middle East, and Australian First Nations who participated in surveys and interviews. Our modest study seeks to prompt conversation about ethics and computing in the Global Souths and inform revisions to the Association of Computer Machinery's curricular guidelines for the Society, Ethics and Professionalism knowledge area in undergraduate CS programs. Participants describe frictions between static and anticipatory approaches to ethics in globalised regulations and formal codes of ethics and professional conduct and local practices, values, and impacts of technologies in the Global Souths. Codes and regulations are instruments for international control and their gap with local realities can cause harm, despite local efforts to compensate. However, our insights also illustrate opportunities for university teaching to link more closely to priorities, actions, and experiences in the Global Souths and enrich students’ education in the Global North.",10.1145/3608113,https://doi.org/10.1145/3608113
Data extraction for systematic mapping study using a large language model - a proof-of-concept study in software engineering,,Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement,2024,"Context: Systematic mapping studies (SMS) are adopted in Software Engineering (SE) to select and synthesize relevant literature on a research topic and, thus, support evidence-based decision-making. Performing SMS is effort-demanding and time-consuming. Hence, using tools is beneficial. Large Language Models (LLMs) such as ChatGPT–4.o can potentially accelerate repetitive activities, such as data extraction in SMS, saving time and effort. Goal: We conducted this work to evaluate and provide preliminary evidence on how ChatGPT–4.o can support data extraction in SMS. Method: We performed a proof-of-concept study and assessed the results’ accuracy of using ChatGPT 4.0 to extract data in one SMS compared to the results produced manually. Results: The accuracy of ChatGPT–4.o was 87.83%. Conclusions: Our preliminary findings suggest that entirely replacing the manual data extraction with ChatGPT–4.o is not recommended. However, employing ChatGPT for semi-automated data extraction to aid in evidence synthesis in SMS is promising.",10.1145/3674805.3690743,https://doi.org/10.1145/3674805.3690743
Students' Attitudes Towards Cheating Before and After ChatGPT,"Kann, Viggo",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"Opportunities for and inclinations towards academic dishonesty among students have emerged as prominent topics of contemporary discourse. Some reasons for this are new assessment methods, some of which were introduced during the COVID-19 pandemic, and the potential for assistance from generative AI tools. To gain a comprehensive understanding of computing students' perceptions of academic dishonesty, we conducted a survey study based on the seminal work done by Sheard and Dick at the turn of the century and ten years later, which focused on the perceptions of computing students at two Australian universities [19-22]. Computer science and engineering students at our institution were asked about their definition of academic dishonesty, its prevalence, the motivations and deterrents for engaging in such behaviour, and strategies to mitigate it. The survey was administered to students across all five year levels of the programme in 2021 (before the advent of GitHub Copilot and ChatGPT) and again in 2023. The results of these two surveys are compared with each other and against the results of the Sheard and Dick study of 2010. Additionally, we conducted a comparative analysis on the responses of students in different academic years to determine if fifth-year students exhibit more mature perceptions of academic dishonesty than first-year students. To further explore student attitudes towards cheating within the context of generative AI, a specialised survey was conducted in 2024, including an open-ended query. A thematic analysis of the responses to this question revealed seven distinct themes.",10.1145/3724363.3729108,https://doi.org/10.1145/3724363.3729108
Investigating the Use of ChatGPT to Support the Learning of Python Programming Among Upper Secondary School Students: A Design-Based Research Study,"Stone, Irene",Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research,2024,"This study investigates how ChatGPT can be used to support the learning of Python programming among upper second-level students in an Irish classroom. It addresses critical gaps in the literature, such as the lack of research at secondary level, the need for human-centered studies conducted over time, and the absence of guidelines for integrating ChatGPT into introductory programming education. Employing a design-based research methodology, this study aims to understand student engagement with ChatGPT and investigates how to support their use of prompts when learning to program. The research involves students as co-creators alongside their teacher, who is also the researcher, in developing a pedagogical framework that integrates ChatGPT into Python programming education.",10.1145/3689535.3689537,https://doi.org/10.1145/3689535.3689537
Research on Innovative Applications and Impacts of Using Generative AI for User Interface Design in Programming Courses,"Ho, Chia-Ling and Liu, Xin-Ying and Qiu, Yu-Wei and Yang, Shih-Yang","Proceedings of the 2024 International Conference on Information Technology, Data Science, and Optimization",2024,"Generative Artificial Intelligence (GAI) has become a hot topic nowadays, as its powerful content generation models enable users to instantly create everything from digital media products to coding examples through simple text queries, providing more possibilities in the field of education. This study aims to investigate the impact of Generative AI intervention in teaching App Inventor programming courses, analyzing the differences between UI materials designed by traditional teachers based on their professional knowledge and experience, and UI materials created by Generative AI in classroom teaching. The study also evaluates the impact of Generative AI on students' learning outcomes and motivation through satisfaction and Technology Acceptance Model (TAM) questionnaires. The results indicate that UI materials produced through Generative AI effectively enhance students' satisfaction with the course and their acceptance of new technologies. Compared to traditional teaching methods, Generative AI significantly saves teachers' time and effort in designing materials while simultaneously improving teaching efficiency and quality.",10.1145/3658549.3658566,https://doi.org/10.1145/3658549.3658566
Will Code Remain a Relevant User Interface for End-User Programming with Generative AI Models?,"Sarkar, Advait","Proceedings of the 2023 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software",2023,"The research field of end-user programming has largely been concerned with helping non-experts learn to code sufficiently well in order to achieve their tasks. Generative AI stands to obviate this entirely by allowing users to generate code from naturalistic language prompts. In this essay, we explore the extent to which",10.1145/3622758.3622882,https://doi.org/10.1145/3622758.3622882
Instructor Perceptions of AI Code Generation Tools - A Multi-Institutional Interview Study,"Sheard, Judy and Denny, Paul and Hellas, Arto and Leinonen, Juho and Malmi, Lauri and Simon",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"Much of the recent work investigating large language models and AI Code Generation tools in computing education has focused on assessing their capabilities for solving typical programming problems and for generating resources such as code explanations and exercises. If progress is to be made toward the inevitable lasting pedagogical change, there is a need for research that explores the instructor voice, seeking to understand how instructors with a range of experiences plan to adapt. In this paper, we report the results of an interview study involving 12 instructors from Australia, Finland and New Zealand, in which we investigate educators' current practices, concerns, and planned adaptations relating to these tools. Through this empirical study, our goal is to prompt dialogue between researchers and educators to inform new pedagogical strategies in response to the rapidly evolving landscape of AI code generation tools.",10.1145/3626252.3630880,https://doi.org/10.1145/3626252.3630880
Oversight in Action: Experiences with Instructor-Moderated LLM Responses in an Online Discussion Forum,"Qiao, Shuying and Denny, Paul and Giacaman, Nasser",Proceedings of the 27th Australasian Computing Education Conference,2025,"The integration of large language models (LLMs) into computing education offers many potential benefits to student learning, and several novel pedagogical approaches have been reported in the literature. However LLMs also present challenges, one of the most commonly cited being that of student over-reliance. This challenge is compounded by the fact that LLMs are always available to provide instant help and solutions to students, which can undermine their ability to independently solve problems and diagnose and resolve errors. Providing instructor oversight of LLM-generated content can mitigate this problem, however it is often not practical in real-time learning contexts. Online class discussion forums, which are widely used in computing education, present an opportunity for exploring instructor oversight because they operate asynchronously. Unlike real-time interactions, the discussion forum format aligns with the expectation that responses may take time, making oversight not only feasible but also pedagogically appropriate. In this practitioner paper, we present the design, deployment, and evaluation of a ‘bot’ module that is controlled by the instructor, and integrated into an online discussion forum. The bot assists the instructor by generating draft responses to student questions, which are reviewed, modified, and approved before release. Key features include the ability to leverage course materials, access archived discussions, and publish responses anonymously to encourage open participation. We report our experiences using this tool in a 12-week second-year software engineering course on object-oriented programming. Instructor feedback confirmed the tool successfully alleviated workload but highlighted a need for improvement in handling complex, context-dependent queries. We report the features that were viewed as most beneficial, and suggest avenues for future exploration.",10.1145/3716640.3716651,https://doi.org/10.1145/3716640.3716651
A Multi-Institutional Assessment of Oral Exams in Software Courses,"Ohmann, Peter and Novak, Ed",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Oral exams are an inviting alternative to traditional paper-and-pencil exams. However, they are largely under-utilized in computer science education. In this report, we describe our design for comprehensive final oral exams in five software engineering class sections, across two different small institutions. We present our exam format and our subjective assessment of the exam format in assessing student knowledge as instructors. We also gather quantitative and qualitative data from student surveys. We surveyed students before and after the oral exam to assess their perceptions of it, including their predicted grade and their subjective opinions and experiences. Our work shows evidence that oral exams are effective and practical mechanisms for software engineering classes of a smaller size (approximately 20 students). Student survey responses indicated favorable feedback for our oral exam format; students viewed oral exams as a good assessment of their knowledge and useful beyond that individual class.",10.1145/3641554.3701848,https://doi.org/10.1145/3641554.3701848
CS1-LLM: Integrating LLMs into CS1 Instruction,"Vadaparty, Annapurna and Zingaro, Daniel and Smith IV, David H. and Padala, Mounika and Alvarado, Christine and Gorson Benario, Jamie and Porter, Leo",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"The recent, widespread availability of Large Language Models (LLMs) like ChatGPT and GitHub Copilot may impact introductory programming courses (CS1) both in terms of what should be taught and how to teach it. Indeed, recent research has shown that LLMs are capable of solving the majority of the assignments and exams we previously used in CS1. In addition, professional software engineers are often using these tools, raising the question of whether we should be training our students in their use as well. This experience report describes a CS1 course at a large research-intensive university that fully embraces the use of LLMs from the beginning of the course. To incorporate the LLMs, the course was intentionally altered to reduce emphasis on syntax and writing code from scratch. Instead, the course now emphasizes skills needed to successfully produce software with an LLM. This includes explaining code, testing code, and decomposing large problems into small functions that are solvable by an LLM. In addition to frequent, formative assessments of these skills, students were given three large, open-ended projects in three separate domains (data science, image processing, and game design) that allowed them to showcase their creativity in topics of their choosing. In an end-of-term survey, students reported that they appreciated learning with the assistance of the LLM and that they interacted with the LLM in a variety of ways when writing code. We provide lessons learned for instructors who may wish to incorporate LLMs into their course.",10.1145/3649217.3653584,https://doi.org/10.1145/3649217.3653584
Comparison of Three Programming Error Measures for Explaining Variability in CS1 Grades,,Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"Programming courses can be challenging for first year university students, especially for those without prior coding experience. Students initially struggle with code syntax, but as more advanced topics are introduced across a semester, the difficulty in learning to program shifts to learning computational thinking (e.g., debugging strategies). This study examined the relationships between students' rate of programming errors and their grades on two exams. Using an online integrated development environment, data were collected from 280 students in a Java programming course. The course had two parts. The first focused on introductory procedural programming and culminated with exam 1, while the second part covered more complex topics and object-oriented programming and ended with exam 2. To measure students' programming abilities, 51095 code snapshots were collected from students while they completed assignments that were autograded based on unit tests. Compiler and runtime errors were extracted from the snapshots, and three measures - Error Count, Error Quotient and Repeated Error Density - were explored to identify the best measure explaining variability in exam grades. Models utilizing Error Quotient outperformed the models using the other two measures, in terms of the explained variability in grades and Bayesian Information Criterion. Compiler errors were significant predictors of exam 1 grades but not exam 2 grades; only runtime errors significantly predicted exam 2 grades. The findings indicate that leveraging Error Quotient with multiple error types (compiler and runtime) may be a better measure of students' introductory programming abilities, though still not explaining most of the observed variability.",10.1145/3649217.3653563,https://doi.org/10.1145/3649217.3653563
An Empirical Study on How Large Language Models Impact Software Testing Learning,"Mezzaro, Simone and Gambi, Alessio and Fraser, Gordon",Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering,2024,"Software testing is a challenging topic in software engineering education and requires creative approaches to engage learners. For example, the Code Defenders game has students compete over a Java class under test by writing effective tests and mutants. While such gamified approaches deal with problems of motivation and engagement, students may nevertheless require help to put testing concepts into practice. The recent widespread diffusion of Generative AI and Large Language Models raises the question of whether and how these disruptive technologies could address this problem, for example, by providing explanations of unclear topics and guidance for writing tests. However, such technologies might also be misused or produce inaccurate answers, which would negatively impact learning. To shed more light on this situation, we conducted the first empirical study investigating how students learn and practice new software testing concepts in the context of the Code Defenders testing game, supported by a smart assistant based on a widely known, commercial Large Language Model. Our study shows that students had unrealistic expectations about the smart assistant, “blindly” trusting any output it generated, and often trying to use it to obtain solutions for testing exercises directly. Consequently, students who resorted to the smart assistant more often were less effective and efficient than those who did not. For instance, they wrote 8.6% fewer tests, and their tests were not useful in 78.0% of the cases. We conclude that giving unrestricted and unguided access to Large Language Models might generally impair learning. Thus, we believe our study helps to raise awareness about the implications of using Generative AI and Large Language Models in Computer Science Education and provides guidance towards developing better and smarter learning tools.",10.1145/3661167.3661273,https://doi.org/10.1145/3661167.3661273
Synthetic Students: A Comparative Study of Bug Distribution Between Large Language Models and Computing Students,"MacNeil, Stephen and Rogalska, Magdalena and Leinonen, Juho and Denny, Paul and Hellas, Arto and Crosland, Xandria",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1,2024,"Large language models (LLMs) present an exciting opportunity for generating synthetic classroom data. Such data could include code containing a typical distribution of errors, simulated student behavior to address the cold start problem when developing education tools, and synthetic user data when access to authentic data is restricted due to privacy reasons. In this research paper, we conduct a comparative study examining the distribution of bugs generated by LLMs in contrast to those produced by computing students. Leveraging data from two previous large-scale analyses of student-generated bugs, we investigate whether LLMs can be coaxed to exhibit bug patterns that are similar to authentic student bugs when prompted to inject errors into code. The results suggest that unguided, LLMs do not generate plausible error distributions, and many of the generated errors are unlikely to be generated by real students. However, with guidance including descriptions of common errors and typical frequencies, LLMs can be shepherded to generate realistic distributions of errors in synthetic code.",10.1145/3649165.3690100,https://doi.org/10.1145/3649165.3690100
Designing LLM-Resistant Programming Assignments: Insights and Strategies for CS Educators,"McDanel, Bradley and Novak, Ed",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"The rapid advancement of Large Language Models (LLMs) like ChatGPT has raised concerns among computer science educators about how programming assignments should be adapted. This paper explores the capabilities of LLMs (GPT-3.5, GPT-4, and Claude Sonnet) in solving complete, multi-part CS homework assignments from the SIGCSE Nifty Assignments list. Through qualitative and quantitative analysis, we found that LLM performance varied significantly across different assignments and models, with Claude Sonnet consistently outperforming the others. The presence of starter code and test cases improved performance for advanced LLMs, while certain assignments, particularly those involving visual elements, proved challenging for all models. LLMs often disregarded assignment requirements, produced subtly incorrect code, and struggled with context-specific tasks. Based on these findings, we propose strategies for designing LLM-resistant assignments. Our work provides insights for instructors to evaluate and adapt their assignments in the age of AI, balancing the potential benefits of LLMs as learning tools with the need to ensure genuine student engagement and learning.",10.1145/3641554.3701872,https://doi.org/10.1145/3641554.3701872
ICER '23: Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1,,,2023,,,
Use of AI-driven Code Generation Models in Teaching and Learning Programming: a Systematic Literature Review,"Cambaz, Doga and Zhang, Xiaoling",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"The recent emergence of LLM-based code generation models can potentially transform programming education. To pinpoint the current state of research on using LLM-based code generators to support the teaching and learning of programming, we conducted a systematic literature review of 21 papers published since 2018. The review focuses on (1) the teaching and learning practices in programming education that utilized LLM-based code generation models, (2) characteristics and (3) performance indicators of the models, and (4) aspects to consider when utilizing the models in programming education, including the risks and challenges. We found that the most commonly reported uses of LLM-based code generation models for teachers are generating assignments and evaluating student work, while for students, the models function as virtual tutors. We identified that the models exhibit accuracy limitations; generated content often contains minor errors that are manageable by instructors but pose risks for novice learners. Moreover, risks such as academic misconduct and over-reliance on the models are critical when considering integrating these models into education. Overall, LLM-based code generation models can be an assistive tool for both learners and instructors if the risks are mitigated.",10.1145/3626252.3630958,https://doi.org/10.1145/3626252.3630958
Detecting AI-Generated Pseudocode in High School Online Programming Courses Using an Explainable Approach,"Liu, Zifeng and Jiao, Xinyue and Xing, Wanli and Zhu, Wangda",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Despite extensive research on code plagiarism detection in higher education and for programming languages like Java and Python, limited work has focused on K-12 settings, particularly for pseudocode. This study aims to address this gap by building explainable machine learning models for pseudocode plagiarism detection in online programming education. To achieve this, we construct a comprehensive dataset comprising 7,838 pseudocode submissions from 2,578 high school students enrolled in an online programming foundations course, along with 6,300 pseudocode samples generated by three versions of generative pre-trained transformer (GPT) models. Utilizing this dataset, we develop an explainable model to detect AI-generated pseudocode across various assessments. The model not only identifies AI-generated content but also provides insights into its predictions at both the student and problem levels, thus enhancing our understanding of AI-generated pseudocode in K-12 education. Furthermore, we analyzed SHAP values and key features of the model to pinpoint student submissions that closely resemble AI-generated pseudocode. This research offers implications for developing robust educational technologies and methodologies to uphold academic integrity in online programming courses.",10.1145/3641554.3701942,https://doi.org/10.1145/3641554.3701942
Finding Misleading Identifiers in Novice Code Using LLMs,,Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"Clear, well-chosen names for variables and functions significantly enhance code readability and maintainability. In computer science education, teaching students to select appropriate identifiers is a critical task, especially in CS1. This study explores how large language models (LLMs) could assist in teaching this skill. While prior research has explored the use of LLMs in programming education, their precision and consistency in teaching code quality, particularly identifier selection, remains largely unexplored. For this purpose, this study investigated how well different LLMs can detect and report misleading identifiers. In a dataset of 33 code samples, we manually labeled misleading identifiers. On this dataset, we then tested five different LLMs on their ability to detect these misleading identifiers, measuring the overall accuracy, precision, recall, and f-score. Results revealed that the most successful model, GPT-4o, was able to correctly detect most of the manually flagged misleading variable names. However, it also tended to flag issues with variable identifiers in cases where the human evaluators would not, and refined prompting was not able to discourage this behavior.",10.1145/3641555.3705282,https://doi.org/10.1145/3641555.3705282
Can ChatGPT pass a Theory of Computing Course?,"Golesteanu, Matei A. and Vowinkel, Garrett B. and Dougherty, Ryan E.",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1,2024,"Large Language Models (LLMs) have had considerable difficulty when prompted with mathematical and formal questions, especially those within theory of computing (ToC) courses. In this paper, we detail two experiments regarding our own ToC course and the ChatGPT LLM. For the first, we evaluated ChatGPT's ability to pass our own ToC course's exams. For the second, we created a database of sample ToC questions and responses to accommodate other ToC offerings' choices for topics and structure. We scored each of ChatGPT's outputs on these questions. Overall, we determined that ChatGPT can pass our ToC course, and is adequate at understanding common formal definitions and answering",10.1145/3649165.3690116,https://doi.org/10.1145/3649165.3690116
Constructive Alignment in Modern Computing Education: An Open-Source Computer-Based Examination System,"Linhuber, Matthias and Bernius, Jan Philip and Krusche, Stephan",Proceedings of the 23rd Koli Calling International Conference on Computing Education Research,2024,"Large-scale paper-based examinations (PBEs) in computing education frequently emphasize rote memorization, thereby misaligning instructional objectives with assessment techniques. Such incongruities hinder the preparation of students for real world challenges in both industry and academia by inadequately evaluating higher-order cognitive abilities. Often, educators are deterred from implementing comprehensive skills assessment due to the perceived complexity and resource-intensive grading processes involved. To mitigate these limitations, this paper introduces an exam mode as an integral feature of the open-source learning platform Artemis. Designed for both local and cloud-based deployment, this exam mode incorporates anti-cheating protocols, automates the grading of diverse exercise types, and features double-blind manual grading to ensure assessment integrity. It fosters the evaluation of complex cognitive skills while substantially reducing the administrative load on faculty. This paper substantiates the effectiveness of the Artemis&nbsp; exam mode through widespread institutional adoption, demonstrated by over 50 successful computer-based examinations (CBEs). An in-depth case study involving 1,700 undergraduate software engineering students offers key insights, best practices, and lessons learned. This research not only pioneers the documentation of a secure, scalable, and reliable exam system at an institutional scale but also marks a seminal contribution to modernizing assessment strategies in computing education, with a particular focus on constructive alignment.",10.1145/3631802.3631818,https://doi.org/10.1145/3631802.3631818
Kattis vs ChatGPT: Assessment and Evaluation of Programming Tasks in the Age of Artificial Intelligence,"Dunder, Nora and Lundborg, Saga and Wong, Jacqueline and Viberg, Olga",Proceedings of the 14th Learning Analytics and Knowledge Conference,2024,"AI-powered education technologies can support students and teachers in computer science education. However, with the recent developments in generative AI, and especially the increasingly emerging popularity of ChatGPT, the effectiveness of using large language models for solving programming tasks has been underexplored. The present study examines ChatGPT’s ability to generate code solutions at different difficulty levels for introductory programming courses. We conducted an experiment where ChatGPT was tested on 127 randomly selected programming problems provided by Kattis, an automatic software grading tool for computer science programs, often used in higher education. The results showed that ChatGPT independently could solve 19 out of 127 programming tasks generated and assessed by Kattis. Further, ChatGPT was found to be able to generate accurate code solutions for simple problems but encountered difficulties with more complex programming tasks. The results contribute to the ongoing debate on the utility of AI-powered tools in programming education.",10.1145/3636555.3636882,https://doi.org/10.1145/3636555.3636882
WiPSCE '23: Proceedings of the 18th WiPSCE Conference on Primary and Secondary Computing Education Research,,,2023,,,
Design and implementation of digital training evaluation management system based on AI's generative AI technology,"Xing, Kongduo",Proceedings of the 2023 7th International Conference on Electronic Information Technology and Computer Engineering,2024,"With the advancement of information technology, traditional offline training is gradually giving way to online digital training. The conventional online digital training evaluation management system entails manual data collection followed by the utilization of these gathered data for training effectiveness assessment. This entire process is intricate and can introduce potential biases. To address these challenges, we have developed a digital training management system rooted in AI's generative AI technology. This innovative system employs both the fuzzy comprehensive evaluation method and the artificial intelligence evaluation method to assess the quality and effectiveness indexes of digital training. Furthermore, it is designed on the foundation of deep learning algorithms, creating an AI-driven digital training evaluation management system. To ensure the security and privacy of the system, extensive simulation experiments have been conducted. These experiments help control the deviation values of evaluation results, ultimately guaranteeing the fairness of outcomes generated by the evaluation system.",10.1145/3650400.3650606,https://doi.org/10.1145/3650400.3650606
Quack! Configuring Large Language Models to Serve as Rubber Duck Coding Assistants,"Gonzalez, Elias and Chan, Joel and Weintrop, David",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"The emergence of Generative Artificial Intelligence (GenAI) tools broadly, and Large Language Models (LLMs) specifically, are equipping introductory programming instructors with a whole new class of pedagogical tools. While GenAI certainly poses threats to time-honored instructional techniques, it also provides opportunities for new forms of instructional support. In this work, we introduce our strategy for configuring an LLM to serve as a ''rubber duck debugging'' coding assistant to help novice programmers when they encounter difficulties in programming assignments. The key contribution of this work is not in the idea of using LLMs for debugging itself (which has already been demonstrated elsewhere, e.g., [3]) but to demonstrate the ease, flexibility, and pedagogical potential of the strategy. In particular, through carefully crafted prompts and easily accessible platforms, rubber duck LLMs can assist learners with specific questions while also situating those questions alongside larger computer science concepts and computational thinking practices. This work contributes an easily replicated and model-agnostic instructional strategy that productively and responsibly leverages the power of LLMs to assist novice programmers in developing foundational programming skills.",10.1145/3641555.3705235,https://doi.org/10.1145/3641555.3705235
Navigating Compiler Errors with AI Assistance - A Study of GPT Hints in an Introductory Programming Course,"Pankiewicz, Maciej and Baker, Ryan S.",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"We examined the efficacy of AI-assisted learning in an introductory programming course at the university level by using a GPT-4 model to generate personalized hints for compiler errors within a platform for automated assessment of programming assignments. The control group had no access to GPT hints. In the experimental condition GPT hints were provided when a compiler error was detected, for the first half of the problems in each module. For the latter half of the module, hints were disabled. Students highly rated the usefulness of GPT hints. In affect surveys, the experimental group reported significantly higher levels of focus and lower levels of confrustion (confusion and frustration) than the control group. For the six most commonly occurring error types we observed mixed results in terms of performance when access to GPT hints was enabled for the experimental group. However, in the absence of GPT hints, the experimental group's performance surpassed the control group for five out of the six error types.",10.1145/3649217.3653608,https://doi.org/10.1145/3649217.3653608
Seeing the Forest and the Trees: Solving Visual Graph and Tree Based Data Structure Problems using Large Multimodal Models,"Gutierrez, Sebastian and Hou, Irene and Lee, Jihye and Angelikas, Kenneth and Man, Owen and Mettille, Sophia and Prather, James and Denny, Paul and MacNeil, Stephen",Proceedings of the 27th Australasian Computing Education Conference,2025,"Recent advancements in generative AI systems have raised concerns about academic integrity among educators. Beyond excelling at solving programming problems and text-based multiple-choice questions, recent research has also found that large multimodal models (LMMs) can solve Parsons problems based only on an image. However, such problems are still inherently text-based and rely on the capabilities of the models to convert the images of code blocks to their corresponding text. In this paper, we further investigate the capabilities of LMMs to solve graph and tree data structure problems based only on images. To achieve this, we computationally construct and evaluate a novel benchmark dataset comprising 9,072 samples of diverse graph and tree data structure tasks to assess the performance of the GPT-4o, GPT-4 with Vision (GPT-4V), Gemini 1.5 Pro, Gemini 1.5 Flash, Gemini 1.0 Pro Vision, and Claude 3 model families. GPT–4o and Gemini 1.5 Flash performed best on trees and graphs respectively. GPT-4o achieved 87.6% accuracy on tree samples, while Gemini 1.5 Pro, achieved 76.9% accuracy on graph samples. Our findings highlight the influence of structural and visual variations on model performance. This research not only introduces an LMM benchmark to facilitate replication and further exploration but also underscores the potential of LMMs in solving complex computing problems, with important implications for pedagogy and assessment practices.",10.1145/3716640.3716654,https://doi.org/10.1145/3716640.3716654
One Step at a Time: Combining LLMs and Static Analysis to Generate Next-Step Hints for Programming Tasks,"Birillo, Anastasiia and Artser, Elizaveta and Potriasaeva, Anna and Vlasov, Ilya and Dzialets, Katsiaryna and Golubev, Yaroslav and Gerasimov, Igor and Keuning, Hieke and Bryksin, Timofey",Proceedings of the 24th Koli Calling International Conference on Computing Education Research,2024,"Students often struggle with solving programming problems when learning to code, especially when they have to do it online, with one of the most common disadvantages of working online being the lack of personalized help. This help can be provided as next-step hint generation, i.e., showing a student what specific small step they need to do next to get to the correct solution. There are many ways to generate such hints, with large language models (LLMs) being among the most actively studied right now. While LLMs constitute a promising technology for providing personalized help, combining them with other techniques, such as static analysis, can significantly improve the output quality. In this work, we utilize this idea and propose a novel system to provide both textual and code hints for programming tasks. The pipeline of the proposed approach uses a chain-of-thought prompting technique and consists of three distinct steps: (1) generating subgoals — a list of actions to proceed with the task from the current student’s solution, (2) generating the code to achieve the next subgoal, and (3) generating the text to describe this needed action. During the second step, we apply static analysis to the generated code to control its size and quality. The tool is implemented as a modification to the open-source JetBrains Academy plugin, supporting students in their in-IDE courses. To evaluate our approach, we propose a list of criteria for all steps in our pipeline and conduct two rounds of expert validation. Finally, we evaluate the next-step hints in a classroom with 14 students from two universities. Our results show that both forms of the hints — textual and code — were helpful for the students, and the proposed system helped them to proceed with the coding tasks.",10.1145/3699538.3699556,https://doi.org/10.1145/3699538.3699556
KernelVM: Teaching Linux Kernel Programming through a Browser-Based Virtual Machine,"Wen, Elliott and Ma, Sean and Denny, Paul and Tempero, Ewan and Weber, Gerald and Yue, Zongcheng",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Providing students with hands-on experience in kernel programming within a real-world operating system is highly beneficial in an Operating Systems (OS) course for teaching core operating system concepts and developing practical skills. However, accessing suitable devices for such hands-on experimentation poses significant challenges. Traditional solutions involve hosting virtual machines on cloud platforms, which are expensive and do not scale well with increasing student numbers. Additionally, many students' personal devices, such as Macs or iPads, have limited support for running Linux, creating further barriers. In this paper, we introduce KernelVM, a novel cost-effective platform that offers students a Linux virtual machine with full superuser access and pre-configured kernel programming toolchains. KernelVM is accessible via any modern browser on any device. It performs all computations locally within the user's browser, thus eliminating cloud computing costs. KernelVM provides a robust learning environment by incorporating interactive virtual hardware components and an automatic evaluation system, supporting a wide range of tasks, including multi-threaded cryptographic kernel modules and Linux drivers for hardware interaction. We detail the design of KernelVM, and describe our experiences incorporating it for the first time into an OS course with 159 undergraduate students. We found that KernelVM was instrumental in improving the quality and efficiency of hands-on learning experiences, with students reporting increased satisfaction and engagement due to the immediate feedback and the ability to experiment in a risk-free environment. Our experience suggests that KernelVM not only addresses the logistical challenges of kernel programming education, but it helps foster a highly interactive and engaging learning experience.",10.1145/3641554.3701831,https://doi.org/10.1145/3641554.3701831
"Faceless Adversary, Feckless Colleague: The Many Sides of ChatGPT","Bird, William",Proceedings of the 26th Western Canadian Conference on Computing Education,2024,"Although CS educators have studied the potential of generative AI for years, the release of ChatGPT in late 2022 sparked a wave of uncertainty and anxiety. With students arriving at university already experienced with using ChatGPT for work across the academic spectrum, educators were under pressure to somehow address the presence of this new resource in their classroom. This article describes both the “climate of fear” surrounding ChatGPT’s impacts on education and an attempt by the authors to induct ChatGPT as a colleague instead of an adversary. While creating a video series where we used ChatGPT to generate practice exercises for CS1 and CS2, we found it to be patient, charismatic and friendly, but also sometimes obstinate, misinformed, stubborn and confused; in other words, it was surprisingly human.",10.1145/3660650.3660656,https://doi.org/10.1145/3660650.3660656
"Self-Regulation, Self-Efficacy, and Fear of Failure Interactions with How Novices Use LLMs to Solve Programming Problems","Margulieux, Lauren E. and Prather, James and Reeves, Brent N. and Becker, Brett A. and Cetin Uzun, Gozde and Loksa, Dastyni and Leinonen, Juho and Denny, Paul",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"We explored how undergraduate introductory programming students naturalistically used generative AI to solve programming problems. We focused on the relationship between their use of AI to their self-regulation strategies, self-efficacy, and fear of failure in programming. In this repeated-measures, mixed-methods research, we examined students' patterns of using generative AI with qualitative student reflections and their self-regulation, self-efficacy, and fear of failure with quantitative instruments at multiple times throughout the semester. We also explored the relationships among these variables to learner characteristics, perceived usefulness of AI, and performance. Overall, our results suggest that student factors affect their baseline use of AI. In particular, students with higher self-efficacy, lower fear of failure, or higher prior grades tended to use AI less or later in the problem-solving process and rated it as less useful than others. Interestingly, we found no relationship between students' self-regulation strategies and their use of AI. Students who used AI less or later in problem-solving also had higher grades in the course, but this is most likely due to prior characteristics as our data do not suggest that this is a causal relationship.",10.1145/3649217.3653621,https://doi.org/10.1145/3649217.3653621
Insights from Social Shaping Theory: The Appropriation of Large Language Models in an Undergraduate Programming Course,"Padiyath, Aadarsh and Hou, Xinying and Pang, Amy and Viramontes Vargas, Diego and Gu, Xingjian and Nelson-Fromm, Tamara and Wu, Zihan and Guzdial, Mark and Ericson, Barbara",Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1,2024,"The capability of large language models (LLMs) to generate, debug, and explain code has sparked the interest of researchers and educators in undergraduate programming, with many anticipating their transformative potential in programming education. However, decisions about why and how to use LLMs in programming education may involve more than just the assessment of an LLM’s technical capabilities. Using the social shaping of technology theory as a guiding framework, our study explores how students’ social perceptions influence their own LLM usage. We then examine the correlation of self-reported LLM usage with students’ self-efficacy and midterm performances in an undergraduate programming course. Triangulating data from an anonymous end-of-course student survey (n = 158), a mid-course self-efficacy survey (n=158), student interviews (n = 10), self-reported LLM usage on homework, and midterm performances, we discovered that students’ use of LLMs was associated with their expectations for their future careers and their perceptions of peer usage. Additionally, early self-reported LLM usage in our context correlated with lower self-efficacy and lower midterm scores, while students’ perceived over-reliance on LLMs, rather than their usage itself, correlated with decreased self-efficacy later in the course.",10.1145/3632620.3671098,https://doi.org/10.1145/3632620.3671098
Automation Support for Giving Feedback in Learning Programming by Doing,"Rump, Arthur",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 2,2025,"Providing effective feedback on open-ended programming assignments is a challenge, particularly at scale. This challenge impacts student learning, as timely and accurate feedback is crucial to improve their programming and program design skills. We intend to develop an approach leveraging automation to support the feedback process, without requiring changes to assignments that enable full automation. This method aims to improve the consistency and efficiency of giving feedback, helping students learn more effectively.",10.1145/3724389.3731300,https://doi.org/10.1145/3724389.3731300
What Can Computer Science Educators Learn From the Failures of Top-Down Pedagogy?,"Thorgeirsson, Sverrir and Ewen, Tracy and Su, Zhendong",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"While educational researchers in various disciplines are grappling with how to develop policies and pedagogical approaches that address the use of generative artificial intelligence, the challenge is particularly complex in computer science education where the new technology is changing the core of the field. In this paper, we take a look at the pedagogy of other subjects with a longer history than computer science and a more extensive body of educational research to collect insights on how this challenge can be met. We begin by drawing from recent neurological research to find domains that share cognitive commonalities with computer programming and then build upon comparisons that others have made to literacy and mathematics education. We then consider how the",10.1145/3641554.3701873,https://doi.org/10.1145/3641554.3701873
Proceedings of the 2024 on RESPECT Annual Conference,"Gelder, William and Baker-Ramos, Rachel and Cho, Ayoung and Kolakaluri, Jahnavi and Uchidiuno, Judith and Hester, Josiah",Proceedings of the 2024 on RESPECT Annual Conference,2024,"Hawaiian bilingual language immersion (Kaiapuni) schools infuse curricula with place-based education to increase student connection to culture. However, stand-in teachers often lack the background and tools needed to support immersion learning, resulting in discontinuity for students in their culturally relevant education. This experience report describes a partnership between the Ka Moamoa Lab at the Georgia Institute of Technology and Ke Kula Kaiapuni 'O Pu'ohala School to design a teacher-substitute support platform via a hybrid of assets-based design methodology and emerging technology capabilities. We share insights offered by teachers and design requirements for such a platform. We also reflect on how HCI methodologies should adapt to center and respect Native Hawaiian perspectives.",10.1145/3653666.3656066,https://doi.org/10.1145/3653666.3656066
Refuting LLM-generated Code with Reactive Task Comprehension,"Hebbar, Sannidhi V and Harini S, Sasmita and Kumar, Viraj",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"Large Language Models (LLMs) for code generation have improved to the point where they are being integrated into professional software development workflows. Since these models occasionally generate buggy code, it is important for students to develop the ability to refute such code (typically, by identifying a counterexample input on which the code fails to perform the desired task). To create counterexamples manually, prior work has suggested code comprehension and task comprehension as two necessary skills. In this paper, we anticipate advances in software development tools and consider a limited form of the latter skill -- reactive task comprehension -- where students only need to correctly state the code's desired behavior on inputs suggested by an automated system. We make two contributions. First, we demonstrate the feasibility of such a system based on existing LLMs and code coverage tools. Second, we show that reactive task comprehension is surprisingly effective in refuting LLM-generated buggy Python functions in the HumanEval+ dataset. Bearing in mind that students are likely to have access to increasingly sophisticated code generation models and assistive systems, we discuss the implications of our findings for introductory programming education.",10.1145/3724363.3729100,https://doi.org/10.1145/3724363.3729100
Evaluation of a Node-based Automatic Short Answer Tool “NodeGrade”,"Fischer, David Vincent and Haug, Jim and Schoppel, Paul and Abke, J\",Proceedings of the 6th European Conference on Software Engineering Education,2025,"NodeGrade tries to provide a suitable solution for the problem of time-intensive short answer grading. This research focuses simultaneously on performance, functionality and user experience, which is underlined by a triangulated approach. The evaluation results show comparable performance of NodeGrade on public datasets, even outperforming GPT-4 on the SemEval 2013 Task 7. Matching of NodeGrade’s output with multiple human expert raters reveals some weaknesses regarding cases at the lower and upper boundary. In terms of user experience, the interviewed and observed students recognized both positive facets, like better learning support and helpful feedback, and negative sides, including technical limitations and lack of transparency. Overall, NodeGrade promises high potential for further practical use and testing in the field of software engineering education and automatic short answer grading.",10.1145/3723010.3723021,https://doi.org/10.1145/3723010.3723021
LLM-based Individual Contribution Summarization in Software Projects,"de Miranda, Fabio and Ferrao, Rafael Corsi and Soler, Diego Pavan and Vieira Graglia, Marcelo Augusto",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2,2024,"This work in progress is about preliminary results in using a Large Language Model (LLM) to summarize individual student contributions in open-ended software projects. Projects for industry clients are good real-world learning opportunities. Though, if the scope is open and defined based on external clients' needs, each group's project will look unique, what makes a challenge for grading and regular feedback. Distributed code version control systems such as Git and resources such as Git classroom help, but it is still burdensome to have professors and TAs looking at the repositories with a frequency that enables useful, timely feedback for the students. We prototyped a method of summarizing each student's contributions to a project's Git repository using an LLM, indicating how to preprocess and break down repository data in order to get better responses from the system. Each student's contributions were extracted using Pydriller. This technique was tested during a 3-week full-time software development sprint in a class of 28 students. Preliminary results indicate a general agreement of students and faculty with the synthesized summaries and an increase in students' awareness of individual responsibilities within the teams and an improvement in engagement among less active members.",10.1145/3649409.3691092,https://doi.org/10.1145/3649409.3691092
Counting the Trees in the Forest: Evaluating Prompt Segmentation for Classifying Code Comprehension Level,"Smith, David H., IV and Fowler, Max and Denny, Paul and Zilles, Craig",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"Reading and understanding code are fundamental skills for novice programmers, and especially important with the growing prevalence of AI-generated code and the need to evaluate its accuracy and reliability. ''Explain in Plain English'' questions are a widely used approach for assessing code comprehension, but providing automated feedback, particularly on comprehension levels, is a challenging task. This paper introduces a novel method for automatically assessing the comprehension level of responses to ''Explain in Plain English'' questions. Central to this is the ability to distinguish between two response types: multi-structural, where students describe the code line-by-line, and relational, where they explain the code's overall purpose. Using a Large Language Model (LLM) to segment both the student's description and the code, we aim to determine whether the student describes each line individually (many segments) or the code as a whole (fewer segments). We evaluate this approach's effectiveness by comparing segmentation results with human classifications, achieving substantial agreement. We conclude with how this approach, which we release as an open source Python package, could be used as a formative feedback mechanism.",10.1145/3724363.3729045,https://doi.org/10.1145/3724363.3729045
Fostering Responsible AI Use Through Negative Expertise: A Contextualized Autocompletion Quiz,"MacNeil, Stephen and Prather, James and Nabid, Rahad Arman and Gutierrez, Sebastian and Carvalho, Silas and Shrestha, Saimon and Denny, Paul and Reeves, Brent N. and Leinonen, Juho and Rossetti, Rachel Louise",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"Generative AI tools, like GitHub Copilot, are becoming an industry standard by offering real-time code suggestions that streamline the coding process. Although these systems improve productivity, they also introduce pedagogical challenges. Students may become overly reliant on AI-generated code suggestions, accepting them without critical thought, potentially reducing their ability to engage with the underlying logic of the code. We developed an interactive quiz system within a simulated IDE environment designed to help students think critically about autogenerated code suggestions. Instructors use the tool to create contextualized coding quizzes that present multiple code suggestions at each line. Students must choose the correct option to move on to the next step. Survey responses suggest that this approach could promote critical thinking and scaffold metacognitive skills like planning and reflection. Students reported that the system helped them distinguish between good and bad suggestions. Most students preferred this experience to traditional quizzes or Github Copilot. These findings show the potential to scaffold more critical use of generative AI coding tools.",10.1145/3724363.3729067,https://doi.org/10.1145/3724363.3729067
Peer Code Review Methods: An Experience Report from a Data Structures and Algorithms Course,"Koitz-Hristov, Roxane",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Peer code review is a key practice in professional software development, and its integration into computer science education can provide valuable learning experiences for students. However, few reports compare different peer code review methods within a single educational context. This experience report shares insights from implementing various review types-individual, team, and pair code reviews-in a first-year Data Structures and Algorithms course in a bachelor's degree program. Throughout the semester, students took an active role in their learning by completing three programming assignments, each followed by a different peer review method. Feedback was collected through questionnaires to capture the students' perceptions of their data structure knowledge, programming skills, and overall learning experience. Our report outlines the design of the different review learning activities, provides insights into the students' opinions on the review techniques, and reflects on the challenges and successes we encountered. As each method offers unique benefits, we believe that incorporating a variety of peer code review methods can enhance the overall learning experience in computer science courses.",10.1145/3641554.3701799,https://doi.org/10.1145/3641554.3701799
The Impact of Students' Views of Failure on Performance in Introductory Programming Courses,"Rahimi, Masoumeh and Margulieux, Lauren E. and Towell, Dwayne and Calver, Jonathan and Loksa, Dastyni and Prather, James",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"Introductory programming courses present a unique challenge for many students as a novel discipline, requiring significant time investment and featuring a steep learning curve, resulting in students experiencing high levels of failure while learning. Students' perspectives on failure are crucial in determining how they confront these challenges and, consequently, their learning outcomes. This study investigates the relationship between undergraduate students' views on failure--measured by validated scales about growth mindset, fear of failure, self-efficacy, and academic resilience--with their performance in introductory programming courses. While self-efficacy and growth mindset are well-studied in computing education, fear of failure and academic resilience remain understudied despite their prominence in other disciplines. We collected data from three universities to conduct a repeated measures study of 58 students' attitudes toward failure at the beginning and the end of the semester. Our results indicated self-efficacy and fear of failure uniquely predicted performance, with lower self-efficacy and higher fear of failure related to poorer outcomes. Furthermore, students with lower self-efficacy and higher fear of failure were four times more likely to withdraw from or fail the course. Our findings suggest that measuring self-efficacy and fear of failure at the beginning of the semester can help identify at-risk students who need support. Research and interventions related to academic fear of failure from other STEM fields should be examined in the context of computing education to improve outcomes for our students.",10.1145/3724363.3729112,https://doi.org/10.1145/3724363.3729112
Combining LLM-Generated and Test-Based Feedback in a MOOC for Programming,"Gabbay, Hagit and Cohen, Anat",,2024,"In large-scale programming courses, providing learners with immediate and effective feedback is a significant challenge. This study explores the potential of Large Language Models (LLMs) to generate feedback on code assignments and to address the gaps in Automated Test-based Feedback (ATF) tools commonly employed in programming courses. We applied dedicated metrics in a Massive Open Online Course (MOOC) on programming to assess the correctness of feedback generated by two models, GPT-3.5-turbo and GPT-4, using a reliable ATF as a benchmark. The findings point to effective error detection, yet the feedback is often inaccurate, with GPT-4 outperforming GPT-3.5-turbo. We used insights gained from the prompt practices to develop Gipy, an application for submitting course assignments and obtaining LLM-generated feedback. Learners participating in a field experiment perceived the feedback provided by Gipy as moderately valuable, while at the same time recognizing its potential to complement ATF. Given the learners' critique and their awareness of the limitations of LLM-generated feedback, the studied implementation may be able to take advantage of the best of both ATF and LLMs as feedback resources. Further research is needed to assess the impact of LLM-generated feedback on learning outcomes and explore the capabilities of more advanced models.",10.1145/3657604.3662040,https://doi.org/10.1145/3657604.3662040
Oral Exams in CS-Education: Pros and Cons in the Age of AI Assisted Programming,"Novak, Ed and Ohmann, Peter",J. Comput. Sci. Coll.,2023,"As AI coding tools proliferate through the computer science community, oral exams present a compelling way to assess the skills of students. Unfortunately, oral exams also present some difficulties, particularly for large class sizes.",,
Creating in-IDE Programming Courses,"Birillo, Anastasiia and Keuning, Hieke and Migut, Gosia and Dzialets, Katsiaryna and Golubev, Yaroslav",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"The in-IDE learning format represents a novel way of teaching programming to students entirely within an industry-grade IDE, allowing them to learn both the language and the necessary tooling at the same time. In this tutorial, we will teach the audience everything they need to know to create in-IDE courses and analyze how the students are working in them. In the first part of the tutorial, the audience will get to know the JetBrains Academy plugin that allows creating courses for IntelliJ-based IDEs such as IntelliJ IDEA and PyCharm. The participants will develop their own simple courses with theory, programming tasks, and quizzes, as well as employ some LLM-based features like automatic test generation. In the second part, we will learn how to use another plugin to collect code snapshots and the usage of IDE features of students when they are solving the tasks. Finally, the participants will solve tasks in their own course while using the data gathering plugin, and we will show them how to process and analyze the collected data. As the outcome of the tutorial, the audience will know how to create in-IDE courses, track the students' performance and analyze it, and will already have their own simple course and a dataset that can be expanded or used for further research.",10.1145/3641555.3704762,https://doi.org/10.1145/3641555.3704762
Assessing the Influence of ChatGPT on Student Outcomes in a Models of Computing Course,,Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"This study investigates the impact of ChatGPT on student performance in a Models of Computing course, foundational for the computer science major. Analysing data from 11 pre-lecture quizzes across four terms, we found a decline in average quiz scores, particularly in the latest term. The results suggest a correlation between increased reliance on ChatGPT and decreased student performance, especially on challenging questions where the AI frequently struggled. These findings highlight both the benefits and challenges of integrating AI in education. Our ongoing research aims to explore this further across multiple courses, ultimately promoting responsible AI use to enhance learning outcomes.",10.1145/3641555.3705132,https://doi.org/10.1145/3641555.3705132
Simulating Requirement Elicitation: Development and Evaluation of a Persona-Based Tool,"Akhmetov, Ildar and Prpa, Mirjana",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,We present the Requirement Elicitation Tool that leverages Large Language Model (LLM) (gpt-4o-mini) to enable simulated real-world interactions of requirements gathering from three synthetic personas. We demonstrate the use case of Computer Science (CS) students in Database Management Systems leveraging the tool to build a conceptual model and Entity-Relationship (ER) diagrams. Our preliminary findings show the potential of this tool to engage students in discovery process without providing predefined solutions and set the directions for future work.,10.1145/3641555.3705250,https://doi.org/10.1145/3641555.3705250
Evaluating Automatically Generated Contextualised Programming Exercises,"Del Carpio Gutierrez, Andre and Denny, Paul and Luxton-Reilly, Andrew",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"Introductory programming courses often require students to solve many small programming exercises as part of their learning. Researchers have previously suggested that the context used in the problem description for these exercises is likely to impact student engagement and motivation. Furthermore, supplying programming exercises that use a broad range of contexts or even allowing students to select contexts to personalize their own exercises, may support the interests of a diverse student population. Unfortunately, it is time-consuming for instructors to create large numbers of programming exercises that provide a wide range of contextualized problems. However, recent work has shown that large language models may be able to automate the mass production of programming exercises, reducing the burden on instructors. In this research, we explore the potential of OpenAI's GPT-4 to create high-quality and novel programming exercises that implement various contexts. Finally, through prompt engineering, we compare different prompting strategies used to generate many programming exercises with various contextualized problem descriptions and then evaluate the quality of the exercises generated.",10.1145/3626252.3630863,https://doi.org/10.1145/3626252.3630863
Beyond Traditional Teaching: Large Language Models as Simulated Teaching Assistants in Computer Science,"Liu, Mengqi and M'Hiri, Faten",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"As the prominence of Large Language Models (LLMs) grows in various sectors, their potential in education warrants exploration. In this study, we investigate the feasibility of employing GPT-3.5 from OpenAI, as an LLM teaching assistant (TA) or a virtual TA in computer science (CS) courses. The objective is to enhance the accessibility of CS education while maintaining academic integrity by refraining from providing direct solutions to current-semester assignments. Targeting Foundations of Programming (COMP202), an undergraduate course that introduces students to programming with Python, we have developed a virtual TA using the LangChain framework, known for integrating language models with diverse data sources and environments. The virtual TA assists students with their code and clarifies complex concepts. For homework questions, it is designed to guide students with hints rather than giving out direct solutions. We assessed its performance first through a qualitative evaluation, then a survey-based comparative analysis, using a mix of questions commonly asked on the COMP202 discussion board and questions created by the authors. Our preliminary results indicate that the virtual TA outperforms human TAs on clarity and engagement, matching them on accuracy when the question is non-assignment-specific, for which human TAs still proved more reliable. These findings suggest that while virtual TAs, leveraging the capabilities of LLMs, hold great promise towards making CS education experience more accessible and engaging, their optimal use necessitates human supervision. We conclude by identifying several directions that could be explored in future implementations.",10.1145/3626252.3630789,https://doi.org/10.1145/3626252.3630789
LLM-aided Pair Programming for Algorithm Tracing,"Andrei, Oana and Sojtory, Zoltan",Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research,2024,"The recent widespread popularity of generative AI models has inspired the development of large-language model (LLM) based tools for educational purposes. We explore the impact of LLM-based tools on pair programming for algorithm tracing with the aim of addressing challenges inherent to pair programming. We designed and developed a GPT-4 based tool, TraceCompanion, that acts as students’ pair programming partner for algorithm tracing. We describe insights gained from running a pilot study to investigate students’ interactions with the tool and their initial perceptions.",10.1145/3689535.3689546,https://doi.org/10.1145/3689535.3689546
Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education,"Pan, Wei Hung and Chok, Ming Jie and Wong, Jonathan Leong Shan and Shin, Yung Xin and Poon, Yeong Shian and Yang, Zhou and Chong, Chun Yong and Lo, David and Lim, Mei Kuan",Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training,2024,"Educators are increasingly concerned about the usage of Large Language Models (LLMs) such as ChatGPT in programming education, particularly regarding the potential exploitation of imperfections in Artificial Intelligence Generated Content (AIGC) Detectors for academic misconduct.In this paper, we present an empirical study where the LLM is examined for its attempts to bypass detection by AIGC Detectors. This is achieved by generating code in response to a given question using different variants. We collected a dataset comprising 5,069 samples, with each sample consisting of a textual description of a coding problem and its corresponding human-written Python solution codes. These samples were obtained from various sources, including 80 from Quescol, 3,264 from Kaggle, and 1,725 from Leet-Code. From the dataset, we created 13 sets of code problem variant prompts, which were used to instruct ChatGPT to generate the outputs. Subsequently, we assessed the performance of five AIGC detectors. Our results demonstrate that existing AIGC Detectors perform poorly in distinguishing between human-written code and AI-generated code.",10.1145/3639474.3640068,https://doi.org/10.1145/3639474.3640068
Assessment in CS50 with AI: Leveraging Generative Artificial Intelligence for Personalized Student Evaluation,"Liu, Rongxin and Xu, Benjamin and Perez, Christopher and Zhao, Julianna and Zhukovets, Yuliia and Malan, David J.",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"The scalability challenges of code review and pair-programming assessments in large computer science courses, such as CS50 at Harvard University, have opened up opportunities for the application of Generative AI. Leveraging large language models (LLMs), CS50.ai offers a suite of AI-based tools that assist both students and instructors in mastering course material while overcoming the limitations posed by human resource constraints. This demo highlights how generative AI can be employed to conduct code reviews and pair-programming simulations, providing real-time feedback, code explanations, and collaborative programming insights. By integrating these AI tools into students' learning journeys, we aim to mimic the 1:1 interaction between instructor and student, improving both formative and summative assessments. We will showcase how these tools are implemented to scale personalized feedback, ensure academic integrity, and maintain pedagogical efficacy. Our presentation will also reflect on lessons learned from deploying these AI-driven tools in recent course offerings.",10.1145/3641555.3705061,https://doi.org/10.1145/3641555.3705061
Koli Calling '22: Proceedings of the 22nd Koli Calling International Conference on Computing Education Research,,,2022,,,
More Robots are Coming: Large Multimodal Models (ChatGPT) can Solve Visually Diverse Images of Parsons Problems,"Hou, Irene and Man, Owen and Mettille, Sophia and Gutierrez, Sebastian and Angelikas, Kenneth and MacNeil, Stephen",Proceedings of the 26th Australasian Computing Education Conference,2024,"Large language models are reshaping computing education. Based on recent research, these models explain code better than students, answer multiple choice questions at or above the class average, and generate code that can pass automated tests in introductory courses. In response to these capabilities, instructors have quickly adjusted their courses and assessment methods to align with shifting learning goals and the increased risk of academic integrity issues. While some scholars have advocated for the integration of visual problems as a safeguard against the capabilities of language models, new multimodal models now have vision and language capabilities that may allow them to analyze and solve visual problems. In this paper, we compare the large multimodal model (LMMs) GPT-4V with Bard, an LLM that uses Google Lens for text recognition. We find that LMMs, which have learned both pixel features (from images) and text features (from prompts) in the same embedding space, performed substantially better than Bard which uses a piecemeal approach. With a specific focus on Parsons problems presented across diverse visual representations, our results show that GPT-4V solved 96.7% these visual problems, struggling minimally with a single Parsons problem. Conversely, Bard performed poorly by only solving 69.2% of problems, struggling with common issues like hallucinations and refusals. These findings suggest that merely transitioning to visual programming problems might not be a panacea to issues of academic integrity in the generative AI era.",10.1145/3636243.3636247,https://doi.org/10.1145/3636243.3636247
Comparing Code Explanations Created by Students and Large Language Models,"Leinonen, Juho and Denny, Paul and MacNeil, Stephen and Sarsa, Sami and Bernstein, Seth and Kim, Joanne and Tran, Andrew and Hellas, Arto",Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1,2023,"Reasoning about code and explaining its purpose are fundamental skills for computer scientists. There has been extensive research in the field of computing education on the relationship between a student's ability to explain code and other skills such as writing and tracing code. In particular, the ability to describe at a high-level of abstraction how code will behave over all possible inputs correlates strongly with code writing skills. However, developing the expertise to comprehend and explain code accurately and succinctly is a challenge for many students. Existing pedagogical approaches that scaffold the ability to explain code, such as producing exemplar code explanations on demand, do not currently scale well to large classrooms. The recent emergence of powerful large language models (LLMs) may offer a solution. In this paper, we explore the potential of LLMs in generating explanations that can serve as examples to scaffold students' ability to understand and explain code. To evaluate LLM-created explanations, we compare them with explanations created by students in a large course (n ≈ 1000) with respect to accuracy, understandability and length. We find that LLM-created explanations, which can be produced automatically on demand, are rated as being significantly easier to understand and more accurate summaries of code than student-created explanations. We discuss the significance of this finding, and suggest how such models can be incorporated into introductory programming education.",10.1145/3587102.3588785,https://doi.org/10.1145/3587102.3588785
"Performance, Workload, Emotion, and Self-Efficacy of Novice Programmers Using AI Code Generation","Gardella, Nicholas and Pettit, Raymond and Riggs, Sara L.",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"Artificial Intelligence-driven Development Environments (AIDEs) offer developers revolutionary computer programming assistance. There is great potential in incorporating AIDEs into Computer Science education; however, the effects of these tools should be fully examined before doing so. Here, a within-subjects study was conducted to compare the programming performance, workload, emotion, and self-efficacy of seventeen novices coding with and without use of the GitHub Copilot AIDE under time pressure. Results showed that using the AIDE significantly increased programming efficiency and reduced effort and mental workload but did not significantly impact emotion or self-efficacy. However, participants' performance improved with more experience using the AI, and their self-efficacy followed. The results suggest that students who try AIDEs will likely be tempted to use them for time-sensitive work. There is no evidence that providing AIDEs will aid struggling students, but there is a clear need for students to practice with AI to become competent and confident using it.",10.1145/3649217.3653615,https://doi.org/10.1145/3649217.3653615
Towards the Integration of Large Language Models in an Object-Oriented Programming Course,"Cipriano, Bruno Pereira",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2,2024,"The advent of Large Language Models (LLMs) has created multiple challenges for the Computer Science Education Community. This research project aims at integrating LLMs into Object-Oriented Programming courses, by generating and evaluating new teaching methodologies and tools suitable for this paradigm's specificities.",10.1145/3649405.3659473,https://doi.org/10.1145/3649405.3659473
Goodbye Hello World - Research Questions for a Future CS1 Curriculum,"Keuning, Hieke and Luxton-Reilly, Andrew and Ott, Claudia and Petersen, Andrew and Kiesler, Natalie",Proceedings of the 24th Koli Calling International Conference on Computing Education Research,2024,"Generative AI (GenAI) is currently capable of generating correct code for introductory level programming problems, and its performance is improving. We believe that this capability can be leveraged to improve student motivation, broaden students’ understanding of software development, and engage them in more authentic learning. We defined a set of assumptions about GenAI’s future capabilities (e.g., the ability to generate small pieces of code and to compose these pieces of code via user prompts) and engaged in a backcasting exercise to identify what else is needed to develop a CS1 course that places GenAI in a central role. Undertaking this thought experiment immediately revealed that aspects of the software development process usually reserved for later in the curriculum, such as requirements elicitation and design, could be introduced earlier in the process. With GenAI tools bearing the load of generating correct code snippets, students could focus on higher-level software design and construction skills and practice them in an authentic environment. Our thought experiment identified a set of questions that need to be addressed for such a course to actually exist, including questions about student preparation, and the ability of students to decompose problems effectively and to resolve problems that arise when integrating pieces of code. We also identified questions related to the design of a GenAI centered course, such as the impact on student motivation of using GenAI instead of engaging directly with code, the extent to which social learning theories apply to interactions with GenAI, and how existing pedagogies can integrate GenAI tools.",10.1145/3699538.3699591,https://doi.org/10.1145/3699538.3699591
ASCI: AI-Smart Classroom Initiative,"Basit, Nada and Floryan, Mark and Hott, John R. and Huo, Allen and Le, Jackson and Zheng, Ivan",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"The Artificial Intelligence Smart Classroom Initiative (ASCI) presents a re-imagined set of online course tools, designed primarily to support growing computer science classes. The system has four primary tools: an office hours queue, an automatic student grouping algorithm, a course-specific local large-language model (LLM), and administration tools for detecting students and TAs that need support. These tools interoperate to improve the quality of one another (e.g., LLM conversations support students directly in the office hours queue) and are enhanced by synchronizing data from multiple external sources such as Piazza, Gradescope, and Canvas. The system has been deployed in multiple courses over the past three semesters: initially as a FIFO queue, then supporting manual grouping and smart grouping of office hour attendees, and recently including LLM support. Preliminary results indicate that students who were grouped using the tool were more likely to return to the queue more than twice as often (on average) than those who were not. However, while grouping in office hours has the potential to decrease student wait times, teaching assistants and students tend to favor one-on-one meetings over group meetings. This might be improved in the future with updates to the software, TA training, and incorporation of other supporting tools (e.g., LLM technology). The other, newer, tools will be more thoroughly evaluated in future semesters.",10.1145/3641554.3701957,https://doi.org/10.1145/3641554.3701957
"“It's not like Jarvis, but it's pretty close!” - Examining ChatGPT's Usage among Undergraduate Students in Computer Science","Budhiraja, Ritvik and Joshi, Ishika and Challa, Jagat Sesh and Akolekar, Harshal D. and Kumar, Dhruv",Proceedings of the 26th Australasian Computing Education Conference,2024,"Large language models (LLMs) such as ChatGPT and Google Bard have garnered significant attention in the academic community. Previous research has evaluated these LLMs for various applications such as generating programming exercises and solutions. However, these evaluations have predominantly been conducted by instructors and researchers, not considering the actual usage of LLMs by students. This study adopts a student-first approach to comprehensively understand how undergraduate computer science students utilize ChatGPT, a popular LLM, released by OpenAI. We employ a combination of student surveys and interviews to obtain valuable insights into the benefits, challenges, and suggested improvements related to ChatGPT. Our findings suggest that a majority of students (over 57%) have a convincingly positive outlook towards adopting ChatGPT as an aid in coursework-related tasks. However, our research also highlights various challenges that must be resolved for long-term acceptance of ChatGPT amongst students. The findings from this investigation have broader implications and may be applicable to other LLMs and their role in computing education.",10.1145/3636243.3636257,https://doi.org/10.1145/3636243.3636257
Design and Evaluation of an AI-Assisted Grading Tool for Introductory Programming Assignments: An Experience Report,"Nagakalyani, Goda and Chaudhary, Saurav and Apte, Varsha and Ramakrishnan, Ganesh and Tamilselvam, Srikanth",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"In a typical introductory programming course, grading student-submitted programs involves an autograder which compiles and runs the programs and tests their functionality with predefined test cases, with no attention to the source code. However, in an educational setting, grading based on inspection of the source code is required for two main reasons (1) awarding partial marks to 'partially correct' code that may be failing the testcase check (2) awarding marks (or penalties) based on source code quality or specific criteria that the instructor may have laid out in the problem statement (e.g. 'implement sorting using bubble-sort'). However, grading based on studying the source code can be highly time consuming when the course has a large enrollment. In this paper we present the design and evaluation of an AI Assistant for source code grading, which we have named TA Buddy. TA Buddy is powered by Code Llama, a large language model especially trained for code related tasks, which we fine-tuned using a graded programs dataset. Given a problem statement, student code submissions and a grading rubric, TA Buddy can be asked to generate suggested grades, i.e. ratings for the various rubric criteria, for each submission. The human teaching assistant (TA) can then accept or overrule these grades. We evaluated the TA Buddy-assisted manual grading against 'pure' manual grading and found that the time taken to grade reduced by 24% while maintaining grade agreement in the two cases at 90%.",10.1145/3641554.3701913,https://doi.org/10.1145/3641554.3701913
Breaking the Programming Language Barrier: Multilingual Prompting to Empower Non-Native English Learners,,Proceedings of the 27th Australasian Computing Education Conference,2025,"Non-native English speakers (NNES) face multiple barriers to learning programming. These barriers can be obvious, such as the fact that programming language syntax and instruction are often in English, or more subtle, such as being afraid to ask for help in a classroom full of native English speakers. However, these barriers are frustrating because many NNES students know more about programming than they can articulate in English. Advances in generative AI (GenAI) have the potential to break down these barriers because state of the art models can support interactions in multiple languages. Moreover, recent work has shown that GenAI can be highly accurate at code generation and explanation. In this paper, we provide the first exploration of NNES students prompting in their native languages (Arabic, Chinese, and Portuguese) to generate code to solve programming problems. Our results show that students are able to successfully use their native language to solve programming problems, but not without some difficulty specifying programming terminology and concepts. We discuss the challenges they faced, the implications for practice in the short term, and how this might transform computing education globally in the long term.",10.1145/3716640.3716649,https://doi.org/10.1145/3716640.3716649
From GPT to BERT: Benchmarking Large Language Models for Automated Quiz Generation,"Folajimi, Yetunde",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2,2024,"This study evaluates the effectiveness of four leading large language models (LLMs), GPT-3, GPT-4, GPT-4o, and BERT, in generating quiz questions for Java and Python programming courses. We aim to recognize how LLMs can effectively produce educationally valuable questions that meet specific pedagogical criteria, including technical precision, relevance to course objectives, linguistic clarity, and pedagogical appropriateness. Each model was prompted to generate 200 Java and 200 Python quiz questions, totaling 1600 unique questions. These questions are currently being evaluated based on both quantitative and qualitative assessments by a team of computer science educators. Preliminary findings suggest that GPT-4 outperforms BERT in terms of technical precision. Further analysis is ongoing to assess the performance of the models in generating contextually appropriate and educationally useful questions, offering insights into their potential integration into computer science curricula. This work seeks to contribute to the broader discourse on the utility of LLMs in educational settings, specifically within the scope of automated content creation to enhance teaching and assessment methodologies in computer science education.",10.1145/3649409.3691090,https://doi.org/10.1145/3649409.3691090
A Critical Approach to ChatGPT: An Experience in SQL Learning,"Farinetti, Laura and Cagliero, Luca",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"ChatGPT potential value in education is broadly recognized and many studies report experiments of its use inside or outside the classroom by students and teachers. On the other hand, the use of ChatGPT rises lots of concerns about well-known problems such as hallucination, plagiarism, overreliance, or misinformation. It is of primary importance to teach students a correct and constructive use of ChatGPT and a critical approach to its returned outputs. The paper presents a classroom experience where students were asked to interact with ChatGPT in the context of a database course. The declared challenge for the students was, given a set of predefined relational database schemata, to invent questions for ChatGPT and try to force wrong SQL solutions. Students had to record the question, the ChatGPT solution, their solution, and the comments about the eventual ChatGPT syntactical and/or semantical errors. This gamification approach was meant to enhance students' motivation, but the main teachers' goal was to make them reflect critically (i) on ChatGPT output, experiencing that it does make mistakes, (ii) on the interpretation of ChatGPT errors, and (iii) on the possible strategies for forcing ChatGPT errors. The experiment involved 166 B.S. students in Engineering and the collected data have been analyzed under different points of view to get an insight into the approach and the critical attitude of the students. The paper reports the results of this analysis and discusses the impact of the activity on learning by analyzing the correlation between students' participation and exam performance.",10.1145/3641554.3701932,https://doi.org/10.1145/3641554.3701932
Next-Step Hint Generation for Introductory Programming Using Large Language Models,"Roest, Lianne and Keuning, Hieke and Jeuring, Johan",Proceedings of the 26th Australasian Computing Education Conference,2024,"Large Language Models possess skills such as answering questions, writing essays or solving programming exercises. Since these models are easily accessible, researchers have investigated their capabilities and risks for programming education. This work explores how LLMs can contribute to programming education by supporting students with automated next-step hints. We investigate prompt practices that lead to effective next-step hints and use these insights to build our StAP-tutor. We evaluate this tutor by conducting an experiment with students, and performing expert assessments. Our findings show that most LLM-generated feedback messages describe one specific next step and are personalised to the student’s code and approach. However, the hints may contain misleading information and lack sufficient detail when students approach the end of the assignment. This work demonstrates the potential for LLM-generated feedback, but further research is required to explore its practical implementation.",10.1145/3636243.3636259,https://doi.org/10.1145/3636243.3636259
Evaluating Language Models for Generating and Judging Programming Feedback,"Koutcheme, Charles and Dainese, Nicola and Sarsa, Sami and Hellas, Arto and Leinonen, Juho and Ashraf, Syed and Denny, Paul",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"The emergence of large language models (LLMs) has transformed research and practice across a wide range of domains. Within the computing education research (CER) domain, LLMs have garnered significant attention, particularly in the context of learning programming. Much of the work on LLMs in CER, however, has focused on applying and evaluating proprietary models. In this article, we evaluate the efficiency of open-source LLMs in generating high-quality feedback for programming assignments and judging the quality of programming feedback, contrasting the results with proprietary models. Our evaluations on a dataset of students' submissions to introductory Python programming exercises suggest that state-of-the-art open-source LLMs are nearly on par with proprietary models in both generating and assessing programming feedback. Additionally, we demonstrate the efficiency of smaller LLMs in these tasks and highlight the wide range of LLMs accessible, even for free, to educators and practitioners.",10.1145/3641554.3701791,https://doi.org/10.1145/3641554.3701791
Analyzing Students' Preferences for LLM-Generated Analogies,"Bernstein, Seth and Denny, Paul and Leinonen, Juho and Littlefield, Matt and Hellas, Arto and MacNeil, Stephen",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2,2024,"Introducing students to new concepts in computer science can often be challenging, as these concepts may differ significantly from their existing knowledge and conceptual understanding. To address this, we employed analogies to help students connect new concepts to familiar ideas. Specifically, we generated analogies using large language models (LLMs), namely ChatGPT, and used them to help students make the necessary connections. In this poster, we present the results of our survey, in which students were provided with two analogies relating to different computing concepts, and were asked to describe the extent to which they were accurate, interesting, and useful. This data was used to determine how effective LLM-generated analogies can be for teaching computer science concepts, as well as how responsive students are to this approach.",10.1145/3649405.3659504,https://doi.org/10.1145/3649405.3659504
AI meets AI: Artificial Intelligence and Academic Integrity - A Survey on Mitigating AI-Assisted Cheating in Computing Education,"Xie, Ying and Wu, Shaoen and Chakravarty, Sumit",Proceedings of the 24th Annual Conference on Information Technology Education,2023,"This paper discusses pressing issues in the area where Artificial Intelligence (AI) meets Academic Integrity (AI). It starts by outlining the potential consequences of AI-assisted cheating, including the risks posed to education quality, fairness, and the credibility of academic institutions. After reviewing an array of strategies reported in the literature to counteract such cheating, this paper calls for rigorous research to assess the effectiveness of those strategies. It further suggests a range of research topics in detecting AI-generated content and highlights a promising research direction focusing on motivating students’ interest in learning through innovative AI applications that divert their efforts away from misuse of technology. Lastly, the paper suggests that addressing AI cheating requires ethical education, academia-industry collaboration, integration into AI ethics, and an international consortium. One of the unique contributions of this paper is outlining a range of potential research directions, both technical and non-technical, in this area where AI meets AI.",10.1145/3585059.3611449,https://doi.org/10.1145/3585059.3611449
Improving AI in CS50: Leveraging Human Feedback for Better Learning,"Liu, Rongxin and Zhao, Julianna and Xu, Benjamin and Perez, Christopher and Zhukovets, Yuliia and Malan, David J.",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"In 2023, we developed and deployed AI-based tools in CS50 at Harvard University to provide students with 24/7 interactive assistance, approximating a 1:1 teacher-to-student ratio. These tools offer code explanations, style suggestions, and responses to course-related inquiries, emulating human educators to foster critical thinking. However, maintaining alignment with instructional goals is challenging, especially with frequent updates to the underlying large language models (LLMs). We thus propose a continuous improvement process for LLM-based systems using a collaborative human-in-the-loop approach. We introduce a systematic evaluation framework for assessing and refining the performance of AI-based tutors, combining human-graded and model-graded evaluations. Using few-shot prompting and fine-tuning, we aim to ensure our AI tools adopt pedagogically sound teaching styles. Fine-tuning with a small, high-quality dataset has shown significant improvements in aligning with teaching goals, as confirmed through multi-turn conversation evaluations. Additionally, our framework includes a model-evaluation backend that teaching assistants periodically review, ensuring the AI system remains effective and aligned with instructional objectives. This paper offers insights into our methods and the impact of these AI tools on CS50 and contributes to the discourse on AI in education, showcasing scalable, personalized learning enhancements.",10.1145/3641554.3701945,https://doi.org/10.1145/3641554.3701945
Empowering CS1 Educators: Enhancing Automated Feedback Instruction with Cognitive Load Theory,"Gonzaga, Justin T. and Jiang, Yuchao and Vassar, Alexandra",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"Delivering personalised and timely feedback is crucial for helping students address gaps in their understanding. However, the increasing demands of large class sizes make this task particularly challenging for CS1 educators, especially for casual teaching assistants who lack formal training and experience. Existing feedback training methods are often inconsistent and ineffective, leaving educators unprepared to handle diverse student needs.To address this, we designed an adaptive fading procedure based on Cognitive Load Theory (CLT) to support educators in delivering high-quality, personalised feedback. This pedagogical technique is integrated into FeedbackPulse-CLT, an automated tool that evaluates feedback in real-time and provides guidance for improvement. This paper outlines our approach to designing scalable, evidence-based feedback instruction using Generative AI and large language models (LLMs) to overcome feedback quality concerns in CS1 education.",10.1145/3641555.3705171,https://doi.org/10.1145/3641555.3705171
Analyzing LLM Usage in an Advanced Computing Class in India,"Arora, Utkarsh and Garg, Anupam and Gupta, Aryan and Jain, Samyak and Mehta, Ronit and Oberoi, Rupin and Prachi and Raina, Aryaman and Saini, Manav and Sharma, Sachin and Singh, Jaskaran and Tyagi, Sarthak and Kumar, Dhruv",Proceedings of the 27th Australasian Computing Education Conference,2025,"This study examines the use of large language models (LLMs) by undergraduate and graduate students for programming assignments in advanced computing classes. Unlike existing research, which primarily focuses on introductory classes and lacks in-depth analysis of actual student-LLM interactions, our work fills this gap. We conducted a comprehensive analysis involving 411 students from a Distributed Systems class at an Indian university, where they completed three programming assignments and shared their experiences through Google Form surveys and interviews.Our findings reveal that students leveraged LLMs for a variety of tasks, including code generation, debugging, conceptual inquiries, and test case creation. They employed a spectrum of prompting strategies, ranging from basic contextual prompts to advanced techniques like chain-of-thought prompting and iterative refinement. While students generally viewed LLMs as beneficial for enhancing productivity and learning, we noted a concerning trend of over-reliance, with many students submitting entire assignment descriptions to obtain complete solutions. Given the increasing use of LLMs in the software industry, our study highlights the need to update undergraduate curricula to include training on effective prompting strategies and to raise awareness about the benefits and potential drawbacks of LLM usage in academic settings.",10.1145/3716640.3716657,https://doi.org/10.1145/3716640.3716657
AI Integration in the IT Professional Workplace: A Scoping Review and Interview Study with Implications for Education and Professional Competencies,,2024 Working Group Reports on Innovation and Technology in Computer Science Education,2025,"As Artificial Intelligence (AI) continues transforming workplaces globally, particularly within the Information Technology (IT) industry, understanding its impact on IT professionals and computing curricula is crucial. This research builds on joint work from two countries, addressing concerns about AI's increasing influence in IT sector workplaces and its implications for tertiary education. The study focuses on AI technologies such as generative AI (GenAI) and large language models (LLMs). It examines how they are perceived and adopted and their effects on workplace dynamics, task allocation, and human-system interaction.IT professionals, noted as early adopters of AI, offer valuable insights into the interplay between AI and work engagement, highlighting the significant competencies required for digital workplaces. This study employs a dual-method approach, combining a systematic and multi-vocal literature review and qualitative research methods. These included a thematic analysis of a set of 47 interviews conducted between March and May of 2024 with IT professionals in two countries (New Zealand and Sweden). The research aimed to understand the implications for computing students, education curricula, and the assessment of emerging professional competencies.The literature review found insufficient evidence addressing comprehensive AI practice methodologies, highlighting the need to both develop and regulate professional competencies for effective AI integration. Key interview findings revealed diverse levels of GenAI adoption, ranging from individual experimentation to institutional integration. Participants generally expressed positive attitudes toward the technology and were actively pursuing self-learning despite some concerns. The themes emerging from the interviews included AI's role in augmenting human tasks, privacy and security concerns, productivity enhancements, legal and ethical challenges, and the evolving need for new competencies in the workplace.The study underscores the critical role of competency frameworks in guiding professional development and ensuring preparedness for an AI-driven environment. Additionally, it highlights the need for educational institutions to adapt curricula to address these emerging demands effectively",10.1145/3689187.3709607,https://doi.org/10.1145/3689187.3709607
Source Code Plagiarism Detection as a Service with Dolos,"Maertens, Rien and Dawyndt, Peter and Mesuere, Bart",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 2,2025,"Source code similarity detection tools are crucial for preventing and identifying plagiarism in programming courses. While tools like JPlag and Moss are effective, their complexity often hinders widespread adoption. To address this, we developed Dolos, a user-friendly source code similarity detection pipeline that enhances the user experience with interactive dashboards. The Dolos ecosystem includes software libraries, a CLI tool, a web UI, a web server, and API server enabling seamless integration with educational environments. The Dolos web server allows instructors to perform plagiarism detection directly within their browsers, eliminating the need for additional software installation. A publicly available instance and the option for private instances further enhance accessibility. Dolos' API facilitates integration as a microservice within programming exercise platforms like Dodona, A+ and Radar, and Codio, showcasing its versatility and effectiveness. At Ghent University, Dolos is integral to the plagiarism detection strategy, with visualisations serving as both a detection tool and a deterrent. The focus on user experience, flexibility, and comprehensive documentation has attracted scholars to use Dolos for innovative applications, even outside of the educational field. We invite instructors to explore Dolos and integrate it within their educational platforms for programming assignments.",10.1145/3724389.3731274,https://doi.org/10.1145/3724389.3731274
Generating Personalized Assignments with Students in the Loop,"Fayaz, Avid and Glassey, Richard and Baltatzis, Alexander",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"We present a system that enables students to generate their own programming assignments that are both personalized to their interests and aligned with the course objectives. A group of twelve undergraduate students randomly selected from an introductory programming course (~200) received training and access to the system for six weeks. Students were free to use the system to generate assignments or take regular assignments instead. Weekly student feedback was used to refine the system through three iterations, and a focus group with three students was held after the course to gather opinions on the experience. Our findings are complicated and cautionary: students appreciated generating their own personalized assignments with feedback on demand. However, the cognitive load of having to generate and decide which assignment to complete, along with the variation of difficulty and alignment with learning objectives were noted as problematic and discouraging. Perhaps the most negative but heartwarming result is that students missed the community aspect of independently solving and collectively discussing solutions to a common assignment.",10.1145/3724363.3729070,https://doi.org/10.1145/3724363.3729070
Can Small Language Models With Retrieval-Augmented Generation Replace Large Language Models When Learning Computer Science?,"Liu, Suqing and Yu, Zezhu and Huang, Feiran and Bulbulia, Yousef and Bergen, Andreas and Liut, Michael",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"Leveraging Large Language Models (LLMs) for personalized learning and support is becoming a promising tool in computing education. AI Assistants can help students with programming, problem-solving, converse with them to clarify course content, explain error messages to help with debugging, and much more. However, using cloud-based LLMs poses risks around data security, privacy, but also control of the overarching system.To address these concerns, we created a locally-stored Small Language Model (SLM) that leverages different Retrieval-Augmented Generation (RAG) methods to support computing students' learning. We compare one SLM (neural-chat-7b-v3 - fine-tuned version of Mistral-7B-v0.1) against two popular LLMs (gpt-3.5-turbo and gpt-4-32k) to see the viability for computing educators to use in their course(s).We use conversations from a CS1 course (N = 1,260), providing students with an AI Assistant (using gpt-3.5-turbo) to help them learn content and support problem-solving while completing their Python programming assignment. In total, we had 269 students use the AI Assistant, with a total of 1,988 questions asked. Using this real conversational data, we re-ran student questions using our novel SLM (neural-chat-7b-v3 testing nine different RAG methods) and gpt-4-32k, then compared those results against the original gpt-3.5-turbo responses. Our findings indicate that using an SLM with RAG can perform similarly, if not better, than LLMs. This shows that it is possible for computing educators to use SLMs (with RAG) in their course(s) as a tool for scalable learning, supporting content understanding and problem-solving needs, while employing their own policies on data privacy and security.",10.1145/3649217.3653554,https://doi.org/10.1145/3649217.3653554
Debugging with an AI Tutor: Investigating Novice Help-seeking Behaviors and Perceived Learning,"Yang, Stephanie and Zhao, Hanzhang and Xu, Yudian and Brennan, Karen and Schneider, Bertrand",Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1,2024,"Debugging is a crucial skill for programmers, yet it can be challenging for novices to learn. The introduction of large language models (LLMs) has opened up new possibilities for providing personalized debugging support to students. However, concerns have been raised about potential student over-reliance on LLM-based tools. This mixed-methods study investigates how a pedagogically-designed LLM-based chatbot supports students’ debugging efforts in an introductory programming course. We conducted interviews and debugging think-aloud tasks with 20 students at three points throughout the semester. We specifically focused on characterizing when students initiate help from the chatbot during debugging, how they engage with the chatbot’s responses, and how they describe their learning experiences with the chatbot. By analyzing data from the debugging tasks, we identified varying help-seeking behaviors and levels of engagement with the chatbot’s responses, depending on students’ familiarity with the suggested strategies. Interviews revealed that students appreciated the content and experiential knowledge provided by the chatbot, but did not view it as a primary source for learning debugging strategies. Additionally, students self-identified certain chatbot usage behaviors as negative, “non-ideal” engagement and others as positive, “learning-oriented” usage. Based on our findings, we discuss pedagogical implications and future directions for designing pedagogical chatbots to support debugging.",10.1145/3632620.3671092,https://doi.org/10.1145/3632620.3671092
Learning and Assessment in the Age of GenAI,"Silberg, Owen and Glavan, Mary and Myers, Risa B.",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 2,2025,"This work presents an approach to integrating generative artificial intelligence (GenAI) into computer and data science courses. We guide students to use GenAI tools to learn key concepts and to complete low-stakes homework assignments. To assess whether students are partnering with GenAI rather than merely automating crucial learning processes, students take rapid-fire weekly quizzes where they demonstrate their mastery of the content. We conclude by reflecting on the strengths and limitations of our approach.",10.1145/3724389.3731270,https://doi.org/10.1145/3724389.3731270
Achievement Goals in CS1-LLM,"Vadaparty, Annapurna and Geng, Francis and Smith, David H and Benario, Jamie Gorson and Zingaro, Daniel and Porter, Leo",Proceedings of the 27th Australasian Computing Education Conference,2025,"Introduction: The emergence and widespread adoption of generative AI (GenAI) chatbots such as ChatGPT, and programming assistants such as GitHub Copilot, have radically redefined the landscape of programming education. This calls for replication of studies and reexamination of findings from pre-GenAI CS contexts to understand the impact on students. Objectives: Achievement Goals are well studied in computing education and can be predictive of student interest and exam performance. The objective in this study is to compare findings from prior achievement goal studies in CS1 courses with new CS1 courses that emphasize the use of human-GenAI collaborative coding. Methods: In a CS1 course that integrates GenAI, we use linear regression to explore the relationship between achievement goals and prior experience on student interest, exam performance, and perceptions of GenAI. Results: As with prior findings in traditional CS1 classes, Mastery goals are correlated with interest in computing. Contradicting prior CS1 findings, normative goals are correlated with exam scores. Normative and mastery goals correlate with students’ perceptions of learning with GenAI. Mastery goals weakly correlate with reading and testing code output from GenAI.",10.1145/3716640.3716656,https://doi.org/10.1145/3716640.3716656
Towards Integrating Behavior-Driven Development in Mobile Development: An Experience Report,"Hao, Qiang and Liu, Ruohan",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Testing is an important yet often neglected skill in learning and teaching of computing science at the college level. Prior studies explored integrating test-driven development (TDD) into computer science courses with some degree of success, but also observed issues such as students' lack of appreciation, expressed frustration, and inconsistent adherence to TDD. TDD is a software development methodology that emphasizes writing low-level unit test cases prior to writing the corresponding portion of implementation. Behavior-driven development (BDD) was proposed as an evolution of TDD to emphasize software behavior from users' perspective. BDD has been widely adopted in industry, and holds great potential in addressing the issues in using TDD to improve students' learning of testing. However, BDD was rarely explored in enhancing students' mastery of testing. Informed by the literature, this experience report explored the integration of BDD into a mobile development course. Students' performance, attitude and feedback on BDD was examined, and potential improvement on the integration of BDD was discussed. The results of this report sheds light on how to effectively integrate BDD into computer science courses.",10.1145/3641554.3701875,https://doi.org/10.1145/3641554.3701875
Supporting Students in Prototyping AI-backed Software with Hosted Prompt Template APIs,"Aveni, Timothy J. and Smith, James and Fox, Armando and Hartmann, Bj\",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"Large AI models, such as LLMs and text-to-image models, can be used to power intelligent components of software applications. In our User Interface Design and Development course, we encourage students to practice integrating AI-powered capabilities into their software prototypes. To facilitate this practice, we developed reagent, an open source Web platform that facilitates student exploration through iterative authorship of prompt templates, then hosts AI model APIs for those templates with billing configured by instructors. After an introductory homework assignment, students were encouraged to invent their own AI features in an open-ended final team project. Students widely reported that their experiences with AI in this course were valuable, offering a deeper understanding of the capabilities and limitations of using AI in software. By supporting authorship, facilitating integration, providing visibility, and reducing administrative hurdles, reagent facilitated both student exploration and instructors' involvement. Additionally, we offer insight we gleaned as instructors into how students form conceptual models about AI.",10.1145/3724363.3729109,https://doi.org/10.1145/3724363.3729109
Always Provide Context: The Effects of Code Context on Programming Error Message Enhancement,"Santos, Eddie Antonio and Prasad, Prajish and Becker, Brett A.",Proceedings of the ACM Conference on Global Computing Education Vol 1,2023,"Programming error messages (PEMs) are notoriously difficult for novice programmers to utilise. Many efforts have been made to enhance PEMs such that they are reworded to explain problems in terms that novices can understand. However, the effectiveness of these efforts to enhance PEMs has been weak or inconclusive. This work seeks to determine the role that code context has on programming error message enhancement. Erroneous Java code written by novices was sampled from the Blackbox Mini dataset. The erroneous code was presented to expert raters with four different PEM variants: javac (control), Decaf -- an error message enhancing IDE -- and two variants generated using GPT-4: one that enhanced just the javac error message alone, and one that incorporates the code context in the prompt. We find that providing code context to LLMs increases the likelihood of correct explanations for underlying errors, produces more specific fixes for erroneous programs, and produces fixes that are more likely to be correct. In large language models, the community now has a resource that is capable of taking code context into account, to the benefit of novice programmers.",10.1145/3576882.3617909,https://doi.org/10.1145/3576882.3617909
Detecting ChatGPT-Generated Code Submissions in a CS1 Course Using Machine Learning Models,"Hoq, Muntasir and Shi, Yang and Leinonen, Juho and Babalola, Damilola and Lynch, Collin and Price, Thomas and Akram, Bita",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"The emergence of publicly accessible large language models (LLMs) such as ChatGPT poses unprecedented risks of new types of plagiarism and cheating where students use LLMs to solve exercises for them. Detecting this behavior will be a necessary component in introductory computer science (CS1) courses, and educators should be well-equipped with detection tools when the need arises. However, ChatGPT generates code non-deterministically, and thus, traditional similarity detectors might not suffice to detect AI-created code. In this work, we explore the affordances of Machine Learning (ML) models for the detection task. We used an openly available dataset of student programs for CS1 assignments and had ChatGPT generate code for the same assignments, and then evaluated the performance of both traditional machine learning models and Abstract Syntax Tree-based (AST-based) deep learning models in detecting ChatGPT code from student code submissions. Our results suggest that both traditional machine learning models and AST-based deep learning models are effective in identifying ChatGPT-generated code with accuracy above 90%. Since the deployment of such models requires ML knowledge and resources that are not always accessible to instructors, we also explore the patterns detected by deep learning models that indicate possible ChatGPT code signatures, which instructors could possibly use to detect LLM-based cheating manually. We also explore whether explicitly asking ChatGPT to impersonate a novice programmer affects the code produced. We further discuss the potential applications of our proposed models for enhancing introductory computer science instruction.",10.1145/3626252.3630826,https://doi.org/10.1145/3626252.3630826
Leveraging LLM for Detecting and Explaining LLM-generated Code in Python Programming Courses,"Baek, Jeonghun and Yamazaki, Tetsuro and Morihata, Akimasa and Mori, Junichiro and Yamakata, Yoko and Taura, Kenjiro and Chiba, Shigeru",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"As large language models (LLMs) have become more advanced, generating code to solve exercises in programming courses has become significantly easier. However, this convenience raises the concern of over-reliance on these tools, potentially hindering students from developing independent coding skills. To address this concern, we introduce an LLM-based detector that not only detects LLM-generated code but also explains the reasons for its judgments. These reasons provide insight into the characteristics of LLM-generated code, enhancing transparency in the detection process. We evaluate the detector in an introductory Python programming course, achieving over 99% accuracy. Additionally, instructors manually reviewed the reasons provided by the detector and verified that 64.7% of reasons for classifying code as LLM-generated were appropriate. These reasons can also serve as feedback, helping students improve their coding skills by understanding the characteristics of expert-level LLM-generated code.",10.1145/3641555.3705212,https://doi.org/10.1145/3641555.3705212
Piloting a Diagnostic Tool to Measure AP CS Principles Teachers' Knowledge Against CSTA Teacher Standard 1,"McGill, Monica M. and Tise, Joseph C. and Decker, Adrienne",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"Problem. Understanding computer science (CS) teacher CS knowledge primarily relies on self-reported data from participants to understand the learning impact on teachers and improve teacher growth. There is currently a lack of quality instruments to determine where CS teachers need to improve their knowledge.Research Question. Our research question for this project was: What are the preliminary psychometric properties of a developed measure for AP CS Principles teachers? Methodology. We developed and piloted a diagnostic tool for high school teachers (n=18) who have been or will be engaged in teaching AP Computer Science Principles (AP CSP). We then administered the diagnostic with two groups of teachers at the CSTA PD week in 2023, and analyzed the results.Findings. The full 22-item measure demonstrated acceptable reliability (alpha = 0.74) in the present sample. However, four items were identified as",10.1145/3626252.3630905,https://doi.org/10.1145/3626252.3630905
Towards Understanding the Geospatial Skills of ChatGPT: Taking a Geographic Information Systems (GIS) Exam,,Proceedings of the 6th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery,2023,"This paper examines the performance of ChatGPT, a large language model (LLM), in a geographic information systems (GIS) exam. As LLMs like ChatGPT become increasingly prevalent in various domains, including education, it is important to understand their capabilities and limitations in specialized subject areas such as GIS. Human learning of spatial concepts significantly differs from LLM training methodologies. Therefore, this study aims to assess ChatGPT's performance and ability to grasp geospatial concepts by challenging it with a real GIS exam. By analyzing ChatGPT's responses and evaluating its understanding of GIS principles, we gain insights into the potential applications and challenges of LLMs in spatially-oriented fields. We conduct our evaluation with two models, GPT-3.5 and GPT-4, to understand whether general improvements of an LLM translate to improvements in answering questions related to the spatial domain. We find that both GPT variants can pass a balanced, introductory GIS exam, scoring 63.3% (GPT-3.5) and 88.3% (GPT-4), which correspond to grades D and B+ respectively in standard US letter grading scale. In addition, we also identify specific questions and topics where the LLMs struggle to grasp spatial concepts, highlighting the challenges in teaching such topics to these models. Finally, we assess ChatGPT's performance in specific aspects of GIS, including spatial analysis, basic concepts of mapping, and data management. This granular analysis provides further insights into the strengths and weaknesses of ChatGPT's GIS literacy. This research contributes to the ongoing dialogue on the integration of AI models in education and can provide guidance for educators, researchers, and practitioners seeking to leverage LLMs in GIS. By focusing on specific questions or concepts that pose difficulties for the LLM, this study addresses the nuances of teaching spatial concepts to AI models and offers potential avenues for improvement in spatial literacy within future iterations of LLMs.",10.1145/3615886.3627745,https://doi.org/10.1145/3615886.3627745
Scaffolding Mock Conference Projects in Theory of Computing Courses,"Dougherty, Ryan E.",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"Theory of Computing (ToC) courses have important connections to other CS courses as ToC is a foundation for them. ToC course grading schemes often involve mostly exams, and sometimes a small weight for traditional assignments. Recent work experimented with a",10.1145/3641555.3705243,https://doi.org/10.1145/3641555.3705243
Evaluating GenAI's Effectiveness for Students with Varied Programming Backgrounds in a Software Development Course,"Bouamor, Houda and Gongora-Svartzman, Gabriela and Heimann, Larry and Huang, Shihong",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"Using Generative AI (GenAI) tools in education presents both opportunities and challenges to the traditional teaching methods and students' learning experience and outcomes, particularly in technical and programming courses. This experience report evaluates the impact of GenAI tools, specifically ChatGPT and GitHub CoPilot, in leveling the playing field for Information Systems students with varying technical backgrounds in an application design and development course. By integrating these tools into course labs and projects, this study aimed to determine whether they improve the success rates of less technically prepared and struggling students. Data were collected from five sessions of a semester-long course across two campuses, involving 162 students with five parallel sessions across two continents. The analysis of student performance metrics and surveys revealed that GenAI tools significantly helped students complete programming tasks. However, those who were less technically prepared and relied heavily on AI assistance struggled with more complex, transformative tasks, such as closed-book exams. These findings suggest that while GenAI tools can help close gaps in temporary programming skills, they are less effective - and may even exacerbate disparities - in fostering long-term deeper learning and developing transformative knowledge and critical thinking.",10.1145/3641555.3705175,https://doi.org/10.1145/3641555.3705175
"Compiler-Integrated, Conversational AI for Debugging CS1 Programs","Renzella, Jake and Vassar, Alexandra and Lee Solano, Lorenzo and Taylor, Andrew",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Large Language Models (LLMs) present a transformative opportunity to address longstanding challenges in computing education. This paper presents a conversational AI extension to an LLM-enhanced C/C++ compiler which generates pedagogically sound programming error explanations. Our new tool, DCC Sidekick, retains compiler integration, allowing students to see their code, error messages, and stack frames alongside a conversational AI interface. Compiler context improves error explanations, and provides a seamless development experience. We present quantitative analyses of Sidekick's usage and engagement patterns in a large CS1 course. In the first seven weeks of use, 959 students initiated 11,222 DCC Sidekick sessions, generating 17,982 error explanations. Over half of all conversations occur outside of business hours, highlighting the value of these always-available tools. Early results indicate strong adoption of conversational AI debugging tools, demonstrating scalability in supporting large CS1 courses. We share implementation details and lessons learned, offering guidance to educators considering integrating AI tools with pedagogical guardrails.",10.1145/3641554.3701827,https://doi.org/10.1145/3641554.3701827
Code Generation Based Grading: Evaluating an Auto-grading Mechanism for,"Smith, David H. and Zilles, Craig",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"Comprehending and conveying the purpose of code is often cited as being a key learning objective within introductory programming courses. To address this objective,",10.1145/3649217.3653582,https://doi.org/10.1145/3649217.3653582
An Exploration of the Impact of Generalized Big Model Programming Educational Applications of Artificial Intelligence,"Zhou, Yaxin and He, Xiangchun and Jiang, Ruishuang and Zhang, Shaojun and Han, Yuqi and Guo, Xue",Proceedings of the 2024 7th International Conference on Educational Technology Management,2025,"The application of artificial intelligence in the field of education has gone through several stages, initially using machine learning technology to optimize the teaching process to achieve automation of the",10.1145/3711403.3711445,https://doi.org/10.1145/3711403.3711445
Investigating Student Errors in Code Refactoring,"Oliveira, Eduardo",Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 2,2023,"Learning to develop code of good quality is challenging. One way to improve code quality is through code refactoring. Students make several mistakes when refactoring code. This research project aims to comprehend student errors in code refactoring, as well as to evaluate how the use of automated tools can help students remediate these errors.",10.1145/3587103.3594146,https://doi.org/10.1145/3587103.3594146
Evaluating ChatGPT-4 Vision on Brazil's National Undergraduate Computer Science Exam,,ACM Trans. Comput. Educ.,2024,"The recent integration of visual capabilities into Large Language Models (LLMs) has the potential to play a pivotal role in science and technology education, where visual elements such as diagrams, charts, and tables are commonly used to improve the learning experience. This study investigates the performance of ChatGPT-4 Vision, OpenAI’s most advanced visual model at the time the study was conducted, on the Bachelor in Computer Science section of Brazil’s 2021 National Undergraduate Exam (ENADE). By presenting the model with the exam’s open and multiple-choice questions in their original image format and allowing for reassessment in response to differing answer keys, we were able to evaluate the model’s reasoning and self-reflecting capabilities in a large-scale academic assessment involving textual and visual content. ChatGPT-4 Vision significantly outperformed the average exam participant, positioning itself within the top 10 best score percentile. While it excelled in questions that incorporated visual elements, it also encountered challenges with question interpretation, logical reasoning, and visual acuity. A positive correlation between the model’s performance in multiple-choice questions and the performance distribution of the human participants suggests multimodal LLMs can provide a useful tool for question testing and refinement. However, the involvement of an independent expert panel to review cases of disagreement between the model and the answer key revealed some poorly constructed questions containing vague or ambiguous statements, calling attention to the critical need for improved question design in future exams. Our findings suggest that while ChatGPT-4 Vision shows promise in multimodal academic evaluations, human oversight remains crucial for verifying the model’s accuracy and ensuring the fairness of high-stakes educational exams. The paper’s research materials are publicly available at .",10.1145/3674149,https://doi.org/10.1145/3674149
Decoding Logic Errors: A Comparative Study on Bug Detection by Students and Large Language Models,"Macneil, Stephen and Denny, Paul and Tran, Andrew and Leinonen, Juho and Bernstein, Seth and Hellas, Arto and Sarsa, Sami and Kim, Joanne",Proceedings of the 26th Australasian Computing Education Conference,2024,"Identifying and resolving logic errors can be one of the most frustrating challenges for novices programmers. Unlike syntax errors, for which a compiler or interpreter can issue a message, logic errors can be subtle. In certain conditions, buggy code may even exhibit correct behavior – in other cases, the issue might be about how a problem statement has been interpreted. Such errors can be hard to spot when reading the code, and they can also at times be missed by automated tests. There is great educational potential in automatically detecting logic errors, especially when paired with suitable feedback for novices. Large language models (LLMs) have recently demonstrated surprising performance for a range of computing tasks, including generating and explaining code. These capabilities are closely linked to code syntax, which aligns with the next token prediction behavior of LLMs. On the other hand, logic errors relate to the runtime performance of code and thus may not be as well suited to analysis by LLMs. To explore this, we investigate the performance of two popular LLMs, GPT-3 and GPT-4, for detecting and providing a novice-friendly explanation of logic errors. We compare LLM performance with a large cohort of introductory computing students (n = 964) solving the same error detection task. Through a mixed-methods analysis of student and model responses, we observe significant improvement in logic error identification between the previous and current generation of LLMs, and find that both LLM generations significantly outperform students. We outline how such models could be integrated into computing education tools, and discuss their potential for supporting students when learning programming.",10.1145/3636243.3636245,https://doi.org/10.1145/3636243.3636245
The Power of Context: An LLM-based Programming Tutor with Focused and Proactive Feedback,"Mueller, Moritz and List, Corinna and Kipp, Michael",Proceedings of the 6th European Conference on Software Engineering Education,2025,"Current research aims to utilize Large Language Models (LLMs) for tutoring beginning programming students efficiently and at scale. Students often struggle to interact effectively with LLMs to obtain meaningful feedback. We introduce an LLM-based Intelligent Tutoring System (ITS) with a structured interface and prompts aligned with Hattie’s feedback model. To provide more focused feedback, we utilize the user interaction history for context. Additionally, we explore the question of proactivity.A user study with 9 participants compared history-based and current-state feedback methods using ChatGPT, showing a preference for history-based feedback in 69% of cases and with higher usefulness ratings (M = 7.57 vs. M = 4.1, p = 0.03 (statistically significant at p &lt; 0.05)). This effect became more pronounced in later learning stages. For proactivity, we collected user data from the study, where participants explicitly requested feedback, and trained a neural network (NN) to predict optimal feedback timing. While the model achieved 97% accuracy on test data, the small sample size (N = 10) and the use of oversampling limit its generalizability. Future work will refine history-based feedback with eye-tracking data and integrate NN-driven proactive behavior to further enhance the effectiveness of LLM-based ITS in programming education.",10.1145/3723010.3723034,https://doi.org/10.1145/3723010.3723034
An LLM-based Reflection Analysis Tool for Identifying and Addressing Challenging Topics,"Dehbozorgi, Nasrin and Kunuku, Mourya T.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"Traditional evaluation of students' learning primarily relies on assessing learning outcomes through either summative or formative assessment methods. In these approaches, the primary emphasis is on the students' learning outcome, rather than the learning process. However, assessing the learning process is as important since it allows providing timely feedback which can directly impact students' learning outcomes. One of the known approaches to getting information about the learning process is the use of formative reflection tools, which also help students in developing their meta-cognitive skills. One effective method for formative reflection is the Minute Paper technique which asks students two concise questions after each class session: what they have learned and what challenges they have encountered. While Minute Papers encourage brief responses, the analysis process can become time-consuming as the number of students and class sessions grows. To address this challenge, in this study, we propose a Large Language Model (LLM)-based reflection analysis tool designed to assess the challenging topics students encounter during each class session. This tool suggests additional learning modules for students to study based on the frequency of the challenging topics. To achieve this, the model utilizes a local repository of lecture materials to create query contexts, which are then input into the LLM as prompts. Students are given access to these recommended resources for further learning, and they are encouraged to provide feedback after completing these modules. These data-driven recommended learning resources serve as continuous content delivery channels to foster a deeper understanding of the subjects at hand.",10.1145/3626253.3635601,https://doi.org/10.1145/3626253.3635601
Generating AI Literacy MCQs: A Multi-Agent LLM Approach,"Wang, Jiayi and Xiao, Ruiwei and Tseng, Ying-Jui",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"Artificial intelligence (AI) is transforming society, making it crucial to prepare the next generation through AI literacy in K-12 education. However, scalable and reliable AI literacy materials and assessment resources are lacking. To address this gap, our study presents a novel approach to generating multiple-choice questions (MCQs) for AI literacy assessments. Our method utilizes large language models (LLMs) to automatically generate scalable, high-quality assessment questions. These questions align with user-provided learning objectives, grade levels, and Bloom's Taxonomy levels. We introduce an iterative workflow incorporating LLM-powered critique agents to ensure the generated questions meet pedagogical standards. In the preliminary evaluation, experts expressed strong interest in using the LLM-generated MCQs, indicating that this system could enrich existing AI literacy materials and provide a valuable addition to the toolkit of K-12 educators.",10.1145/3641555.3705189,https://doi.org/10.1145/3641555.3705189
Leveraging Undergraduate Perspectives to Redefine AI Literacy,"Ebert, Jack and Kramarczuk, Kristina",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Artificial intelligence (AI) represents the future of the workforce, but existing curricula inadequately prepare students to comprehend and use these new technologies. Despite the push for educators to teach AI literacy, there is a distinct lack of research exploring student perspectives on the topic. Utilizing an explanatory sequential mixed methods research design, we first administered an AI literacy survey to undergraduate students in a computing major to learn how they think about AI, and then conducted focus group interviews after further refining our research questions. There was a discrepancy between undergraduate competence with AI applications and underlying AI principles, which were conflated on the survey and positively influenced overall knowledge. Participant confidence in AI's capability as a learning tool was infrequently limited by perception of personal ability, but rather by beliefs about limitations in AI tool efficacy. Participants believed that students pursuing any field would benefit from AI literacy and that AI literacy education, if implemented effectively, could mitigate concerns with AI pervasion in the workplace. A combination of surveys and assessments will be beneficial when centering students in AI curricula, the former establishing a student's AI confidence and the latter competence.",10.1145/3641554.3701916,https://doi.org/10.1145/3641554.3701916
NeuRL: A Standalone No-Code Web-Based Agent Environment to Explore Neural Networks and Reinforcement Learning,"Siegel, Scott and Kapoor, Amanpreet and Rashidi, Parisa",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Neural networks and reinforcement learning (RL) are fundamental to machine learning (ML) and AI. Given the widespread adoption of AI algorithms in industrial sectors, ensuring students understand these concepts will prepare them for a technology-driven job market. In this experience report, we introduce NeuRL, a free and accessible no-code web-based application that allows innovative real-time exploration of RL and neural networks. NeuRL provides interactive 3D WebGL environments, enabling students to experiment with multiple popular RL algorithms and observe the evolution of agents and neural networks as agents learn to accomplish tasks. To ensure NeuRL runs smoothly on low-performance computers, we created a custom neural network and RL library written in the OpenGL Shading Language (GLSL). To evaluate NeuRL's effectiveness, we introduced it to teach RL fundamentals to 111 students enrolled in an ML course. After the lesson, students completed a survey that assessed NeuRL's usability and learning effectiveness. Students found NeuRL easy to use and enjoyed its inclusion during the lesson. To the best of our knowledge, NeuRL is the first tool that enables students from any background to explore RL and observe both neural networks and agent behaviors in real time. NeuRL demonstrates the feasibility and value of providing accessible web-based tools that empower students to explore AI concepts in a manner that transcends conventional teaching methodologies.",10.1145/3641554.3701850,https://doi.org/10.1145/3641554.3701850
Expanding the Horizons of Autograding: Innovative Questions at UBC,"Niu, Jeffrey and Wong, Jessica and Lake, Charlie and Rahardjo, Justin and Zarkoob, Hedayat and Ola, Oluwakemi and Belleville, Patrice and Mochetti, Karina and Allen, Meghan and Moosvi, Firas and Wolfman, Steven",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"The popularity of autograding has grown due to increasing class sizes and the need to reduce grading load while ensuring quality. Autograding has conventionally been used for multiple choice and fill in the blank questions, or to check code correctness. In this work, we discuss the use of autograders at UBC and some non-conventional autograding implementations in our curricula. We reflect upon our autograder use in our courses and discuss the benefits, implications, and considerations of this pedagogical choice.",10.1145/3641554.3701892,https://doi.org/10.1145/3641554.3701892
Edugator: An AI-enabled Tool for Creating and Delivering Interactive Computing Content,"Diaz, Marc and Karp, Dustin and Tuli, Prayuj and Kapoor, Amanpreet",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"Edugator is a browser-based, AI-enabled tool designed to help instructors of introductory computing courses create and deliver interactive educational content. It streamlines the content authoring process by incorporating generative AI models into both the creation and delivery stages. Instructors can create bespoke interactive computing lessons and programming problems by providing a prompt and a few clicks. They can also author templates and test cases in programming languages such as C++, Java, C, and Python. Additionally, instructors can validate programming problems by running them against an auto-generated solution, allowing them to refine the problems before releasing it to students, preventing misinformation or ambiguity. Students can complete lessons and solve programming problems in a browser-based text editor receiving immediate feedback. They can also interact with a large language model-powered AI chatbot that scaffolds a student on how to approach the problem without giving out solutions. Edugator is built using modern web frameworks and the goal of the tool is to accelerate the adoption of automated assessment tools by minimizing the challenges instructors face with such tools. It also supports Learning Tools Interoperability (LTI), allowing seamless integration with learning management systems (LMS). The demo will provide an overview of Edugator's features, including authoring programming problems and lessons using AI or remixing existing problems obtained from test banks, LTI integration, and AI-chatbot. More information about the tool can be found at https://edugator.app/ and https://github.com/edugatorlabs/resources",10.1145/3641555.3705025,https://doi.org/10.1145/3641555.3705025
Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems,"Ali, Murtaza and Dasgupta, Sayamindu",Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems,2025,"Programming education is increasingly seen as an important curricular component of non-Computer Science (CS) disciplines at the undergraduate level. While existing research has studied non-CS majors’ experiences in introductory programming courses, there is limited work that explores such experiences across universities and disciplines. To address this gap, we conducted semi-structured interviews with 12 non-CS major programming students across several majors and universities and interpreted the results through reflexive thematic analysis. Our findings suggest that while students are excited about and interested in learning programming, they face barriers that often arise from the design of the courses they take and a lack of targeted resources and tools to support them. Building on our findings, we conclude with a set of recommendations for the design of tools, artifacts, and courses that can support programming education for non-major students.",10.1145/3706598.3713624,https://doi.org/10.1145/3706598.3713624
When Coding Meets Biology: The Tension Between Access and Authenticity in a Contextualized Coding Class,"Zuckerman, Austin L. and Juavinett, Ashley L.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"As programming skills become more demanded in fields outside of computer science, we need to consider how we should be teaching these skills to our students. One option is to encourage students to pursue introductory computer science courses; however, these courses are often geared towards computer science (CS) majors and without important discipline-specific context. Other avenues include short coding modules within disciplinary courses or full courses that blend CS with another discipline. Guided by insights from an introductory CS course in the context of biology, we describe a key tension when coding meets biology: while contextualized programming classes are often perceived as more accessible, students may also view them as less authentic. Taken together, these observations point to specific recommendations for educators who choose to integrate coding and biology in this way. Ultimately, we conclude that discipline-specific programming education is essential to improve equity in computing education.",10.1145/3626252.3630966,https://doi.org/10.1145/3626252.3630966
ChatGPT Comes to Campus: Unveiling Core Themes in AI Policies Across U.S. Universities with Large Language Models,"Alba, Charles and Xi, Wang and Wang, Chenyu and An, Ruopeng",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"The release of popular generative artificial intelligence (AI) tools like ChatGPT have prompted universities to introduce new policies or update existing ones. Currently, most institutions adapt their policies reactively as challenges arise, often without adopting a systematic framework, with minimal guidance and limited knowledge of the approaches taken by other institutions across the United States (U.S.). This study aims to bridge this gap by identifying core themes surrounding AI policies and guidelines across the top 50 U.S. universities. Given the labor- and time-intensive nature required to manually synthesize multiple policy documents across many institutions, we leverage large language models (LLMs) to identify common and prevalent themes. Our framework first summarizes AI policies at the institutional level, followed by the generation of multiple sets of themes through an iterative process of prompt chaining and self-refinement. Finally, the common themes from these distinct sets were consolidated. This framework is designed to address potential flaws in pre-trained LLMs, such as hallucinations. Seven distinct themes are uncovered: (1) academic integrity and responsible AI use, (2) communication of AI policies, (3) data privacy and security concerns, (4) ethical considerations in AI use, (5) continuous adaptation and policy evolution, (6) documentation and transparency in AI usage, and (7) instructor discretion in AI integration. Our work lays the foundation for future analyses or recommendations in developing comprehensive and equitable AI policies. Furthermore, leveraging LLMs allows us to respond swiftly to developments surrounding AI policies across universities.",10.1145/3641555.3705141,https://doi.org/10.1145/3641555.3705141
"Teaching Our Teacher Assistants to Thrive: A Reflexive, Inclusive Approach to Scalable Undergraduate Education","Yan, Lisa",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Teaching assistants (TAs) are well-poised to improve student performance and retention-particularly for those from minoritized backgrounds. In this experience report, we present a TA pedagogy course that trains TAs to effectively teach large-scale undergraduate courses in data science-and does so by centering inclusion and the classroom as a social space of engagement. This curriculum is grounded in a justice-oriented pedagogy framework and also tackles the interdisciplinary teaching skills necessary to teach data science. Course topics cover pedagogical frameworks and evidence-based teaching practices alongside professional and management skills that reflect the TA's positionality as both instructor and student. We present our experiences with offering this semester-long course and discuss how to adapt this course to other higher education institutions.",10.1145/3641554.3701950,https://doi.org/10.1145/3641554.3701950
K-12 Students' (Mis-)Conceptions of Machine Learning Paradigms,Kr\,Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"Understanding Artificial Intelligence (AI) is on its way to becoming a key competence in the coming years due to its rapid advancements and growing societal impact. Learning about different paradigms in AI, particularly in machine learning, is crucial to enabling students to critically engage with and shape an AI-driven world. The study investigates how students of three grade levels (5th, 8th, and 11th) understand AI concepts, addressing the challenge of widespread misconceptions and the limited presence of AI in school curricula. A deductive qualitative analysis was used to analyze the students' preconceptions. The results indicate that younger students typically exhibit minimal or anthropomorphic views, reflecting limited exposure to basic AI principles. Older students show somewhat more advanced, yet still partial, understandings, with misconceptions persisting across all groups. The findings underscore the importance of integrating AI literacy into school curricula and aligning instruction with students' developmental stages. For younger learners, hands-on activities can introduce basic AI functionality while dispelling human-like attributions. Older students benefit from exploring ethical, technical, and societal dimensions of AI. This research highlights the need for age-appropriate AI education to foster informed, responsible users and creators of AI systems.",10.1145/3724363.3729085,https://doi.org/10.1145/3724363.3729085
Exploring Student Reactions to LLM-Generated Feedback on Explain in Plain English Problems,"Kerslake, Chris and Denny, Paul and Smith, David H. and Leinonen, Juho and MacNeil, Stephen and Luxton-Reilly, Andrew and Becker, Brett A.",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Code reading and comprehension skills are essential for novices learning programming, and explain-in-plain-English tasks (EiPE) are a well-established approach for assessing these skills. However, manual grading of EiPE tasks is time-consuming and this has limited their use in practice. To address this, we explore an approach where students explain code samples to a large language model (LLM) which generates code based on their explanations. This generated code is then evaluated using test suites, and shown to students along with the test results. We are interested in understanding how automated formative feedback from an LLM guides students' subsequent prompts towards solving EiPE tasks. We analyzed 177 unique attempts on four EiPE exercises from 21 students, looking at what kinds of mistakes they made and how they fixed them. We found that when students made mistakes, they identified and corrected them using either a combination of the LLM-generated code and test case results, or they switched from describing the purpose of the code to describing the sample code line-by-line until the LLM-generated code exactly matched the obfuscated sample code. Our findings suggest both optimism and caution with the use of LLMs for unmonitored formative feedback. We identified false positive and negative cases, helpful variable naming, and clues of direct code recitation by students. For most students, this approach represents an efficient way to demonstrate and assess their code comprehension skills. However, we also found evidence of misconceptions being reinforced, suggesting the need for further work to identify and guide students more effectively.",10.1145/3641554.3701934,https://doi.org/10.1145/3641554.3701934
Experiences with Scaffolding Research Projects in Theory of Computing Courses,"Dougherty, Ryan E.",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"Theory of Computing (ToC) courses are essential because of their connections to other CS courses, serving as a foundation. Traditional ToC courses are structured to be heavily weighted with in-class examinations and the rest for proof-type assignments. Recent published research created a new type of assignment for a ToC course: a ''mock conference'' project. Here, students approach and present ToC problems as if they were submitting to a ''real'' CS conference, and separately anonymously referee other student projects. This prior research noted a disadvantage in that curation of different project topics for groups is prohibitively time-consuming. In this paper we outline a framework about adding scaffolding this assignment and provide our experiences in running such a conference in a small-scale ToC course. We anecdotally found that students were more engaged and can see the connections with other CS courses, both directly and indirectly. On the other hand, we found no statistically significant difference between our scaffolded project and the non-scaffolded version in prior work. We conclude with an extended version of our framework that could be applied to large-scale ToC courses.",10.1145/3724363.3729059,https://doi.org/10.1145/3724363.3729059
Howzat? Appealing to Expert Judgement for Evaluating Human and AI Next-Step Hints for Novice Programmers,"Brown, Neil C. C. and Weill-Tessier, Pierre and Leinonen, Juho and Denny, Paul and K\",ACM Trans. Comput. Educ.,2025,"Motivation: Students learning to program often reach states where they are stuck and can make no forward progress – but this may be outside the classroom where no instructor is available to help. In this situation, an automatically generated next-step hint can help them make forward progress and support their learning. It is important to know what makes a good hint or a bad hint, and how to generate good hints automatically in novice programming tools, for example using Large Language Models (LLMs).Method and participants: We recruited 44 Java educators from around the world to participate in an online study. We used a set of real student code states as hint-generation scenarios. Participants used a technique known as comparative judgement to rank a set of candidate next-step Java hints, which were generated by Large Language Models (LLMs) and by five human experienced educators. Participants ranked the hints without being told how they were generated. The hints were generated with no explicit detail given to the LLMs/humans on what the target task was. Participants then filled in a survey with follow-up questions. The ranks of the hints were analysed against a set of extracted hint characteristics using a random forest approach.Findings: We found that LLMs had considerable variation in generating high quality next-step hints for programming novices, with GPT-4 outperforming other models tested. When used with a well-designed prompt, GPT-4 outperformed human experts in generating pedagogically valuable hints. A multi-stage prompt was the most effective LLM prompt. According to a fitted random forest model, the two most important factors of a good hint were length (80–160 words being best), and reading level (US grade nine or below being best). Offering alternative approaches to solving the problem was considered bad, and we found no effect of sentiment.Conclusions: Automatic generation of these hints is immediately viable, given that LLMs outperformed humans – even when the students’ task is unknown. Hint length and reading level were more important than several pedagogical features of hints. The fact that it took a group of experts several rounds of experimentation and refinement to design a prompt that achieves this outcome suggests that students on their own are unlikely to be able to produce the same benefit. The prompting task, therefore, should be embedded in an expert-designed tool.",10.1145/3737885,https://doi.org/10.1145/3737885
"What Is Your Biggest Pain Point? An Investigation of CS Instructor Obstacles, Workarounds, and Desires","Mirhosseini, Samim and Henley, Austin Z. and Parnin, Chris",Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1,2023,"Computer science instructors have one of the most crucial roles in training and making educational materials. However, they face many challenges everyday that make it difficult to provide a high-quality learning experience to their students. Additionally, demand for computer science training is rapidly increasing, and to meet this demand, classrooms need to run on a larger scale, which may exacerbate instructor pain points further. While many of the previous studies in the computer science education community have focused on improving the students' learning experience, in this study we investigate computer science instructors. It is paramount to understand how instructors can be supported more effectively while continuing to improve the material they use in their courses and allow them to focus on student needs. To understand these instructor challenges, we conducted semi-structured interviews with 32 computer science instructors at universities and community colleges to ask about their experiences in preparing course material, lecturing, grading, providing feedback to students, and what they wished they could change. In this paper, we summarize our findings as themes of challenges and pain points for instructors, the consequences of not solving them, and suggested guidelines that may help resolve or reduce these pain points.",10.1145/3545945.3569816,https://doi.org/10.1145/3545945.3569816
Predicting Student Performance Using Sequence Models in XLogoOnline,"Marbach, Jeremy and Staub, Jacqueline and Schmerenbeck, Dirk and Wen, Chao",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1,2024,"This study investigates the efficacy of sequence modelling in predicting student performance. Over eight months, user interactions were recorded as students solved navigation tasks in the XLogoOnline programming environment. On this data, three sequence models were trained to learn the temporal dependencies for several performance features. We compared the models' predictive capabilities and found the Transformer architecture to perform best in making multi-step predictions. Although prediction quality declines for multi-step forecasts due to the accumulation of error, we show that the quality of long-term forecast becomes closer to those of shortterm forecasts, as the input length increases. Our results provide valuable insights for the development of more effective teaching tools that can monitor student learning in real time.",10.1145/3649165.3690098,https://doi.org/10.1145/3649165.3690098
An Evaluation on the Impact of Large Language Models on Computer Science Curricula,"Rhee, Junghwan and Shrestha, Aakankshya and Qian, Gang and Zuo, Fei and Fu, Jicheng and Park, Myungah and Qu, Xianshan and Mylavarapu, Goutam and Sung, Hong",J. Comput. Sci. Coll.,2024,"Since their introduction, large language model (LLM) services have been widely used in our society, including the computer science education area. While this technology provides various types of intelligent assistance to users, its capabilities and impact on computer science education regarding students' learning need further study. In this paper, we present our manual assessment of LLM services' ability to solve questions in various course assignments and projects in our computer science curriculum. Based on the result of the study, we provide our observations of the extent of LLM services' impact on different computer science disciplines. Suggestions are summarized and offered to computer science instructors on the possible strategies for dealing with LLMs in current and future computer science curriculum designs.",,
ReDefining Code Comprehension: Function Naming as a Mechanism for Evaluating Code Comprehension,"Smith, David H., IV and Fowler, Max and Denny, Paul and Zilles, Craig",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"''Explain in Plain English'' (EiPE) questions are widely used to assess code comprehension skills but are challenging to grade automatically. Recent approaches like Code Generation Based Grading (CGBG) leverage large language models (LLMs) to generate code from student explanations and validate its equivalence to the original code using unit tests. However, this approach does not differentiate between high-level, purpose-focused responses and low-level, implementation-focused ones, limiting its effectiveness in assessing comprehension level. We propose a modified approach where students generate function names, emphasizing the function's purpose over implementation details. We evaluate this method in an introductory programming course and analyze it using Item Response Theory (IRT) to assess the difficulty and discrimination of function naming exercises as exam items and to compare their alignment with traditional EiPE grading standards. We also publish this work as an open source Python package for auto-grading EiPE questions, providing a scalable solution for adoption.",10.1145/3724363.3729097,https://doi.org/10.1145/3724363.3729097
Improved Program Repair Methods using Refactoring with GPT Models,"Ishizue, Ryosuke and Sakamoto, Kazunori and Washizaki, Hironori and Fukazawa, Yoshiaki",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"Teachers often utilize automatic program repair methods to provide feedback on submitted student code using model answer code. A state-of-the-art tool is Refactory, which achieves a high repair success rate and small patch size (less code repair) by refactoring code to expand the variety of correct code samples that can be referenced. However, Refactory has two major limitations. First, it cannot fix code with syntax errors. Second, it has difficulty fixing code when there are few correct submissions. Herein we propose a new method that combines Refactory and OpenAI's GPT models to address these issues and conduct a performance measurement experiment. The experiment uses a dataset consisting of 5 programming assignment problems and almost 1,800 real-life incorrect Python program submissions from 361 students for an introductory programming course at a large public university. The proposed method improves the repair success rate by 1-21% when the set of correct code samples is sufficient and the patch size is smaller than Refactory alone in 16-45% of the cases. When there was no set of correct code samples at all (only the model answer code was used as a reference for repair), method improves the repair success rate by 1-43% and the patch size is smaller than Refactory alone in 42-68% of the cases.",10.1145/3626252.3630875,https://doi.org/10.1145/3626252.3630875
Developing Critical Thinking with AI Coding Assistants: An Educational Experience focusing on Testing and Legacy Code,"Blasquez, Isabelle",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"The rise of AI coding assistants, like GitHub Copilot, is transforming software development. These tools promise productivity gains and support for various tasks, from code generation to explain legacy systems. However, their integration into education raises pedagogical challenges: How can we use their potential without compromising students' autonomy and mastery of fundamental concepts? How can we stay critical of their limitations?This paper explores these questions through a structured educational experience. It is based on a guided tutorial designed to confront students with the assistants' limitations. A simultaneous questionnaire is provided to allow students to take the necessary time to thoroughly analyze the assistant's responses. The tutorial has three stages. It introduces students to real-world scenarios of increasing complexity: getting started, implementing business rules, and working on a legacy project.This approach helps develop skills such as critical thinking, prompt refinement, and error correction. The results also show that well-supervised use of coding assistants can enhance teaching in testing and working with legacy code. They help students overcome initial roadblocks and encourage them to think about best practices. Furthermore, students themselves highlight the importance of supervising these tools to maintain their autonomy.",10.1145/3724363.3729050,https://doi.org/10.1145/3724363.3729050
Decoding Debugging Instruction: A Systematic Literature Review of Debugging Interventions,"Yang, Stephanie and Baird, Miles and O’Rourke, Eleanor and Brennan, Karen and Schneider, Bertrand",ACM Trans. Comput. Educ.,2024,"Students learning computer science frequently struggle with debugging errors in their code. These struggles can have significant downstream effects—negatively influencing how students assess their programming ability and contributing to their decision to drop out of CS courses. However, debugging instruction is often an overlooked topic, and instructors report feeling unaware of effective approaches to teach debugging. Within the literature, research on the topic is sporadic, and though there are rigorous and insightful studies to be found, there is a need to synthesize instructional approaches for debugging. In this article, we review research from 2010 to 2022 on debugging interventions. We summarize the common pedagogical approaches for learning and categorize how these target specific cognitive and non-cognitive debugging skills, such as self-efficacy and emotion regulation. We also present a summary of assessment methods and their outcomes in order to discuss intervention efficacy and directions for further research. Our sample displays a diverse variety of debugging interventions and pedagogical approaches, ranging from games to unplugged activities. An evaluation of article results also presents encouraging findings, revealing several interventions that improved debugging accuracy and learning. Still, we notice gaps in interventions addressing non-cognitive debugging skills and observe limited success in guiding students toward adopting systematic debugging strategies. The review concludes with a discussion of future directions and implications for researchers and instructors in the field.",10.1145/3690652,https://doi.org/10.1145/3690652
Show Me the Mastery Learning! Obstacles to Adoption and Opportunities for New Solutions,,Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"Mastery learning was first defined in the late 1960s, but despite the promise of a student-focused methodology to establish firm foundations for later studies, it has not been widely adopted. In this paper, we consider why. We consider the evidence for mastery learning, and explore the organisational, structural, staffing, and pedagogical needs and challenges. We find, immediately, that there are competing implementations for mastery learning in computing education. We propose a way of representing pedagogical theories that use aspects of mastery learning in a way that allows a clear separation of techniques that appear similar but are not identical, to ensure the most appropriate implementation for a given area of application. These techniques still share similar challenges for adoption. We build towards possible solutions by considering recent developments in generative AI---and how these technologies could potentially provide automated assistants as a supporting component of mastery learning, in order to fully realise Bloom's vision.",10.1145/3724363.3729104,https://doi.org/10.1145/3724363.3729104
Sociotechnical AI Education Course Design for CS Majors and Non-Majors,"Tadimalla, Sri Yash and Maher, Mary Lou",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"As generative AI increasingly integrates into society and education, the number of institutions implementing AI usage policies and offering introductory AI courses is rising. These introductory AI courses mustn't replicate the",10.1145/3641555.3705252,https://doi.org/10.1145/3641555.3705252
"Outcomes, Perceptions, and Interaction Strategies of Novice Programmers Studying with ChatGPT","Penney, Jacob and Acharya, Pawan and Hilbert, Peter and Parekh, Priyanka and Sarma, Anita and Steinmacher, Igor and Gerosa, Marco Aurelio",Proceedings of the 7th ACM Conference on Conversational User Interfaces,2025,"Large Language Model (LLM) conversational agents are increasingly used in programming education, yet we still lack insight into how novices engage with them for conceptual learning compared with human tutoring. This mixed‑methods study compared learning outcomes and interaction strategies of novices using ChatGPT or human tutors. A controlled lab study with 20 students enrolled in introductory programming courses revealed that students employ markedly different interaction strategies with AI versus human tutors: ChatGPT users relied on brief, zero‑shot prompts and received lengthy, context‑rich responses but showed minimal prompt refinement, while those working with human tutors provided more contextual information and received targeted explanations. Although students distrusted ChatGPT’s accuracy, they paradoxically preferred it for basic conceptual questions due to reduced social anxiety. We offer empirically grounded recommendations for developing AI literacy in computer science education and designing learning‑focused conversational agents that balance trust‑building with maintaining the social safety that facilitates uninhibited inquiry.",10.1145/3719160.3736625,https://doi.org/10.1145/3719160.3736625
A Unified Holistic Model of Visual Perception for Code Reviews,"Hauser, Florian and Ezer, Timur and Grabinger, Lisa and Mottok, J\",Proceedings of the 6th European Conference on Software Engineering Education,2025,"Despite being a well-structured domain, software engineering lacks standardized definitions, metrics, and theories for analyzing eye movements in domain-specific tasks. This gap can be addressed by adapting models from other fields, such as radiology and psychology. In particular, the holistic models of image perception provide a suitable framework for software engineering applications. This paper introduces a unified model of visual perception focused on eye movements during code reviews. It is based on prior research, findings from other studies, and cross-domain theories. Empirical studies on C and C++ code reviews confirm a phase-based process, where experts switch between global scanning and focal viewing. In addition, significant differences in the fixation rate, fixation duration, number of saccades, and AOI-specific metrics highlight the role of expertise in visual processing. The proposed model offers a structured framework for eye-tracking analysis in software engineering, defining relevant metrics and supporting future refinements across various software engineering tasks.",10.1145/3723010.3723017,https://doi.org/10.1145/3723010.3723017
Making ChatGPT Work for Me,"Keppler, Samantha and Sinchaisri, Wichinpong Park and Snyder, Clare",Proc. ACM Hum.-Comput. Interact.,2025,"Increasingly, work happens through human collaboration with generative AI (e.g., ChatGPT). In this paper, we present a qualitative study of this collaboration for real-life work tasks. We focus our study on US K12 public school teachers (N = 24) who regularly design and complete text-generation tasks such as creating quizzes, slide decks, word problems, reading passages, lesson plans, classroom activities, and projects. In one-on-one video- and audio-recorded virtual sessions, we observe each teacher using ChatGPT-4 for work tasks of their choosing for 15 minutes, then debrief their experience. Analyzing 201 prompts inputted by the 24 teachers, we uncover four main modes with which the teachers request support from ChatGPT: (1) make for me (55% of prompts), (2) find for me (15%), (3) jump-start for me (10.5%), and (4) iterate with me (15.5%). The first three modes (make, find, and jump-start) are often requests of generative AI to do something, whereas the fourth mode (iterate) is a request of generative AI to think. In a follow-up survey of the same 24 teachers, most report using multiple modes for their work, but infrequently. Our study contributes new data and knowledge about how teachers are coming to understand whether and how to integrate generative AI into their teaching preparation routines.",10.1145/3711026,https://doi.org/10.1145/3711026
LLM-Driven Feedback for Enhancing Conceptual Design Learning in Database Systems Courses,"Riazi, Sara and Rooshenas, Pedram",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"The integration of LLM-generated feedback into educational settings has shown promise in enhancing student learning outcomes. This paper presents a novel LLM-driven system that provides targeted feedback for conceptual designs in a Database Systems course. The system converts student-created entity-relationship diagrams (ERDs) into JSON format, allows the student to prune the diagram by isolating a relationship, extracts relevant requirements for the selected relationship, and utilizes a large language model (LLM) to generate detailed feedback. Additionally, the system creates a tailored set of questions and answers to further aid student understanding. Our pilot implementation in a Database System course demonstrates effective feedback generation that helped the students improve their design skills.",10.1145/3641554.3701940,https://doi.org/10.1145/3641554.3701940
Scaling Code Understanding for Introductory Programming in the AI Era,"Zhang, Ashley Ge",Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems,2025,"Scaling programming education has become a significant challenge due to rapidly increasing learning needs and limited instructional resources. With the numerous data generated in programming education, scaling code understanding is crucial for instructors to make informed decisions, such as providing feedback and adapting course materials. However, this is impractical due to the wide variation among students’ code and the complexity of activities like tracking coding progress and analyzing solution trajectories. Artificial Intelligence (AI) has great potential for analyzing large volumes of data, but it also presents difficulties in making this data quickly understandable for humans. My research aims to scale code understanding in meaningful ways for introductory programming through combining techniques from AI and visualization. I design and develop interactive systems that enable instructors navigate large, complex collections of code and identify patterns, thereby enhancing teaching activities and improving learning outcomes.",10.1145/3706599.3721095,https://doi.org/10.1145/3706599.3721095
"Computer Science Curricula 2023 (CS2023): Rising to the Challenges of Change in AI, Security, and Society","Aly, Sherif G. and Becker, Brett A. and Kumar, Amruth N. and Raj, Rajendra K.",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2,2024,"Model curricula for baccalaureate computer science (CS) have been published regularly from 1968 through 2013. In early 2021, the ACM, IEEE-Computer Society, and the Association for the Advancement of Artificial Intelligence (AAAI) constituted a task force to revise these curricula, which have now been released as Computer Science 2023 Curricula (CS2023). The CS2023 curricular guidelines inform educators and administrators on the what, why, and how to cover undergraduate CS over the next decade. Like past guidelines, CS2023 provides curricular content - a knowledge model largely backward compatible with CS2013, supplemented by a competency framework influenced by Computing Curricula 2020 (CC2020) - and complementary curricular practices, which include articles by international experts on program design and delivery. Ongoing drafts of CS2023 were disseminated via the CS2023 website, along with regular publications or presentations at various computing education venues.This panel focuses on three among the 17 CS2023 knowledge areas: Society, Ethics, and the Profession (SEP), Artificial Intelligence (AI), and Security (SEC). While the other 14 knowledge areas remain important in CS education, these three have been in the news due to inadequacies in current CS education. The panelists, who served on the CS2023 steering committee, will discuss how CS2023 addresses these challenges. Attendees will appreciate the approach taken by CS2023 toward these three hot-button items of CS education, especially constraints on curriculum design, and how CS2023 may be used to educate the next generation of CS graduates to rise to these three challenges.",10.1145/3649405.3659537,https://doi.org/10.1145/3649405.3659537
Can GPT Help? Supporting Teachers to Brainstorm Customized Instructional Scratch Projects,"Tran, Minh and Gonzalez-Maldonado, David and Zhou, Elaine and Franklin, Diana",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"While many recent studies have explored how large language models can transform computer science instruction from the instructor perspective, they are primarily at the college level. Thus, little is known about using large language models towards curriculum development and teacher supports outside of the college setting. Given the emphasis placed on culturally responsive teaching at the K-8 level and well-documented evidence of insensitive and inaccurate language model outputs from a cultural perspective, it is imperative to perform systematic and principled research before considering their use in this setting.This paper explores the potential of teachers using large language models to brainstorm instructional Scratch projects. Specifically, we use GPT-3 to mimic structured projects from an existing computer science curriculum but situate the generated projects in different contexts/themes. We qualitatively analyze 300 project ideas generated by GPT and find 81% of the generated ideas satisfy our metrics for technical alignment and theme quality. We identify two major weaknesses: code complexity of generated projects and presence of potential insensitive elements that would require human filtering. We conclude that, while not ready as a student-facing solution, teachers could use GPT to effectively brainstorm customized instructional materials.",10.1145/3641554.3701858,https://doi.org/10.1145/3641554.3701858
Prior What Experience? The Relationship Between Prior Experience and Student Help-Seeking Beyond CS1,"Ko, Shao-Heng and Stephens-Martinez, Kristin",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"Background and Context. Prior experience (PE) has been shown to be related to computing students' performance, persistence, and help-seeking behavior. However, most works studied prior programming experience in introductory programming (CS1) courses, while other forms of PE in other contexts are underexplored.Objectives. We seek to study the relationship between all kinds of relevant PE and help-seeking behavior in course-affiliated resources within and beyond the typical CS1 context.Method. We analyzed N=2,625 students' self-reported PE and course-affiliated help-seeking records, originating from 19 offerings of six courses at a post-secondary US institution. Four of the six courses are non-programming or non-introductory courses.Findings. We found pronounced negative relations between PE and students' frequency of seeking one-on-one student-staff interactions, as well as positive relations between PE and students' self-reported progress from these interactions. When multiple forms of PE are tracked, the PE that is more aligned with the course activities has a more pronounced effect. We found little relation between PE and students' behavior in class discussion forums.Implications. Our results highlight that (1) the relationship between PE and help-seeking extends beyond the CS1 context; and (2) this relationship differs between help resources and between course contexts. This motivates providing resource-specific and course-specific training on helping different student populations.",10.1145/3724363.3729092,https://doi.org/10.1145/3724363.3729092
Infinite Story,"Piech, Chris and Sahami, Mehran and Alonso, Yasmine and Liu, Katie and Arifov, Javokhir and Sreenivas, Anjali and Webber, Dan and Zheng, Tina and Nguyen, Ngoc and Mlauzi, Iddah and Woodrow, Juliette",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"In Infinite Story, students build a choose-your-own-adventure game that integrates generative AI to create a dynamic, interactive",10.1145/3641555.3705037,https://doi.org/10.1145/3641555.3705037
Gamification Powered by Large Language Models in Undergraduate Computer Science,"Kelly, Kathleen",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 2,2025,"Gamification is a popular pedagogical approach in computer science education, and advances in large language models (LLMs) enable dynamic and engaging learning experiences. In this PhD dissertation work, gamification is being studied alongside artificial intelligence (AI) in an effort to create educational games that include personalization for each student and competition driven by AI.",10.1145/3724389.3731291,https://doi.org/10.1145/3724389.3731291
"ChatGPT, Can You Generate Solutions for my Coding Exercises? An Evaluation on its Effectiveness in an undergraduate Java Programming Course.","Ouh, Eng Lieh and Gan, Benjamin Kok Siew and Jin Shim, Kyong and Wlodkowski, Swavek",Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1,2023,"In this study, we assess the efficacy of employing the ChatGPT language model to generate solutions for coding exercises within an undergraduate Java programming course. ChatGPT, a large-scale, deep learning-driven natural language processing model, is capable of producing programming code based on textual input. Our evaluation involves analyzing ChatGPT-generated solutions for 80 diverse programming exercises and comparing them to the correct solutions. Our findings indicate that ChatGPT accurately generates Java programming solutions, which are characterized by high readability and well-structured organization. Additionally, the model can produce alternative, memory-efficient solutions. However, as a natural language processing model, ChatGPT struggles with coding exercises containing non-textual descriptions or class files, leading to invalid solutions. In conclusion, ChatGPT holds potential as a valuable tool for students seeking to overcome programming challenges and explore alternative approaches to solving coding problems. By understanding its limitations, educators can design coding exercises that minimize the potential for misuse as a cheating aid while maintaining their validity as assessment tools.",10.1145/3587102.3588794,https://doi.org/10.1145/3587102.3588794
"ChatGPT Didn't Take Me Very Far, Did It?","Sane, Aamod and Albuquerque, Melwina and Gupta, Madhav and Valadi, Jayaraman",Proceedings of the ACM Conference on Global Computing Education Vol 2,2023,"The effect of ChatGPT (CG) on teachers, assessment and other matters have been discussed in many works, but no one appears to have studied how students are actually using it. We study how students use CG for coursework, a semester long project, and summer internships. We discover that from a student's perspective, CG responses fall into three classes: it is immediately helpful, it needs user help, or it leads to unhelpful frustration. We are developing a classification of these uses as a prelude to understanding how CG can contribute to improving student learning outcomes.",10.1145/3617650.3624947,https://doi.org/10.1145/3617650.3624947
GenAI Integration in Upper-Level Computing Courses,"Bouvier, Dennis J and Cipriano, Bruno Pereira and Glassey, Richard and Pettit, Raymond and Anderson, Emma and Birillo, Anastasiia and Dougherty, Ryan and Hazzan, Orit and Petrovska, Olga and Pombo, Nuno and Rahimi, Ebrahim and Ramakrishnan, Charanya and Steinmaurer, Alexander and Taneja, Shubbhi and Usman, Muhammad and Vadaparty, Annapurna and Yeluripati, Govindha Ramaiah",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 2,2025,"GenAI is playing an increasingly important role in computing courses at all levels, offering new opportunities to support teaching and learning. However, using GenAI effectively raises important concerns regarding trust, academic integrity, and broader social and ethical dimensions. This Working Group was formed to report on the current state of the art in using GenAI in upper-level computing courses to aid educators. The working group will undertake a methodological review of published work and solicit input from the computing educational community as part of the report.",10.1145/3724389.3731276,https://doi.org/10.1145/3724389.3731276
Exploring the Humanistic Role of Computer Science Teaching Assistants across Diverse Institutions,"Barkhuff, Grace and Pruitt, Ian and Namani, Vyshnavi and Johnson, William Gregory and Borela, Rodrigo and Zegura, Ellen and Bourgeois, Anu G. and Shapiro, Ben Rydal",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Recently, there has been a growing interest in the role of teaching assistants (TAs) in computer science (CS). This interest is due to the vital role CS TAs play in supporting student learning and their expanding responsibilities driven by growing enrollments in CS programs worldwide. While much of this research focuses on the technical and pedagogical aspects of CS TAs' duties, researchers recognize the need to further explore the unique value human CS TAs provide, particularly with the rise of AI tools and assistants. In this paper, we use qualitative methods to analyze 109 survey responses collected across two different institutions in the United States as part of a larger design-based research project to make two contributions. First, we illustrate how CS TAs adopt humanistic stances and demonstrate care in their roles, thereby expanding prevailing understandings of CS TAs. Second, we detail similarities and differences across CS TAs' experiences at each institution that underscore the importance of understanding CS TAs as they are situated in different institutional contexts. We conclude by discussing implications of this work for computing instruction and TA training, emphasizing the importance of foregrounding the roles and values brought by TAs.",10.1145/3641554.3701861,https://doi.org/10.1145/3641554.3701861
Automating Personalized Parsons Problems with Customized Contexts and Concepts,"del Carpio Gutierrez, Andre and Denny, Paul and Luxton-Reilly, Andrew",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"Parsons problems provide useful scaffolding for introductory programming students learning to write code. However, generating large numbers of high-quality Parsons problems that appeal to the diverse range of interests in a typical introductory course is a significant challenge for educators. Large language models (LLMs) may offer a solution, by allowing students to produce on-demand Parsons problems for topics covering the breadth of the introductory programming curriculum, and targeting thematic contexts that align with their personal interests. In this paper, we introduce PuzzleMakerPy, an educational tool that uses an LLM to generate unlimited contextualized drag-and-drop programming exercises in the form of Parsons Problems, which introductory programmers can use as a supplemental learning resource. We evaluated PuzzleMakerPy by deploying it in a large introductory programming course, and found that the ability to personalize the contextual framing used in problem descriptions was highly engaging for students, and being able to customize the programming topics was reported as being useful for their learning.",10.1145/3649217.3653568,https://doi.org/10.1145/3649217.3653568
Teaching with AI (GPT),"Liu, Rongxin and Malan, David J. and Zhukovets, Yuliia and Lloyd, Doug",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"Teaching computer science at scale can be challenging. From our experience in CS50, Harvard University's introductory course, we've seen firsthand the impactful role that generative artificial intelligence can play in education. Recognizing its potential and stakes, we integrated OpenAI's GPT into our own teaching methodology. The goal was to emulate a 1:1 teacher-to-student ratio, incorporating",10.1145/3641555.3704765,https://doi.org/10.1145/3641555.3704765
Teens' Ethical Sensemaking About Emerging Technologies,"Landesman, Rotem",Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 2,2024,"Emerging technologies, among them generative AI, are continuously being integrated into the mundane fabric of young people’s lives and routines. Recently, scholars called to expand computing education beyond learning to use and create with technologies to think critically and ethically about their potential impacts as a means to encourage the development of a sense of computational empowerment. My research aims to explore this space and opportunities which encourage ethical thinking with youth - specifically adolescents - on and about generative AI, a recent emerging innovation. This exploration will take inspiration from previous work pointing to the efficacy of practices from the field of Philosophy for Children (P4C) as well as recent work pointing to the potential of eliciting ethical thinking through a critical reflection and making framework, and suggest a novel framework to elicit a sense of computational empowerment as youth grow up in our digital world.",10.1145/3632621.3671415,https://doi.org/10.1145/3632621.3671415
Need a Programming Exercise Generated in Your Native Language? ChatGPT's Got Your Back: Automatic Generation of Non-English Programming Exercises Using OpenAI GPT-3.5,"Jordan, Mollie and Ly, Kevin and Soosai Raj, Adalbert Gerald",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"Large language models (LLMs) like ChatGPT are changing computing education and may create additional barriers to those already faced by non-native English speakers (NNES) learning computing. We investigate an opportunity for a positive impact of LLMs on NNES through multilingual programming exercise generation. Following previous work with LLM exercise generation in English, we prompt OpenAI GPT-3.5 in 4 natural languages (English, Tamil, Spanish, and Vietnamese) to create introductory programming problems, sample solutions, and test cases. We evaluate these problems on their sensibility, readability, translation, sample solution accuracy, topicality, and cultural relevance. We find that problems generated in English, Spanish, and Vietnamese are largely sensible, easily understood, and accurate in their sample solutions. However, Tamil problems are mostly non-sensible and have a much lower passing test rate, indicating that the abilities of LLMs for problem generation are not generalizable across languages. Our analysis suggests that these problems could not be given verbatim to students, but with minimal effort, most errors can be fixed. We further discuss the benefits of these problems despite their flaws, and their opportunities to provide personalized and culturally relevant resources for students in their native languages.",10.1145/3626252.3630897,https://doi.org/10.1145/3626252.3630897
Student Perceptions of the Help Resource Landscape,"Ko, Shao-Heng and Stephens-Martinez, Kristin and Zahn, Matthew and Velasco, Yesenia and Battestilli, Lina and Heckman, Sarah",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Background and Context. Existing works in computing students' help-seeking and resource selection identified an expanding set of important dimensions that students consider when choosing a help resource. However, most works either assume a predefined list of help resources or focus on one specific help resource, while the landscape of help resources evolve at a faster speed.Objectives. We seek to study how students value each dimension in the help landscape in their resource selection and utilization processes, as well as how their identities relate to their perceptions of the landscape.Method. We surveyed N=1,625 students on their perceptions of 8 dimensions across 12 offerings of 7 courses at 2 institutions.Findings. We found a consistent pattern of four distinct dimension tiers ordered from most to least important: (1) timeliness of help, (2) availability and adaptability of the resource, (3) the resource's time/space anchor and the effort to phrase the help need, (4) formality and socialness of the resource. We also found men and first-years rate all dimensions as less important than their classmates.Implications. Our results reveal what the students collectively value most when selecting help resources and thus can inform practitioners seeking to improve their course help ecosystem.",10.1145/3641554.3701851,https://doi.org/10.1145/3641554.3701851
Validation of an Instrument to Measure Self-Efficacy in Information Security,"Tise, Joseph C. and McGill, Monica M.",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1,2024,"Problem. Extant measures of students' cybersecurity self-efficacy lack sufficient evidence of validity based on internal structure. Such evidence of validity is needed to enhance confidence in conclusions drawn from use of self-efficacy measures in the cybersecurity domain. Research Question. To address this identified problem, we sought to answer our research question: What is the underlying factor structure of a new self-efficacy for Information Security measure?   Method. We leveraged exploratory factor analysis (EFA) to determine the number of factors underlying a new measure of student self-efficacy to conduct information security. This measure was created to align with the five elements of the information security section of the K-12 cybersecurity Education framework. Participants were 190 undergraduate students recruited from computer science courses across the U.S.  Findings. Results from the EFA indicated that a four-factor solution best fit the data while maximizing interpretability of the factors. The internal reliability of the measure was quite strong (α = .99).  Implications. The psychometric quality of this measure was demonstrated, and thus evidence of validity based on internal structure has been established. Future work will conduct a confirmatory factor analysis (CFA) and assess measurement invariance across subgroups of interest (e.g., over- vs. under-represented race/ethnicity groups, gender).",10.1145/3649165.3690095,https://doi.org/10.1145/3649165.3690095
How Novices Use Program Visualizations to Understand Code that Manipulates Data Tables,"Wu, Ylesia and Zheng, Qirui and Lau, Sam",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"As data science and artificial intelligence continue to impact society, more and more people are learning how to manipulate data with code. To support these learners, program visualization tools automatically generate diagrams to show how code transforms data, in contrast to tools based on large language models (LLMs) that primarily focus on textual explanations. Although program visualization tools are popular among instructors, do novices find these tools usable and useful for data science programs that often manipulate datasets with many rows? To address this, we evaluate a popular, publicly available tool that generates diagrams for Python pandas code through a randomized, in-lab usability study with 17 data science novices. Despite minimal instruction on how to use the tool, novices found that program visualizations increased their confidence in comprehending and debugging code. In addition, even though the tool sometimes produced diagrams with many visual elements, participant performance on the study tasks was not negatively impacted. These findings suggest design guidelines for program visualization tools to help manage cognitive load for data science novices. To our knowledge, this is the first empirical study that investigates how novices use program visualization tools to understand code that manipulates data tables, and suggests a future where novices can use automatically generated diagrams as a complement to LLM tools for effectively understanding unfamiliar programs in data science.",10.1145/3641554.3701959,https://doi.org/10.1145/3641554.3701959
"Teaching AI to K-12 Learners: Lessons, Issues, and Guidance","Grover, Shuchi",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"There is growing recognition of the need to teach artificial intelli- gence (AI) and machine learning (ML) at the school level. This push acknowledges the meteoric growth in the range and diversity of ap- plications of ML in all industries and everyday consumer products, with Large Language Models (LLMs) being only the latest and most compelling example yet. Efforts to bring AI, especially ML educa- tion to school learners are being propelled by substantial industry interest, research efforts, as well as technological developments that make sophisticated ML tools readily available to learners of all ages. These early efforts span a variety of learning goals captured by the AI4K12",10.1145/3626252.3630937,https://doi.org/10.1145/3626252.3630937
UML Mentor: A Tool for Interactive and Collaborative Software Design Education,"Engineer, Rutwa and Yaremchuk, Volodymyr and Suner, Eren and Khamis, Omar and Apostolu, Alex and Ng, Arthur",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2,2024,"This lightning talk describes a homegrown digital educational tool, Unified Modeling Language Mentor (UML Mentor), that allows students to participate in software design challenges and create UML diagrams. Introducing design patterns in an undergraduate object-oriented software design course offers a unique opportunity to embed good design techniques, which can be transferred to real-world scenarios. UML Mentor encourages students to evaluate software design challenges from diverse perspectives by experimenting and reflecting through UML diagram creation. The software design challenges consist of a description, use cases, and expected functionality. Each challenge describes a program for which the students are expected to create a UML class diagram. Once students have completed creating the UML diagram for a challenge, they can post it for others to review. We recognize that providing feedback on UML diagrams can be time-consuming for CS educators, especially because there can be multiple valid design patterns acceptable for a challenge. As a result, in UML Mentor, students can collaborate and provide formative peer feedback through comments. To encourage community building and mentoring in the classroom, the original creator of a UML diagram can mark some peer comments as 'helpful' to show gratitude towards the commentator. Our tool helps students build confidence in creating UML diagrams according to diverse design patterns and facilitates peer feedback. During the talk, we will do a walk-through of an example software design challenge, showcase implemented features, and gather participant input and critique on UML Mentor to improve and inform future releases.",10.1145/3649409.3691078,https://doi.org/10.1145/3649409.3691078
Introducing SIGCSE Virtual,"Dorodchi, Mohsen and Gal-Ezer, Judith and Cooper, Stephen",SIGCSE Bull.,2025,"SIGCSE Virtual 2024, the First ACM Virtual Global Computing Education Conference, will be held fully online from December 5 to 8, 2024. The conference has different themes based on the global aspects of CS education, while considering regional circumstances, and the sessions are offered considering time-zone constraints.",10.1145/3717402.3717403,https://doi.org/10.1145/3717402.3717403
Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,"Lum, Christopher and Xu, Guoxuan and Lau, Sam",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Data scientists often need to read and understand messy and undocumented code that relies on large software libraries. What makes data science experts more effective than novices at this task? To understand expert practices, we conducted a think-aloud study where 4 novice and 5 expert data scientists reasoned about an unfamiliar data analysis script with realistic complexity that used the Python pandas library. Surprisingly, familiarity of the pandas package had relatively minor importance for experts. Instead, experts consistently performed three practices that novices did not: experts examined the data in detail rather than fixating on surface-level code features; experts consistently verified their assumptions about how the data was transformed; and experts navigated lengthy program outputs in a goal-directed way. Using these findings, we provide a practical set of guidelines for data science pedagogy and for future tools to support data science learners.",10.1145/3641554.3701933,https://doi.org/10.1145/3641554.3701933
Let's Ask AI About Their Programs: Exploring ChatGPT's Answers To Program Comprehension Questions,"Lehtinen, Teemu and Koutcheme, Charles and Hellas, Arto",Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training,2024,"Recent research has explored the creation of questions from code submitted by students. These Questions about Learners' Code (QLCs) are created through program analysis, exploring execution paths, and then creating code comprehension questions from these paths and the broader code structure. Responding to the questions requires reading and tracing the code, which is known to support students' learning. At the same time, computing education researchers have witnessed the emergence of Large Language Models (LLMs) that have taken the community by storm. Researchers have demonstrated the applicability of these models especially in the introductory programming context, outlining their performance in solving introductory programming problems and their utility in creating new learning resources. In this work, we explore the capability of the state-of-the-art LLMs (GPT-3.5 and GPT-4) in answering QLCs that are generated from code that the LLMs have created. Our results show that although the state-of-the-art LLMs can create programs and trace program execution when prompted, they easily succumb to similar errors that have previously been recorded for novice programmers. These results demonstrate the fallibility of these models and perhaps dampen the expectations fueled by the recent LLM hype. At the same time, we also highlight future research possibilities such as using LLMs to mimic students as their behavior can indeed be similar for some specific tasks.",10.1145/3639474.3640058,https://doi.org/10.1145/3639474.3640058
Exploring the Responses of Large Language Models to Beginner Programmers’ Help Requests,"Hellas, Arto and Leinonen, Juho and Sarsa, Sami and Koutcheme, Charles and Kujanp\",Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1,2023,"Background and Context: Over the past year, large language models (LLMs) have taken the world by storm. In computing education, like in other walks of life, many opportunities and threats have emerged as a consequence. Objectives: In this article, we explore such opportunities and threats in a specific area: responding to student programmers’ help requests. More specifically, we assess how good LLMs are at identifying issues in problematic code that students request help on. Method: We collected a sample of help requests and code from an online programming course. We then prompted two different LLMs (OpenAI Codex and GPT-3.5) to identify and explain the issues in the students’ code and assessed the LLM-generated answers both quantitatively and qualitatively. Findings: GPT-3.5 outperforms Codex in most respects. Both LLMs frequently find at least one actual issue in each student program (GPT-3.5 in 90% of the cases). Neither LLM excels at finding all the issues (GPT-3.5 finding them 57% of the time). False positives are common (40% chance for GPT-3.5). The advice that the LLMs provide on the issues is often sensible. The LLMs perform better on issues involving program logic rather than on output formatting. Model solutions are frequently provided even when the LLM is prompted not to. LLM responses to prompts in a non-English language are only slightly worse than responses to English prompts. Implications: Our results continue to highlight the utility of LLMs in programming education. At the same time, the results highlight the unreliability of LLMs: LLMs make some of the same mistakes that students do, perhaps especially when formatting output as required by automated assessment systems. Our study informs teachers interested in using LLMs as well as future efforts to customize LLMs for the needs of programming education.",10.1145/3568813.3600139,https://doi.org/10.1145/3568813.3600139
Asking ChatGPT for Pattern Recommendations: EuroPLoP 2024 Focus Group Report,,"Proceedings of the 29th European Conference on Pattern Languages of Programs, People, and Practices",2024,"This report summarizes a focus group held at EuroPLoP 2024 on using ChatGPT as a recommender for design patterns. Apart from the organizers, 11 participants from academia and industry took part in the focus group. In this focus group, we discussed the results of two experiments exploring how well ChatGPT gives recommendations on using patterns from the GoF collection when a situation is described which suggests the application of such a pattern. It was found that the responses are promising in many cases, but their quality depends on a good choice of prompts. The quality of the responses was comparable for prompts in English, German, and Russian, but a little lower for Arabic and absolutely useless in Kyrgyz. Based on our observations, some recommendations are given for selecting suitable prompts when communicating with the chatbot.",10.1145/3698322.3698361,https://doi.org/10.1145/3698322.3698361
ChatGPT in the Classroom: An Analysis of Its Strengths and Weaknesses for Solving Undergraduate Computer Science Questions,"Joshi, Ishika and Budhiraja, Ritvik and Dev, Harshal and Kadia, Jahnvi and Ataullah, Mohammad Osama and Mitra, Sayan and Akolekar, Harshal D. and Kumar, Dhruv",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"This research paper aims to analyze the strengths and weaknesses associated with the utilization of ChatGPT as an educational tool in the context of undergraduate computer science education. ChatGPT's usage in tasks such as solving assignments and exams has the potential to undermine students' learning outcomes and compromise academic integrity. This study adopts a quantitative approach to demonstrate the notable unreliability of ChatGPT in providing accurate answers to a wide range of questions within the field of undergraduate computer science. While the majority of existing research has concentrated on assessing the performance of Large Language Models in handling programming assignments, our study adopts a more comprehensive approach. Specifically, we evaluate various types of questions such as true/false, multi-choice, multi-select, short answer, long answer, design-based, and coding-related questions. Our evaluation highlights the potential consequences of students excessively relying on ChatGPT for the completion of assignments and exams, including self-sabotage. We conclude with a discussion on how can students and instructors constructively use ChatGPT and related tools to enhance the quality of instruction and the overall student experience.",10.1145/3626252.3630803,https://doi.org/10.1145/3626252.3630803
The Future of the Error Message: Comparing Large Language Models and Novice Programmer Effectiveness in Fixing Errors,"Howard-Sarin, Brij",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"Research on enhancing error message presentation is of great interest to teachers and developers alike because improving Integrated Development Environments (IDEs) increases early student retention and efficiency at all levels with more effective developing tools. This study aims to compare GPT-4 and novice programmer accuracy in fixing errors to assess the viability of Large Language Models as an error message enhancement tool. First, a random sample of 100,000 sessions from all users of BlueJ 5, an IDE for novice programmers, was analyzed to determine the time it took programmers to resolve coding errors. Subsequently, for each of the five most common errors, GPT-4 was given 20 randomly-selected snippets of code from Blackbox mini, a curated subset of Blackbox with source code attached, and prompted to explain and fix the errors. This study replicated prior research that proposed a Zipf-Mandelbrot Distribution of error message frequency; the five most common errors comprised 45% of all error messages. In comparing GPT-4 and novices, it was found that humans fix code at higher rates, but GPT-4 provided completely correct explanations for error messages 96% of the time. This study concludes that GPT-4 functions best as a tool to explain error messages in an interactive format, rather than as a tool to produce correct code on its own. In conclusion, GPT-4 would be best utilized to enhance the classroom experience as a chat assistant to reduce time spent on syntactical errors, leading to improved productivity and better novice retention.",10.1145/3626253.3635404,https://doi.org/10.1145/3626253.3635404
Using Large Language Models to Develop Requirements Elicitation Skills,,Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 2,2025,Requirements Elicitation (RE) is a crucial software engineering skill that involves interviewing a client and then devising a software design based on the interview results. We propose conditioning a large language model to play the role of the client during a chat-based interview. We evaluate our approach in a study (n=120) using both a qualitative survey and quantitative observations about participants' work. Our positive findings suggest a new way to practice critical RE skills in a scalable and realistic manner without the overhead of arranging live interviews.,10.1145/3724389.3730772,https://doi.org/10.1145/3724389.3730772
On the Opportunities of Large Language Models for Programming Process Data,"Edwards, John and Hellas, Arto and Leinonen, Juho",Proceedings of the 27th Australasian Computing Education Conference,2025,"Computing educators and researchers have long used programming process data to understand how students construct programs and address challenges. Despite its potential, fully automated feedback systems remain underexplored. The emergence of Large Language Models (LLMs) offers new opportunities for analyzing programming data and providing formative feedback. This study explores using LLMs to summarize programming processes and deliver formative feedback. A case study analyzed keystroke-level data from an introductory programming course, processed into code snapshots. Three state-of-the-art LLMs – Claude 3 Opus, GPT-4 Turbo, and LLaMa2 70B Chat – were evaluated for their feedback capabilities. Results show LLMs effectively provide tailored feedback, emphasizing incremental development, algorithmic planning, and code readability. Our findings highlight the potential of combining keystroke data with LLMs to automate formative feedback, showing that the computing education research and practice community is again one step closer to automating formative programming process feedback.",10.1145/3716640.3716652,https://doi.org/10.1145/3716640.3716652
Enhancing Accessibility in Software Engineering Projects with Large Language Models (LLMs),"Aljedaani, Wajdi and Eler, Marcelo Medeiros and Parthasarathy, P D",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Digital accessibility ensures that digital products and services are usable by a diverse range of users, regardless of their physical or cognitive abilities. While numerous standards and guidelines have been established to aid developers in creating accessible content, studies reveal a persistent lack of accessibility in many web and mobile applications. This gap is often attributed to barriers such as lack of awareness, insufficient knowledge, absence of specific requirements, time constraints, and lack of executive support. In this context, we aim to address the lack of awareness and knowledge challenges by proposing a hands-on approach that leverages the capabilities of Large Language Models (LLMs) like ChatGPT to enhance students' accessibility awareness, knowledge, and practical skills. We engaged software engineering students in tasks involving website development and accessibility evaluation using checker tools, and we utilized ChatGPT 3.5 to fix identified accessibility issues. Our findings suggest that practical assignments significantly enhance learning outcomes, as interactions with LLMs allow students to develop a deeper understanding of accessibility concepts. This approach not only reinforces theoretical knowledge but also highlights the real-world impact of their work. The results indicate that combining practical assignments with AI-driven support effectively improves students' proficiency in web accessibility.",10.1145/3641554.3701841,https://doi.org/10.1145/3641554.3701841
Quack the Code: A Computer Game Show Offers Learning Through Teaching AI in Undergraduate Software Engineering,"Kelly, Kathleen Marie and Wu, Bo and Liebe, Christine",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"Gamification is a popular pedagogical approach in computer science education, and advances in large language models (LLMs) enable dynamic and engaging learning experiences, including competition driven by artificial intelligence (AI). This study introduces Quack the Code, a game-show-themed learning tool where students teach an LLM-powered ''debug duck'' while competing in an AI-hosted game. AI was used to generate personalized avatars, usernames, questions, host responses, and interactions with game elements. Offered to undergraduate computer science students (N=25) over a 16-week semester, the game was used repeatedly, mainly near quiz and exam periods. Most of the students (87%) preferred non-competitive play and focused on Java Basics, the default topic. The students were divided when choosing the type of question, with 45% requesting the default option of code debugging exercises and 47% requesting multiple choice questions. The students also changed the difficulty of the question from the default setting (44%) to the most difficult setting (37%). Focus groups highlighted positive reactions to competition, AI interactivity, and customization, but noted challenges with unclear instructions and user interfaces. The results suggest that LLM-powered gamification can enhance engagement and learning, with future improvements focused on usability and curriculum integration to increase participation and impact.",10.1145/3724363.3729096,https://doi.org/10.1145/3724363.3729096
61A Bot Report: AI Assistants in CS1 Save Students Homework Time and Reduce Demands on Staff. (Now What?),"Zamfirescu-Pereira, J.D. and Qi, Laryn and Hartmann, Bj\",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"LLM-based chatbots enable students to get immediate, interactive help on homework assignments, but even a thoughtfully-designed bot may not serve all pedagogical goals. We report here on the development and deployment of a GPT-4-based interactive homework assistant (",10.1145/3641554.3701864,https://doi.org/10.1145/3641554.3701864
Exploring ChatGPT as a Qualitative Research Assistant,,Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"In many CS educational research studies, students are surveyed to understand their reactions to a particular pedagogical approach or tool. These surveys, as well as other types of evaluations, often invite students to provide open-ended feedback about their experiences. However, analyzing these comments can prove to be a challenge, especially to CS educators who may not have strong expertise in qualitative research methods. In addition, in a large study, evaluating all of the provided comments can consume a significant amount of researcher time. In this work, we undertook two separate conversations with ChatGPT in which we prompted it to perform qualitative analysis of a set of comments collected in an earlier study. This allowed us to begin to judge how effectively a modern large language model can serve as an assistant in qualitative analysis. We found that with the prompts we used, ChatGPT can reliably build a set of reasonable labels (codes) for a set of comments, but the application of its labels to specific comments may or may not be effective and human researchers still need to use care and their own understanding in interpreting its output.",10.1145/3641555.3705180,https://doi.org/10.1145/3641555.3705180
Programming Is Hard - Or at Least It Used to Be: Educational Opportunities and Challenges of AI Code Generation,"Becker, Brett A. and Denny, Paul and Finnie-Ansley, James and Luxton-Reilly, Andrew and Prather, James and Santos, Eddie Antonio",Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1,2023,"The introductory programming sequence has been the focus of much research in computing education. The recent advent of several viable and freely-available AI-driven code generation tools present several immediate opportunities and challenges in this domain. In this position paper we argue that the community needs to act quickly in deciding what possible opportunities can and should be leveraged and how, while also working on overcoming otherwise mitigating the possible challenges. Assuming that the effectiveness and proliferation of these tools will continue to progress rapidly, without quick, deliberate, and concerted efforts, educators will lose advantage in helping shape what opportunities come to be, and what challenges will endure. With this paper we aim to seed this discussion within the computing education community.",10.1145/3545945.3569759,https://doi.org/10.1145/3545945.3569759
Analysis of Students’ Problem-Solving Behavior when Using Copilot for Open-Ended Programming Projects,"Akram, Bita and Magooda, Ahmed",Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2,2023,,10.1145/3568812.3603487,https://doi.org/10.1145/3568812.3603487
Evaluating LLM-generated Worked Examples in an Introductory Programming Course,"Jury, Breanna and Lorusso, Angela and Leinonen, Juho and Denny, Paul and Luxton-Reilly, Andrew",Proceedings of the 26th Australasian Computing Education Conference,2024,"Worked examples, which illustrate the process for solving a problem step-by-step, are a well-established pedagogical technique that has been widely studied in computing classrooms. However, creating high-quality worked examples is very time-intensive for educators, and thus learners tend not to have access to a broad range of such examples. The recent emergence of powerful large language models (LLMs), which appear capable of generating high-quality human-like content, may offer a solution. Separate strands of recent work have shown that LLMs can accurately generate code suitable for a novice audience, and that they can generate high-quality explanations of code. Therefore, LLMs may be well suited to creating a broad range of worked examples, overcoming the bottleneck of manual effort that is currently required. In this work, we present a novel tool, ‘WorkedGen’, which uses an LLM to generate interactive worked examples. We evaluate this tool with both an expert assessment of the content, and a user study involving students in a first-year Python programming course (n = ~400). We find that prompt chaining and one-shot learning are useful strategies for optimising the output of an LLM when producing worked examples. Our expert analysis suggests that LLMs generate clear explanations, and our classroom deployment revealed that students find the LLM-generated worked examples useful for their learning. We propose several avenues for future work, including investigating WorkedGen’s value in a range of programming languages, and with more complex questions suitable for more advanced courses.",10.1145/3636243.3636252,https://doi.org/10.1145/3636243.3636252
"Agile Ethics: A Low Stakes, Skills-based Framework for Teaching CS Ethics","Brooks, Alexi",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"Computer Science educators widely agree that ethics is a vital and underdeveloped part of the CS curriculum. Attempts to increase ethics content within undergraduate CS programs have faced challenges integrating material into the current coursework. I present an ethical framework applicable to the core Computer Science activities of programming and software development, with potential for extension into other CS subfields. The application of this framework to a specific educational intervention is reserved for future work. In this paper, I focus on the framework itself and its theoretical justification. By shifting emphasis from hard ethical quandaries and advanced CS products to mundane challenges faced by a front line software developer, this framework may allow instructors to more easily and effectively integrate ethics material into introductory CS coursework. While instructors may continue to apply prepared scenarios, the framework de-emphasizes those in favor of scaffolding student coding practices that maximize the frequency of practice with ethical skills.The Agile Ethics framework provides a structure which students and educators can use to think about (1) when during a project ethical reasoning is needed, (2) what questions need to be asked at that time, and (3) how to apply Computer Science skills and knowledge to answer each question. Frequent, low intensity instances of ethical reasoning under this framework reinforce the integration of ethics as a habitual part of the software development process.",10.1145/3649217.3653539,https://doi.org/10.1145/3649217.3653539
"Code Metrics, Rules of Thumb for Introductory CS","Garcia, Yuan and Ngo, Jenny and Lin, Florence Rui",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2,2024,"In response to the recent surge in easily accessible generative AI, Harvey Mudd College has integrated AI-assisted coding into the introductory Computer Science course. In this context, a question arises: How do we measure the quality of students' code when AI-generated code is present?Allowing generative AI to write coding assignments comes with the expectation of improved efficiency and accuracy. While generative AI is a useful tool, it merely supplements fundamental computing skills. This technological step towards being fully syntax-free allows for emphasis on the already important skill of developing problem-solving and critical thinking skills in more abstract contexts. In past years, metrics were designed to measure quantitative aspects of code, but these metrics alone are insufficient when evaluating how code written with the assistance of AI will perform in broader applications. When students submit code written with the assistance of generative AI, they are still expected to meet standards given by past metrics, such as Correctness and Complexity. To establish foundational computing skills, students will also be held to new standards and evaluated by new metrics such as Individuality and Ambition.While the model does give objective measures of the metrics, due to the fast-evolving nature of programming, predefined rules-of-thumb for these metrics are not provided. As users of our system, we recognize that evaluating the measurements will require our judgment, which will evolve over time. This work offers the foundation for that evolution.",10.1145/3649409.3691093,https://doi.org/10.1145/3649409.3691093
Enhancing University Curricula with Integrated AI Ethics Education: A Comprehensive Approach,"Deb, Debzani and Taylor, Greg and Betz, Scott and Maddux, Bao Anh T. and Ebert, C. Edward and Richardson, Flourice W. and Couto, Jeanine Lino S. and Jarrett, Michael S. and Madjd-Sadjadi, Zagros",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"As AI technologies become more prevalent, it is crucial for students to develop responsible, ethical, and proactive AI engagement skills. Recent educational initiatives have focused on enhancing CS and engineering students' AI ethics education but have largely overlooked integrating these concepts across other disciplines. This paper presents and assesses a pioneering initiative that integrates AI ethics into university curricula through a collaborative framework between CS and domain educators. We introduced 1-3 week AI ethics modules in seven diverse courses from Art to Chemistry, incorporating case studies and hands-on activities using chat- or image-based Large Language Models (LLMs). Student surveys indicated significant gains in confidence regarding AI ethics discussions, application of principles, and reasoning skills. Our approach advocates for utilizing structured frameworks and faculty collaboration in embedding AI ethics into university curricula, enhancing students' practical skills and ethical understanding across diverse professional settings.",10.1145/3641554.3701953,https://doi.org/10.1145/3641554.3701953
Exploring Student Interactions with AI in Programming Training,"Fenu, Gianni and Galici, Roberta and Marras, Mirko and Reforgiato, Diego","Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization",2024,"In recent years, the integration of artificial intelligence (AI) in education has collected significant attention due to its potential to revolutionize learning experiences and support student skill development. This study delves into the dynamics of student interactions with AI support within the domain of C programming education, with a specific focus on the utilization of ChatGPT, a conversational AI model, during training sessions. Through manual clustering analysis, this research unveils distinct patterns of student engagement, elucidating diverse problem-solving approaches and varying levels of interaction with ChatGPT. Our findings underscore the importance of acknowledging individual differences in learning strategies and preferences, highlighting the necessity for personalized educational interventions tailored to meet the diverse needs of learners. However, despite the strides made in AI-supported learning, gaps persist in the existing literature, particularly concerning our understanding of how students approach prompts and exercises when utilizing AI-driven educational tools. This research aims to address this gap by shedding light on the nuanced dynamics of student-AI interactions during training of C programming, offering insights into effective pedagogical strategies and instructional design principles for integrating AI technologies into educational settings. This study makes a significant contribution to the continuous endeavors of educators and AI developers by furthering the discussion on AI-facilitated learning. It aims to enhance student engagement, learning outcomes, and overall educational experiences through the integration of technology into learning environments.",10.1145/3631700.3665227,https://doi.org/10.1145/3631700.3665227
Math IDE: A Platform for Creating with Math,"Wang, Sierra and Mitchell, John and Haber, Nick and Piech, Chris",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"To inspire student engagement in middle school math, we explore the possibility of using generative AI to enhance the creativity of math learning. We present the Math IDE, a math education environment in which students learn about math concepts by building artifacts. We aimed to create a platform in which students can engage with mathematical concepts, create an artifact that embodies the math that they are learning about, and practice their high-level specification skills. In the current iteration of the Math IDE, students can create custom web pages by describing and demonstrating understanding of the math that is involved in the web page. In this short overview, we describe our process and discuss several open questions regarding the design and application of this novel method of math education.",10.1145/3626253.3635572,https://doi.org/10.1145/3626253.3635572
Could ChatGPT Be Used for Reviewing Learnersourced Exercises?,"Pirttinen, Nea and Leinonen, Juho",Proceedings of the 23rd Koli Calling International Conference on Computing Education Research,2024,"Large language models and tools based on large language models such as ChatGPT have received intense attention in the past year in computing education. In this work, we explore whether ChatGPT could be used to review learnersourced exercises. One of the major downsides of learnersourcing is the dubious quality of the created content, leading to many systems using peer review for curating the content. Our results suggest that ChatGPT is not yet ready for this task.",10.1145/3631802.3631845,https://doi.org/10.1145/3631802.3631845
CAET: Code Analysis and Education Tutor,"Glynn, Colin and Hed, Emily and Pexa, Abbigail and Pohlmann, Tyler and Rahal, Imad and Hesse, Robert",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"The introduction of OpenAI's ChatGPT in 2022 kickstarted the release of Generative Artificial Intelligence (GAI) applications to the public domain. Such chat interfaces are based on large language models (LLMs) and possess a vast array of abilities spanning conversation, the writing and debugging of code, the writing of papers, and the creation of images, music, and songs. With students now having access to a myriad of GAI tools, academia has been permanently altered.Our proposed system, named Code Analysis and Education Tutor (CAET), integrates GAI into early Computer Science education by providing students with an ethical alternative to existing GAI tools. CAET is designed to assist students with programming tasks in a manner tailored to their individual needs without jeopardizing the integrity of their learning. A point of uniqueness from existing works is CAET's ability to display or hide generated code based on its pertinence to the problem at hand. After subjecting multiple GAI models to common programming errors and queries, we settled on OpenAI's GPT-3.5 Turbo model due to its comprehensive capabilities and cost-effectiveness. Overall, CAET underscored the model's conversational dynamics and provided insights for creating a more personalized learning experience for students in an introductory computer science course.",10.1145/3626253.3635543,https://doi.org/10.1145/3626253.3635543
"Diversity, Equity, and Inclusion in Computing Science: Culture is the Key, Curriculum Contributes","Toti, Giulia and Lindner, Peggy and Gao, Alice and Baghban Karimi, Ouldooz and Engineer, Rutwa and Hur, Jinyoung and McNeill, Fiona and Reckinger, Shanon and Robinson, Rebecca and Sollazzo, Anna and Wicentowski, Richard",2024 Working Group Reports on Innovation and Technology in Computer Science Education,2025,"Undergraduate computer science programs worldwide struggle to attract and retain underrepresented students for many reasons. Culture, stereotype threats, uneven gender and racial representations, lack of role models, and uncertain career prospects for minority groups are among the many reasons behind this situation. Many computer science programs are trying to change course through strategies to foster equity, diversity, and inclusion (EDI), aimed at improving outreach, recruitment, admissions, and retention of underrepresented students. EDI approaches may also include modifications to the undergraduate computer science curriculum. However, if not properly planned, these modifications risk amplifying existing stereotypes rather than producing positive change [38]. In this study, through an extensive literature review, a rigorous curriculum analysis of 49 computer science programs across the globe, and qualitative and quantitative analysis of surveys and interviews bringing in the voices of 613 students and 30 educators participating from around the world, we explore equity, diversity, and inclusion in the computer science curriculum. We highlight the role of inclusive content and course design, discuss program flexibility, and the impact of inclusive courses and program design in attracting and retaining historically marginalized students. Finally, we provide concrete steps to make computing science undergraduate curricula more appealing to a diverse audience.",10.1145/3689187.3709611,https://doi.org/10.1145/3689187.3709611
The Research Project in Computer Science Bachelor Education: Undergraduate Research Experience at Scale,"Migut, Gosia and Buszydlik, Aleksander and de Weerdt, Mathijs M.",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"Exposure to research is an important component of undergraduate university education, cultivating critical thinking, problem-solving, and preparation for advanced study. However, providing individual research experiences for large cohorts of undergraduate students poses significant logistical challenges. This paper demonstrates how an undergraduate research experience can be achieved at scale for a large computer science program. Our approach integrates individual research projects into the undergraduate computer science curriculum for up to almost 400 students within a single 10-week course. We describe three key features of our approach: (1) a matching algorithm that assigns students to research projects based on their preferences, (2) peer-group collaboration, and (3) a distributed supervision and assessment model to guide students through key research activities that include reformulating research questions, designing experiments/user studies, and presenting research. Results and feedback indicate that both students and supervisors are satisfied, demonstrating the feasibility and effectiveness of this scalable approach for integrating research experiences into large undergraduate computer science programs.",10.1145/3724363.3729101,https://doi.org/10.1145/3724363.3729101
Evaluating GPT for use in K-12 Block Based CS Instruction Using a Transpiler and Prompt Engineering,"Gonzalez-Maldonado, David and Liu, Jonathan and Franklin, Diana",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Though the increased availability of Large Language Models (LLMs) presents significant potential for change in the way students learn to program, the text-based nature of the available tools currently preclude block-based languages from much of that innovation. In an attempt to remedy this, we identify the strengths and weaknesses of using a transpiler to leverage the existing learning in commercially available LLMs and Scratch, a visual block-based programming language.Using only prompt engineering, we evaluate an LLM's performance on two common classroom tasks in a Scratch curriculum. We evaluate the LLM's ability to: 1) Create project solutions that compile and satisfy project requirements and 2) Analyze student projects' completion of project requirements using natural language. In both cases, we find results indicating that prompt-engineering alone is insufficient to reliably produce high-quality results. For projects of medium complexity, the LLM-generated solutions consistently failed to follow correct syntax or, in the few instances with correct syntax, produce correct solutions. When used for auto-grading, we found a correlation between scores assigned by the official Scratch Encore autograder and those generated by the LLM, nevertheless the discrepancies between the 'real' scores and the scores assigned by the LLM remained too great for the tool to be reliable in a classroom setting.",10.1145/3641554.3701910,https://doi.org/10.1145/3641554.3701910
"Using Benchmarking Infrastructure to Evaluate LLM Performance on CS Concept Inventories: Challenges, Opportunities, and Critiques","Ali, Murtaza and Rao, Prerna and Mai, Yifan and Xie, Benjamin",Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1,2024,"BACKGROUND AND CONTEXT. The pace of advancement of large language models (LLMs) motivates the use of existing infrastructure to automate the evaluation of LLM performance on computing education tasks. Concept inventories are well suited for evaluation because of their careful design and prior validity evidence. OBJECTIVES. Our research explores the feasibility of using an automated benchmarking framework to evaluate computer science (CS) concept inventories. We explore three primary objectives: evaluation of LLM performance on the SCS1 and BDSI concept inventories; informal expert panel review of items which had variations between LLM and expected student performance; and description of challenges with using benchmarking infrastructure as a methodological innovation. METHOD. We used the Holistic Evaluation of Language Models (HELM) framework to evaluate the SCS1 and BDSI against 10 LLMS with zero-shot and few-shot in-context learning: GPT (3.5, 4.0), Claude (1.3, 2.0, 2.1), Llama (7B, 13B, 70B), Mistral v0.1 7B, and Mixtral 8x7B. We used psychometric data from prior studies to measure knowledge levels for each LLM run. We then conducted an informal expert review to qualitatively explore how question design, CS content knowledge, and LLM design may explain differences between LLM and expected student performances. FINDINGS. Our quantitative analysis found that most LLM response patterns reflected a below average introductory computing student with the SCS1 and did not fit the psychometric 2PL model for the BDSI. Our qualitative analysis identified that LLMs performed well on code infill questions, but poorly on nested conditionals, runtime analysis, and longer questions. We also identified several methodological challenges related to item security, translation, the structure when using HELM. IMPLICATIONS. We consider the feasibility of using automated benchmarking as a methodology to support more reproducible, replicable, and rigorous investigations to understand the intersection of LLM capabilities, computing concepts, and assessment design. We also consider connections between psychometric approaches and LLM evaluations to inform the design of computing assessments that are more resilient to LLM advancements.",10.1145/3632620.3671097,https://doi.org/10.1145/3632620.3671097
A Plan for a Joint Study into the Impacts of AI on Professional Competencies of IT Professionals and Implications for Computing Students,,Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2,2024,,10.1145/3649405.3659527,https://doi.org/10.1145/3649405.3659527
"Coding Pathfinder: A Platform for Creative, Self-Guided Mastery in Programming","Gupta, Ishita and Bridgman, Maya and Wang, Sierra and Mitchell, John",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"We present Coding Pathfinder, a platform to help non-programmers learn to code for a specific purpose. This paper explores how we can scaffold generative AI to provide structure and ensure mastery in informal learning settings, introducing a new approach to coding education. In the current iteration of Pathfinder, a user describes the coding task that they are working on. After collecting some details and scoping the project, Pathfinder identifies the skills that the user will master upon successful completion of the project. It then assesses which of the skills our users already has, and designs a personalised learning journey. The guided journey consists of instructions, explanations, tasks and videos. We also incorporate a chat feature so users can ask questions and engage as if they are working with a tutor.",10.1145/3641555.3705144,https://doi.org/10.1145/3641555.3705144
Iterative Design of a Teaching Assistant Training Program in Computer Science Using the Agile Method,"Liu, Runda and Chen, Shengqi and Chen, Jiajie and Niu, Songjie and Ma, Yuchun and Tang, Xiaofeng",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Facing soaring enrollment and disruptive educational technologies, computing education increasingly relies on the contributions of teaching assistants (TAs), hence the critical importance of high-quality TA training. However, the design and implementation of TA training in computer science face substantial barriers, such as the lack of experienced TA trainers and the scarcity of relevant training materials.This experience report describes the design and implementation of a peer-led computer science TA training program that began in 2022 and has since undergone three iterations, inspired by the approach of agile software development. The current program consists of 10 sessions, organized to serve TAs in three respective stages of professional development. The iterations involved updating and enrichment of the syllabus, transitioning from lecture-centered to discussion-centered training, and discussions of emerging topics in computing education such as the use of large language models (LLMs). Participant feedback showed that TAs approved the iterative design of the training, while identifying areas for further improvement. We summarize lessons learned from the iterative process, reflect on the role of peer TA trainers, and discuss plans for future iterations.",10.1145/3641554.3701829,https://doi.org/10.1145/3641554.3701829
Bob or Bot: Exploring ChatGPT's Answers to University Computer Science Assessment,"Richards, Mike and Waugh, Kevin and Slaymaker, Mark and Petre, Marian and Woodthorpe, John and Gooch, Daniel",ACM Trans. Comput. Educ.,2024,"Cheating has been a long-standing issue in university assessments. However, the release of ChatGPT and other free-to-use generative AI tools has provided a new and distinct method for cheating. Students can run many assessment questions through the tool and generate a superficially compelling answer, which may or may not be accurate.&nbsp;We ran a dual-anonymous “quality assurance” marking exercise across four end-of-module assessments across a distance university computer science (CS) curriculum. Each marker received five ChatGPT-generated scripts alongside 10 student scripts. A total of 90 scripts were marked; every ChatGPT-generated script for the undergraduate modules received at least a passing grade (&gt;40%), with all of the introductory module CS1 scripts receiving a distinction (&gt;85%). None of the ChatGPT-taught postgraduate scripts received a passing grade (&gt;50%). We also present the results of interviewing the markers and of running our sample scripts through a GPT-2 detector and the TurnItIn AI detector, which both identified every ChatGPT-generated script but differed in the number of false positives. As such, we contribute a baseline understanding of how the public release of generative AI is likely to significantly impact quality assurance processes. Our analysis demonstrates that in most cases, across a range of question formats, topics, and study levels, ChatGPT is at least capable of producing adequate answers for undergraduate assessment.",10.1145/3633287,https://doi.org/10.1145/3633287
DCC Sidekick: Helping Novices Solve Programming Errors Through a Conversational Explanation Interface,"Lee Solano, Lorenzo and Renzella, Jake and Vassar, Alexandra",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"Students in introductory computing courses often lack the experience required to effectively identify and resolve errors in their code. For such students, Programming Error Messages (PEMs) are often the first indication of an error, and could provide valuable debugging guidance. However, in many cases, such as with standard C compiler implementations, PEMs are largely unsuitable for novices. Confusing, misleading, and filled with terse language and jargon, these messages instead act as an additional source of difficulty.In this paper, we present DCC Sidekick, which integrates the Debugging C Compiler (DCC) with a Large Language Model (LLM) in a web-based dashboard to produce contextual, accurate guidance conducive to student learning. This dashboard is directly accessible from the output of the compiler, and provides a bird's-eye-view of the program source, compiler output, and a conversational AI interface to help unravel cryptic error messages. We aim to deploy DCC Sidekick to a C-based CS1 cohort at a large higher education institution to investigate how novice students utilise the conversational explanation interface during debugging activities. In this work, we present our experience designing and building DCC Sidekick.",10.1145/3626253.3635483,https://doi.org/10.1145/3626253.3635483
Assessing the Real-World Impact of Disagreement Between Human Graders and LLMs,"Speiser, Sebastian",Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing,2025,"Applying artificial intelligence models to grade student answers is a popular application. Lately Large Language Models (LLMs) have shown promising results. However, the disagreement between human graders and LLMs is often considered too large for practical adoption. In this paper, we investigate the real-world impact of this disagreement on final grades. Instead of focusing on individual answers, we simulate the grading process of an entire exam. We use an unmodified LLM (OpenAI GPT-3.5 Turbo) with one-shot prompting for grading individual answers to short answer questions from computer science courses at a German university. Our main contributions are the evaluation of the real-world impact on examination grades in contrast to correctness of individual student answers, the simulation of grading strategies common in human grading practice, and the discussion of the results in the context of observed inter-rater variabilities among human graders. The findings confirm the natural expectation that the impact of the disagreement is lower for final grades than when looking at individual answers. We quantify this effect and compare it to a grading obtained by simulating a second human grader.",,https://doi.org/10.1145/3672608.3707736
Individualising Assessments at Scale,"Burridge, Joshua",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2,2024,"This paper presents a novel 'Socketed' approach to assessment design in computing education, aiming to reconcile the need for individual student assessment with the benefits of collaborative learning. By providing a skeleton project to be combined with individualised components, students experienced a tailored yet unified assessment structure. Initial feedback shows improved comprehension and peer collaboration, and suggests mitigation of pressures towards academic dishonesty. Motivating context criteria and design considerations are provided to assist educators in implementing this in their own teaching.",10.1145/3649405.3659524,https://doi.org/10.1145/3649405.3659524
Explorotron: An IDE Extension for Guided and Independent Code Exploration and Learning (Discussion Paper),"Malaise, Yoshi and Signer, Beat",Proceedings of the 23rd Koli Calling International Conference on Computing Education Research,2024,"We introduce the Explorotron Visual Studio Code extension for guided and independent code exploration and learning. Explorotron is a continuation of earlier work to explore how we can enable small organisations with limited resources to provide pedagogically sound learning experiences in programming. We situate Explorotron in the field of Computing Education Research&nbsp;(CER) and envision it to initiate a discussion around different topics, including how to balance the optimisation between the researcher-student-teacher trifecta that is inherent in CER, how to ethically and responsibly use large language models&nbsp;(LLMs) in the independent learning and exploration by students, and how to define better learning sessions over coding content that students obtained on their own. We further reflect on the question raised by Begel and Ko whether technology should “structure learning for learners” or whether learners should “be taught how to structure their own independent learning” outside of the classroom.",10.1145/3631802.3631816,https://doi.org/10.1145/3631802.3631816
Using Large Language Models for Teaching Computing,"Leinonen, Juho and MacNeil, Stephen and Denny, Paul and Hellas, Arto",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"In the past year, large language models (LLMs) have taken the world by storm, demonstrating their potential as a transformative force in many domains including computing education. Computing education researchers have found that LLMs can solve most assessments in introductory programming courses, including both traditional code writing tasks and other popular tasks such as Parsons problems. As more and more students start to make use of LLMs, the question instructors might ask themselves is",10.1145/3626253.3633436,https://doi.org/10.1145/3626253.3633436
Enhancing Self-Explanation in Student Learning Through Large Language Models,"Wen, Jessica and Zavaleta Bernuy, Angela and Sibia, Naaz and Petersen, Andrew and Liut, Michael",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 2,2025,"Self-explanation deepens understanding by giving learners an opportunity to reflect on what they are learning in a structured way. However, many students struggle to engage in it effectively. We investigate whether large language models (LLMs) can scaffold self-explanations in a flipped computer organization course. In an A/B test, one group used a fixed prompt to compare their explanations with an expert's, while another engaged in an interactive dialogue with an LLM to identify gaps. Although the overall quality of the explanation did not differ significantly between conditions, some students (non-native English speakers and women) reported greater comfort and perceived value when using the LLM.",10.1145/3724389.3730790,https://doi.org/10.1145/3724389.3730790
Students' Use of GitHub Copilot for Working with Large Code Bases,"Shah, Anshul and Chernova, Anya and Tomson, Elena and Porter, Leo and Griswold, William G. and Soosai Raj, Adalbert Gerald",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Large language models (LLMs) are already heavily used by professional software engineers. An important skill for new university graduates to possess will be the ability to use such LLMs to effectively navigate and modify a large code base. While much of the prior work related to LLMs in computing education focuses on novice programmers learning to code, less work has focused on how upper-division students use and trust these tools, especially while working with large code bases. In this study, we taught students about various GitHub Copilot features, including Copilot chat, in an upper-division software engineering course and asked students to add a feature to a large code base using Copilot. Our analysis revealed a novel interaction pattern that we call one-shot prompting, in which students ask Copilot to implement the entire feature at once and spend the next few prompts asking Copilot to debug the code or asking Copilot to regenerate its incorrect response. Finally, students reported significantly more trust in the code comprehension features than code generation features of Copilot, perhaps due to the presence of trust affordances in the Copilot chat that are absent in the code generation features. Our study takes the first steps in understanding how upper-division students use Github Copilot so that our instruction can adequately prepare students for a career in software engineering.",10.1145/3641554.3701800,https://doi.org/10.1145/3641554.3701800
TA Buddy: AI-Assisted Grading Tool for Introductory Programming Assignments,"Nagakalyani, Goda and Chaudhary, Saurav and Apte, Varsha and Ramakrishnan, Ganesh",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"In introductory programming courses, autograders typically evaluate student programs by running testcases without inspecting the source code. However, educational grading often requires manual code inspection for two key reasons: (1) to award partial marks for code that may fail test cases but is partially correct, and (2) to assign marks based on code quality or specific criteria set by the instructor, such as requiring a particular algorithm, e.g., bubble sort. Rubric-based subjective grading is beneficial for these reasons, but manual grading for large course enrollments is time consuming. This demo introduces TA Buddy, an AI assistant integrated with IIT Bombay's BodhiTree Evalpro platform, which is designed to streamline grading in introductory programming courses. It is powered by a pre-trained code LLM, which was fine-tuned with a dataset created here at IITB Bombay. Its key benefits include speeding up the grading process with AI-generated suggestions for ratings of the criteria of a grading rubric. Furthermore, it provides feedback with justifications for assigned grades, making it useful for large courses where manual grading is time-consuming. Note that TA-Buddy only suggests grades to TAs, TAs are still required to review the grades and accept or reject them. In that sense, TA-Buddy offers an AI-Assisted grading option to TAs. This hybrid approach reduces grading time by up to 45% while maintaining an average match of 90% (on a sample of six problems) with un-assisted manual grades.",10.1145/3641555.3705051,https://doi.org/10.1145/3641555.3705051
dcc --help: Transforming the Role of the Compiler by Generating Context-Aware Error Explanations with Large Language Models,"Taylor, Andrew and Vassar, Alexandra and Renzella, Jake and Pearce, Hammond",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"In the challenging field of introductory programming, high enrolments and failure rates drive us to explore tools and systems to enhance student outcomes, especially automated tools that scale to large cohorts. This paper presents and evaluates the dcc --help tool, an integration of a Large Language Model (LLM) into the Debugging C Compiler (DCC) to generate unique, novice-focused explanations tailored to each error. dcc --help prompts an LLM with contextual information of compile- and run-time error occurrences, including the source code, error location and standard compiler error message. The LLM is instructed to generate novice-focused, actionable error explanations and guidance, designed to help students understand and resolve problems without providing solutions. dcc --help was deployed to our CS1 and CS2 courses, with 2,565 students using the tool over 64,000 times in ten weeks. We analysed a subset of these error/explanation pairs to evaluate their properties, including conceptual correctness, relevancy, and overall quality. We found that the LLM-generated explanations were conceptually accurate in 90% of compile-time and 75% of run-time cases, but often disregarded the instruction not to provide solutions in code. Our findings, observations and reflections following deployment indicate that dcc --help provides novel opportunities for scaffolding students' introduction to programming.",10.1145/3626252.3630822,https://doi.org/10.1145/3626252.3630822
Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,"Bernstein, Seth and Denny, Paul and Leinonen, Juho and Kan, Lauren and Hellas, Arto and Littlefield, Matt and Sarsa, Sami and Macneil, Stephen",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"Grasping complex computing concepts often poses a challenge for students who struggle to anchor these new ideas to familiar experiences and understandings. To help with this, a good analogy can bridge the gap between unfamiliar concepts and familiar ones, providing an engaging way to aid understanding. However, creating effective educational analogies is difficult even for experienced instructors. We investigate to what extent large language models (LLMs), specifically ChatGPT, can provide access to personally relevant analogies on demand. Focusing on recursion, a challenging threshold concept, we conducted an investigation analyzing the analogies generated by more than 350 first-year computing students. They were provided with a code snippet and tasked to generate their own recursion-based analogies using ChatGPT, optionally including personally relevant topics in their prompts. We observed a great deal of diversity in the analogies produced with student-prescribed topics, in contrast to the otherwise generic analogies, highlighting the value of student creativity when working with LLMs. Not only did students enjoy the activity and report an improved understanding of recursion, but they described more easily remembering analogies that were personally and culturally relevant.",10.1145/3649217.3653533,https://doi.org/10.1145/3649217.3653533
An Investigation of the Drivers of Novice Programmers' Intentions to Use Web Search and GenAI,"Skripchuk, James and Bacher, John and Price, Thomas",Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1,2024,"External help resources are frequently used by novice programmers solving classwork in undergraduate computing courses. Traditionally, these tools consisted of web resources such as tutorial websites and Q&amp;A forums. With the rise of Generative AI (GenAI), there has been increasing concern and research about how external resources should be used in the classroom. However, little work has directly contrasted student beliefs and perceptions of web resources with GenAI, has grounded these beliefs in prior psychological theory, and has investigated how demographic factors and student backgrounds influence these beliefs and intentions. We administered a vignette-style survey across two courses required for a CS major at an R1 University, a freshman (n = 152) and senior capstone course (n = 44). Students responded to likert questions aiming to measure behavioral factors related to these tools, such as intention to use, perceived attitudes, peer perceptions, and their own perceived tool competency. We primarily investigate the results of an introductory course, finding that novices have a wide range of opinions on both resources, but overall find them slightly useful and have a tendency to prefer web-search. We compare this with seniors, who have more positive perceptions of these tools, and discuss possible reasons and implications for this difference. We constructed two path models to investigate which factors strongly influence novices’ intention to use resources and find the primary factor to be their general attitudes in how these tools will result in a positive or negative outcome (e.g. perceived benefits, justifiability). We also measure the effects of student background on intention to use these resources. Finally, we discuss implications and suggestions on how instructors can use this information to approach, address, and influence resource usage in their classrooms.",10.1145/3632620.3671112,https://doi.org/10.1145/3632620.3671112
Tackling Students' Coding Assignments with LLMs,"Dingle, Adam and Krulis, Martin",Proceedings of the 1st International Workshop on Large Language Models for Code,2024,"State-of-the-art large language models (LLMs) have demonstrated an extraordinary ability to write computer code. This ability can be quite beneficial when integrated into an IDE to assist a programmer with basic coding. On the other hand, it may be misused by computer science students for cheating on coding tests or homework assignments. At present, knowledge about the exact capabilities and limitations of state-of-the-art LLMs is still inadequate. Furthermore, their capabilities have been changing quickly with each new release. In this paper, we present a dataset of 559 programming exercises in 10 programming languages collected from a system for evaluating coding assignments at our university. We have experimented with four well-known LLMs (GPT-3.5, GPT-4, Codey, Code Llama) and asked them to solve these assignments. The evaluation results are intriguing and provide insights into the strengths and weaknesses of the models. In particular, GPT-4 (which performed the best) is currently capable of solving 55% of all our exercises and achieved an average score of 86% on exercises from the introductory programming course (using the best of five generated solutions).",10.1145/3643795.3648389,https://doi.org/10.1145/3643795.3648389
Unrestricted Use of LLMs in a Software Project Course: Student Perceptions on Learning and Impact on Course Performance,"Korpimies, Kai and Laaksonen, Antti and Luukkainen, Matti",Proceedings of the 24th Koli Calling International Conference on Computing Education Research,2024,"Large language models (LLMs) provide round-the-clock personalized programming assistance, unlike course instructors or traditional online information sources such as Stack Overflow. While LLMs can aid in code generation, concerns about over-reliance and the impact on learning persist. This study discusses students’ experiences with LLMs in a software project course where students were allowed to use LLMs freely except for unit test generation. We conducted surveys during course instances in autumn 2023 and spring 2024. The surveys assessed the extent of LLM usage, methods of application, and perceived impact on learning. Results indicate diverse usage patterns, with many students finding LLMs beneficial for efficiency and problem-solving, though over-reliance and poor-quality outputs were noted concerns. The usage patterns can be linked to course performance and time spent on the project.",10.1145/3699538.3699541,https://doi.org/10.1145/3699538.3699541
Attitudes Towards the Use (and Misuse) of ChatGPT: A Preliminary Study,"Rogers, Michael P. and Hillberg, Hannah Miller and Groves, Christopher L.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"ChatGPT is the front end to a powerful large language model that has garnered widespread attention in many fields of study, including computer science (CS), where it promises to be transformational. As educators, we are just starting to grapple with the ramifications of this new technology, including implications for what we teach, how we teach, and how we grade. The decisions educators make moving forward depend heavily on the prevalence of students' use (and misuse) of ChatGPT in the classroom. Further, predictors of nefarious use could aid educators as well. We conducted an online survey to capture CS student awareness of, experience with, and attitudes toward ChatGPT. Through quantitative and qualitative analysis, we found that awareness of ChatGPT is generally high, and it is more frequently being used as a study tool than to complete students' work for them. Most students are aware of the potential for abuse in academic pursuits, but a notable minority of students admit to using it unscrupulously and to the potential for it to interfere with their learning. We conclude with a discussion of factors to consider as educators modify their approaches and develop guidelines for ChatGPT usage in their classrooms.",10.1145/3626252.3630784,https://doi.org/10.1145/3626252.3630784
A Didactical Tool for LLM-supported Interactive Prompt Construction for AI Literacy Courses,"Reetz, Robert and Lewerentz, Lars and Kurian, Philip and Novak, Jasminko",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 2,2025,"We present a didactical tool in the form of an interactive Large Language Model (LLM) application that allows users to develop a better understanding of prompt construction. To achieve this, the application includes a modular, interactive prompt construction tool that allows end-users to generate prompt variations and explore how different prompt characteristics influence the reliability of the output. The tool takes a prompt, optimizes it based on selected parameters, and provides the LLM response to the optimized prompt. The visualization of the differences between the prompt variations and the differences between the corresponding model results, allows users to develop a better understanding of how specific prompt characteristics can affect the reliability of LLM outputs.",10.1145/3724389.3731265,https://doi.org/10.1145/3724389.3731265
Analyzing Pedagogical Quality and Efficiency of LLM Responses with TA Feedback to Live Student Questions,"Miroyan, Mihran and Mitra, Chancharik and Jain, Rishi and Ranade, Gireeja and Norouzi, Narges",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"While Large Language Models (LLMs) have emerged as promising methods for automated student question-answering, guaranteeing consistent instructional effectiveness of the response remains a key challenge. Therefore, there is a need for fine-grained analysis of State-Of-The-Art (SOTA) LLM-powered educational assistants.  This work evaluates Edison: a Retrieval Augmented Generation (RAG) pipeline based on GPT-4. We determine the pedagogical effectiveness of Edison's responses through expert Teaching Assistant (TA) evaluation of the answers. After the TA edits and improves the response, we analyze the original LLM response, the TA-assigned ratings, and the TA's edits to ascertain the essential characteristics of a high-quality response. Some key insights of our evaluation are as follows: (1) Edison can give relevant and factual answers in an educational style for conceptual and assignment questions, (2) Most TA edits are deletions made to improve the style of the response, and finally (3) Our analysis indicates that Edison improves TAs' efficiency by reducing the effort required to respond to student questions.",10.1145/3641554.3701965,https://doi.org/10.1145/3641554.3701965
Empowering Future Software Engineers: Integrating AI Tools into Advanced CS Curriculum,"Roy, Nimisha and Olufisayo, Omojokun and Horielko, Oleksandr",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"Artificial Intelligence (AI) tools have transformed software development, making it crucial to equip computer science (CS) students with the skills to leverage these technologies. This talk presents an innovative curriculum approach, integrating AI tools into an advanced CS capstone course at a stage where students possess foundational skills in software engineering. This strategic timing ensures students can critically engage with AI, recognizing biases and managing challenges like hallucinations in AI-generated outputs.Before redesigning the curriculum, independent research was conducted to understand the strengths and limitations of various AI tools, such as Lucidchart, Eraser.io for design documentation, and GitHub Copilot, GPT-4, Codeium, Claude, and Gemini for implementation tasks like code generation, code completion, UI design, error handling, and API integration. This research guided the curriculum by shaping assignment design and delivering foundational lectures on prompt engineering to ease the learning curve for students. Experiments during the capstone course included AI-enhanced assignments and projects, where students applied these tools for software design and implementation. Quantitative data-prompt refinement counts, error rates, code accuracy, and qualitative reflections revealed increased confidence in AI tools, enhanced productivity, and greater readiness for industry roles. Despite these benefits, students faced challenges with complex tasks that required iterative refinement and oversight, but they gained skills in managing biases and hallucinations in AI outputs. The curriculum's ''right-left'' approach enables a smooth transition to AI-assisted development, preparing students for the evolving tech landscape. This talk shares key findings, best practices, and insights into balancing manual skills with AI-enhanced learning.",10.1145/3641555.3705074,https://doi.org/10.1145/3641555.3705074
Measuring CS Student Attitudes Toward Large Language Models,"Weber, Jason Lee and Martinez Neda, Barbara and Carbajal Juarez, Kitana and Wong-Ma, Jennifer and Gago-Masague, Sergio and Ziv, Hadar",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"With the mainstream adoption of Large Language Models (LLMs), members of both academia and the media have raised concerns around their impact on student learning and pedagogy. Many students and educators wonder about the pedagogical fit of this emerging technology. We aim to measure the adoption of and attitudes toward LLMs among the CS student population at an R1 University to determine how students are using these new tools. To this end, we conducted a large survey study targeting two populations participating in computing courses at the university: intro-sequence students (ISS) and experienced students (ES).In our preliminary results from Spring 2023, we've found several significant differences among the views of over 700 respondents across the two groups. Most students reported LLMs' unparalleled potential for quick information access, yet many harbor concerns about the reliability of the LLM responses, and the impact on academic integrity. Additionally, while ES have rapidly integrated LLMs into their learning, ISS remain cautious of the tools, highlighting a stark contrast in adoption rates between the groups.LLMs are clearly going to reshape pedagogical approaches and student engagement. Our study hopes to provide insight on the nuanced student attitudes toward LLMs. For example, the notable reservations expressed by ISS illustrate an imperative for careful, informed, and ethical integration to ensure these tools enhance rather than compromise the educational experience. In the future, we plan to continue tracking student attitudes in order to gain further understanding of the changing perceptions of LLMs and their impact.",10.1145/3626253.3635604,https://doi.org/10.1145/3626253.3635604
PyDex: Repairing Bugs in Introductory Python Assignments using LLMs,,Proc. ACM Program. Lang.,2024,"Students often make mistakes in their introductory programming assignments as part of their learning process. Unfortunately, providing custom repairs for these mistakes can require a substantial amount of time and effort from class instructors. Automated program repair (APR) techniques can be used to synthesize such fixes. Prior work has explored the use of symbolic and neural techniques for APR in the education domain. Both types of approaches require either substantial engineering efforts or large amounts of data and training. We propose to use a large language model trained on code, such as Codex (a version of GPT), to build an APR system – PyDex – for introductory Python programming assignments. Our system can fix both syntactic and semantic mistakes by combining multi-modal prompts, iterative querying, test-case-based selection of few-shots, and program chunking. We evaluate PyDex on 286 real student programs and compare to three baselines, including one that combines a state-of-the-art Python syntax repair engine, BIFI, and a state-of-the-art Python semantic repair engine for student assignments, Refactory. We find that PyDex can fix more programs and produce smaller patches on average.",10.1145/3649850,https://doi.org/10.1145/3649850
The Stress of Improvisation: Instructors' Perspectives on Live Coding in Programming Classes,"Su, Xiaotian and Wang, April Yi",Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems,2025,"Live coding is a pedagogical technique in which an instructor writes and executes code in front of students to impart skills like incremental development and debugging. Although live coding offers many benefits, instructors face many challenges in the classroom, like cognitive challenges and psychological stress, most of which have yet to be formally studied. To understand the obstacles faced by instructors in CS classes, we conducted (1) a formative interview with five teaching assistants in exercise sessions and (2) a contextual inquiry study with four lecturers for large-scale classes. We found that the improvisational and unpredictable nature of live coding makes it difficult for instructors to manage their time and keep students engaged, resulting in more mental stress than presenting static slides. We discussed opportunities for augmenting existing IDEs and presentation setups to help enhance live coding experience.",10.1145/3706599.3719993,https://doi.org/10.1145/3706599.3719993
A Global Survey of Introductory Programming Courses,"Mason, Raina and Simon and Becker, Brett A. and Crick, Tom and Davenport, James H.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"We present results of an in-depth survey of nearly 100 introductory programming (CS1) instructors in 18 countries spanning six continents. Although CS1 is well studied, relatively few broadly-scoped studies have been conducted, and none prior have exceeded regional scale. In addition, CS1 is a notoriously fickle and often changing course, and many might find it beneficial to know what other instructors are doing across the globe; perhaps more so as we continue to understand the impact of the COVID-19 pandemic on computing education and as the effects of Generative AI take hold. Expanding upon several surveys conducted in Australasia, the UK, and Ireland, this survey facilitates a direct comparison of global trends in CS1. The survey goes beyond environmental factors such as languages used, and examines why CS1 instructors teach what they do, in the ways they do. In total the survey spans 84 institutions and 91 courses in which a total of over 40,000 students are enrolled.",10.1145/3626252.3630761,https://doi.org/10.1145/3626252.3630761
Enhancing CS1 Education through Experiential Learning with Robotics Projects,"Borela, Rodrigo and Liding, Zhixian and McDaniel, Melinda",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"To address the challenges of generative AI in CS1 education, especially its misuse by students to bypass coding exercises, which undermines their engagement with foundational learning, CS1 curricula are evolving to emphasize higher-level problem-solving and systems thinking. In response, a novel experiential learning initiative grounded in High-Impact Practices was introduced to a CS1 course over the course of 2 semesters, involving 132 students. This initiative utilized robotics lab assignments to enhance computational thinking across various levels of granularity, from individual functional components to overall system behaviors, bridging conceptual understanding with real-world applications. The approach emphasized project-based learning, extended engagement time, and reflective practices to deepen students' understanding of core computing concepts and scaffold knowledge integration. The curriculum featured both individual and team-based lab assignments to build foundational skills followed by collaborative problem-solving. The initiative's impact was assessed against a control group of 427 students who completed traditional web development lab assignments. Evaluation methods included thematic analyses of student reflections, instructor opinion surveys, and statistical analysis of exam performances across the semester. Results revealed a substantial positive effect on self-efficacy and learning outcomes. Students in the experiential learning group reported increased confidence in applying their computing skills to real-world scenarios, heightened engagement, and greater improvements in technical proficiency. Notably, their exam scores demonstrated a statistically significant improvement compared to the control group. These findings highlight the effectiveness of integrating practical, interactive elements into computer science education to meet the demands of a rapidly evolving technological landscape.",10.1145/3641554.3701810,https://doi.org/10.1145/3641554.3701810
Crafting Disability Fairness Learning in Data Science: A Student-Centric Pedagogical Approach,"Newman, Pax and Opdahl, Tyanin and Liu, Yudong and Wehrwein, Scott and Elglaly, Yasmine N.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"Ensuring the fairness of machine learning (ML) systems for individuals with disabilities is crucial. Proactive measures are required to identify and mitigate biases in data and models, thereby preventing potential harm or bias against people with disabilities. While previous research on ML fairness education primarily concentrated on gender and race fairness, the domain of disability fairness has received comparatively little attention. Addressing this gap, we adopted a student-centric approach to craft a disability fairness teaching intervention. A focus group of students experienced in ML and accessible computing underscored the significance of engagement and scaffolding strategies for effectively learning intricate topics. Consequently, we crafted a disability fairness hands-on programming assignment that delves into uncovering disability bias with a lens that takes intersectionality into account. The assignment was tailored for an introductory undergraduate data science (DS) course. We employed reflective questions and surveys to gauge the effectiveness of our approach. The findings indicate the success of our approach in promoting a deeper understanding of disability fairness within the context of DS education.",10.1145/3626252.3630815,https://doi.org/10.1145/3626252.3630815
ChatGPT and Cheat Detection in CS1 Using a Program Autograding System,"Pang, Ashley and Vahid, Frank",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"We experimented with ChatGPT's ability to write programs in a CS1 class, and the ability of a popular tool to auto-detect ChatGPT-written programs. We found ChatGPT was proficient at generating correct programs from a mere copy-paste of the English programming assignment specifications. However, running ChatGPT for 10 programming assignments and acting as 20 different students, and using zyBook's APEX beta tool for academic integrity, we found: (1) ChatGPT-generated programs tend to use a programming style departing from the style taught in the textbook or by the instructor, and these",10.1145/3649217.3653558,https://doi.org/10.1145/3649217.3653558
VizCode: A Practical Real-time Tool for In-Class Computer Programming Tutoring,"Yang, Yinuo and Oney, Steve",,2024,"Prior research has shown the benefits and promise of allowing instructors in large programming classes to monitor students' coding activity in real-time. However, translating these findings into practical, user-friendly tools remains a challenge. This demonstration showcases VizCode, a tool that allows instructors to monitor students' code in real-time as they edit in the popular Visual Studio Code (VSCode) IDE. VizCode is designed to be practical (integrating with widely-used tools and requiring minimal server overhead), scalable (minimizing network latency by only communicating code changes), and easy to use (requiring minimal setup from students). By focusing on practicality and seamless integration with VSCode, VizCode bridges the gap between research and practice, making it easier for instructors to monitor students' code in real-time.",10.1145/3657604.3664716,https://doi.org/10.1145/3657604.3664716
Examining the Relationship between Socioeconomic Status and Beliefs about Large Language Models in an Undergraduate Programming Course,"Pang, Amy and Padiyath, Aadarsh and Viramontes Vargas, Diego and Ericson, Barbara Jane",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1,2024,"Research on students' use of large language models (LLMs) in academic settings has increased recently, focusing on usage patterns, tasks, and instructor policies. However, there is limited research on the relationships between students' socioeconomic backgrounds, perceptions, and usage of these resources. As socioeconomic factors may shape students' approach to learning, it is important to understand their impact on students' perceptions and attitudes towards emerging technologies like LLMs. Thus, we analyzed a quantitative and internally consistent student survey (N=144) and qualitative interview (N=2) responses of students taking an undergraduate-level programming course at a public university for correlations between socioeconomic background, attitudes towards LLMs, and LLM usage. Regression analysis found a significant positive association between socioeconomic status (SES) and belief that LLM use will lead to career success. Qualitative interviews suggested low-SES students perceived LLMs as helpful tools for debugging and learning concepts, but not as a significant factor in long-term career success. Rather, programming knowledge itself was still paramount for career success. Our findings contribute to our understanding of the complex influences social and cultural factors have on students' perceptions and attitudes towards LLMs.",10.1145/3649165.3690099,https://doi.org/10.1145/3649165.3690099
A Pedagogical Framework for Developing Abstraction Skills,"Begum, Marjahan and Crossley, Julia and Str\",2024 Working Group Reports on Innovation and Technology in Computer Science Education,2025,"Abstraction is a fundamental yet challenging skill to teach and learn in Computer Science education. Traditional frameworks of abstraction and concept formation often emphasize understanding an abstraction over its application, the latter being critical for practical Computer Science. Additionally, a common issue in education is when students may understand a concept in a classroom or a very specific setting but struggle to apply it outside of that context. In response, we present here a novel pedagogical framework designed to enhance both the development and application of abstraction skills in diverse educational contexts within the field of Computer Science. Our framework synthesizes common themes from existing models while introducing a new dimension focused explicitly on the actionable development of abstraction skills. Educators can adapt the framework to various educational contexts to support development of students' abstraction skills. Our framework was iteratively developed through a combination of theoretical analysis and reflective practice across multiple teaching contexts. We demonstrate the suitability of the framework by applying it to various case studies, demonstrating its broad applicability and practical utility. By offering a flexible yet comprehensive structure, our framework enables educators to effectively organize and deliver educational content, guiding students from abstract theoretical concepts to their practical application in Computer Science.",10.1145/3689187.3709613,https://doi.org/10.1145/3689187.3709613
Semantic Similarity Search for Source Code Plagiarism Detection: An Exploratory Study,"Ebrahim, Fahad and Joy, Mike",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"Source code plagiarism detection (SCPD) is a crucial challenge in computer science education that affects academic integrity. It can be considered as an Information Retrieval (IR) task. One of the IR approaches is the Semantic Similarity Search (S-3), which aims to retrieve related results, given a query. It can be applied to SCPD by obtaining the most similar pairs given a large collection of codes.The paper presents an exploratory study that examines the utilisation of S-3 in the context of the SCPD task. So, given the source code reuse dataset (SOCO) written in Java/C++, the task is to retrieve the most similar (potentially plagiarised) pairs of codes. Technically, S-3 is based on vector search. So, embedding vectors generated by the major Code Pre-Trained Models (CodePTMs) were used as features of the conducted experiments. The accuracy of the S-3 approach exceeded the other SOCO-IR baselines in most of the CodePTMs without any training in terms of F1 score. The CodePTMs that incorporated multiple representations produced robust embeddings.For improved accuracy metrics, several experiments were conducted to train the embedding models in both supervised and unsupervised manners. The results concluded that overall performance could improve slightly after supervised training due to the limited training set of the SOCO dataset. Unsupervised training tests had a negative impact on accuracy. The advantage of the S-3 is that it is lightweight and fast with the ability to produce excellent performance.",10.1145/3649217.3653622,https://doi.org/10.1145/3649217.3653622
Customizing ChatGPT to Help Computer Science Principles Students Learn Through Conversation,"Frazier, Matthew and Damevski, Kostadin and Pollock, Lori",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"This paper explores leveraging conversational agents, specifically ChatGPT, to enhance the introduction of computing, focused on the Advanced Placement Computer Science Principles (CSP) course in secondary schools. Despite the potential benefits for diverse student audiences, little research has investigated their effectiveness and engagement in this context. We examine the customization of ChatGPT for secondary school CSP students, assessing its impact on exploratory searches for learning CSP concepts. Results from 20 high school students in grades 10-12 (ages 15-18) in a CSP course indicate that students preferred a customized ChatGPT, with its terminology more suitable to secondary school level, examples more understandable, and better connections to personal experiences compared to standard ChatGPT.",10.1145/3649217.3653570,https://doi.org/10.1145/3649217.3653570
Experience Report: Identifying common misconceptions and errors of novice programmers with ChatGPT,"Fwa, Hua Leong",Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training,2024,"Identifying the misconceptions of novice programmers is pertinent for informing instructors of the challenges faced by their students in learning computer programming. In the current literature, custom tools, test scripts were developed and, in most cases, manual effort to go through the individual codes were required to identify and categorize the errors latent within the students' code submissions. This entails investment of substantial effort and time from the instructors. In this study, we thus propose the use of ChatGPT in identifying and categorizing the errors. Using prompts that were seeded only with the student's code and the model code solution for questions from two lab tests, we were able to leverage on ChatGPT's natural language processing and knowledge representation capabilities to automatically collate frequencies of occurrence of the errors by error types. We then clustered the generated error descriptions for further insights into the misconceptions of the students. The results showed that although ChatGPT was not able to identify the errors perfectly, the achieved accuracy of 93.3% is sufficiently high for instructors to have an aggregated picture of the common errors of their students. To conclude, we have proposed a method for instructors to automatically collate the errors latent within the students' code submissions using ChatGPT. Notably, with the novel use of generated error descriptions, the instructors were able to have a more granular view of the misconceptions of their students, without the onerous effort of manually going through the students' codes.",10.1145/3639474.3640059,https://doi.org/10.1145/3639474.3640059
"BRAFAR: Bidirectional Refactoring, Alignment, Fault Localization, and Repair for Programming Assignments","Xie, Linna and Li, Chongmin and Pei, Yu and Zhang, Tian and Pan, Minxue",Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis,2024,"The problem of automated feedback generation for introductory programming assignments (IPAs) has attracted significant attention with the increasing demand for programming education. While existing approaches, like Refactory, that employ the ”block-by-block” repair strategy have produced promising results, they suffer from two limitations. 		First, Refactory randomly applies refactoring and mutation operations to correct and buggy programs, respectively, to align their control-flow structures (CFSs), which, however, has a relatively low success rate and often complicates the original repairing tasks.                                                                            		Second, Refactory generates repairs for each basic block of the buggy program when its semantics differs from the counterpart in the correct program, which, however, ignores the different roles that basic blocks play in the programs and often produces unnecessary repairs.                                                              		To overcome these limitations, we propose the Brafar approach to feedback generation for IPAs.                                                                         		The core innovation of Brafar lies in its novel bidirectional refactoring algorithm and coarse-to-fine fault localization.                                            		The former aligns the CFSs of buggy and correct programs by applying semantics-preserving refactoring operations to both programs in a guided manner,                       		while the latter identifies basic blocks that truly need repairs based on the semantics of their enclosing statements and themselves.                                     		In our experimental evaluation on 1783 real-life incorrect student submissions from a publicly available dataset, Brafar significantly outperformed Refactory and Clara, generating correct repairs for more incorrect programs with smaller patch sizes in a shorter time.",10.1145/3650212.3680326,https://doi.org/10.1145/3650212.3680326
Investigating Autograder Usage in the Post- Pandemic and LLM Era,"Weber, Jason Lee and Park, Hyunjun and Song, Daniel J. and Apillanes, Jared and Martinez Neda, Barbara and Wong-Ma, Jennifer and Gago-Masague, Sergio",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"This work investigates the impact of Large Language Models (LLMs) and the COVID-19 pandemic on student behavior with autograder systems in three programming-heavy courses. We examine whether the release of LLMs like ChatGPT and GitHub Copilot, along with post-pandemic effects, has modified student interactions with autograders. Using data from student submissions over five years, totalling over 4,500 students across over 420,000 submissions, we analyze trends in submission behaviors before and after these events. Our methodology involves tracking submission patterns, focusing on timing, frequency, and score.Contrary to expectations, our findings reveal that metrics remain relatively consistent in the post-ChatGPT and post-pandemic era. Despite yearly fluctuations, no significant shift in student behaviors is attributable to these changes. Students continue to rely on a combination of manual debugging and autograder feedback without noticeable changes in their problem-solving approach.These findings highlight the resilience of the educational practices in these courses and suggest that integrating LLMs into mid-level CS curriculum may not necessitate the significant paradigm shift previously envisioned. Future work should extend these analyses to courses with different structures to determine if these results are generalizable. If not, the specific course aspects contributing to our observed ChatGPT and pandemic resilience should be identified.",10.1145/3641555.3705208,https://doi.org/10.1145/3641555.3705208
Early Computer Science Students' Perspectives Towards The Importance Of Writing,"Engineer, Rutwa and Sibia, Naaz and Kaler, Michael and Simion, Bogdan and Zhang, Lisa",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"Faculty and industry practitioners recognize written communication to be important in computer science, but it can be challenging to convince students of the same. As student perceptions are molded early in a program of study, we focus on early-year CS students to understand their perceptions towards the importance of writing in CS, with the goal of framing discipline-specific writing pedagogy. We qualitatively analyze responses from first and second-year CS students in a survey about the role of writing in their field. The responses reveal that a majority view writing as an indispensable skill. Specifically, students recognize it as a fundamental skill, applicable across diverse contexts, and uniquely relevant in CS compared to other fields. We identified 4 perceptions that they hold which are helpful to their development as writers: that writing is a useful fundamental skill, which is useful for achieving various goals in a variety of contexts, and that writing in CS is different than in other fields. However, 20% of responses include reasons why writing is not important in CS, and we identify 4 perceptions harmful to students' development as writers: that writing skills can be avoided, are defined narrowly, do not need to be developed beyond a baseline, and come at the cost of computing skills. We believe that there is an opportunity to align discipline-specific writing instruction with these useful and harmful perceptions.",10.1145/3649217.3653576,https://doi.org/10.1145/3649217.3653576
ITiCSE 2024 Recap,"Lonati, Violetta and Monga, Mattia and Barendsen, Erik",SIGCSE Bull.,2025,"The 29th annual ACM conference on Innovation and Technology in Computer Science Education (ITiCSE) was held in Milan, Italy, July 5-10, 2024. Despite some last-minute changes due to an ongoing student protest at the University of Milan, we can consider this edition a success. A total of 345 participants attended ITiCSE, coming from 36 different countries",10.1145/3717402.3717404,https://doi.org/10.1145/3717402.3717404
An Eye for an AI: Evaluating GPT-4o's Visual Perception Skills and Geometric Reasoning Skills Using Computer Graphics Questions,"Feng, Tony Haoran and Denny, Paul and W\",SIGGRAPH Asia 2024 Educator's Forum,2024,"CG (Computer Graphics) is a popular field of CS (Computer Science), but many students find this topic difficult due to it requiring a large number of skills, such as mathematics, programming, geometric reasoning, and creativity. Over the past few years, researchers have investigated ways to harness the power of GenAI (Generative Artificial Intelligence) to improve teaching. In CS, much of the research has focused on introductory computing. A recent study evaluating the performance of an LLM (Large Language Model), GPT-4 (text-only), on CG questions, indicated poor performance and reliance on detailed descriptions of image content, which often required considerable insight from the user to return reasonable results. So far, no studies have investigated the abilities of LMMs (Large Multimodal Models), or multimodal LLMs, to solve CG questions and how these abilities can be used to improve teaching.In this study, we construct two datasets of CG questions requiring varying degrees of visual perception skills and geometric reasoning skills, and evaluate the current state-of-the-art LMM, GPT-4o, on the two datasets. We find that although GPT-4o exhibits great potential in solving questions with visual information independently, major limitations still exist to the accuracy and quality of the generated results. We propose several novel approaches for CG educators to incorporate GenAI into CG teaching despite these limitations. We hope that our guidelines further encourage learning and engagement in CG classrooms.",10.1145/3680533.3697064,https://doi.org/10.1145/3680533.3697064
Probing the Unknown: Exploring Student Interactions with Probeable Problems at Scale in Introductory Programming,"Denny, Paul and Kumar, Viraj and MacNeil, Stephen and Prather, James and Leinonen, Juho",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"Introductory programming courses often rely on small code-writing exercises that have clearly specified problem statements. This limits opportunities for students to practice how to clarify ambiguous requirements - a critical skill in real-world programming. In addition, the emerging capabilities of large language models (LLMs) to produce code from well-defined specifications may harm student engagement with traditional programming exercises. This study explores the use of ''Probeable Problems'', automatically gradable tasks that have deliberately vague or incomplete specifications. Such problems require students to submit test inputs, or 'probes', to clarify requirements before implementation. Through analysis of over 40,000 probes in an introductory course, we identify patterns linking probing behaviors to task success. Systematic strategies, such as thoroughly exploring expected behavior before coding, resulted in fewer incorrect code submissions and correlated with course success. Feedback from nearly 1,000 participants highlighted the challenges and real-world relevance of these tasks, as well as benefits to critical thinking and metacognitive skills. Probeable Problems are easy to set up and deploy at scale, and help students recognize and resolve uncertainties in programming problems.",10.1145/3724363.3729093,https://doi.org/10.1145/3724363.3729093
Scaffolding Critical Thinking about Stakeholders' Power in Socio-Technical AI Literacy,"Solyst, Jaemarie and Amspoker, Emily and Yang, Ellia and Luo, Yi and Hammer, Jessica and Ogan, Amy",Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 2,2024,,10.1145/3632621.3671430,https://doi.org/10.1145/3632621.3671430
CodeTailor: LLM-Powered Personalized Parsons Puzzles for Engaging Support While Learning Programming,"Hou, Xinying and Wu, Zihan and Wang, Xu and Ericson, Barbara J.",,2024,"Learning to program can be challenging, and providing high-quality and timely support at scale is hard. Generative AI and its products, like ChatGPT, can create a solution for most intro-level programming problems. However, students might use these tools to just generate code for them, resulting in reduced engagement and limited learning. In this paper, we present CodeTailor, a system that leverages a large language model (LLM) to provide personalized help to students while still encouraging cognitive engagement. CodeTailor provides a personalized Parsons puzzle to support struggling students. In a Parsons puzzle, students place mixed-up code blocks in the correct order to solve a problem. A technical evaluation with previous incorrect student code snippets demonstrated that CodeTailor could deliver high-quality (correct, personalized, and concise) Parsons puzzles based on their incorrect code. We conducted a within-subjects study with 18 novice programmers. Participants perceived CodeTailor as more engaging than just receiving an LLM-generated solution (the baseline condition). In addition, participants applied more supported elements from the scaffolded practice to the posttest when using CodeTailor than baseline. Overall, most participants preferred using CodeTailor versus just receiving the LLM-generated code for learning. Qualitative observations and interviews also provided evidence for the benefits of CodeTailor, including thinking more about solution construction, fostering continuity in learning, promoting reflection, and boosting confidence. We suggest future design ideas to facilitate active learning opportunities with generative AI techniques.",10.1145/3657604.3662032,https://doi.org/10.1145/3657604.3662032
Teaching with AI (GPT),"Liu, Rongxin and Zenke, Carter and Lloyd, Doug and Malan, David J.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"Teaching computer science at scale can be challenging. From our experience in CS50, Harvard University's introductory course, we've seen firsthand the impactful role that generative artificial intelligence can play in education. Recognizing its potential and stakes, we integrated OpenAI's GPT into our own teaching methodology. The goal was to emulate a 1:1 teacher-to-student ratio, incorporating",10.1145/3626253.3633433,https://doi.org/10.1145/3626253.3633433
ITiCSE 2025 Call for Participation,"Barendsen, Erik and Paterson, Jim and Quille, Keith",SIGCSE Bull.,2025,"You are warmly welcomed to the 30th annual ACM Conference on Innovation and Technology in Computer Science Education (ITiCSE), which will be held at Radboud University in Nijmegen, Netherlands from 30 June to 2 July 2025. ITiCSE is a computing education conference held annually, typically in Europe, sponsored by ACM SIGCSE and in collaboration with ACM Europe Council and Informatics Europe.",10.1145/3732895.3732899,https://doi.org/10.1145/3732895.3732899
Style Anomalies Can Suggest Cheating in CS1 Programs,"Denzler, Benjamin and Vahid, Frank and Pang, Ashley",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"Student cheating on at-home programming assignments is a well-known problem. A key contributor is externally obtained solutions from websites, contractors, and recently generative AI. In our experience, such externally obtained solutions often use coding styles that depart from a class's style, which we call",10.1145/3626253.3635519,https://doi.org/10.1145/3626253.3635519
Bridging the Community College Cybersecurity Classroom and Workplace with the CyberSim Lab,,Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Most postsecondary cybersecurity education focuses on technical knowledge and skills without commensurate attention to vital non-technical skills. In this position paper, we argue that cybersecurity education must integrate teaching and practicing of non-technical competencies alongside technical knowledge and skills to ensure that both technical and non-technical skills transfer to cybersecurity workplaces. We identify specific learning outcomes that meet these criteria and suggest research-based pedagogical approaches to support learning and transfer. We present a cybersecurity lab designed to address these learning outcomes through experiential learning, roleplay, collaborative learning, technical simulation and metacognitive engagement. The CyberSim Lab serves as a curricular bridge between the classroom and the workplace.",10.1145/3641554.3701834,https://doi.org/10.1145/3641554.3701834
Programming Skills as a Gateway to Proof Writing Proficiency,"Earth, Steve and Johnson, Jeremy and Char, Bruce",J. Comput. Sci. Coll.,2024,"The intersection of programming and proof writing skills in computer science education is a relatively unexplored area. This paper presents the beginning of a longitudinal study that explores this intersection by analyzing student programmers' solutions to logic puzzles at the beginning and end of an intermediate computer science (CS) course. These puzzles, requiring skills akin to proof writing but without the need for advanced mathematical knowledge, serve as a tool to evaluate the development of proof writing skills. We examine the correlation between students' puzzle-solving capabilities and their academic performance in the course, controlling for other variables such as prior mathematics courses and GPA. This study aims to bridge the gap in understanding how programming education contributes to the development of proof writing abilities.",,
Adding Context to Automated Vulnerability Detection for Teaching Software Security,"Dorard, Antoine and K\",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 2,2025,"Considering the recent developments in the fiel of generative AI, large language models (LLMs) can be leveraged to enhance static application security testing (SAST) tools and teaching about this topic. These models provide contextual information about identified vulnerabilities which can help students to differentiate genuine issues from false alarms while learning about software security. The approach includes analyzing vulnerabilities in android applications using SAST tools, clustering related code functionalities, and generating multi-level summaries for detected vulnerabilities. The process employs advanced clustering techniques and consensus-building methods to ensure accuracy.",10.1145/3724389.3730794,https://doi.org/10.1145/3724389.3730794
Raising the Bar: Automating Consistent and Equitable Student Support with LLMs,"Mittal, Meenakshi and Bailey, Azalea and Phelps, Victoria and Miroyan, Mihran and Mitra, Chancharik and Jain, Rishi and Niousha, Rose and Ranade, Gireeja and Norouzi, Narges",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"Large Language Models (LLMs) can be used to automate many aspects of the educational field. In this paper, we look into the benefits of automating responses to student questions in course discussion forums using our Retrieval-Augmented Generation (RAG)-based LLM pipeline (Edison). Our research questions are:RQ1 How do the responses generated by Edison compare to those of TAs in terms of level of detail and use of examples?RQ2 How does the tone of responses generated by Edison compare to that of TA responses?RQ3 Are responses generated by Edison more self-consistent than TA responses?Our results suggest that Edison generates responses with more detail, examples, positive tone, and self-consistency than TAs. We envision Edison being used as a baseline for TAs to build responses on, reduce response times, and promote equitable feedback.",10.1145/3641555.3705237,https://doi.org/10.1145/3641555.3705237
CodeAid: Evaluating a Classroom Deployment of an LLM-based Programming Assistant that Balances Student and Educator Needs,"Kazemitabaar, Majeed and Ye, Runlong and Wang, Xiaoning and Henley, Austin Zachary and Denny, Paul and Craig, Michelle and Grossman, Tovi",Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems,2024,"Timely, personalized feedback is essential for students learning programming. LLM-powered tools like ChatGPT offer instant support, but reveal direct answers with code, which may hinder deep conceptual engagement. We developed CodeAid, an LLM-powered programming assistant delivering helpful, technically correct responses, without revealing code solutions. CodeAid answers conceptual questions, generates pseudo-code with line-by-line explanations, and annotates student’s incorrect code with fix suggestions. We deployed CodeAid in a programming class of 700 students for a 12-week semester. A thematic analysis of 8,000 usages of CodeAid was performed, further enriched by weekly surveys, and 22 student interviews. We then interviewed eight programming educators to gain further insights. Our findings reveal four design considerations for future educational AI assistants: D1) exploiting AI’s unique benefits; D2) simplifying query formulation while promoting cognitive engagement; D3) avoiding direct responses while encouraging motivated learning; and D4) maintaining transparency and control for students to asses and steer AI responses.",10.1145/3613904.3642773,https://doi.org/10.1145/3613904.3642773
Fine-Tuning Large Language Models for Better Programming Error Explanations,"Vassar, Alexandra and Renzella, Jake and Ross, Emily and Taylor, Andrew",Proceedings of the 24th Koli Calling International Conference on Computing Education Research,2024,"This paper investigates supervised fine-tuning of large language models (LLMs) to improve their pedagogical alignment in computing education, addressing concerns that LLMs may hinder learning outcomes. The project utilised a proprietary dataset of 2,500 high quality question/answer pairs from programming course forums, and explores two research questions: the suitability of university course forums in contributing to fine-tuning datasets, and how supervised fine-tuning can improve LLMs’ alignment with educational principles such as constructivism. Initial findings suggest benefits in pedagogical alignment of LLMs, with deeper evaluations required.",10.1145/3699538.3699581,https://doi.org/10.1145/3699538.3699581
Using LLMs to Detect the Presence of Learning Outcomes in Submitted Work Within Computing Ethics Courses,"Tsang, Jedidiah and Li, Carol and Park, Su Min and Yan, Lisa",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"This study investigates how large language models (LLMs) can identify the presence of learning outcomes within student submitted work in a computing ethics course. To do so, we craft a codebook to spot key learning outcomes, such as the usage of critical reasoning and awareness of various social issues. We leverage the GPT-4o and GPT-3.5-turbo LLMs to apply codes onto 8,500 pieces of student submitted work. We then use Cohen's kappa to assess interrater reliability and compare human reviewers' coding to outputs from those models, finding that GPT-4o performed just as well as the agreement between human reviewers. We then use the model outputs to identify specific course readings that students engaged particularly deeply with to better inform our computing ethics instruction.",10.1145/3641555.3705277,https://doi.org/10.1145/3641555.3705277
Evaluating the Performance of Code Generation Models for Solving Parsons Problems With Small Prompt Variations,"Reeves, Brent and Sarsa, Sami and Prather, James and Denny, Paul and Becker, Brett A. and Hellas, Arto and Kimmel, Bailey and Powell, Garrett and Leinonen, Juho",Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1,2023,"The recent emergence of code generation tools powered by large language models has attracted wide attention. Models such as OpenAI Codex can take natural language problem descriptions as input and generate highly accurate source code solutions, with potentially significant implications for computing education. Given the many complexities that students face when learning to write code, they may quickly become reliant on such tools without properly understanding the underlying concepts. One popular approach for scaffolding the code writing process is to use Parsons problems, which present solution lines of code in a scrambled order. These remove the complexities of low-level syntax, and allow students to focus on algorithmic and design-level problem solving. It is unclear how well code generation models can be applied to solve Parsons problems, given the mechanics of these models and prior evidence that they underperform when problems include specific restrictions. In this paper, we explore the performance of the Codex model for solving Parsons problems over various prompt variations. Using a corpus of Parsons problems we sourced from the computing education literature, we find that Codex successfully reorders the problem blocks about half of the time, a much lower rate of success when compared to prior work on more free-form programming tasks. Regarding prompts, we find that small variations in prompting have a noticeable effect on model performance, although the effect is not as pronounced as between different problems.",10.1145/3587102.3588805,https://doi.org/10.1145/3587102.3588805
Spotting AI Missteps: Students Take on LLM Errors in CS1,"Smith, Samantha Boatright and Wei, Heather and O'Neill, Abby and Durai, Aneesh and DeNero, John and Zamfirescu-Pereira, J.D. and Norouzi, Narges",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"CS1 courses have rapidly adopted Large Language Model (LLM)- based assistance, promising quick and always-available support for homework help. However, it is challenging to ensure that the hints and guidance provided by these models are accurate and not based on hallucinated solutions. In this work, we study and categorize LLM behavior in cases where students believe an LLM-powered homework tutor gave an inaccurate hint. We then describe correlations between certain student behaviors (SB) and our suggested bot-behavior (BB) categories.",10.1145/3641555.3705253,https://doi.org/10.1145/3641555.3705253
RAFIKI: Leveraging Large Language Models to Increase AP Computer Science A Enrollment among Disadvantaged High School Females,"Chopra, Ryka C. and Chakraborty, Suparna",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"The gender gap in computing persists even after decades of investment in lowering the gap. Evidence suggests that stereotypical attitudes and bias perceptions play a critical role in limiting female participation in STEM, beginning in middle and high school. The gap is exacerbated in developing nations with limited academic counselor support. Therefore, the goal is to provide early targeted counseling. RAFIKI -",10.1145/3641555.3705236,https://doi.org/10.1145/3641555.3705236
Style Anomalies Can Suggest Cheating in CS1 Programs,"Denzler, Benjamin and Vahid, Frank and Pang, Ashley and Salloum, Mariam",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"Student cheating on at-home programming assignments is a well- known problem. A key contributor is externally-obtained solutions from websites, contractors, and recently generative AI. In our experience, such externally-obtained solutions often use coding styles that depart from a class' style, which we call",10.1145/3649217.3653626,https://doi.org/10.1145/3649217.3653626
Exploring Critical CS Teacher Education Program Design Through a Science and Technology Studies Approach,"Henrique, Brendan",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Recent calls to reimagine K-12 computer science teacher education have proposed critical visions of pre-service teacher education built on equity, justice, and ethics. Building on these calls, this position paper demonstrates how critical perspectives can be incorporated into K-12 CS teacher education programs by integrating texts from Science and Technology studies. Central to this approach is allowing teachers to gain proficiency in CS content while navigating the tensions of the transformative and oppressive nature of technology as they imagine their future pedagogy. By integrating the often separated strands of pedagogy, content, and justice, pre-service teachers were empowered to reimagine what computer science would look like for their students. This paper concludes by discussing how a Science and Technology Studies approach could be used for entire course sequences in CS teacher preparation programs and preliminary feedback from teachers in the first iteration of this curriculum.",10.1145/3641554.3701903,https://doi.org/10.1145/3641554.3701903
Teaching Programming Error Message Understanding,,Working Group Reports on 2023 ACM Conference on Global Computing Education,2024,About a decade ago there was a sharp increase in the number of research publications focusing on programming error messages. The majority of this work focused on improving or,10.1145/3598579.3689377,https://doi.org/10.1145/3598579.3689377
Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1,"Kasinidou, Maria and Kleanthous, Styliani and Otterbacher, Jahna",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1,2024,"Natural Language Processing (NLP) is a critical area of AI that is increasingly integrated into everyday life. The public regularly engages with systems such as Siri, Alexa, and more recently, ChatGPT, yet few understand how these systems work. In this paper, we examine how students perceive NLP technologies after completing a unit on NLP within an AI course designed for non-CS majors. We further present our students' perspectives on the banning of ChatGPT in Italy, where the course was delivered. The NLP unit featured a lecture, an interactive session, and a practical assignment wherein students developed a smart assistant responsive to textual commands. Students, after creating their smart assistants, highlighted challenges such as inadequate training datasets and natural language ambiguity. Opinions on ChatGPT's ban varied, with privacy concerns prevailing. However, a consensus emerged in favor of educational efforts to raise awareness about technology limitations, advocating understanding over outright bans in anticipation of their inevitable integration into daily life.",10.1145/3649165.3690113,https://doi.org/10.1145/3649165.3690113
CREF: An LLM-Based Conversational Software Repair Framework for Programming Tutors,,Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis,2024,"With the proven effectiveness of Large Language Models (LLMs) in code-related tasks, researchers have explored their potential for program repair. However, existing repair benchmarks might have influenced LLM training data, potentially causing data leakage. To evaluate LLMs’ realistic repair capabilities, (i) we introduce an extensive, non-crawled benchmark TutorCode, comprising 1,239 C++ defect codes and associated information such as tutor guidance, solution description, failing test cases, and the corrected code. Our work assesses LLM’s repair performance on TutorCode, measuring repair correctness (TOP-5 and AVG-5) and patch precision (RPSR). (ii) We then provide a comprehensive investigation into which types of extra information can help LLMs improve their repair performance. Among these types, tutor guidance was the most effective information. To fully harness LLMs’ conversational capabilities and the benefits of augmented information, (iii) we introduce a novel conversational semi-automatic repair framework CREF assisting human programming tutors. It demonstrates a remarkable AVG-5 improvement of 17.2%-24.6% compared to the baseline, achieving an impressive AVG-5 of 76.6% when utilizing GPT-4. These results highlight the potential for enhancing LLMs’ repair capabilities through tutor interactions and historical conversations. The successful application of CREF in a real-world educational setting demonstrates its effectiveness in reducing tutors’ workload and improving students’ learning experience, showing promise for code review and other software engineering tasks.",10.1145/3650212.3680328,https://doi.org/10.1145/3650212.3680328
Midterm Exam Outliers Efficiently Highlight Potential Cheaters on Programming Assignments,"Haji Amin Shirazi, Shirin and Pang, Ashley and Knight, Allan and Salloum, Mariam and Vahid, Frank",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"The ubiquitous use of online tools, contractors and homework sites, has made plagiarism a concerning topic in computer science education. With the introduction of ChatGPT, it poses a threat now more than ever. Many cheating detection tools, such as similarity checkers and style anomaly checkers, help instructors decide whether a student has plagiarized. However, these are not scalable to large classes. Similarity tools can produce high rates of suspected cheating and thus ineffectively use an instructor's time in weeding out the actual cheating cases, especially in the early weeks of CS courses where programs can be small and student solutions can be very similar. We developed a new approach using outlier detection to filter inconsistent performers based on their lab scores throughout the course and their midterm exam scores. Instructors can then manually analyze a manageable amount of students even with large class sizes. We performed our experiment on two large course offerings of CS1 (a total of 177 students) using our algorithm and compared it to a manual analysis performed by an experienced CS1 instructor. The detection approach identified 11 students in the first offering (Winter 2019) and 12 students in the second offering (Spring 2023). With an average precision of 83%, our tool produces a list of concerning students with high precision. This significantly helps teachers efficiently allocate their time and pursue cheating early in the term in order to address and prevent further issues.",10.1145/3641554.3701883,https://doi.org/10.1145/3641554.3701883
Novices' Perceptions of Web-Search and AI for Programming,"Skripchuk, James and Bacher, John and Shi, Yang and Tran, Keith and Price, Thomas",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"External help resources are frequently used by novice programmers solving classwork in undergraduate computing courses. Traditionally, these tools consisted of web-based resources such as tutorial websites and Q&amp;A forums. With the rise of AI code-generation and explanation tools, understanding how students use external resources and their roles in classroom have become especially relevant. Despite this, little research has directly investigated the extent to which students intent to use these tools and what factors influence their beliefs. It is unknown when students think it is appropriate to use these tools and what features they find valuable. Understanding these beliefs would allow instructors and researchers to better focus their efforts on what aspects of pedagogy and tool usage should be addressed. We administered a pilot vignette-style survey to introductory programming classes at an R1 University (n=45), giving students scenarios of external resource usage while questioning their attitudes, subjective norms, and their perceived behavioral control on using these external resources. We share preliminary findings on free response data, showcasing the variety of beliefs and opinions that novice programming students have on when and how much external resource usage is acceptable in the classroom. Some students felt that AI tools can provide more exact solutions than searching for help online, but also expressed that this exactness could be detrimental to their learning. Others expressed awareness that professionals use these resources, and expressed a desire to learn how to use them in a way to help their educational and career goals.",10.1145/3626253.3635545,https://doi.org/10.1145/3626253.3635545
Graduate Computer Science TA Perspectives on In-Person Pedagogical Training: An Experience Report,"Zaman, Alina and Cook, Amy and Phan, Vinhthuy and Windsor, Alistair",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"Computer science (CS) departments rely heavily on graduate teaching assistants (GTAs), yet many departments struggle to provide effective pedagogical training, particularly for international GTAs who face additional cultural and communication challenges. While pedagogical training improves student outcomes, engaging GTAs with diverse career priorities in such training remains difficult, and resource constraints often lead departments to default to less engaging online formats. This experience report examines the implementation of a low-cost, in-person training program for CS GTAs using a flipped classroom approach that supplemented existing online modules. Our cohort of 34 international GTAs actively engaged with the training, which focused on grading practices, feedback techniques, cultural competencies, and common teaching scenarios. Survey data collected before and after training and midway through the semester revealed that participants found the training highly beneficial, with 94% reporting increased preparedness for their teaching roles. GTAs consistently applied learned skills throughout the semester, particularly in providing effective feedback (90%) and using rubrics (76%). The program's structure-requiring minimal faculty resources while yielding significant improvements in GTA confidence and teaching practices-offers a practical, replicable model for other CS departments seeking to enhance GTA preparation without substantial resource investment.",10.1145/3724363.3729072,https://doi.org/10.1145/3724363.3729072
How Good are Large Language Models at Generating Subgoal Labels?,"Marwan, Samiha and Ibrahim, Mohamed and Morrison, Briana",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"The use of subgoal labels in introduction to programming classrooms has been shown to improve student performance, learning, retention, and reduce students' drop out rates. However, creating and adding subgoal labels to programming assignments is often hard to articulate and very time-intensive for instructors. In Computing Education Research, Large Language Models (LLMs) have been widely used to generate human-like outputs such as worked examples and source code. In this work, we explore whether ChatGPT could be used to generate high-quality and appropriate subgoal labels in two programming curricula. Our qualitative data analysis suggests that LLMs can assist instructors in creating subgoal labels in their classrooms, opening up directions to empower students' learning experience in programming classrooms.",10.1145/3641555.3705195,https://doi.org/10.1145/3641555.3705195
"Exploring Undergraduate AI Perceptions: Knowledge, Enthusiasm, and Concerns","Diaz, Nicolas and Roy, Saunak and Beltran, Jonathan",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"As Artificial Intelligence (AI) develops and grows its presence in society, college students are increasingly interacting with AI and utilizing tools like ChatGPT as part of their education. Particularly in STEM fields, educators themselves are incorporating AI by encouraging its use as an assistive tool for coursework or designing courses that teach about its inner workings. Understanding students' perceptions and knowledge of AI can help educators know whether students will embrace learning in AI-heavy environments, as well as which student concerns they should acknowledge. Our study uses both quantitative and qualitative data from undergraduate CMNS (College of Computer, Mathematical, and Natural Sciences) students at the University of Maryland, College Park to explore students' perceived knowledge, enthusiasm, and concerns over AI. Our data was collected via a survey administered via email to undergraduates and subsequent focus group interviews with these students about their relationship with AI. Survey findings indicated that students were confident in their knowledge of AI and related competencies, as well as enthusiastic about learning and using AI. Students also highly believed in the need for standards and testing for AI systems to curtail risks. There was a positive correlation between perceived knowledge and enthusiasm of AI, but no correlation between knowledge and concerns. In interviews, students' main uses of AI were summarizing information, creating practice problems, and writing assistance. Popular concerns included academic dishonesty, overreliance on AI tools, and fabricated information in outputs.",10.1145/3641555.3705031,https://doi.org/10.1145/3641555.3705031
Beyond AI Hype: A Hands-on Workshop Series for Enhancing AI Literacy in Middle and High School Students,"Okolo, Chinasa T.",Proceedings of the 2024 on RESPECT Annual Conference,2024,"The increasing usage of AI in high-stakes decision-making underscores a pressing need for various stakeholders to understand AI, learn how to identify AI-generated content, and become aware of its societal risks. We detail outcomes from engaging underrepresented secondary school students in a 5-day workshop series consisting of brief lectures, hands-on activities, and short research assignments. We find that the workshop improved students' knowledge about AI and the ethical implications of using these technologies. Our work highlights policy implications and outlines actionable efforts needed to advance AI literacy, with the workshop content being developed into an open-source AI literacy curriculum.",10.1145/3653666.3656075,https://doi.org/10.1145/3653666.3656075
Explaining Code with a Purpose: An Integrated Approach for Developing Code Comprehension and Prompting Skills,"Denny, Paul and Smith, David H. and Fowler, Max and Prather, James and Becker, Brett A. and Leinonen, Juho",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"Reading, understanding and explaining code have traditionally been important skills for novices learning programming. As large language models (LLMs) become prevalent, these foundational skills are more important than ever given the increasing need to understand and evaluate model-generated code. Brand new skills are also needed, such as the ability to formulate clear prompts that can elicit intended code from an LLM. Thus, there is great interest in integrating pedagogical approaches for the development of both traditional coding competencies and the novel skills required to interact with LLMs. One effective way to develop and assess code comprehension ability is with",10.1145/3649217.3653587,https://doi.org/10.1145/3649217.3653587
Investigating the Proficiency of Large Language Models in Formative Feedback Generation for Student Programmers,"S Kumar, Smitha and Adam Lones, Michael and Maarek, Manuel and Zantout, Hind",Proceedings of the 1st International Workshop on Large Language Models for Code,2024,"Generative AI has considerably altered traditional workplace practice across numerous industries. Ever since the emergence of large language models (LLMs), their potential to generate formative feedback for introductory programming courses has been extensively researched. However, most of these studies have focused on Python. In this work, we examine the bug-fixing and feedback-generation abilities of Code Llama and ChatGPT for Java programming assignments using our new Java benchmark called CodeWBugs. The results indicate that ChatGPT performs reasonably well, and was able to fix 94.33% programs. By comparison, we observed high variability in the results from Code Llama. We further analyzed the impact of different types of prompts and observed that prompts that included task descriptions and test inputs yielded better results. In most cases, the LLMs precisely localized the bugs and also offered guidance on how to proceed. Nevertheless, we also noticed incorrect responses generated by the LLMs, emphasizing the need to validate responses before disseminating feedback to learners.",10.1145/3643795.3648380,https://doi.org/10.1145/3643795.3648380
Feasibility Study of Augmenting Teaching Assistants with AI for CS1 Programming Feedback,"Ahmed, Umair Z. and Sahai, Shubham and Leong, Ben and Karkare, Amey",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"With the increasing adoption of Large Language Models (LLMs), there are proposals to replace human Teaching Assistants (TAs) with LLM-based AI agents for providing feedback to students. In this paper, we explore a new hybrid model where human TAs receive AI-generated feedback for CS1 programming exercises, which they can then review and modify as needed. We conducted a large-scale randomized intervention with 185 CS1 undergraduate students, comparing the efficacy of this hybrid approach against manual feedback and direct AI-generated feedback.Our initial hypothesis predicted that AI-augmented feedback would improve TA efficiency and increase the accuracy of guidance to students. However, our findings revealed mixed results. Although students perceived improvements in feedback quality, the hybrid model did not consistently translate to better student performance. We also observed complacency among some TAs who over-relied on LLM generated feedback and failed to identify and correct inaccuracies. These results suggest that augmenting human tutors with AI may not always result in improved teaching outcomes, and further research is needed to ensure it is truly effective.",10.1145/3641554.3701972,https://doi.org/10.1145/3641554.3701972
An Investigation on Task Difficulty: Does Task Difficulty Depend on the Technology Used in Task Completion?,"Akgun, Mahir and Toker, Sacip",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"Previous research indicates that task difficulty (i.e., students' judgments on a task's complexity) impacts their task performance. However, whether students' perceived task difficulty changes depending on the technology they use when completing tasks is still under investigation. The present study aims to address this gap in the literature. One hundred twenty-three students completed the study procedures. Students were randomly assigned to one of four groups (one control group and three experimental groups). Students were not allowed to use any technology in the control group. In contrast, those in experimental groups were permitted to use one of the following tools: e-textbook, Google, and ChatGPT. Students in each group completed three tasks with different complexities in the same order. The data was analyzed using repeated-measures ANOVA. The study revealed a significant interaction effect between groups and task difficulty perceptions at three levels. In all groups, perceived difficulty increased as the task complexity increased, but the change in students' perceived task difficulty across three tasks was impacted by the tool used when completing the tasks.",10.1145/3626253.3635602,https://doi.org/10.1145/3626253.3635602
Developing Computing Teacher Guidance on GenAI,"Sentance, Sue and Watson, Steven and Addo, Salomey Afua and Shi, Shengpeng and Waite, Jane and Yu, Bo",Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research,2024,"Generative AI (GenAI) is becoming widely available for use in schools by teachers and students. While many educators appreciate the potential benefits of GenAI for enhancing learning, there are also significant concerns about authorship, authenticity, plagiarism, ethics, biases, and the broader implications of their use in education. For computing teachers in schools, these issues can be even more acute. In this project, we established a working group of practising computing teachers to bring together a range of views and experiences. Initial results of the project led to a booklet for computing teachers on how to use GenAI, illustrating the effectiveness of teacher-researcher partnerships in developing resources for school use. This project will be followed by further work on computing teachers’ actual experience of GenAI in practice.",10.1145/3689535.3689538,https://doi.org/10.1145/3689535.3689538
ITiCSE Announcement,"Barendsen, Erik and Paterson, Jim and Quille, Keith",SIGCSE Bull.,2025,"The 30th annual ACM Conference on Innovation and Technology in Computer Science Education (ITiCSE) will be held at Radboud University in Nijmegen, Netherlands, from 30 June to 2 July 2025. ITiCSE is a computing education conference held annually, typically in Europe, sponsored by ACM SIGCSE and in collaboration with ACM Europe Council and Informatics Europe.",10.1145/3717596.3717600,https://doi.org/10.1145/3717596.3717600
Comparative Analysis of GPT-4o and GPT-4.0 in Business Ethics Role-Play Simulations,"Xu, Xiao",Proceedings of the 2024 International Conference on Artificial Intelligence and Teacher Education,2025,"The rapid advancement of artificial intelligence (AI) technologies has opened new frontiers in educational methodologies, particularly in enhancing interactive learning environments. This paper examines the integration of two AI-driven models, ChatGPT-4.0 and its advanced iteration, GPT-4o, into the teaching of complex subjects such as climate risk management within higher education. Utilizing role-play simulations, a method proven to effectively deepen understanding and engagement, we explore how these models enhance traditional educational approaches by providing dynamic, real-time interactions that mimic real-world decision-making processes. Our comparative analysis focuses on the performance of these models in terms of response time, emotional intelligence, and quality of engagement. The findings indicate that GPT-4o, with its quicker response times and enhanced emotional recognition capabilities, significantly improves learner engagement and the effectiveness of role-play simulations. This study highlights the potential of AI to not only complement but substantially enrich pedagogical practices, offering educators valuable insights into selecting appropriate AI tools for their instructional needs. Through this exploration, we advocate for a hybrid educational model that synergistically combines the strengths of both traditional and AI-enhanced learning, proposing a future where education is more adaptive, personalized, and aligned with the evolving demands of the digital age.",10.1145/3702386.3702388,https://doi.org/10.1145/3702386.3702388
The AI-Enhanced Software Engineer: A Snapshot of the Profession,"Lee, Irene and Malyn-Smith, Joyce and Kam, Matthew and Miller, Cody and Wang, Miaoxin",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"Generative AI and other emerging technologies are significantly impacting the work of software engineers. This impact is not re- stricted to programming; rather it has permeated multiple phases in the software development pipeline. As such, it is increasingly important to understand and analyze the changing work of the AI-enabled software developers who work at the cutting edge of AI Integration. This poster shares the ''Profile of the AI-enhanced Software Engineer'' developed in collaboration between Education Development Center (EDC) and Google. The profile describes in detail the work goals and associated tasks; and the skills, knowledge and attributes needed to do that work effectively. The poster will also share a framework for prompting used by skilled AI-enhanced software engineers across a variety of tasks. Though rapid change is predicted for the field, the Profile can inform K-20 CS and AI education efforts as well as workforce development of the current state of the field and stimulate discussion of how best to prepare for and adapt to the future of work.",10.1145/3641555.3705263,https://doi.org/10.1145/3641555.3705263
Debugging for Inclusivity in Online CS Courseware: Does it Work?,"Chatterjee, Amreeta and Choudhuri, Rudrajit and Sarkar, Mrinmoy and Chattopadhyay, Soumiki and Liu, Dylan and Hedaoo, Samarendra and Burnett, Margaret and Sarma, Anita",Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1,2024,"Online computer science (CS) courses have broadened access to CS education, yet inclusivity barriers persist for minoritized groups in these courses. One problem that recent research has shown is that often inclusivity biases (“inclusivity bugs”) lurk within the course materials themselves, disproportionately disadvantaging minoritized students. To address this issue, we investigated how a faculty member can use AID—an Automated Inclusivity Detector tool—to remove such inclusivity bugs from a large online CS1 (Intro CS) course and what is the impact of the resulting inclusivity fixes on the students’ experiences. To enable this evaluation, we first needed to (Bugs):&nbsp;investigate inclusivity challenges students face in 5 online CS courses; (Build):&nbsp;build decision rules to capture these challenges in courseware (“inclusivity bugs”) and implement them in the AID tool; (Faculty):&nbsp;investigate how the faculty member followed up on the inclusivity bugs that AID reported; and (Students):&nbsp;investigate how the faculty member’s changes impacted students’ experiences via a before-vs-after qualitative study with CS students. Our results from (Bugs) revealed 39 inclusivity challenges spanning courseware components from the syllabus to assignments. After implementing the rules in the tool (Build), our results from (Faculty) revealed how the faculty member treated AID more as a “peer” than an authority in deciding whether and how to fix the bugs. Finally, the study results with (Students) revealed that students found the after-fix courseware more approachable - feeling less overwhelmed and more in control in contrast to the before-fix version where they constantly felt overwhelmed, often seeking external assistance to understand course content.",10.1145/3632620.3671117,https://doi.org/10.1145/3632620.3671117
20 Years Later: A Replication Study on Teaching CS1 Concepts,"Garcia, Rita and Craig, Michelle",ACM Trans. Comput. Educ.,2025,"Introduction: Computer Science Education does not have a universally defined set of concepts consistently covered in all introductory courses (CS1). One approach to understanding the concepts covered in CS1 is to ask educators. In 2004, Nell Dale did just this. She also collected their perceptions on challenging topics to teach. Dale mused how the findings of a similar survey conducted in later years would compare with her results.Objectives: We answered Dale’s call to consider changes in teaching CS1 concepts by performing a replication study 20 years later. Our goals were to determine how the teaching of CS1 concepts has changed and to identify concepts educators perceive as challenging to teach.Methods: We created a survey based on Dale’s original study and added concepts from the CS2023 recommended curricula to include CS1 concepts for today’s teaching practice. We used a mixed-methods approach to analyse the 178 responses from CS1 educators.Results: Our survey results show Python is predominately used to teach today’s CS1 courses, with educators continuing to teach basic programming concepts similar to 20 years ago. However, our survey shows recursion continues to be challenging to teach, with most secondary school educators perceiving it does not belong in CS1. Today’s educators also teach less of the CS1 concepts from 20 years ago, such as inheritance and polymorphism, and have a limited focus on ethics and professionalism in their courses. Participants also found good learning behaviours like thinking and planning strategies challenging to teach.Conclusion: We conclude our article by discussing the challenges of conducting a replication study, which includes reproducing studies with limited or no access to the original instruments. We present future research opportunities raised by the study’s findings, including how to support educators in teaching the challenging concept of good learning behaviours and further refine curricular guidelines to remove ambiguity on concepts covered in CS1 and CS2 courses.",10.1145/3730405,https://doi.org/10.1145/3730405
ChatGPT on ChatGPT: An Exploratory Analysis of its Performance in the Public Sector Workplace,,Digit. Gov.: Res. Pract.,2025,"This study explores the impact of Generative Artificial Intelligence (GenAI), in particular, ChatGPT, on the public sector workforce in the United States, focusing on task replacement, assistance potential, and the evolving landscape of skills. Utilizing GPT-4 to evaluate 1,022 core tasks across 51 public sector occupations, we provide an exploratory analysis of the roles susceptible to ChatGPT automation and those in which ChatGPT can augment human efforts. Our findings reveal that while 63% of tasks are resistant to ChatGPT replacement, primarily due to their requirement for physical presence, emotional intelligence, and complex decision-making, tasks that are routine, rule-based, and involving basic content generation show a high potential for automation. The study also identifies key skills that will remain vital, those likely to become obsolete, and new skills that will emerge as essential, highlighting the need for a strategic approach to workforce development in the face of AI advancements. In particular, our findings underscore the growing importance of skills in applying AI technologies and the ability to validate and interpret AI-generated content for humans to remain competitive. We offer insights into public-sector-specific impacts and propose a methodological framework for future research, emphasizing the importance of adapting educational curricula and policies to prepare for an AI-integrated future.",10.1145/3676281,https://doi.org/10.1145/3676281
FastFixer: An Efficient and Effective Approach for Repairing Programming Assignments,"Liu, Fang and Liu, Zhenwei and Zhao, Qianhui and Jiang, Jing and Zhang, Li and Sun, Zian and Li, Ge and Li, Zhongqi and Ma, Yuchi",Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering,2024,,10.1145/3691620.3695062,https://doi.org/10.1145/3691620.3695062
Understanding Algorithmic Problem Solving using LLMs,"Velez, Xavier",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2,2024,"With the rapid advancement of Large Language Models (LLMs) many instructors for Computer Science courses have begun to opt to allow students to use them as an additional educational resource but often warn that the output may be unreliable. Recent research on LLMs has demonstrated their ability to interpret commands in natural language and produce code in a variety of programming languages. However, it is not clear how well LLMs fair in tackling more complex problem set ups, like those typically seen in Algorithms courses in which students are provided natural language descriptions of an ambiguous problem and use what they learn to map the problem to an algorithmic solution. In this paper, we explore use of LLMs, such as OpenAI's GPT-4o, as tools for assisting students with complex Computer Science curricula, such as algorithmic problem solving. We specifically aim to see if using prompt refinement techniques, LLMs are capable of taking a problem statement in plain English and performing the following tasks: providing both a natural language description and code solution in the Python programming language, producing an analytical argument for the solutions correctness, and finally providing runtime analysis for the produced solution. Our experiments show that GPT-4o is well suited to solving problems like LeetCode 75 that have been seen during training, and prompt-refinement helps with those that have not been seen.",10.1145/3649409.3691086,https://doi.org/10.1145/3649409.3691086
Unraveling the Impact of ChatGPT as a Knowledge Anchor in Business Education,"George, Amrita and Storey, Veda Catherine and Hong, Shuguang",ACM Trans. Manage. Inf. Syst.,2025,"The emergence of Large Language Models (LLM), such as ChatGPT, is considered a productivity revolution in many areas of business and society. For a classroom setting, especially, it would be useful to understand whether, and how, to incorporate ChatGPT, similar to any other productivity revolution technology, such as calculators or a Google search engine. Although there are concerns regarding the use of LLMs in business education, the positive or negative impact of LLM use is not well-understood. In this research, we examine the substitution and complementarity effects of using ChatGPT in business curricula on learning outcomes and well-being in a socially supportive learning environment. Specifically, we examine whether technology anchors impact students’ goal orientation, learning outcomes, and well-being by conducting an empirical study with students majoring in Information Systems. Our analysis reveals that a technology anchor (computer playfulness) can complement the effects of social support on learning outcomes, while enhancing well-being for simple tasks. Students’ well-being and learning outcomes are hindered by LLM use (specifically, the computer anxiety anchor), substituting social support for simple and difficult tasks. These findings have implications for educational institutions that are assessing how to incorporate LLMs into business curricula.",10.1145/3705734,https://doi.org/10.1145/3705734
Can You Spot the AI? Incorporating GenAI into Technical Writing Assignments,"Rajabi, Parsa and Kerslake, Chris",Proceedings of the 26th Western Canadian Conference on Computing Education,2024,"In an effort to foster critical reflection on the usage of generative AI (genAI) during computer science writing assignments, this three-part assignment challenges students to predict whether their peers can detect which essays are generated using AI. Implemented as part of a third-year professional responsibility and technical writing course for N=200 students during Spring 2024, students individually generated two short persuasive essays, one using genAI and the other without. They then combined the two essays into a single document and submitted it for peer-review. Additionally, they formulated a guess on whether their peers would be able to detect which essay was generated as well as a rationale for their guess. Following the peer-review process, students reflected on their own experience trying to detect which essays were generated as well as the outcome of their guess about their peers abilities as well. Feedback indicates its effectiveness in engaging students in their understanding of the potentials and limitations of genAI. Recommended prerequisites include a clear course AI-usage policy and a brief overview of genAI prompt engineering.",10.1145/3660650.3660673,https://doi.org/10.1145/3660650.3660673
An International Examination of Non-Technical Skills and Professional Dispositions in Computing -- Identifying the Present Day Academia-Industry Gap,"Garcia, Rita and Csizmadia, Andrew and Pearce, Janice L. and Alshaigy, Bedour and Glebova, Olga and Harrington, Brian and Liaskos, Konstantinos and Lunn, Stephanie J. and Mackellar, Bonnie and Nasir, Usman and Pettit, Raymond and Schulz, Sandra and Stewart, Craig and Zavaleta Bernuy, Angela",2024 Working Group Reports on Innovation and Technology in Computer Science Education,2025,Computing graduates are frequently reported by members of industry to lack in professional dispositions and/or non-technical skills (often referred to as,10.1145/3689187.3709610,https://doi.org/10.1145/3689187.3709610
The Implications of Large Language Models for CS Teachers and Students,"MacNeil, Stephen and Kim, Joanne and Leinonen, Juho and Denny, Paul and Bernstein, Seth and Becker, Brett A. and Wermelinger, Michel and Hellas, Arto and Tran, Andrew and Sarsa, Sami and Prather, James and Kumar, Viraj",Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2,2023,"The introduction of Large Language Models (LLMs) has generated a significant amount of excitement both in industry and among researchers. Recently, tools that leverage LLMs have made their way into the classroom where they help students generate code and help instructors generate learning materials. There are likely many more uses of these tools -- both beneficial to learning and possibly detrimental to learning. To help ensure that these tools are used to enhance learning, educators need to not only be familiar with these tools, but with their use and potential misuse. The goal of this BoF is to raise awareness about LLMs and to build a learning community around their use in computing education. Aligned with this goal of building an inclusive learning community, our BoF is led by globally distributed discussion leaders, including undergraduate researchers, to facilitate multiple coordinated discussions that can lead to a broader conversation about the role of LLMs in CS education.",10.1145/3545947.3573358,https://doi.org/10.1145/3545947.3573358
Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,"Wilkin, G. Aaron",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"This experience report examines a new course,",10.1145/3641554.3701893,https://doi.org/10.1145/3641554.3701893
What Skills Do You Need When Developing Software Using ChatGPT? (Discussion Paper),"Jeuring, Johan and Groot, Roel and Keuning, Hieke",Proceedings of the 23rd Koli Calling International Conference on Computing Education Research,2024,"Since the release of LLM-based tools such as GitHub Copilot and ChatGPT the media and popular scientific literature, but also journals such as the Communications of the ACM, have been flooded with opinions how these tools will change programming. The opinions range from “machines will program themselves”, to “AI does not help programmers”. Of course, these statements are meant to to stir up a discussion, and should be taken with a grain of salt, but we argue that such unfounded statements are potentially harmful. Instead, we propose to investigate which skills are required to develop software using LLM-based tools. In this paper we report on an experiment in which we explore if Computational Thinking (CT) skills predict the ability to develop software using LLM-based tools. Our results show that the ability to develop software using LLM-based tools can indeed be predicted by the score on a CT assessment. There are many limitations to our experiment, and this paper is also a call to discuss how to approach, preferably experimentally, the question of which skills are required to develop software using LLM-based tools. We propose to rephrase this question to include by what kind of people/programmers, to develop what kind of software using what kind of LLM-based tools.",10.1145/3631802.3631807,https://doi.org/10.1145/3631802.3631807
FEEDBOT: Formative Design Feedback on Programming Assignments,"Zhu, Elaine and Teja, Smaran and Coombes, Chris and Patterson, Daniel",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"This paper describes FEEDBOT, an open-source formative assessment tool leveraging large language models (LLMs) to provide structured, high-level feedback on design-oriented programming assignments. Designed to address the limitations of traditional autograding and overcome scaling challenges of formative assessment, FEEDBOT uses an existing pedagogical framework to provide targeted but limited actionable feedback. Early results demonstrate measurable improvements in student performance in a large introductory computer science course, while avoiding the pitfall of providing too much assistance that more unstructured tools commonly encounter. Although this experience report focuses on a particular implementation, we believe that FEEDBOT (and its general approach) is adaptable to many other contexts.",10.1145/3724363.3729063,https://doi.org/10.1145/3724363.3729063
AI-Grading Standup Updates to Improve Project-Based Learning Outcomes,"Menezes, Tyler and Egherman, Lola and Garg, Nikhil",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"Integrating project-based learning (such as class projects, capstones, or internships) into a Computer Science degree helps students apply what they have learned in lectures and homework. Often, these projects involve group work, but ensuring all students are contributing and learning equally is a large challenge.This experience report describes how we built and used a chatbot to collect and publish brief answers to the",10.1145/3649217.3653541,https://doi.org/10.1145/3649217.3653541
Machine Learning-Based Automated Grading and Feedback Tools for Programming: A Meta-Analysis,"Messer, Marcus and Brown, Neil C. C. and K\",Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1,2023,"Research into automated grading has increased as Computer Science courses grow. Dynamic and static approaches are typically used to implement these graders, the most common implementation being unit testing to grade correctness. This paper expands upon an ongoing systematic literature review to provide an in-depth analysis of how machine learning (ML) has been used to grade and give feedback on programming assignments. We conducted a backward snowball search using the ML papers from an ongoing systematic review and selected 27 papers that met our inclusion criteria. After selecting our papers, we analysed the skills graded, the preprocessing steps, the ML implementation, and the models' evaluations.We find that most the models are implemented using neural network-based approaches, with most implementing some form of recurrent neural network (RNN), including Long Short-Term Memory, and encoder/decoder with attention mechanisms. Some graders implement traditional ML approaches, typically focused on clustering. Most ML-based automated grading, not many use ML to evaluate maintainability, readability, and documentation, but focus on grading correctness, a problem that dynamic and static analysis techniques, such as unit testing, rule-based program repair, and comparison to models or approved solutions, have mostly resolved. However, some ML-based tools, including those for assessing graphical output, have evaluated the correctness of assignments that conventional implementations cannot.",10.1145/3587102.3588822,https://doi.org/10.1145/3587102.3588822
What Gets Them Talking? Identifying Catalysts for Student Engagement Within a Computing Ethics Course,"Li, Carol and Park, Su Min and Tsang, Jedidiah and Yan, Lisa",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"The expansion of undergraduate CS programs brings different forms of student identity, sociotechnical perspectives, and intersectionality into the classroom. These background factors affect student understanding of the world, and, consequently, their work in computing ethic classes. Instructors of computing ethics courses therefore must facilitate topics that are not only pertinent to modern technologies but that are also interesting for students from a range of backgrounds. In this work, we introduce a low-overhead, natural language processing tool that can assist instructors in extracting student talking points from over 600 discussion forum posts in a large-scale undergraduate computing ethics course. When compared to large language model approaches, this n-gram-based scripting tool is more effective in selecting popular quotes and summarizing course discussion. This tool is simple in implementation and can be easily adapted by instructors to prepare for classroom discussion.",10.1145/3641555.3705281,https://doi.org/10.1145/3641555.3705281
Not Just Novelty: A Longitudinal Study on Utility and Customization of an AI Workflow,"Long, Tao and Gero, Katy Ilonka and Chilton, Lydia B",Proceedings of the 2024 ACM Designing Interactive Systems Conference,2024,"Generative AI brings novel and impressive abilities to help people in everyday tasks. There are many AI workflows that solve real and complex problems by chaining AI outputs together with human interaction. Although there is an undeniable lure of AI, it is uncertain how useful generative AI workflows are after the novelty wears off. Additionally, workflows built with generative AI have the potential to be easily customized to fit users’ individual needs, but do users take advantage of this? We conducted a three-week longitudinal study with 12 users to understand the familiarization and customization of generative AI tools for science communication. Our study revealed that there exists a familiarization phase, during which users were exploring the novel capabilities of the workflow and discovering which aspects they found useful. After this phase, users understood the workflow and were able to anticipate the outputs. Surprisingly, after familiarization the perceived utility of the system was rated higher than before, indicating that the perceived utility of AI is not just a novelty effect. The increase in benefits mainly comes from end-users’ ability to customize prompts, and thus potentially appropriate the system to their own needs. This points to a future where generative AI systems can allow us to design for appropriation.",10.1145/3643834.3661587,https://doi.org/10.1145/3643834.3661587
Transforming Computer-Based Exams with BYOD: An Empirical Study,S\,Proceedings of the 24th Koli Calling International Conference on Computing Education Research,2024,"The assessment landscape in computing education is at a pivotal juncture, necessitating research-backed innovations to align with evolving pedagogical requirements. Paper-based exams, despite their historical prominence, present substantial limitations in assessing coding skills and knowledge. This paper rigorously interrogates these limitations and advocates for a paradigm shift towards computer-based assessments, with a particular focus on Bring Your Own Device (BYOD) configurations. It shows an implementation of a special exam mode in the Artemis learning platform, specifically designed for BYOD contexts with a process that is scalable to exams with more than thousand students. In a field study employing action research, we used Artemis in three separate large-scale exams, involving 920 students in total, and gathered both quantitative and qualitative data through an online survey. The empirical evaluation of the data reveals a marked preference among students for computer-based assessments in computing education, specifically when utilizing personal setups. Findings indicate a reduced possibility in instances of academic dishonesty as compared to remote exam environments. This research substantiates the potential of computer-based exams in BYOD scenarios to rectify the incongruence between learning activities and assessment methods, thereby making a significant contribution to enhancing learning outcomes in computing education following constructive alignment.",10.1145/3699538.3699560,https://doi.org/10.1145/3699538.3699560
From Play to Pedagogy: Discovering the Ecosystem of AI Educational Tools and Curricula,"Vahedian Movahed, Saniya and Martin, Fred",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"This paper explores the evolution of artificial intelligence (AI) and machine learning (ML) educational tools and curricula for children, describing a spectrum from playful exploration to structured pedagogy. We address three research questions: (RQ1) What themes are revealed in the literature on AI/ML for children? (RQ2) In what ways do the development of AI/ML tools and curricula co-evolve? (RQ3) How does the historical context of the field frame current work on AI/ML for children? We observe a co-evolution of tools and curricula, where researchers build new tools and curriculum developers adopt tools created by others. As tools prove successful, they become widely available and are adopted by a broad range of users. Additionally, we note instances where tool creators take on the role of curriculum developer. Recognizing the need for a clear overview of AI/ML educational resources, we introduce major themes of tools, tool-forward, and curriculum-forward works. These themes are designed to help educators, researchers, and curriculum designers in discerning the fundamental nature and potential applications of resources. By distinguishing tools that are standalone from those integrated into curricula, our framework supports strategic decisions in resource adoption and development. Drawing on the field's history, we outline a continuum of tools and platforms, from constructionist elements to interactive play environments.",10.1145/3724363.3729068,https://doi.org/10.1145/3724363.3729068
Teaching Digital Accessibility to Industry Professionals using the Community of Practice framework: An Experience Report,"Parthasarathy, P. D. and Joshi, Swaroop",Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training,2024,"Despite recent initiatives aimed at improving accessibility, the field of digital accessibility remains markedly behind contemporary advancements in the software industry, as many real-world software and web applications continue to fall short of accessibility requirements. A persisting skills deficit within the existing technology workforce has been an enduring impediment, hindering organizations from delivering truly accessible software products. This, in turn, elevates the risk of isolating and excluding a substantial portion of potential users. In this paper, we report lessons learned from a training program for teaching digital accessibility using the Communities of Practice (CoP) framework to industry professionals. We recruited 66 participants from a large multinational software company and assigned them to two groups: one participating in a CoP and the other using self-paced learning. We report experiences from designing the training program, conducting the actual training, and assessing the efficiency of the two approaches. Based on these findings, we provide recommendations for practitioners in Learning and Development teams and educators in designing accessibility courses for industry professionals.",10.1145/3639474.3640083,https://doi.org/10.1145/3639474.3640083
Improving User Engagement and Learning Outcomes in LLM-Based Python Tutor: A Study of PACE,"Shochcho, Muhtasim Ibteda and Rahman, Mohammad Ashfaq Ur and Rohan, Shadman and Islam, Ashraful and Heickal, Hasnain and Rahman, AKM Mahbubur and Amin, M. Ashraful and Ali, Amin Ahsan",Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems,2025,"Large Language Models (LLMs) are increasingly being adopted for educational applications, but sometimes, limited internet access and budget constraints restrict their accessibility. Small Language Models (SLMs) have emerged as viable alternatives, capable of providing effective tutoring in resource-constrained contexts. This paper introduces PACE (Python AI Companion for Enhanced Engagement), a system leveraging SLMs to deliver step-by-step guidance and adaptive feedback for teaching Python. An evaluation with varying levels of learners showed PACE’s effectiveness, achieving a System Usability Scale (SUS) score of 77.28. While participants were generally satisfied with its clarity and personalized feedback, they identified some areas for improvement, such as loss of context during lengthy conversations. This study examines (1) the PACE system’s effectiveness in programming education according to learners, (2) learners’ trust in PACE versus traditional resources, and (3) design recommendations to enhance engagement and learning outcomes. PACE contributes to advancing cost-effective, scalable programming education.",10.1145/3706599.3720240,https://doi.org/10.1145/3706599.3720240
How Do You Solve A Problem Like Recruitment? On The Hiring and Retention of Computing Academics,"Alshaigy, Bedour and Grande, Virginia and Kiesler, Natalie and Settle, Amber",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1,2024,"This paper critically examines persistent inequities in existing computing faculty hiring and retention practices, which gravely impact computing educators from marginalized groups. Throughout these processes, applicants fight against multiple systemic barriers, including but not limited to, biased job ads and discriminatory interview practices. The increasing use of generative AI tools to aid in tasks connected to the hiring process, such as writing recommendation letters, exacerbates these biases. The inequities persist despite global initiatives and legal mandates and serve as a direct contradiction to widespread institutional commitments to diversity and inclusion. By building on literature and the lived experiences of the SIGCSE community represented in a recent Technical Symposium session, we raise concerns about the different stages of this process, highlighting the importance of clear expectations and adequate support. The paper concludes with a call to align hiring practices with inclusive institutional values, requiring the academic community to reflect on and revise hiring policies for a more equitable future. It is of paramount importance to address the role of these practices in the erosion of marginalized communities from the computing education community, a marginalization that occurs in many different contexts and negatively impacts everyone involved.",10.1145/3649165.3703622,https://doi.org/10.1145/3649165.3703622
Bridging the Theory-Practice Gap in a Maintenance Programming Course: An Experience Report,"Ouhbi, Sofia",Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training,2024,"This paper presents our experience in teaching a maintenance programming course with the aim of bridging the gap between theory and practice, a recurring issue in previous course offerings. To achieve this goal, we implemented active learning strategies within an active learning classroom setting and redesigned the project work. Our approach involves peer learning and teamwork activities to cover various aspects of legacy code maintenance. For the project work, we adopted an open-ended approach that allowed students to choose their legacy code projects, which could be open-source software or a previous software project they had worked on. Analysis of students' feedback and project reports highlighted the effectiveness of our approach in bridging the gap between theory and practice. We believe that our approach had the potential to enhance students' engagement and critical thinking abilities, as well as improve practical maintenance skills relevant to their future careers.",10.1145/3639474.3640062,https://doi.org/10.1145/3639474.3640062
Mapping Coursework to Course Outcomes for CS Teachers Using Limited Data,"Christie, Aaja",Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2,2023,"The need for computing across different domains and industry segments has resulted in a significant shortage in the availability of computing professionals. To address this issue, interventions at the K-12 level, such as government policies requiring access to computer science classes, have become increasingly more common. Despite these interventions, major inconsistencies in high school computer science classes remain. The approach in this work seeks to remedy these inconsistencies by mapping coursework to specific course outcomes. This would make it possible for teachers to evaluate their own coursework to ensure it all contributes to the course outcomes without the need for standardizing class materials across school systems.",10.1145/3568812.3603450,https://doi.org/10.1145/3568812.3603450
Pair Programming with ChatGPT,"Chen, Xi and Liang, Jingsai",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"This poster explores the potential of ChatGPT to replace the traditional approach of pair programming in introductory computer science courses. Traditionally, two students collaborate as a driver and a navigator, periodically switching roles. Now, a student can pair up with ChatGPT, which offers an innovative approach to pair programming. This exploratory activity, which emphasizes collaboration and communication, provides step-by-step instructions for effectively interacting with ChatGPT during pair programming.This poster reflects on the advantages and limitations of using ChatGPT in pair programming. The main advantages of using ChatGPT include rapid responses, syntax error-free code generation, and flexibility in handling incomplete pseudocode. The primary limitations include the coding generation style, redundancy in responses, and challenges in understanding the code. Despite the advantages, it may still be valuable to have students work with human partners in certain situations, particularly for learning purposes.This poster proposes that ChatGPT is an invaluable tool for enhancing productivity and emphasizes the importance of becoming proficient in its use during students' college years. It also provides insights into the effective utilization of ChatGPT in pair programming and its preparation for future careers in programming and related fields.",10.1145/3626253.3635600,https://doi.org/10.1145/3626253.3635600
Automated Detection of AI-Obfuscated Plagiarism in Modeling Assignments,,Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training,2024,"Plagiarism is a widespread problem in computer science education, exacerbated by the impracticability of manual inspection in large courses. Even worse, tools based on large language models like ChatGPT have made it easier than ever to obfuscate plagiarized solutions. Additionally, most plagiarism detectors only apply to code, and only a few approaches exist for modeling assignments, which lack broad resilience to obfuscation attacks. This paper presents a novel approach for automated plagiarism detection in modeling assignments that combines automated analysis with human inspection. We evaluate our approach with real-world assignments and plagiarism obfuscated by ChatGPT. Our results show that we achieve a significantly higher detection rate for AI-generated attacks and a broader resilience than the state-of-the-art.",10.1145/3639474.3640084,https://doi.org/10.1145/3639474.3640084
Automated Coding Challenges Assembly Using Pre-trained Programming Language Models,"Lim, Yumi Chin Yin and Weng, Kai",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1,2024,"In programming language courses, many online platforms already feature extensive question banks. When teachers prepare course exercises, they need to select several programming problems of equivalent difficulty from the vast existing question bank so that different students can answer different but similar questions. These chosen problems are then assembled into a question pool, from which each student is randomly assigned a programming problem to complete. However, manually selecting problems and forming the pool can be extremely time-consuming due to the sheer volume of available problems. To address this, we propose an Automated Coding Challenge Assembly strategy to help teachers automatically identify similar yet distinct problems from large question banks. By analyzing the similarities in the code submitted by students, our method enables the automatic assembly of programming problems with equivalent difficulty levels. Experimental results have shown that the programming problems selected by this automated method exhibit high relevance and consistent difficulty, providing practical proof of our algorithm's effectiveness.",10.1145/3649165.3690107,https://doi.org/10.1145/3649165.3690107
Integrating Natural Language Prompting Tasks in Introductory Programming Courses,"Kerslake, Chris and Denny, Paul and Smith, David H. and Prather, James and Leinonen, Juho and Luxton-Reilly, Andrew and MacNeil, Stephen",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1,2024,"Introductory programming courses often emphasize mastering syntax and basic constructs before progressing to more complex and interesting programs. This bottom-up approach can be frustrating for novices, shifting the focus away from problem solving and potentially making computing less appealing to a broad range of students. The rise of generative AI for code production could partially address these issues by fostering new skills via interaction with AI models, including constructing high-level prompts and evaluating code that is automatically generated. In this experience report, we explore the inclusion of two prompt-focused activities in an introductory course, implemented across four labs in a six-week module. The first requires students to solve computational problems by writing natural language prompts, emphasizing problem-solving over syntax. The second involves students crafting prompts to generate code equivalent to provided fragments, to foster an understanding of the relationship between prompts and code. Most of the students in the course had reported finding programming difficult to learn, often citing frustrations with syntax and debugging. We found that self-reported difficulty with learning programming had a strong inverse relationship with performance on traditional programming assessments such as tests and projects, as expected. However, performance on the natural language tasks was less strongly related to self-reported difficulty, suggesting they may target different skills. Learning how to communicate with AI coding models is becoming an important skill, and natural language prompting tasks may appeal to a broad range of students.",10.1145/3649165.3690125,https://doi.org/10.1145/3649165.3690125
"Diverging assessments: What, Why, and Experiences","Sakzad, Amin and Paul, David and Sheard, Judithe and Brankovic, Ljiljana and Skerritt, Matthew P. and Li, Nan and Minagar, Sepehr and Simon and Billingsley, William",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"In this experience paper, we introduce the concept of 'diverging assessments', process-based assessments designed so that they become unique for each student while all students see a common skeleton. We present experiences with diverging assessments in the contexts of computer networks, operating systems, ethical hacking, and software development. All the given examples allow the use of generative-AI-based tools, are authentic, and are designed to generate learning opportunities that foster students' meta-cognition. Finally, we reflect upon these experiences in five different courses across four universities, showing how diverging assessments enhance students' learning while respecting academic integrity.",10.1145/3626252.3630832,https://doi.org/10.1145/3626252.3630832
Bridging Education and Development: IDEs as Interactive Learning Platforms,"Birillo, Anastasiia and Tigina, Mariia and Kurbatova, Zarina and Potriasaeva, Anna and Vlasov, Ilya and Ovchinnikov, Valerii and Gerasimov, Igor",Proceedings of the 1st ACM/IEEE Workshop on Integrated Development Environments,2024,"In this work, we introduce a novel approach to programming education - in-IDE courses implemented for IntelliJ-based IDEs via the JetBrains Academy Plugin. The primary objective of this approach is to address the challenge of familiarizing students with industrial technologies by moving all theory and practical materials to a professional IDE. This approach allows students to immediately use modern industrial tools as they are fully integrated into the learning process. We have already applied this approach in over 40 courses, and it successfully educates students across diverse topics such as Plugin Development, Algorithms, Data Analysis, and Language mastery in various programming languages, including Kotlin, Java, C++, and Python. Along with the paper, we are providing the community not only with a new way of learning and a set of ready-made courses but also a collection of helpful resources to assist educators in getting started with the plugin.",10.1145/3643796.3648454,https://doi.org/10.1145/3643796.3648454
Pensieve Discuss: Scalable Small-Group CS Tutoring System with AI,"Yang, Yoonseok and Liu, Jack and Zamfirescu-Pereira, J.D. and DeNero, John",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"Small-group tutoring in Computer Science (CS) is effective, but presents the challenge of providing a dedicated tutor for each group and encouraging collaboration among group members at scale. We present Pensieve Discuss, a software platform that integrates synchronous editing for scaffolded programming problems with online human and AI tutors, designed to improve student collaboration and experience during group tutoring sessions. Our semester-long deployment to CS61A at UC Berkeley demonstrated consistently high collaboration rates, positive feedback about the AI tutor's helpfulness, and increased satisfaction with the group tutoring experience. The use of our system was preferred over an interface lacking AI tutors and synchronous editing capabilities. Our experiences suggest that small-group tutoring sessions are an important avenue for future research in educational AI.",10.1145/3641555.3705244,https://doi.org/10.1145/3641555.3705244
AI Enhanced Learning: Powering Curated Videos with Generative Intelligence,"Gunawardena, Ananda and Chaturvedi, Naina",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"Instructional videos are becoming increasingly popular among computer science students. Over 78% of students frequently visit YouTube to find videos as supplement to their textbook or classroom instruction[1]. Recent surveys show that on average, 73% of students prefer having their instructors curate a supplemental video library to aid in their learning. Now, the emergence of generative AI is revolutionizing supplemental video instruction, enabling instructors to generate slides, recording scripts, and produce high-quality videos with deep search and embedded interactive activities.Generative AI also takes the student video learning to a new level by providing AI-generated video summaries, on-demand questions, and exploration of topics in greater depth. Integrating AI into standard videos greatly expands the possibilities of video-based learning. This workshop demonstrates how educators can enhance their existing video playlists by incorporating AI to increase student engagement and establish safety measures for AI use in education. By using dynamic dashboards, scheduled content, and gamified questions, instructors can maintain student focus.Drawing on insights from computer science courses taught at Princeton and Rutgers Universities, we will highlight the transformative potential of AI-enhanced videos in promoting active learning, particularly in large classes. We will discuss engagement strategies and real-time data visualizations applicable to any video platform. We will utilize the cubits.ai[2] platform, a Princeton University initiative that enhances the impact of computer science courses. The platform is free, and participants are encouraged to bring their own video playlists to curate them into AI-enabled collections by enhancing the student experience through integrated generative AI.",10.1145/3626253.3633418,https://doi.org/10.1145/3626253.3633418
Needs-Supportive Teaching Interventions in an Intro Computer Science Course: Exploring Impacts on Student Motivation and Achievement,"Hunter, Jessica and Bai, Elena and Alberini, Giulia and Robinson, Kristy A.",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"The instructor of a large, introductory computer science (CS) course at a public Canadian university implemented two interventions designed to support students' academic success and basic psychological needs as posited by self-determination theory (SDT). Interventions involved providing grading scheme choice for all students and sending targeted support emails to students who struggled on early term assessments. In keeping with SDT, we assessed the possible effect of these interventions on students' perceptions of competence (self-efficacy), autonomy, relatedness (via measures of instructor warmth), and final grades, by comparing the intervention cohort with a previous control cohort. Results indicate that all students in the intervention term may have benefited from grading scheme choice, as they earned higher final grades and felt more autonomous than the control group students. Moreover, struggling students who received support emails earned an average final grade 11.3% higher than struggling students in the control term. These students also performed closer to their non-struggling counterparts than those in the control group, reducing the achievement gap between early struggling and non-struggling students by 8.1%. Furthermore, even when controlling for past achievement, perceptions of self-efficacy and autonomy support positively predicted students' final grades across groups, with a small effect size. These results offer theoretical and practical insight into effective, light-touch teaching interventions which CS instructors can implement in large courses.",10.1145/3641554.3701852,https://doi.org/10.1145/3641554.3701852
Fostering Computational Thinking in Elementary Mathematics Instruction and Learning with the Support of Large Language Models,"Ylagan, Emma S. and Parekh, Heena P. and Das, Malisha and Dahshan, Mai",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 2,2025,"Computational thinking (CT) integration in elementary mathematics engages young learners in the decomposition of complex problems and the construction of iterative approaches to mathematical thinking. To effectively integrate MATH+CT, we need to build teachers' capacity in developing knowledge of CT concepts and creating Math+CT activities. This can positively influence students' mathematical outcomes and their readiness for computer science (CS) in middle and high school. Although various professional development programs aim to build teachers' CT knowledge, limited research exists on how teachers apply this knowledge to classroom-based Math+CT activities. Simultaneously, the rapid improvement of large Language Models (LLMs) creates a catalyst for building an innovative resource space to support elementary teachers' integration of MATH+CT in their existing school or district curriculum. In this poster, we present a tool that leverages LLMs to support teachers in creating Scratch programs designed to explore and deepen students' understanding of mathematical concepts.",10.1145/3724389.3730802,https://doi.org/10.1145/3724389.3730802
"Mentoring, AI, and the End of Affirmative Action: Connecting with SIGCSE Reads","Veilleux, Nanette and Bates, Rebecca and Goldsmith, Judy and Summet, Valerie",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"This Birds of a Feather will begin with a high-level overview of the SIGCSE Reads 2024 books and then quickly move to discussion about mentoring students in the era of large language models and ChatGPT, including how students may value the curriculum differently, how learning outcomes may change, and how we can support students and alumni/ae as they work with rapidly changing job and learning expectations. We expect that many of the sessions at SIGCSE will address the radical shifts in learning outcomes and curricular changes due to LLMs. We will not focus on the particulars of these changes, but rather on mentoring in this time with Sister Resisters: Mentoring Black Women on Campus by Janie Victoria Ward and Tracy L. Robinson-Wood as a resource. How do we guide our students through the curriculum upheaval triggered by shifting learning outcomes? How do we help them prepare for the new instantiation of computer science? This BOF is the primary session for SIGCSE Reads. We encourage discussion of this year's fiction works The Lifecycle of Software Objects by Ted Chiang and",10.1145/3626253.3635380,https://doi.org/10.1145/3626253.3635380
Reconstructing the Digital – An Architectural Perspective for Non-Engineers (Discussion Paper),"Winkelnkemper, Felix and Schulte, Carsten",Proceedings of the 23rd Koli Calling International Conference on Computing Education Research,2024,"Knowing and understanding the world of digital artefacts we are living in is a requirement for everyone today, regardless of their general interest in technology. Computer science education, however, often treats pupils as if they all wanted to become engineers. Educational models of computer science are rather not targeted at understanding the behaviour of the digital world, but at constructing it. Our paper complements such classical approaches with an Ontology of the Digital as an approach which reconstructs digital artefacts and thereby creates a model which helps to understand and explain the technological potentials of digital artefacts without relying on minute details of the engineering discipline of computing.",10.1145/3631802.3631826,https://doi.org/10.1145/3631802.3631826
Sieving Coding Assignments Over Submissions Generated by AI and Novice Programmers,"Jegourel, Cyrille and Ong, Jung Yi and Kurniawan, Oka and Meng Shin, Lim and Chitluru, Kushat",Proceedings of the 24th Koli Calling International Conference on Computing Education Research,2024,"In the era of AI tools like ChatGPT and GitHub Copilot, and with the numerous online resources, computer science education faces the challenge of students potentially submitting plagiarised coding assignments or assignments generated by these technologies. Distinguishing between AI-generated and human-written text is notoriously difficult. In this study, we applied two text distance algorithms, commonly used for machine translation and document comparisons, to detect similarities between various computer Python code submissions and employed hierarchical clustering to analyze them from both AI tools and human programmers. Our results indicate that the distances to the cluster representatives can effectively predict whether a code submission is generated by AI or by novice programmers, achieving an accuracy of over 90%. These findings demonstrate the significant potential of text distance algorithms in identifying the origin of coding submissions, whether generated by AI or by novice programmers.",10.1145/3699538.3699569,https://doi.org/10.1145/3699538.3699569
Comparing Feedback from Large Language Models and Instructors: Teaching Computer Science at Scale,"Nguyen, Ha and Stott, Nate and Allan, Vicki",,2024,"Large language models (LLMs) can provide formative feedback in programming to help students improve the code they have written. We investigate the use of LLMs (GPT-4) to provide formative code feedback in a sophomore-level computer science (CS) course on data structures and algorithms. In three quizzes on recursion, half of the students randomly received GPT-4's feedback, while the other half received feedback from the course instructor. Students resubmitted their code based on the provided feedback. We found that students in the LLM-feedback condition scored higher in resubmissions than those receiving feedback from the instructor. Students perceived the two types of feedback as equally supportive of guiding resubmissions. We discuss the implications of using LLMs to provide formative feedback at scale in CS instruction.",10.1145/3657604.3664660,https://doi.org/10.1145/3657604.3664660
Modernizing the CS Introductory Sequence with Parallel and Distributed Computing (and some AI),"Sussman, Alan and Prasad, Sushil and Bunde, David P. and Spacco, Jaime and Gannod, Gerald and Crockett, April Renee and Vaidyanathan, Ramachandran",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"Parallel and distributed computing (PDC) has become pervasive in all aspects of computing, so it is essential that students include parallelism and distribution in the computational thinking that they apply to problem solving, from the beginning of their computing education. With all computing devices that students use having multiple cores as well as a GPU in many cases, many students' favorite applications use multiple cores and/or distributed processors. However, we are still teaching them to solve problems using only sequential thinking. Why?This hands-on tutorial will demonstrate how easy it is to open students' eyes to exploiting concurrency in problem solving. You will participate in plugged and unplugged activities that will help students to recognize examples of PDC concepts and concurrency in the world around them. We introduce plugged and unplugged curriculum modules that have been successfully integrated in existing computing classes at multiple institutions. We will also discuss recent efforts at integrating AI methods, including LLMs, into introductory classes.A laptop capable of running a C/C++ compiler, a Java virtual environment, and a Python interpreter is needed to fully participate in activities. However, attendees may learn the core concepts without a laptop. The activities and curriculum modules have been used successfully to teach PDC concepts in early computing courses and will be available after the workshop. Participants will receive a stipend of 400 to defray their cost of registration and one-night hotel stay. The CDER center will also have a booth in the exhibition hall for additional support.",10.1145/3641555.3704769,https://doi.org/10.1145/3641555.3704769
The Innovative Development of Artificial Intelligence and STEM Education-Cognition and Practice,"Zheng, Qinghua",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1,2024,"Artificial intelligence has emerged as a transformative force, driving productivity and shaping new forms of education. The future of education will be characterized by interactive learning, the blending of virtual and physical environments, and personalized learning experiences. The key to empowering science education with AI lies in creating new learning scenarios and applications, such as immersive teaching, personalized services, and comprehensive assessments. It is essential to understand the principles and objectives of talent development, emphasizing the integration of theoretical research and practical engineering. Furthermore, it is important to explore the mechanisms of the integrated development of AI and science education, as well as the scientific and technological issues involved. We briefly discuss three viewpoints. STEM education is the fundamental way to cultivate innovative talents. Science education, namely STEM education, conforms to the basic laws of historical materialism and the principle that science and technology are the primary productive forces. The purpose of STEM is to teach the fundamental methods for understanding, describing, transforming, and constructing the world. The key to empowering scientific education with AI lies in new scenarios and new applications. In the field of education, AI empowers the processes of teaching, learning, assessment, management, and services. In terms of engineering, knowledge graphs combined with LLMs represent a new key to personalized tutoring. AI+ is also creating new scenarios and applications, such as autonomous infrastructure inspection and intelligent diagnosis with micro-nano robots. The key to the integration of AI with STEM education lies in teachers. AI will empower education but cannot replace teachers. Teachers who understand how to use AI may replace those who do not, enabling a new form of intelligence that surpasses the limitations of human intelligence through human-machine collaboration.",10.1145/3649165.3699862,https://doi.org/10.1145/3649165.3699862
Feedback Literacy: Holistic Analysis of Secondary Educators' Views of LLM Explanations of Program Error Messages,"Cucuiat, Veronica and Waite, Jane",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"The implications of using large language model (LLM) tools for learning to program at secondary school level are largely unknown, and yet there is pressure for teachers to engage with these. To start addressing this gap, we investigated: RQ1: What are secondary educators' views on the potential classroom use of LLM program error message explanations? RQ2: In what ways can a feedback literacy perspective support the analysis of educators' views of potential classroom use of LLM program error message explanations? The responses of eight expert secondary school educators were gathered during a semi-structured, activity-based interview and qualitatively analysed. Fifteen themes were derived from their commentary, of which ten corresponded to enhanced program error message (PEM) guidelines. Yet, all themes correlated to feedback literacy theory, providing a more holistic view. The analysis revealed that educators preferred LLM explanations to guide and develop understanding rather than tell, that students should be supported to make judgements and action LLM-generated feedback. Combining PEM guideline and feedback literacy findings, we suggest augmented IDEs should be designed with educators and students in mind, and teacher professional development (PD) is needed. Research is needed to compare our findings with a wider range of educators and investigate what feedback literacy means for resource design, PD, and classroom practice in secondary and undergraduate contexts.",10.1145/3649217.3653595,https://doi.org/10.1145/3649217.3653595
Assessing the Effectiveness of ChatGPT in Secure Code Development: A Systematic Literature Review,"Bouzid, Rezika and Khoury, Rapha\",ACM Comput. Surv.,2025,"ChatGPT, a Large Language Model (LLM) maintained by OpenAI, has demonstrated a remarkable ability to seemingly comprehend and contextually generate text. Among its myriad applications, its capability to autonomously generate and analyze computer code stands out as particularly promising. This functionality has piqued substantial interest due to its potential to streamline the software development process. However, this technological advancement also brings to the forefront significant apprehensions concerning the security of code produced by LLMs. In this paper, we survey recent research that examines the use of ChatGPT to generate secure code, detect vulnerabilities in code, or perform other tasks related to secure code development. Beyond categorizing and synthesizing these studies, we identify important insights into ChatGPT’s potential impact on secure programming. Key findings indicate that while ChatGPT shows great promise as an aid in writing secure code, challenges remain. Its effectiveness varies across security tasks, depending on the context of experimentation (e.g., programming language, CWE, code length, etc.) and the benchmark used for comparison—whether against other LLMs, traditional analysis tools, or its own versions. The overall trend indicates that GPT-4 consistently surpasses its predecessor in most tasks.",10.1145/3744553,https://doi.org/10.1145/3744553
Can Generative Pre-trained Transformers (GPT) Pass Assessments in Higher Education Programming Courses?,"Savelka, Jaromir and Agarwal, Arav and Bogart, Christopher and Song, Yifan and Sakr, Majd",Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1,2023,"We evaluated the capability of generative pre-trained transformers (GPT), to pass assessments in introductory and intermediate Python programming courses at the postsecondary level. Discussions of potential uses (e.g., exercise generation, code explanation) and misuses (e.g., cheating) of this emerging technology in programming education have intensified, but to date there has not been a rigorous analysis of the models' capabilities in the realistic context of a full-fledged programming course with diverse set of assessment instruments. We evaluated GPT on three Python courses that employ assessments ranging from simple multiple-choice questions (no code involved) to complex programming projects with code bases distributed into multiple files (599 exercises overall). Further, we studied if and how successfully GPT models leverage feedback provided by an auto-grader. We found that the current models are not capable of passing the full spectrum of assessments typically involved in a Python programming course (&lt;70% on even entry-level modules). Yet, it is clear that a straightforward application of these easily accessible models could enable a learner to obtain a non-trivial portion of the overall available score (&gt;55%) in introductory and intermediate courses alike. While the models exhibit remarkable capabilities, including correcting solutions based on auto-grader's feedback, some limitations exist (e.g., poor handling of exercises requiring complex chains of reasoning steps). These findings can be leveraged by instructors wishing to adapt their assessments so that GPT becomes a valuable assistant for a learner as opposed to an end-to-end solution.",10.1145/3587102.3588792,https://doi.org/10.1145/3587102.3588792
On a Time Crunch: Examining Learning Outcomes Within a One Unit Computing Ethics Course,"Tsang, Jedidiah and Li, Carol and Park, Su Min and Yan, Lisa",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"This study examines the challenges and opportunities of teaching computing ethics within the context of a large, low-workload, standalone course. CS199 is a one-unit, pass/fail computing ethics course designed to provide students with exposure to a wide array of topics and promote critical peer-based engagement. We leverage submitted work via Question, Quote, Comment, and Replies (QQCRs) and podcasts to facilitate discussions outside the classroom. While QQCRs have shown promise in promoting engagement and exposing students to diverse perspectives, limitations remain in stimulating deeper critiques of the material. We reflect on the effectiveness of asynchronous discussion and its alignment with broader learning goals in computing ethics education.",10.1145/3641555.3705223,https://doi.org/10.1145/3641555.3705223
Automatically Generating CS Learning Materials with Large Language Models,"MacNeil, Stephen and Tran, Andrew and Leinonen, Juho and Denny, Paul and Kim, Joanne and Hellas, Arto and Bernstein, Seth and Sarsa, Sami",Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2,2023,"Recent breakthroughs in Large Language Models (LLMs), such as GPT-3 and Codex, now enable software developers to generate code based on a natural language prompt. Within computer science education, researchers are exploring the potential for LLMs to generate code explanations and programming assignments using carefully crafted prompts. These advances may enable students to interact with code in new ways while helping instructors scale their learning materials. However, LLMs also introduce new implications for academic integrity, curriculum design, and software engineering careers. This workshop will demonstrate the capabilities of LLMs to help attendees evaluate whether and how LLMs might be integrated into their pedagogy and research. We will also engage attendees in brainstorming to consider how LLMs will impact our field.",10.1145/3545947.3569630,https://doi.org/10.1145/3545947.3569630
"Literature Mapping: A Scaffolded, Scalable, Low-Overhead Undergraduate Research Experience","Harrington, Brian and Kulkarni, Aditya and Nalluri, Rohita and Vadarevu, Anagha and Zavaleta Bernuy, Angela",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"There is a wealth of evidence that involving undergraduate students in research has positive impacts in a variety of areas, from representation and retention to outcomes and self-efficacy. However, developing and growing an undergraduate research program can be daunting, especially for institutions that do not have a large existing research enterprise. In this work, we detail a program that revolves around student-developed literature maps to help students gain the ability to read and assess research papers in a way that is accessible, robust, and requires relatively little faculty overhead. We further detail how this program has been run through 4 iterations, with a total of 47 students producing 5 posters or short papers, and 3 full papers. In this work, we provide our experiences using literature mapping projects to boot-strap an undergraduate research program and provide quantitative and qualitative analysis of the students who have participated. All of the materials, including sample spreadsheets, and scripts to generate LaTeX tables and figures are included for anyone wishing to undertake a literature mapping project of their own.",10.1145/3641554.3701938,https://doi.org/10.1145/3641554.3701938
Working with Large Code Bases: A Cognitive Apprenticeship Approach to Teaching Software Engineering,"Shah, Anshul and Yu, Jerry and Tong, Thanh and Soosai Raj, Adalbert Gerald",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"Prior work has highlighted the gap between industry expectations for recent university graduates and the abilities those recent graduates possess. These works have even specifically recommended that students be given the opportunity to work on large, pre-existing code bases in their undergraduate career. This paper presents our experience teaching a newly-created course calledWorking with Large Code Bases. Guided by a Cognitive Apprenticeship approach to provide an authentic classroom experience that emphasizes the implicit processes and techniques involved in real-world software engineering, the course serves as a practical introduction to the skills and workflow involved in navigating and understanding a large code base. The goal of this experience report is to provide the motivation for key course design decisions, an overview of the course content, and a detailed description of key course components. We present student feedback indicating improved confidence in navigating a large code base and course outcomes related to specific tools and techniques students used in the course. Finally, we provide the full set of course materials we used and actionable recommendations for instructors to administer this course at their own institution, even with limited TA support.",10.1145/3626252.3630755,https://doi.org/10.1145/3626252.3630755
Moving What's in the CS Curriculum Forward: A Proposition to Address Ten Wicked Curricular Issues,"Blumenthal, Richard and Blumenthal, Johanna",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Every decade, a Steering Committee convenes tasked with creating new computer science curricular recommendations. As they work, they are faced with a plethora of wicked curricular issues and a short timeline to resolve these issues. A systemic literature review of the ten years preceding CS2023 reveals a small number of publications focused on curricular issues. Intentional discussion among the education community is ideal for addressing these wicked issues. Towards this end, ten unsettled representative wicked curricular issues faced by the CS2023 Steering Committee are introduce with the aim of motivating the community to engage in increased and intentional formal discussions regarding these issues. Preserving these discussions will improve the next curriculum. A framework for structuring such discussions is also offered.",10.1145/3641554.3701924,https://doi.org/10.1145/3641554.3701924
Evaluating the Pedagogical Impact of Large Language Models on Programming Skills in Higher Education,"Crocetti, Giancarlo and Bak, Seonwoo and Noory, Naqib A. and Vautor-Laplaceliere, Daena D.",J. Comput. Sci. Coll.,2025,"This empirical study investigated the impact of Generative AI (GenAI) tools, particularly large language models (LLMs), on college students' Python programming skills in a graduate-level data science course. Using a pretest-posttest methodology and accounting for variables like prior programming experience, the research examined how guided LLM usage affected students' self-assessed programming abilities. The findings revealed that while LLMs positively influenced students' capacity to develop complex applications, work with Python libraries, and write quality code, they had no significant impact on students' grasp of fundamental Python concepts or their general comfort with the language. These results suggest that LLMs serve as effective tools for advancing practical programming skills but cannot substitute for the foundational programming knowledge that must be developed through traditional learning.",,
Restorying with AI Art among Latinx Elementary Students,"Garcia, Leiny and Ojeda-Ramirez, Santiago and Warschauer, Mark",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"The Latinx community is underrepresented in tech-oriented fields, which aligns with the lack of culturally relevant learning experiences in CS for Latinx youth, hindering their ability to conceptualize technology as a tool for transformation and vehicle for cultural expression. This study takes on a restorying approach at the elementary level, where 9 fourth-grade students engaged in focus group discussions over three days to generate prompts for a generative AI art. Through the lens of restorying, the prompts had students conceptualize a future with a focus on their Mexican-American heritage, local community, and technology. The study revealed that students associated their heritage with symbolic representations such as food and music, and characterized the community as a commercialized space while also emphasizing locations conducive to family-oriented activities. As a result, technology in community spaces was associated with consumerism. However, when envisioning a futuristic, transformed community, they made deeper connections between the role of technology in the community, making intricate connections between community improvements and technology-based solutions. This underscores the need for computing education to dedicate time for young learners to reflect on the role technology has on their current culture and community to make deeper connections.",10.1145/3626253.3635618,https://doi.org/10.1145/3626253.3635618
Leveraging or Limiting: Strategies and Implications of ChatGPT Use by Undergraduate TAs in Large CS2 Courses,"Rahman, Farzana",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"As AI tools like ChatGPT become more prevalent in educational settings, their potential to assist undergraduate teaching assistants (uTAs) in large Computer Science 2 (CS2) courses presents both opportunities and challenges. This work focuses on how ChatGPT can be strategically utilized by uTAs during office hours to enhance student support, particularly in complex topics such as data structures, algorithm development, and object-oriented programming. We explored effective strategies for uTAs to use ChatGPT in ways that promote deeper student understanding without compromising the development of independent problem-solving skills. Key strategies include leveraging ChatGPT for real-time code debugging assistance, offering alternative approaches to solving coding problems, comparing and critiquing self and AI generated documentation, and code reviewing. This work also identifies potential challenges, such as the risk of students or uTAs becoming overly dependent on AI-generated solutions and the possibility of inaccurate or incomplete responses from the AI. Hence, our findings highlight the dual role of ChatGPT as both an asset and a potential hindrance, depending on how it is utilized. To mitigate these risks, we propose a set of best practices that ensure ChatGPT enhances, rather than replaces, the uTA's role as a facilitator of learning. The findings from this research provide valuable insights into how uTAs can integrate AI tools thoughtfully into office hours to offer more effective support, ultimately improving student engagement and learning outcomes in large-scale CS2 courses.",10.1145/3641555.3705066,https://doi.org/10.1145/3641555.3705066
Teaching Assistants' Experiences of and Opinions on CS Ethics,"Barkhuff, Grace and Pruitt, Ian",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"Computer Science (CS) ethics coursework is required at many institutions for undergraduate CS majors. However, little is known about how students perceive the addition of this topic into the CS curriculum which is otherwise largely technical in nature. To understand perceptions of CS ethics as a course, we included questions about CS ethics instruction on a survey of 88 graduate and undergraduate teaching assistants (TAs) at two institutions in the United States. We found that learning CS ethics was not a universal experience for all TAs, but that a majority of TAs felt that CS ethics is a vital curricular topic. We recommend further research with a wider study population to better understand the perceptions of students of CS ethics coursework.",10.1145/3641555.3705261,https://doi.org/10.1145/3641555.3705261
"Testing, Socializing, Exploring: Characterizing Middle Schoolers’ Approaches to and Conceptions of ChatGPT","Belghith, Yasmine and Mahdavi Goloujeh, Atefeh and Magerko, Brian and Long, Duri and Mcklin, Tom and Roberts, Jessica",Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems,2024,"As generative AI rapidly enters everyday life, educational interventions for teaching about AI need to cater to how young people, in particular middle schoolers who are at a critical age for reasoning skills and identity formation, conceptualize and interact with AI. We conducted nine focus groups with 24 middle school students to elicit their interests, conceptions of, and approaches to a popular generative AI tool, ChatGPT. We highlight a) personally and culturally-relevant topics to this population, b) three distinct approaches in students’ open-ended interactions with ChatGPT: AI testing-oriented, AI socializing-oriented, and content exploring-oriented, and 3) an improved understanding of youths’ conceptions and misconceptions of generative AI. While misconceptions highlight gaps in understanding what generative AI is and how it works, most learners show interest in learning about what AI is and what it can do. We discuss the implications of these conceptions for designing AI literacy interventions in museums.",10.1145/3613904.3642332,https://doi.org/10.1145/3613904.3642332
Empowering Children’s AI Literacy Through Co-Creating Stories with LLM,"Han, Ariel and Han, Shenshen",Proceedings of the 24th Interaction Design and Children,2025,"As AI becomes increasingly embedded in children’s daily lives, it is essential to cultivate AI literacy among young learners. To address this need, we explored the potential of a Large Language Model (LLM)-based interactive storytelling platform, AIStoryBot, designed to foster AI literacy through collaborative story creation. In a study involving 12 students aged 8 to 14, we examined how narrative-based learning can enhance students’ motivation, confidence, and understanding of AI concepts. Data were collected through pre- and post-surveys and semi-structured interviews. Findings reveal that AIStoryBot increased students’ perceived motivation and AI efficacy while promoting constructive student-AI interactions. However, limitations were noted regarding student agency, open-ended exploration, and a deeper understanding of AI functionality. Students emphasized the need for extended, hands-on activities to connect abstract AI concepts to real-world applications. This research highlights the potential of narrative-based platforms to engage learners in AI literacy and provides insights into the instructional and technical design of AI-driven educational tools that foster active learning, critical thinking, and student agency.",,https://doi.org/10.1145/3713043.3731520
An Educational Approach to Introduce Theory of Computation in Social Sciences and Economics Degrees Using Impossibility,,Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"Students in social sciences or economics programs with computer science and mathematics components, including data structures and algorithms, often lack theoretical computer science background. In fields such as Economics, Sociology and Politics, CS Theory topics, in particular proofs of impossibility by contradiction concerning algorithmic undecidability, can be useful in understanding the computability (or lack thereof) of concepts such as voting theory, social choice or economic equilibrium. The objective of this paper is to develop an educational approach that can bridge this gap in knowledge of presenting computability topics to students of social sciences and economics during their study of CS subjects in data structures and algorithms. The introduction of Theory of Computation issues around impossibility and undecidability results allows students to acquire computational thinking skills and the ability to reason around paradoxes, with which they can deepen and raise computability questions in later courses on concepts related to social sciences and economics. We have analyzed the performance of students to conclude that the presentation of theoretical computing results of impossibility increases students' academic performance and motivation in their CS education, and their computational view of traditional social sciences and economics problems.",10.1145/3724363.3729030,https://doi.org/10.1145/3724363.3729030
Perspectives on Computer Science Curricula 2023 (CS2023),"Raj, Rajendra K. and Becker, Brett A. and Goldweber, Michael and Jalote, Pankaj",Proceedings of the ACM Conference on Global Computing Education Vol 2,2023,"This panel examines Computer Science Curricula 2023 (CS2023) from different perspectives. All panelists serve on the CS2023 steering committee and have an intimate understanding of CS2023. The moderator will lay out its overall vision and structure while panelists will emphasize three major perspectives of CS education: software development fundamentals; systems development; and the increased role of societal, ethical, and professional aspects crucial to a modern CS graduate. Strong interdependencies exist between these perspectives, along with tensions arising from how much can be squeezed into a tight undergraduate CS curriculum. Attendees will take home an understanding of the approach taken by the CS2023 task force, the constraints on curriculum design, and how best to use the CS2023 guidelines to educate the next generation of CS graduates.",10.1145/3617650.3624928,https://doi.org/10.1145/3617650.3624928
The Trees in the Forest: Characterizing Computing Students' Individual Help-Seeking Approaches,"Ko, Shao-Heng and Stephens-Martinez, Kristin",Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1,2024,"Background and Context. Academic help-seeking is vital to post-secondary computing students’ effective learning. However, most empirical works in this domain study students’ help resource selection and utilization by aggregating the entire student body as a whole. Moreover, existing theoretical frameworks often implicitly assume that whether/how much a student seeks help from a specific resource only depends on context (the type of help needed and the properties of the resources), not the individual student. Objectives. To address the gap, we seek to investigate individual computing students’ help-seeking approaches by analyzing what help-seeking characteristics are individual-driven (and thus stay consistent for the same student across different course contexts) and what are context-driven. Method. We analyzed N = 597 students’ survey responses on their help resource utilization as well as their actual help-seeking records across 6 courses. We examined relations between individual students’ frequency-based help usage metrics, type-of-help requested in office/consulting hours, self-reported order of ideal help resource usage, and their collaboration inclination in small-scale sections. Findings. We found that students’ frequency-based help metrics and their order of ideal help resource usage stays relatively consistent across different course contexts, and thus may be treated as part of students’ individual help-seeking approaches. On the other hand, the type of help students seek in office/consulting hours and how much they collaborate with peers in small sections do not seem to stay consistent across different contexts and thus might be deemed more context-driven than individual-driven. Implications. Our findings reveal that part of students’ help-seeking characteristics is individual-driven. This opens up a possibility for institutions to track students’ help-seeking records in early/introductory courses, so that some preliminary understanding of students can be acquired before they enter downstream courses. Our insights may also help instructors identify which part of students’ help-seeking behavior are more likely to be influenced by their course context and design.",10.1145/3632620.3671099,https://doi.org/10.1145/3632620.3671099
LLMs in Open and Closed Book Examinations in a Final Year Applied Machine Learning Course (Early Findings),"Quille, Keith and Becker, Brett A. and Faherty, Roisin and Gordon, Damien and Harte, Miriam and Hensman, Svetlana and Hofmann, Markus and Nolan, Keith and O'Leary, Ciaran",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2,2024,"This research has three prongs, with each comparing open- and closed-book exam questions across six years (2017-2023) in a final year undergraduate applied machine learning course. First, the authors evaluated the performance of numerous LLMs, compared to student performance, and comparing open and closed book exams. Second, at a micro level, the examination questions and categories for which LLMs were most and least effective were compared. This level of analysis is rarely if ever, discussed in the literature. The research finally investigates LLM detection techniques, specifically their efficacy in identifying replies created wholly by an LLM. It considers both raw LLM outputs and LLM outputs that have been tampered with by students, with an emphasis on academic integrity. This study is a staff-student research collaboration, featuring contributions from eight academic professionals and six students.",10.1145/3649405.3659514,https://doi.org/10.1145/3649405.3659514
Fine-Tuning AI to Assist in Building Curriculum for the CIA Triad and Cyber Kill Chain,"Flores, Paige and Kaza, Siddharth and Taylor, Blair",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2,2024,"Educators face the continuous challenge of updating their teaching materials with the fast-paced changes in cybersecurity and integrating emerging topics into their existing content. This work presents the development progress of a cybersecurity curriculum fine-tuned Large Language Model (LLM) designed to assist educators in creating engaging curricular materials for introductory cybersecurity topics. Recent advancements in Natural Language Processing (NLP) and the increased number of openly available LLMs like OpenAI's GPT and Meta's Llama present an opportunity to fine-tune these models for specific domains like cybersecurity. The fine-tuned LLMs offer a potential solution by reducing the amount of work necessary to regularly update curricular content, including lab assignments, assessments, in-class activities, and other additional resources for both synchronous and asynchronous classrooms.",10.1145/3649405.3659495,https://doi.org/10.1145/3649405.3659495
"Secondary Students' Emerging Conceptions of AI: Understanding AI Applications, Models, Engines and Implications","Whyte, Robert and Kirby, Diana and Sentance, Sue",Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research,2024,"Despite the growing use of AI technologies, there is limited empirical evidence of secondary students’ understanding of AI. Gaining insights into ways in which this might be influenced by their everyday engagement with these tools can support the teaching of AI, including the design of educational resources. The SEAME framework proposes four dimensions for thinking about AI: (i) the social and ethical (SE) implications of AI; (ii) its use in applications (A); (iii) how models (M) are trained; and (iv) the underlying engines (E) used. In this paper, we investigate students’ emerging conceptions of AI and how these can be understood through classification using an appropriate framework. Drawing on data from 474 secondary and college students (11–18), we found that students mostly focused on the applications of AI, followed by its social and ethical implications. We found evidence that students held some primarily accurate conceptions of how AI works, such as how models are trained using large datasets and how human behaviours are simulated (e.g. talking, problem-solving). Specific conceptions relating to generative AI tools were also observed, including the ability to generate content and response to prompts. Conversely, we found students held naive conceptions relating to AI systems having agency or emotions. We argue that efforts to promote accurate conceptions of AI should build on students’ conceptions and take into account how language and representation are used (e.g. anthropomorphism). The results of this study have implications for educators, resource developers and researchers.",10.1145/3689535.3689552,https://doi.org/10.1145/3689535.3689552
The Case for LLM Workshops,"Bopp, Chris and Foerst, Anne and Kellogg, Brian",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"Large Language Models (LLMs) are radically changing the academic landscape. Many professors are unaware of how LLMs work and are therefore unsure how to incorporate them in their teaching. This is problematic as students will use them anyway. In this paper, we outline our institution as a case study for a curricular initiative. We develop an intellectual framework for creating workshops for faculty at small liberal arts universities. We base their development on the literature we have analyzed and discussed as a group. Our approach is to address our colleagues across a variety of different disciplines and teach them the responsible use of LLMs in the classroom. We also teach our colleagues how to modify assignments to make them, to some extent, LLM proof. This includes adding personalized elements, and including LLM designed parts explicitly, such as article summaries. We also design a syllabus policy about the responsible use of LLMs. We present philosophical and ethical challenges and teach a list of other actionable items. We ultimately support the use of LLMs in academia but seek to teach our colleagues how they can guide students to use them mindfully and responsibly.",10.1145/3626252.3630941,https://doi.org/10.1145/3626252.3630941
Assessing Team-Based Capstone Projects: Challenges and Recommendations,"Hooshangi, Sara and Shakil, Asma and Riddle, Steve and Aydin, Ilknur and Nasir, Nayla and Parupudi, Tejasvi and Rehman, Attiqa and Scott, Michael James and Vahrenhold, Jan and Weerasinghe, Amali and Wu, Xi",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 2,2025,"Team-based capstone projects are vital in preparing computer science students for real-world challenges by fostering teamwork, communication, and industry-relevant technical skills. However, their assessment presents challenges, such as aligning academic criteria with other stakeholders' expectations, evaluating individual contributions within teams, fairly addressing the diverse skills required, and determining the appropriate level of external partners' involvement in the evaluation process. Moreover, the high stakes of these projects necessitate transparent and equitable assessment methods that all stakeholders perceive as fair. Our working group (WG) aims to address the challenges of assessing capstone projects by examining the perspectives of instructors, students, and other stakeholders to ensure fair and effective evaluation. Building on insights from our previous WG and a comprehensive review of the literature, we will employ a mixed-methods approach to explore the issues faced by various stakeholders in assessing capstone projects and to capture both common challenges experienced (quantitative), and delve into nuanced individual experiences (qualitative). By conducting this research in a multi-national, multi-institutional context, we aim to capture a diverse range of global perspectives while accounting for the variation in capstone courses. Our goal is to provide actionable recommendations that enhance assessment practices, improve learning outcomes, and foster effective team collaboration in team-based capstone courses, ultimately preparing students for real-world challenges.",10.1145/3724389.3731281,https://doi.org/10.1145/3724389.3731281
Propagating Large Language Models Programming Feedback,"Koutcheme, Charles and Hellas, Arto",,2024,"Large language models (LLMs) such as GPT-4 have emerged as promising tools for providing programming feedback. However, effective deployment of LLMs in massive classes and Massive Open Online Courses (MOOCs) raises financial concerns, calling for methods to minimize the number of calls to the APIs and systems serving such powerful models. In this article, we revisit the problem of 'propagating feedback' within the contemporary landscape of LLMs. Specifically, we explore feedback propagation as a way to reduce the cost of leveraging LLMs for providing programming feedback at scale. Our study investigates the effectiveness of this approach in the context of students requiring next-step hints for Python programming problems, presenting initial results that support the viability of the approach. We discuss our findings' implications and suggest directions for future research in optimizing feedback mechanisms for large-scale educational environments.",10.1145/3657604.3664665,https://doi.org/10.1145/3657604.3664665
What Does It Take to Support Problem Solving in Programming Classrooms? A New Framework from the K-12 Teacher Perspective,,Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems,2025,"Developers rarely build programming environments that help secondary teachers support student learning. We interviewed 11 K12 teachers to discover how they support students learning to program and how tools might assist their teaching practice. Based on thematic analysis and organizing teacher activities around student actions, we have derived a new framework that can be used to design a programming learning system to support teachers. Our results suggest that teachers structure their activities based on their ideals about effective programming teaching and learning, and student problem solving and help-seeking processes. Therefore, our framework relates the themes we discovered about teacher activities to ideals and student problem solving in a time-based framework that can inform the design for new programming learning systems.",10.1145/3706599.3719763,https://doi.org/10.1145/3706599.3719763
Playing Dumb to Get Smart: Creating and Evaluating an LLM-based Teachable Agent within University Computer Science Classes,"Rogers, Kantwon and Davis, Michael and Maharana, Mallesh and Etheredge, Pete and Chernova, Sonia",Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems,2025,"This work presents the iterative design and evaluation of a large-language-model (LLM) based teachable agent, MatlabTutee, that facilitates learning-by-teaching (LBT) experiences within university computer science courses. We detail four different experiments, with a total of 119 students, where we refine our system, compare it to human-facilitated LBT experiences, and deploy it in two, month-long in-the-wild environments. We find that our system is able to successfully convey a learner persona similar to a human pretending to be novice while also providing comparable LBT benefits. These benefits include helping students identify areas for improvement, develop a more accurate assessment of their own abilities, and improve their overall attitudes toward computer science. We also explore how students choose to adopt our system into their study habits while situated in real university courses.",10.1145/3706598.3713644,https://doi.org/10.1145/3706598.3713644
Instructors' Perspectives on Capstone Courses in Computing Fields: A Mixed-Methods Study,"Hooshangi, Sara and Shakil, Asma and Dasgupta, Subhasish and C. Davis, Karen C. and Farghally, Mohammed and Fitzpatrick, KellyAnn and Gutica, Mirela and Hardt, Ryan and Riddle, Steve and Seyam, Mohammed",2024 Working Group Reports on Innovation and Technology in Computer Science Education,2025,"Team-based capstone courses are integral to many undergraduate and postgraduate degree programs in the computing field. They are designed to help students gain hands-on experience and practice professional skills such as communication, teamwork, and self-reflection as they transition into the real world. Prior research on capstone courses has focused primarily on the experiences of students. The perspectives of instructors who teach capstone courses have not been explored comprehensively. However, an instructor's experience, motivation, and expectancy can have a significant impact on the quality of a capstone course. In this working group, we used a mixed methods approach to understand the experiences of capstone instructors. Issues such as class size, industry partnerships, managing student conflicts, and factors influencing instructor motivation were examined using a quantitative survey and semi-structured interviews with capstone teaching staff from multiple institutions across different continents. Our findings show that there are more similarities than differences across various capstone course structures. Similarities include team size, team formation methodologies, duration of the capstone course, and project sourcing. Differences in capstone courses include class sizes and institutional support. Some instructors felt that capstone courses require more time and effort than regular lecture-based courses. These instructors cited that the additional time and effort is related to class size and liaising with external stakeholders, including industry partners. Some instructors felt that their contributions were not recognized enough by the leadership at their institutions. Others acknowledged institutional support and the value that the capstone brought to their department. Overall, we found that capstone instructors were highly intrinsically motivated and enjoyed teaching the capstone course. Most of them agree that the course contributes to their professional development. The majority of the instructors reported positive experiences working with external partners and did not report any issues with Non-Disclosure Agreements (NDAs) or disputes about Intellectual Property (IP). In most institutions, students own the IP of their work, and clients understand that. We use the global perspective that this work has given us to provide guidelines for institutions to better support capstone instructors.",10.1145/3689187.3709608,https://doi.org/10.1145/3689187.3709608
Exploring Computing Teachers' Readiness to Teach AI in Secondary Schools,"Addo, Salomey Afua and Sentance, Sue",Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research,2024,"Artificial intelligence (AI) is significantly impacting how we live, and the increased capabilities of generative AI applications have positioned AI firmly in the public domain. There is a growing interest in what AI might look like as a subject within the K-12 curriculum, whilst research on teachers’ readiness for teaching AI is as yet limited. This paper describes a qualitative study investigating teachers’ readiness to teach AI in secondary education. The interview study involved eight computing teachers with varying teaching experiences. We used reflexive thematic analysis for themes development. Findings suggest several indicators of teachers’ readiness, including attitudes, prior AI experience, professional development, and access to quality resources. This paper contributes to ongoing debates about how to best support teachers to be ready to teach AI effectively at the school level.",10.1145/3689535.3689543,https://doi.org/10.1145/3689535.3689543
Using Large Language Models to Automatically Identify Programming Concepts in Code Snippets,"Tran, Andrew and Li, Linxuan and Rama, Egi and Angelikas, Kenneth and Macneil, Stephen",Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2,2023,"Curating course material that aligns with students’ learning goals is a challenging and time-consuming task that instructors undergo when preparing their curricula. For instance, it is a challenge to find multiple-choice questions or example codes that demonstrate recursion in an unlabeled question bank or repository. Recently, Large Language Models (LLMs) have demonstrated the capability to generate high-quality learning materials at scale. In this poster, we use LLMs to identify programming concepts found within code snippets, allowing instructors to quickly curate their course materials. We compare programming concepts generated by LLMs with concepts generated by experts to see the extent to which they agree. The agreement was calculated using Cohen’s Kappa.",10.1145/3568812.3603482,https://doi.org/10.1145/3568812.3603482
Test Case-Informed Knowledge Tracing for Open-ended Coding Tasks,"Duan, Zhangqi and Fernandez, Nigel and Hicks, Alexander and Lan, Andrew",Proceedings of the 15th International Learning Analytics and Knowledge Conference,2025,"Open-ended coding tasks, which ask students to construct programs according to certain specifications, are common in computer science education. Student modeling can be challenging since their open-ended nature means that student code can be diverse. Traditional knowledge tracing (KT) models that only analyze response correctness may not fully capture nuances in student knowledge from student code. In this paper, we introduce Test case-Informed Knowledge Tracing for Open-ended Coding (TIKTOC), a framework to simultaneously analyze and predict both open-ended student code and whether the code passes each test case. We augment the existing CodeWorkout dataset with the test cases used for a subset of the open-ended coding questions, and propose a multi-task learning KT method to simultaneously analyze and predict 1) whether a student’s code submission passes each test case and 2) the student’s open-ended code, using a large language model as the backbone. We quantitatively show that these methods outperform existing KT methods for coding that only use the overall score a code submission receives. We also qualitatively demonstrate how test case information, combined with open-ended code, helps us gain fine-grained insights into student knowledge.",10.1145/3706468.3706500,https://doi.org/10.1145/3706468.3706500
Use of Large Language Models for Extracting Knowledge Components in CS1 Programming Exercises,"Niousha, Rose and Hoq, Muntasir and Akram, Bita and Norouzi, Narges",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"This study utilizes large language models to extract foundational programming concepts in programming assignments in a CS1 course. We seek to answer the following research questions: RQ1. How effectively can large language models identify knowledge components in a CS1 course from programming assignments? RQ2. Can large language models be used to extract program-level knowledge components, and how can the information be used to identify students' misconceptions? Preliminary results demonstrated a high similarity between course-level knowledge components retrieved from a large language model and that of an expert-generated list.",10.1145/3626253.3635592,https://doi.org/10.1145/3626253.3635592
Understanding the Adoption of ChatGPT in Higher Education: A Comparative Study with Insights from STEM and Business Students,,Proceedings of Mensch Und Computer 2024,2024,"Since ChatGPT’s introduction, generative artificial intelligence (AI) has significantly influenced the media, technological innovation, and educational discourse. Its increasing importance, especially in academia, necessitates a detailed examination of the impact of AI on higher education, particularly on how it changes teaching and learning processes. This study therefore looks at the factors affecting students’ attitudes towards AI technologies in the university setting, with a particular focus on the differences between business and STEM programmes. Using a mixed methods approach, the study combines surveys and interviews to collect data on students’ perceptions, attitudes and experiences with generative AI technology in academia. The data collected is analysed both quantitatively and qualitatively to reveal significant trends and insights into the adoption and use of generative AI tools in the university environment. The main objective of the study is to shed light on the determinants that determine the varying degrees of AI adoption in different academic disciplines. The findings have the potential to inform the implementation of educational technology and assist in the development of strategies for the effective integration of generative AI tools to meet the different needs and preferences of students in a range of academic contexts.",10.1145/3670653.3677507,https://doi.org/10.1145/3670653.3677507
RAD: A Framework to Support Youth in Critiquing AI,"Solyst, Jaemarie and Amspoker, Emily and Yang, Ellia and Eslami, Motahhare and Hammer, Jessica and Ogan, Amy",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Artificial intelligence (AI) is ubiquitous in K-12 youths' everyday lives. However, it has become increasingly well-documented that AI can cause harm by reflecting and amplifying societal biases. While many youth are not currently empowered to engage in broader responsible AI discourse and processes, there is great potential. Foundational to engaging in critical conversations is ability to critique AI. We present the RAD framework, designed to scaffold critique of AI in three steps: Recognize (harms of AI), Analyze (societal aspects of AI harms), and Deliberate (what more responsible AI could be). We ran a workshop study with racially diverse middle school girls (N = 21) to investigate its effectiveness. We found that through being scaffolded with the framework, the youth could articulate biases that they saw in an AI scenario and consider how biases may impact different stakeholders. They then could contemplate how different stakeholders had varying amounts of power in the AI scenario and what that meant in terms of creating more responsible AI systems and processes. After participating in the study, the youth felt more strongly about voicing their opinions about AI with others. The RAD framework and activities work toward emboldening youths' engagement in critical discourse about AI.",10.1145/3641554.3701966,https://doi.org/10.1145/3641554.3701966
SCRIPT - Supportive Chatbot for Resolving Introductory Programming Tasks,"Scholl, Andreas and Kiesler, Natalie",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 2,2025,"In this poster, we present a new educational tool based on GenAI: a Supportive Chatbot for Resolving Introductory Programming Tasks (SCRIPT). Its goal is to support novice learners of programming with guardrails and predefined prompts, so they can focus on the problem-solving process, and receive quality feedback.",10.1145/3724389.3730786,https://doi.org/10.1145/3724389.3730786
Chatbot Development Using LangChain: A Case Study to Foster Critical Thinking and Creativity,"Farinetti, Laura and Canale, Lorenzo",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"Critical thinking and creativity are fundamental skills for engineers and computer scientists. The emergence of Large Language Models (LLMs) able to create chatbots that use natural language is an opportunity for educators to foster these skills. The well-known risk of generative AI for potential misinformation offers fertile ground to practice critical thinking.This paper describes a hands-on experience within a database course, where students had to develop a chatbot using the LangChain framework, and to evaluate it from different points of view. The students were free to choose the domain of their chatbot. The learning goal was twofold: on the one hand, to make them practice with state-of-the-art technologies, and on the other hand to stimulate critical analysis on their output. The paper discusses the students' evaluation of the chatbots under several metrics, including document retrieval, syntax and grammar accuracy, semantic relevance and information reliability. Students' assessments were also compared to the teachers' ones, to gain an insight on the critical attitude of the students and to offer a ground for discussion.The experience was stimulating and appreciated by the students. The final results highlight that the majority of students successfully produced chatbot responses that were grammatically and syntactically correct, and that consistently extracted pertinent sections from documents, yielding semantically relevant outputs. Despite these achievements, a significant portion of students expressed reservations about the reliability of the chatbot's responses to prompts, gaining awareness of LLMs' capability to generate responses that make sense to humans but may be potentially misleading.",10.1145/3649217.3653557,https://doi.org/10.1145/3649217.3653557
"A Systematic Literature Review of the Opportunities and Advantages for AIGC (OpenAI ChatGPT, Copilot, Codex) in Programming Course","Chang, Chi In and Choi, Wan Chong and Choi, Iek Chong",Proceedings of the 2024 7th International Conference on Big Data and Education,2025,"This systematic literature review explored the opportunities and advantages of integrating Artificial Intelligence Generated Content (AIGC) tools like OpenAI's ChatGPT, Copilot, and Codex in programming education. From an initial pool of 1,173 papers, 24 were rigorously selected for detailed analysis. The findings highlighted the dominant use of ChatGPT, particularly versions 3/3.5 and 4, underscoring its effectiveness and accessibility. Python emerged as the most frequently studied language, followed by Java, C, R, and Scala. A notable research gap was identified in block-based programming languages and online/blended learning environments. Key opportunities and advantages identified included enhanced code review, where AIGC tools offer efficient and comprehensive assessments; personalized learning, with ChatGPT providing individualized feedback and improving student comprehension; and increased student engagement and motivation through interactive features. Additionally, AIGC tools significantly improved problem-solving and debugging support, effectively identifying and correcting coding errors. They also supported diverse learning styles by offering varied examples and solutions, facilitated innovative teaching strategies that improved educational outcomes, and reduced teacher workload by automating routine tasks. These insights demonstrated the transformative potential of AIGC tools in revolutionizing programming education.",10.1145/3704289.3704301,https://doi.org/10.1145/3704289.3704301
Automated Assessment: Does It Align With Teachers' Views?,"Hickman, Henry and Bell, Tim",Proceedings of the 19th WiPSCE Conference on Primary and Secondary Computing Education Research,2024,"In Aotearoa New Zealand, assessment of programming for the national NCEA standards is carried out manually by teachers, many of whom are not experienced programmers. In an attempt to decrease teacher workload, we have adapted Moodle CodeRunner [23] to assess a widely used recently released high school programming standard. This paper explores in detail how we have automated each criterion of the new standard, including dealing with judgement calls for the more subjective criteria. We then report on interviews with experienced programming teachers who were shown example tasks from our system, as well as model answers for each example. We found that teachers were enthusiastic about using automated assessment to assess the standard, and while there wasn’t one agreed upon interpretation of the standard, teachers were happy with how the system supported marking. We also found no universal agreement among the level of context desired in programming questions to assess the standard, despite the small sample size. These interviews have given us confidence to both release these examples to teachers across New Zealand, many of whom are struggling with how to teach the standard, and to move forward with the pilot of our automated assessment system.",10.1145/3677619.3678113,https://doi.org/10.1145/3677619.3678113
Exploring GenAI as a Tutoring Tool: A Case Study in First-Year Computer Programming,"Stienstra, Liam and Mohamed, Abdallah and Mohamed, Mostafa",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"This study explores the potential of generative artificial intelligence (GenAI) to supplement traditional teaching methods for first-year computer science students. The study evaluates GenAI effectiveness in teaching a new programming concept and examines its perceived utility from the students' perspective. A conversational AI platform, powered by ChatGPT, was developed as a pilot, and used as a virtual tutor, guiding students through an interactive, time-constrained learning session that involved two steps: teaching the new topic followed by problem-solving activities. After the session, students wrote a quiz without assistance to evaluate their newly acquired knowledge. A survey was then administered to collect student perceptions and analyze their interactions with the AI tutor. The preliminary findings suggest that GenAI tutors can effectively support learning, with most students preferring AI over human tutors due to convenience, accessibility, and stress-free environment. While variability of prompt effectiveness and students' misuse or overreliance on AI highlight areas were observed, these results highlight avenues for future research to refine GenAI strategies and improve student learning.",10.1145/3724363.3729060,https://doi.org/10.1145/3724363.3729060
Towards Automated Interactive Tutoring - Focussing on Misconceptions and Adaptive Level-Specific Feedback,"Jell, Lea and List, Corinna and Kipp, Michael",Proceedings of the 5th European Conference on Software Engineering Education,2023,"Programming is an essential cross-disciplinary skill, yet teaching it effectively in large classes can be challenging due to the need for close feedback loops. Identifying and addressing common misconceptions is particularly important during the initial stages of learning to program. While automated interactive tutoring systems have the potential to offer personalized tutoring at scale, current systems tend to emphasize errors and predefined solutions rather than focusing on common misconceptions. In this study, we introduce a novel platform centered on addressing misconceptions in programming education. We describe methods for detecting misconceptions using Abstract Syntax Trees (AST) and providing tailored, level-specific feedback to emulate human-like tutoring. As an empirical basis for this project, we gathered data from various introductory programming courses. Additionally, we advocate for the establishment of a repository of common misconceptions, offering examples derived from both the literature and our own data. Investigating misconceptions can ultimately enhance the teaching strategies of both human educators and AI agents, such as GPT, in guiding learners effectively.",10.1145/3593663.3593692,https://doi.org/10.1145/3593663.3593692
Code Interviews: Design and Evaluation of a More Authentic Assessment for Introductory Programming Assignments,"Kannam, Suhas and Yang, Yuri and Dharm, Aarya and Lin, Kevin",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Generative artificial intelligence poses new challenges around assessment, increasingly driving introductory programming educators to employ invigilated exams. But exams do not afford more authentic programming experiences that involve planning, implementing, and debugging programs with computer interaction. In this experience report, we describe code interviews: a more authentic assessment method for take-home programming assignments. Through action research, we experimented with the number and type of questions as well as whether interviews were conducted individually or with groups of students. To scale the program, we converted most of our weekly teaching assistant (TA) sections to conduct code interviews on 5 major weekly take-home programming assignments. By triangulating data from 5 sources, we identified 4 themes. Code interviews (1) pushed students to discuss their work, motivating more nuanced but sometimes repetitive insights; (2) enabled peer learning, reducing stress in some ways but increasing stress in other ways; (3) scaled with TA-led sections, replacing familiar practice with an unfamiliar assessment; (4) focused on student contributions, limiting opportunities for TAs to give guidance and feedback. We reflect on the design of code interviews for student experience, academic integrity, and teacher workload.",10.1145/3641554.3701806,https://doi.org/10.1145/3641554.3701806
Understanding Optimal Interactions between Students and a Chatbot during a Programming Task,"Shin, Jinnie and Cruz-Castro, Laura and Yang, Zhenlin and Castelblanco, Gabriel and Aggarwal, Ashish and Leite, Walter L. and Carroll, Bruce F.",Proceedings of the Winter Simulation Conference,2025,"This study explores integrating Large Language Models (LLMs) into computer science education by examining undergraduate interactions with a GPT-4-based chatbot during a formative assignment in an introductory course. We aim to delineate optimal help-seeking behaviors and ascertain if effective problem-navigating strategies correlate with improved learning outcomes. Using descriptive statistics and Structural Topic Modeling (STM), we analyze the types of questions posed and their connection to task completion success. Findings reveal a positive association between the number of attempts and help requests, indicating more engaged students seek assistance. STM analysis shows high-ability students address abstract concepts early, while lower-ability students focus on syntax-related issues. These insights underscore the need to evaluate interaction behaviors to optimize chatbot use in education, leading to proposed guidelines to enhance chatbot utilization, promoting responsible use and maximizing educational advantages.",,
Detecting Programming Plans in Open-ended Code Submissions,,Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"Open-ended code-writing exercises are commonly used in large-scale introductory programming courses, as they can be autograded against test cases. However, code writing requires many skills at once, from planning out a solution to applying the intricacies of syntax. As autograding only evaluates code correctness, feedback addressing each of these skills separately cannot be provided. In this work, we explore methods to detect which high-level patterns (i.e. programming plans) have been used in a submission, so learners can receive feedback on planning skills even when their code is not completely correct. Our preliminary results show that LLMs with few-shot prompting can detect the use of programming plans in 95% of correct and 86% of partially correct submissions. Incorporating LLMs into grading of open-ended programming exercises can enable more fine-grained feedback to students, even in cases where their code does not compile due to other errors.",10.1145/3641555.3705166,https://doi.org/10.1145/3641555.3705166
The Importance of Teaching Logic to Computer Scientists and Electrical Engineers,"Mayer, Paul and Baraniuk, Rich",ACM Trans. Comput. Educ.,2025,"It is argued that logic, and in particular mathematical logic, should play a key role in the undergraduate curriculum for students in the computing fields, which include electrical engineering (EE), computer engineering (CE), and computer science (CS). This is based on (1) the history of the field of computing and its close ties with logic, (2) empirical results showing that students with better logical thinking skills perform better in tasks such as programming and mathematics, and (3) the skills students are expected to have in the job market. Further, the authors believe teaching logic to students explicitly will improve student retention, especially involving underrepresented minorities in STEM1, whose rate of attrition is higher than for non-minority students. Though this work focuses specifically on the computing fields, these results demonstrate the importance of logic education to STEM (science, technology, engineering, and mathematics) as a whole.",10.1145/3721986,https://doi.org/10.1145/3721986
Tracking the Progression of Errors Across Successive CS1 Code Submissions,"Liding, Zhixian Christopher and Roy, Nimisha and Borela, Rodrigo",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 2,2025,"Understanding the debugging process of novice programmers as they iteratively solve coding challenges is essential for developing intelligent tutoring systems that address gaps in comprehension and procedural coding skills. This poster presents a framework for systematically analyzing student coding attempts using large language models (LLMs) to identify syntactical, conceptual, and strategic errors. This study investigates 346 coding attempts for three live-coding challenges in a CS1 course, tracking the progression of errors over successive submissions. Preliminary results indicate that among students who attempted the challenges at least ten times, syntactical errors decrease more rapidly within the first ten attempts compared to conceptual or strategic errors. Although students effectively resolve syntax issues early in the debugging process, higher-level conceptual and strategic errors persist, suggesting the need for targeted instructional support at this stage.",10.1145/3724389.3730809,https://doi.org/10.1145/3724389.3730809
Grades are Bugs,"Freitas, Jordan",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"This paper argues that grades are bugs in our educational system, undermining desired behaviors and outcomes. Grades were introduced into higher education for purposes directly at odds with the goals of inclusive pedagogy today, as well as the neuroscience of human motivation and learning. Students enter computer science programs from increasingly varied backgrounds and experiences, and face a rapidly evolving landscape of prospective career paths while higher education costs in the United States are ever increasing. Computer science educators have a responsibility to adapt and carefully re-examine typical approaches to all aspects of the learning environments we build and curricula we execute. This paper aims to elevate conversations about assessment in STEM courses by drawing on strengths of a computer science perspective--problem solving and managing complexity. In keeping with the analogy of debugging, a metaphorical error log is presented, followed by considerations for possible fixes and concluding reflections on why debugging assessment is so important for computer science educators to meet the challenges of this moment and help restore higher education.",10.1145/3724363.3729071,https://doi.org/10.1145/3724363.3729071
On Teaching Novices Computational Thinking by Utilizing Large Language Models Within Assessments,"Hassan, Mohammed and Chen, Yuxuan and Denny, Paul and Zilles, Craig",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Novice programmers often struggle to develop computational thinking (CT) skills in introductory programming courses. This study investigates the use of Large Language Models (LLMs) to provide scalable, strategy-driven feedback to teach CT. Through think-aloud interviews with 17 students solving code comprehension and writing tasks, we found that LLMs effectively guided decomposition and program development tool usage. Challenges included students seeking direct answers or pasting feedback without considering suggested strategies. We discuss how instructors should integrate LLMs into assessments to support students' learning of CT.",10.1145/3641554.3701906,https://doi.org/10.1145/3641554.3701906
The Effectiveness of Coding LLMs and the Challenges in Teaching CS1/2: A Case Study,"Hong, Alexander and Hong, Gongbing",J. Comput. Sci. Coll.,2024,"This paper presents a case study that evaluates the effectiveness of coding Large Language Models (LLMs) in introductory computer science courses at the university level. The study assesses six different AI-powered code generators. The evaluation focuses on the accuracy of these AI code generators in solving ten programming problems from a set of problems that instructors at Duke University can assign to students for weekly completion. The results demonstrate the effectiveness of coding LLMs in solving these problems.Based on the findings, the paper discusses the challenges faced by the computer science education community and potential strategies to address them. The advent of coding LLMs poses significant challenges to traditional teaching and learning methods in computer science. These challenges include the need for strategies to mitigate any negative impact of LLMs on the learning process. At the same time, these code LLMs also offer tremendous opportunities for enhancing teaching and learning.",,
A Large Scale RCT on Effective Error Messages in CS1,"Wang, Sierra and Mitchell, John and Piech, Chris",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"In this paper, we evaluate the most effective error message types through a large-scale randomized controlled trial conducted in an open-access, online introductory computer science course with 8,762 students from 146 countries. We assess existing error message enhancement strategies, as well as two novel approaches of our own: (1) generating error messages using OpenAI's GPT in real time and (2) constructing error messages that incorporate the course discussion forum. By examining students' direct responses to error messages, and their behavior throughout the course, we quantitatively evaluate the immediate and longer term efficacy of different error message types. We find that students using GPT generated error messages repeat an error 23.1% less often in the subsequent attempt, and resolve an error in 34.8% fewer additional attempts, compared to students using standard error messages. We also perform an analysis across various demographics to understand any disparities in the impact of different error message types. Our results find no significant difference in the effectiveness of GPT generated error messages for students from varying socioeconomic and demographic backgrounds. Our findings underscore GPT generated error messages as the most helpful error message type, especially as a universally effective intervention across demographics.",10.1145/3626252.3630764,https://doi.org/10.1145/3626252.3630764
Enhancing Software Modeling Learning with AI-Powered Scaffolding,"Ardimento, Pasquale and Bernardi, Mario Luca and Cimitile, Marta and Scalera, Michele",Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems,2024,"This study introduces an innovative AI-powered scaffolding approach aimed at enhancing software modeling learning through UML diagrams. The focus of this research is on defining the principles and functions comprising the scaffolding. Leveraging recent advancements in generative AI, our approach provides a structured educational framework to improve comprehension and proficiency in modeling concepts. We present the initial implementation of the scaffolding, specifically highlighting the feedback function. By integrating theoretical insights with practical applications, this study seeks to advance Model-Driven Software Engineering education and underscores the potential of AI in enhancing instructional methodologies.",10.1145/3652620.3687776,https://doi.org/10.1145/3652620.3687776
My AI Wants to Know if This Will Be on the Exam: Testing OpenAI’s Codex on CS2 Programming Exercises,"Finnie-Ansley, James and Denny, Paul and Luxton-Reilly, Andrew and Santos, Eddie Antonio and Prather, James and Becker, Brett A.",Proceedings of the 25th Australasian Computing Education Conference,2023,"The introduction of OpenAI Codex sparked a surge of interest in the impact of generative AI models on computing education practices. Codex is also the underlying model for GitHub Copilot, a plugin which makes AI-generated code accessible to students through auto-completion in popular code editors. Research in this area, particularly on the educational implications, is nascent and has focused almost exclusively on introductory programming (or CS1) questions. Very recent work has shown that Codex performs considerably better on typical CS1 exam questions than most students. It is not clear, however, what Codex’s limits are with regard to more complex programming assignments and exams. In this paper, we present results detailing how Codex performs on more advanced CS2 (data structures and algorithms) exam questions taken from past exams. We compare these results to those of students who took the same exams under normal conditions, demonstrating that Codex outscores most students. We consider the implications of such tools for the future of undergraduate computing education.",10.1145/3576123.3576134,https://doi.org/10.1145/3576123.3576134
Can Language Models Employ the Socratic Method? Experiments with Code Debugging,"Al-Hossami, Erfan and Bunescu, Razvan and Smith, Justin and Teehan, Ryan",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"When employing the Socratic method of teaching, instructors guide students toward solving a problem on their own rather than providing the solution directly. While this strategy can substantially improve learning outcomes, it is usually time-consuming and cognitively demanding. Automated Socratic conversational agents can augment human instruction and provide the necessary scale, however their development is hampered by the lack of suitable data for training and evaluation. In this paper, we introduce a manually created dataset of multi-turn Socratic advice that is aimed at helping a novice programmer fix buggy solutions to simple computational problems. The dataset is then used for benchmarking the Socratic debugging abilities of a number of language models, ranging from fine-tuning the instruction-based text-to-text transformer Flan-T5 to zero-shot and chain of thought prompting of the much larger GPT-4. The code and datasets are made freely available for research at the link below.",10.1145/3626252.3630799,https://doi.org/10.1145/3626252.3630799
DevCoach: Supporting Students in Learning the Software Development Life Cycle at Scale with Generative Agents,"Wang, Tianjia and Ramanujan, Ramaraja and Lu, Yi and Mao, Chenyu and Chen, Yan and Brown, Chris",,2024,"Supporting novice computer science students in learning the software development life cycle (SDLC) at scale is vital for ensuring the quality of future software systems. However, this presents unique challenges, including the need for effective interactive collaboration and access to diverse skill sets of members in the software development team. To address these problems, we present ''DevCoach'', an online system designed to support students learning the SDLC at scale by interacting with generative agents powered by large language models simulating members with different roles in a software development team. Our preliminary user study results reveal that DevCoach improves the experiences and outcomes for students, with regard to learning concepts in SDLC's ''Plan and Design'' and ''Develop'' phases. We aim to use our findings to enhance DevCoach to support the entire SDLC workflow by incorporating additional simulated roles and enabling students to choose their project topics. Future studies will be conducted in an online Software Engineering class at our institution, aiming to explore and inspire the development of intelligent systems that provide comprehensive SDLC learning experiences to students at scale.",10.1145/3657604.3664663,https://doi.org/10.1145/3657604.3664663
Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments,"Balse, Rishabh and Valaboju, Bharath and Singhal, Shreya and Warriem, Jayakrishnan Madathil and Prasad, Prajish",Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1,2023,"Recent advances in artificial intelligence have led to the development of large language models (LLMs), which are able to generate text, images, and source code based on prompts provided by humans. In this paper, we explore the capabilities of an LLM - OpenAI's GPT-3 model to provide feedback for student written code. Specifically, we examine the feasibility of GPT-3 to check, critique and suggest changes to code written by learners in an online programming exam of an undergraduate Python programming course.We collected 1211 student code submissions from 7 questions asked in a programming exam, and provided the GPT-3 model with separate prompts to check, critique and provide suggestions on these submissions. We found that there was a high variability in the accuracy of the model's feedback for student submissions. Across questions, the range for accurately checking the correctness of the code was between 57% to 79%, between 41% to 77% for accurately critiquing code, and between 32% and 93% for suggesting appropriate changes to the code. We also found instances where the model generated incorrect and inconsistent feedback. These findings suggest that models like GPT-3 currently cannot be 'directly' used to provide feedback to students for programming assessments.",10.1145/3587102.3588852,https://doi.org/10.1145/3587102.3588852
LLM+RAG Driven Topic Modeling,"Garcia, Frank Ley",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"This paper explores the use of Large Language Models (LLMs) combined with Retrieval-Augmented Generation (RAG) to assist instructors in identifying course-wide student challenges through topic modeling. Unlike previous studies that primarily generate personalized resources for individual students, this research focuses on analyzing reflections from an entire class to inform curriculum design and intervention strategies. Using the LLaMa-3.1-8B model, experiments across varying cosine similarity thresholds reveal both the strengths and limitations of integrating retrieval-based models. While RAG did not consistently outperform standalone LLMs, it offers key insights into the complexities of applying retrieval-augmented approaches in educational settings.",10.1145/3641555.3705040,https://doi.org/10.1145/3641555.3705040
Enhancing Programming Learning with LLMs: Prompt Engineering and Flipped Interaction,"Cowan, Brendan and Watanobe, Yutaka and Shirafuji, Atsushi",Proceedings of the 2023 4th Asia Service Sciences and Software Engineering Conference,2024,"Due to their robustness, large language models (LLMs) are being utilized in many fields of study, including programming and education. Notably, they can be used by programmers by interfacing with their IDEs to assist with development, and in education by giving students meaningful and immediate feedback. In this paper, we propose and explore the groundwork of a framework designed to combine these two applications of LLMs. The framework acts as a facilitator between the LLM and the student by reading the student’s prompts before filtering and modifying them and sending them to the LLM. The intent is that this will improve the responses from the LLM, thereby improving the student’s learning experience. We discuss the framework in detail and analyze the value of individual responses returned from the LLM as a result of our framework. We conclude that the framework causes the LLM to give helpful responses in comparison to how it would respond without the framework.",10.1145/3634814.3634816,https://doi.org/10.1145/3634814.3634816
"Equity-Guided Tutoring: A Scalable, TA-Run Approach","Patterson, Daniel and Torre, Josh and Guo, Zoey and McBride, Thomas",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"We report on a prototype small tutoring program run entirely within the existing undergraduate teaching assistant (TA) staff of a large (around 600 students) first semester Computer Science class with an equally large (around 80) staff of undergraduate TAs. The tutoring team, led by the second, third, and fourth authors (all undergraduate TAs), identified students who could benefit from the service by analyzing existing course assessments (homework, labs, and exams), some of which were slightly modified to aid this task.The service was intentionally not advertised nor available by student request to avoid being dominated by proactive students who benefited from the traditional office hours offered by the course. The tutoring leads matched a team of around 15 TAs with students identified to be at risk of failing the class. 92 one-on-one tutoring sessions were conducted with the matched students over the course of the semester. Of these students, the majority passed the class, and their exam scores improved significantly more than the class population as a whole. Additionally, qualitative feedback demonstrates the program's positive impact on the students.",10.1145/3724363.3729055,https://doi.org/10.1145/3724363.3729055
SIGCSE Technical Symposium 2025: Leading the Transformation,"Stone, Jeffrey A. and Yuen, Timothy",SIGCSE Bull.,2025,"The 2025 SIGCSE Technical Symposium will take place in Pittsburgh, Pennsylvania, from February 26 to March 01, 2025. The SIGCSE community will gather at the David L. Lawrence Convention Center on the banks of the Allegheny River. Our theme for this year is",10.1145/3717402.3717406,https://doi.org/10.1145/3717402.3717406
Satisfactory for All: Supporting Mastery Learning with Human-in-the-loop Assessments in a Discrete Math Course,"Ko, Shao-Heng and Chao, Alex and Pang, Violet",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,This experience report documents an attempt at embracing the,10.1145/3641554.3701854,https://doi.org/10.1145/3641554.3701854
Towards Characterizing Trust in Generative Artificial Intelligence among Students,"Amoozadeh, Matin and Daniels, David and Chen, Stella and Nam, Daye and Kumar, Aayush and Hilton, Michael and Alipour, Mohammad Amin and Ragavan, Sruti Srinivasa",Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2,2023,,10.1145/3568812.3603469,https://doi.org/10.1145/3568812.3603469
Proceedings of the 19th WiPSCE Conference on Primary and Secondary Computing Education Research,"Morales-Navarro, Luis and Gao, Phillip and Yang, Eric and Kafai, Yasmin B",Proceedings of the 19th WiPSCE Conference on Primary and Secondary Computing Education Research,2024,"While experts disagree on whether large pretrained language models (LLMs) understand human language, youth use, play, and experiment with LLM-powered applications every day. Yet little attention has been given to young people’s perspectives on LLMs’ capacity for understanding and the ethical implications of synthetic texts produced by these systems. We conducted a participatory design session using big paper methods with 18 14-15-year-olds in which they (1) interacted with ChatGPT (GPT 3.5) and (2) prompted it with commonsense questions. We examined youths’ big papers, prompts, and conversations during the activity. Our analysis shows that youth had conflicting views on GPTs’ language comprehension and task completion, as well as synthetic text’s ethical implications with regards to misinformation, privacy, and safety. We discuss how these findings could inform the design of learning activities.",10.1145/3677619.3678131,https://doi.org/10.1145/3677619.3678131
From Code to Concepts: Textbook-Driven Knowledge Tracing with LLMs in CS1,"O'Neill, Abby and Smith, Samantha and Durai, Aneesh and DeNero, John and Zamfirescu-Pereira, J.D. and Norouzi, Narges",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"Gauging a student's understanding of course concepts, at an arbitrary point during a course, can be challenging. Standardized exams offer only a snapshot of performance rather than a deep understanding of progress. However, with Large Language Models (LLMs) now deployed at scale in CS1 courses, we can track multiple attempts from each student for every homework problem. This data provides insights into how students learn and deploy concepts over time, presenting a unique opportunity to rethink how we track changes in individual student knowledge. Traditional Knowledge Tracing (KT) methods often lack explainability and are computationally expensive. In contrast, our framework leverages an LLM to identify student progress on labeled, problem-level concepts from a student homework code submission. Our initial results show that the student's knowledge state can be dynamically updated. This knowledge state can then be used to provide more targeted, effective feedback and create tailored study materials.",10.1145/3641555.3705187,https://doi.org/10.1145/3641555.3705187
Nestor: A Personalized Learning Path Recommendation Algorithm for Adaptive Learning Environments,"Nadimpalli, Vamsi Krishna and Maier, Robert and Ezer, Timur and Bugert, Flemming and Staufer, Susanne and R\",Proceedings of the 6th European Conference on Software Engineering Education,2025,"In recent years, advances in technology and the increased use of online and distance learning have led to the widespread adoption of Learning Management Systems (LMS) in higher education institutions and in software engineering education. However, today’s LMS typically consider only a few learner characteristics when recommending personalized learning paths. It is evident that relying on a single learning theory or a limited set of learner characteristics does not fully capture the complex behavior and needs of learners. To address this, we present a hybrid AI algorithm called Nestor that integrates qualitative insights and quantitative evidence to incorporate multiple learning theories, including learning styles, learning strategies, personalities, and preferences for learning elements.In this paper we discuss the design of Nestor to defining its structure and conduct an in-depth comparative analysis to identify optimal data for parameter learning. In addition, a qualitative questionnaire survey of learners who received learning paths evaluates the effectiveness of the recommendations. Performance evaluations on held-out test data and leave-one-out cross-validation indicate that Nestor explains both empirical and synthesized data similarly while achieving improved predictive performance with augmented datasets. Moreover, learner feedback shows neutral to positive responses with the recommendations.",10.1145/3723010.3723016,https://doi.org/10.1145/3723010.3723016
Assessing Elementary Teachers' Knowledge of Integrated Computational Thinking,"Joshi, Deepti and Joswick, Candace and Albert, Jennifer and Jocius, Robin and Blanton, Melanie and Petrulis, Robert and Dawson, Trent",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"During the UnboxingCT project summer professional development, the Integrated CT Assessment was piloted with 72 elementary teachers. The assessment is based on computational thinking integration literature and asks teachers to identify different computational thinking concepts in content area scenarios. The assessment allowed us to identify which computational thinking concepts teachers were most familiar with prior to the professional development and assess changes in their understanding following the professional development. Our next step will be validation of the assessment with a larger group of teachers.",10.1145/3641555.3705131,https://doi.org/10.1145/3641555.3705131
"AI Teaches the Art of Elegant Coding: Timely, Fair, and Helpful Style Feedback in a Global Course","Woodrow, Juliette and Malik, Ali and Piech, Chris",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"Teaching students how to write code that is elegant, reusable, and comprehensible is a fundamental part of CS1 education. However, providing this",10.1145/3626252.3630773,https://doi.org/10.1145/3626252.3630773
Integrating Personalized Parsons Problems with Multi-Level Textual Explanations to Scaffold Code Writing,"Hou, Xinying and Ericson, Barbara J. and Wang, Xu",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"Novice programmers need to write basic code as part of the learning process, but they often face difficulties. To assist struggling students, we recently implemented personalized Parsons problems, which are code puzzles where students arrange blocks of code to solve them, as pop-up scaffolding. Students found them to be more engaging and preferred them for learning, instead of simply receiving the correct answer, such as the response they might get from generative AI tools like ChatGPT. However, a drawback of using Parsons problems as scaffolding is that students may be able to put the code blocks in the correct order without fully understanding the rationale of the correct solution. As a result, the learning benefits of scaffolding are compromised. Can we improve the understanding of personalized Parsons scaffolding by providing textual code explanations? In this poster, we propose a design that incorporates multiple levels of textual explanations for the Parsons problems. This design will be used for future technical evaluations and classroom experiments. These experiments will explore the effectiveness of adding textual explanations to Parsons problems to improve instructional benefits.",10.1145/3626253.3635606,https://doi.org/10.1145/3626253.3635606
VizGroup: An AI-assisted Event-driven System for Collaborative Programming Learning Analytics,"Tang, Xiaohang and Wong, Sam and Pu, Kevin and Chen, Xi and Yang, Yalong and Chen, Yan",Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology,2024,"Programming instructors often conduct collaborative learning activities, like Peer Instruction, to foster a deeper understanding in students and enhance their engagement with learning. These activities, however, may not always yield productive outcomes due to the diversity of student mental models and their ineffective collaboration. In this work, we introduce VizGroup, an AI-assisted system that enables programming instructors to easily oversee students’ real-time collaborative learning behaviors during large programming courses. VizGroup leverages Large Language Models (LLMs) to recommend event specifications for instructors so that they can simultaneously track and receive alerts about key correlation patterns between various collaboration metrics and ongoing coding tasks. We evaluated VizGroup with 12 instructors in a comparison study using a dataset collected from a Peer Instruction activity that was conducted in a large programming lecture. The results showed that VizGroup helped instructors effectively overview, narrow down, and track nuances throughout students’ behaviors.",10.1145/3654777.3676347,https://doi.org/10.1145/3654777.3676347
Snap! 10 --- From Blocks to AI: Empowering Learning with Custom Primitives and Machine Learning,"Phelps, Victoria and Ball, Michael and Garcia, Dan and Garcia, Yuan",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"This year's Snap! 10 release marks a major leap forward, bringing advanced machine learning capabilities directly into the hands of students and educators. Version 10 introduces support for building ML models, including single-layer perceptrons, making it easier than ever for students to explore AI concepts within a block-based environment. These updates are accompanied by the ability to define Snap! primitives using Snap! blocks themselves, empowering users to deeply customize and extend the language.Building on the rich foundation of previous versions, Snap! 10 also includes hundreds of improvements aimed at enhancing both the classroom and the individual learning experience. These include quality-of-life updates such as new debugging tools, dynamic runtime access via the ''this'' reporter, and expanded support for working with dictionaries and APIs.In this demo, we'll showcase the exciting new features in Snap! 10, focusing on how they can be used to engage students in advanced topics like machine learning, data science, and computational thinking. Attendees will learn how to leverage these tools to build custom experiences that meet the evolving needs of their classrooms.",10.1145/3641555.3705048,https://doi.org/10.1145/3641555.3705048
Accelerating Accurate Assignment Authoring Using Solution-Generated Autograders,"Challen, Geoffrey and Nordick, Ben",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Students learning to program benefit from access to large numbers of practice problems. Autograders are commonly used to support programming questions by providing quick feedback on submissions. But authoring accurate autograders remains challenging. Autograders are frequently created by enumerating test cases-a tedious process that can produce inaccurate autograders that fail to correctly classify submissions. When authoring accurate autograders is slow, it is difficult to create large banks of practice problems to support beginning programmers.We present solution-generated autograding: a faster, more accurate, and more enjoyable way to create autograders. Our approach leverages a key difference between software testing and autograding: The question author can provide a solution. By starting with a solution, we can eliminate the need to manually enumerate test cases, validate the autograder's accuracy, and evaluate other aspects of submission code quality beyond behavioral correctness. We describe Questioner, an implementation of solution-generated autograding for Java and Kotlin, and share experiences from four years using Questioner to support a large CS1 course: authoring nearly 800 programming questions used by thousands of students to evaluate millions of submissions.",10.1145/3641554.3701862,https://doi.org/10.1145/3641554.3701862
"Dynamic, Animated Feedback for Randomized Problems with Computer-Based Testing","Choudhary, Arihant and Garcia, Dan",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"Computer-based testing (CBT) is becoming more common in CS Education spaces, and offers many advantages over paper-based modalities. For example, computerized assessments make it easier for students to learn from a wider range of questions in problem sets through problem randomization. Students can then work on problem after problem in a formative assessment mode of learning. While computer-based assessments help facilitate randomized prob- lem generation, solution feedback is typically delivered in static text or image formats, or perhaps a video may be provided. Typically these show or describe the instructor solving a generic problem, not this particular randomized problem.The Dynamic Animation Feedback Tool (DAFT) aims to support mastery learning by helping instructors automatically create algo- rithm visualization animations to explain their solutions, customized to the problem the student was given. The instructor would write code to randomly generate a graph using the CBT system, and ask the student some algorithmic question (e.g., what's the sequence of nodes visited in a depth-first search). Then, that same graph would have its nodes animated (by running the hidden instructor solution to",10.1145/3626253.3635623,https://doi.org/10.1145/3626253.3635623
Designing Courses for Liberal Arts and Sciences Students Contextualized around Creative Expression and Social Justice,"Guzdial, Mark and Nelson-Fromm, Tamara",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"The goal of teaching everyone computing (explicitly including programming) predates the definition of the computer science (CS) major and even the prospect of a software development career. At the University of Michigan, we are creating courses for non-CS majors which are grounded in the computational practices of liberal arts and sciences faculty. These courses have no connection to the CS major curriculum or software development jobs. We focus here on two of the themes that those faculty valued (Computing for Expression and Computing for Justice) and the introductory courses that we designed around each theme. The courses emphasize gaining broad perspectives of computing, which serve the study of multiple disciplines. Student activities include readings, writing essays, classroom discussion, and open-ended programming homework assignments. This experience report describes our design process, the Creative Expression and Social Justice courses, and an initial evaluation of our design. Most of the programming assignments were written in the block-based programming language Snap!, with some in-class exercises using teaspoon languages. Several units ended with an ebook assignment to connect the Snap! programming to equivalent programs in Python, Processing, and SQL. Interview and survey findings suggest that students found this sequence and the courses useful, despite not counting toward a CS major or focusing on early software development skills. Students described usefulness in terms of developing general computing knowledge, preparation for a range of future careers, and introducing them to other course choices.",10.1145/3641554.3701896,https://doi.org/10.1145/3641554.3701896
Fostering and Understanding Diverse Interpersonal Connections in a Massive Online CS1 Course,"Li, Miranda and Malik, Ali and Piech, Chris",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Forming social relationships is critical to student success and well-being, but is one of the first aspects to be neglected in the design of massive online courses. We present our experience deploying an in-course networking tool that enabled 1,600+ learners and teachers in a massive online CS1 course to form 2,000+ connections with other individuals. We discuss how social preferences and networking goals vary by demographics, economic factors, course goals, and course role. Contrary to usual online social behavior, users in our network sent more out-group requests than a random baseline by role (2.04x), gender (1.1x), and developing vs. developed country (1.07x). We highlight differences between developing vs. developed country users: developing country users send 2.5x requests and make, on average, 1.78x as many connections as those from developed countries. From a randomized control trial we find that random recommendations increase the volume of sent requests by 44.48% and promote cross-group requests across developing vs. developed countries (+28.9%), age (+15.1%), and gender (+8.6%). Ultimately we show that integrating socialization as a core feature of online CS1 classrooms can help support people from all backgrounds in achieving their diverse educational goals, which often extend well beyond improving coding proficiency.",10.1145/3641554.3701912,https://doi.org/10.1145/3641554.3701912
Incorporating LLM Activities into Established CS1 Curriculum: An Experience Report,"Fernandez, Amanda S. and Patrick, David and Gomez, Mauricio and Cornell, Kimberly A.",J. Comput. Sci. Coll.,2025,"Large Language Models (LLMs), including Gemini, CoPilot, and ChatGPT, have experienced significant growth in usage and adoption in recent years. As these models become more sophisticated, particularly in code generation capabilities, educators need to adapt their CS1 courses. In this experience report, we share observations we made while designing and teaching LLM activities for CS1 students at two academic institutions during the spring 2024 term. Drawing on recent research, our activities consist of four short 10-15 minute exercises that guide students in how to properly utilize LLMs within their CS1 coursework. These activities can be easily added to the existing CS1 course curriculum to supplement the existing course materials. Post-activity surveys indicated a positive impact on students' understanding of CS concepts and indicated enthusiasm for learning how to use LLMs safely in programming.",,
Reimagining Student Success Prediction: Applying LLMs in Educational AI with XAI,"Riello, Pasquale and Quille, Keith and Jaiswal, Rajesh and Sansone, Carlo",Proceedings of the 2024 Conference on Human Centred Artificial Intelligence - Education and Practice,2024,"Since the conception of Large Language Models (LLMs), their areas of application have increased significantly over time. This is due to their nature of being able to perform natural language processing (NLP) tasks (like question answering, text generation, text summarization, text classification etc.), which gives them flexibility in a multitude of spaces, including in Educational AI (EdAI). Despite their incredible wide range of use, LLMs are typically applied to generative AI, from text to image generation.This paper aims to apply LLMs for a classification task in EdAI, by reproposing the original PreSS (Predicting Student Success) model which makes use of more traditional Machine Learning (ML) algorithms for predicting CS1 students at risk of failing or dropping out. There are two main goals for this work: the first is to identify the best and most accurate method to re-purpose LLMs for a classification task; the second is to explore and access the explainability of the model outputs. For the former we investigate different techniques for using LLMs like Few-Shot Prompting, Fine-Tuning and Transfer Learning using Gemma 2B as base model along with two different kind of prompting techniques. For the latter we focus on attention scores of LLMs transformers, aiming to understanding what are the most important features that the model considers for generating the response. The obtained results are then compared with the previous PreSS model to evaluate whether LLMs can outperform traditional ML algorithms: this paper finds that Na\",10.1145/3701268.3701274,https://doi.org/10.1145/3701268.3701274
CodeHelp: Using Large Language Models with Guardrails for Scalable Support in Programming Classes,"Liffiton, Mark and Sheese, Brad E and Savelka, Jaromir and Denny, Paul",Proceedings of the 23rd Koli Calling International Conference on Computing Education Research,2024,"Computing educators face significant challenges in providing timely support to students, especially in large class settings. Large language models (LLMs) have emerged recently and show great promise for providing on-demand help at a large scale, but there are concerns that students may over-rely on the outputs produced by these models. In this paper, we introduce CodeHelp, a novel LLM-powered tool designed with guardrails to provide on-demand assistance to programming students without directly revealing solutions. We detail the design of the tool, which incorporates a number of useful features for instructors, and elaborate on the pipeline of prompting strategies we use to ensure generated outputs are suitable for students. To evaluate CodeHelp, we deployed it in a first-year computer and data science course with 52 students and collected student interactions over a 12-week period. We examine students’ usage patterns and perceptions of the tool, and we report reflections from the course instructor and a series of recommendations for classroom use. Our findings suggest that CodeHelp is well-received by students who especially value its availability and help with resolving errors, and that for instructors it is easy to deploy and complements, rather than replaces, the support that they provide to students.",10.1145/3631802.3631830,https://doi.org/10.1145/3631802.3631830
CFlow: Supporting Semantic Flow Analysis of Students' Code in Programming Problems at Scale,"Zhang, Ashley Ge and Tang, Xiaohang and Oney, Steve and Chen, Yan",,2024,"Introductory programming courses have been growing rapidly, now enrolling hundreds or thousands of students. In such large courses, it can be overwhelmingly difficult for instructors to understand class-wide problem-solving patterns or issues, which is crucial for improving instruction and addressing important pedagogical challenges. In this paper, we propose a technique and system, CFlow, for creating understandable and navigable representations of code at scale. CFlow is able to represent thousands of code samples in a visualization that resembles a single code sample. CFlow creates scalable code representations by (1) clustering individual statements with similar semantic purposes, (2) presenting clustered statements in a way that maintains semantic relationships between statements, (3) representing the correctness of different variations as a histogram, and (4) allowing users to navigate through solutions interactively using semantic filters. With a multi-level view design, users can navigate high-level patterns, and low-level implementations. This is in contrast to prior tools that either limit their focus on isolated statements (and thus discard the surrounding context of those statements) or cluster entire code samples (which can lead to large numbers of clusters---for example, if there are n code features and m implementations of each, there can be mn clusters). We evaluated the effectiveness of CFlow with a comparison study, found participants using CFlow spent only half the time identifying mistakes and recalled twice as many desired patterns from over 6,000 submissions.",10.1145/3657604.3662025,https://doi.org/10.1145/3657604.3662025
MORepair: Teaching LLMs to Repair Code via Multi-Objective Fine-Tuning,"Yang, Boyang and Tian, Haoye and Ren, Jiadong and Zhang, Hongyu and Klein, Jacques and Bissyande, Tegawende and Le Goues, Claire and Jin, Shunfu",ACM Trans. Softw. Eng. Methodol.,2025,"Within the realm of software engineering, specialized tasks on code, such as program repair, present unique challenges, necessitating fine-tuning Large language models&nbsp;(LLMs) to unlock state-of-the-art performance. Fine-tuning approaches proposed in the literature for LLMs on program repair tasks generally overlook the need to reason about the logic behind code changes, beyond syntactic patterns in the data. High-performing fine-tuning experiments also usually come at very high computational costs. With MORepair, we propose a novel perspective on the learning focus of LLM fine-tuning for program repair: we not only adapt the LLM parameters to the syntactic nuances of the task of code transformation (objective ➊), but we also specifically fine-tune the LLM with respect to the logical reason behind the code change in the training data (objective ➋). Such a multi-objective fine-tuning will instruct LLMs to generate high-quality patches.We apply MORepair to fine-tune four open-source LLMs with different sizes and architectures. Experimental results on function-level and repository-level repair benchmarks show that the implemented fine-tuning effectively boosts LLM repair performance by 11.4% to 56.0%. We further show that our fine-tuning strategy yields superior performance compared to the state-of-the-art approaches, including standard fine-tuning, Fine-tune-CoT, and RepairLLaMA.",10.1145/3735129,https://doi.org/10.1145/3735129
On the Educational Impact of ChatGPT: Is Artificial Intelligence Ready to Obtain a University Degree?,,Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1,2023,"In late 2022, OpenAI released a new version of ChatGPT, a sophisticated natural language processing system capable of holding natural conversations while preserving and responding to the context of the discussion. ChatGPT has exceeded expectations in its abilities, leading to extensive considerations of its potential applications and misuse. In this work, we evaluate the influence of ChatGPT on university education, with a primary focus on computer security-oriented specialization. We gather data regarding the effectiveness and usability of this tool for completing exams, programming assignments, and term papers. We evaluate multiple levels of tool misuse, ranging from utilizing it as a consultant to simply copying its outputs. While we demonstrate how easily ChatGPT can be used to cheat, we also discuss the potentially significant benefits to the educational system. For instance, it might be used as an aid (assistant) to discuss problems encountered while solving an assignment or to speed up the learning process. Ultimately, we discuss how computer science higher education should adapt to tools like ChatGPT.",10.1145/3587102.3588827,https://doi.org/10.1145/3587102.3588827
Multi-Institutional Multi-National Studies of Parsons Problems,"Ericson, Barbara J. and Pearce, Janice L. and Rodger, Susan H. and Csizmadia, Andrew and Garcia, Rita and Gutierrez, Francisco J. and Liaskos, Konstantinos and Padiyath, Aadarsh and Scott, Michael James and Smith, David H. and Warriem, Jayakrishnan M. and Zavaleta Bernuy, Angela",Proceedings of the 2023 Working Group Reports on Innovation and Technology in Computer Science Education,2023,"Students are often asked to learn programming by writing code from scratch. However, many novices struggle to write code and get frustrated when their code does not work. Parsons problems can reduce the difficulty of a coding problem by providing mixed-up blocks the learner rearranges into the correct order. These mixed-up blocks can include distractor blocks that are not needed in a correct solution. Distractor blocks can include common errors, which may help students learn to recognize and fix such errors. Evidence suggests students find Parsons problems engaging, useful for learning to program, and typically easier and faster to solve than writing code from scratch, but with equivalent learning gains. Most research on Parsons problems prior to this work has been conducted at a single institution. This work addresses the need for replication across multiple contexts.A 2022 ITiCSE Parsons Problems Working Group conducted an extensive literature review of Parsons problems, designed several experimental studies for Parsons problems in Python, and created 'study-in-a-box' materials to help instructors run the experimental studies, but the 2022 working group had only sufficient time to pilot two of these studies.Our 2023 ITiCSE Parsons Problems Working Group reviewed these studies, revised some of the studies, expanded both the programming and natural languages used in some of the studies, created new studies, conducted think-aloud observations on some of the studies, and ran both revised as well as new experimental studies. The think-aloud observations and experimental studies provide evidence for using Parsons problems to help students learn common algorithms such as swap, and the usefulness of distractors in helping students learn to recognize, fix, and avoid common errors. In addition, our 2023 ITiCSE Parsons Problems Working Group reviewed Parsons problem papers published after the 2022 literature review and provided a literature review of multi-national (MIMN) studies conducted in computer science education to better understand the motivations and challenges in performing such MIMN studies.In summary, this article contributes an analysis of recent Parsons problem research papers, an itemization of considerations for MIMN studies, the results from our MIMN studies of Parsons problems, and a discussion of recent and future directions for MIMN studies of Parsons problems and more generally.",10.1145/3623762.3633498,https://doi.org/10.1145/3623762.3633498
AI-Enhanced Learning: Comparing Outcomes in Introductory and Advanced Programming Courses,"Zambach, Sine",Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing,2025,"Generative AI chatbots have recently transformed education, necessitating new teaching methods for this paradigm. This study compares the impact of generative AI on introductory and advanced programming courses in fall 2023. Advanced students showed better outcomes, while the performance of introductory students remained unchanged or declined. This highlights the need for tailored AI integration strategies based on students' skill levels.",10.1145/3672608.3707909,https://doi.org/10.1145/3672608.3707909
Mining Students' Mastery Levels from CS Placement Tests via LLMs,,Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"In higher education, introductory Computer Science (CS) programs offer a range of foundational courses. These encompass not only the standard CS1 and CS2 courses but may also include more specialized options like CS0 and CS1.5. In order to appropriately assign students to the suitable introductory courses, many institutions utilize placement tests, which assess students' pre-existing knowledge and skills. While most institutions rely on accuracy alone to make these determinations, there is often additional information concealed within the completed tests. This paper delves into the potential of Large Language Models (LLMs) to uncover this hidden information, particularly in gaining insights into how students perform in different concepts. Moreover, our framework has the flexibility to accommodate variations in curricula across different institutions, providing additional analytical perspectives. Initially, we built a concept inventory (CI) using the concepts covered in an institution's CS0, CS1, and CS2 curricula. Next, an LLM, specifically GPT 3.5, was applied to associate each question in the placement test with one or more concepts in the CI. Finally, the results of the placement tests were scrutinized, allowing the calculation of mastery levels in each concept for individual students. These mastery levels enable institutions to gauge a student's prior knowledge across various concepts simply by using a CS placement test. Additionally, we presented a case study demonstrating the application of this framework to 267 existing placement test results at Boston College.",10.1145/3626253.3635403,https://doi.org/10.1145/3626253.3635403
Challenges and Solutions for Teaching Decomposition and Planning Skills in CS1,"Wiese, Eliane S. and Finnie-Ansley, James and Duran, Rodrigo and Cunningham, Kathryn and Demirtas, Mehmet Arif",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2,2024,"The task of decomposing a problem into sub-problems to build a solution, also formalized as planning in prior work, is a key skill for programming expertise. Improving the decomposition and planning skills of novices is shown to be a challenging goal for educators. Moreover, decomposing complex projects into smaller subtasks is an increasingly relevant skill with rapid developments in tools like large language models (LLMs). While there are many aspects of planning, one skill consistently observed in studies with experts is the ability to identify subtasks that can be solved via common code patterns. To support students in acquiring these skills, many researchers have explored explicit instruction about a set of common patterns in programs (i.e. programming plans). However, recent work implies that students may need additional support to fully benefit from such interventions. This panel aims to bring computing education researchers together to discuss the main challenges around teaching decomposition and planning using common patterns, the crucial factors for designing instruction for teaching these concepts, and the impact evolving technology like LLMs can have on these developments.",10.1145/3649409.3691076,https://doi.org/10.1145/3649409.3691076
Coordinate: A Virtual Classroom Management Tool For Large Computer Science Courses Using Discord,"Brown, Cameron and Cruz Castro, Laura",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Effective classroom management is becoming increasingly challenging with the growing size of core computer science classrooms. However, classroom management remains a critical component of instruction in higher education. Successful classroom management ensures a structured, respectful environment that maximizes student engagement and learning outcomes. To address this, we present Coordinate, a novel educational tool based on Discord, a widely used free voice, video, and text chat application. Coordinate leverages Discord's interface, extensibility, and familiarity with young people. With the innovative blending between communication and logistics, this tool addresses the need to reduce instructors' time on classroom management tasks. Coordinate automatically manages several integral classroom offerings, including office hour queues, student assignment extension requests, teaching team performance, student feedback, and Q&amp;As. Alongside these features, we present details about the tool architecture, implementation, and deployment. Our tool has been deployed throughout a growing number of classes at a large state university to thousands of students. We present the perception of four distinct computer science instructors and their students. Overall, students are satisfied with the tool and find it valuable and easy to use. At the same time, instructors believe it can be a critical component of their classrooms, significantly reducing their time spent on class management and allowing them to focus on other necessary tasks. We also discuss the challenges and opportunities of using the Discord platform in an educational context. Our findings suggest that Coordinate can be a valuable tool for classroom management in higher education.",10.1145/3641554.3701961,https://doi.org/10.1145/3641554.3701961
ML based Evaluation Methodology for Learning Path Recommender Systems,"Bugert, Flemming and Nadimpalli, Vamsi Krishna and Bittner, Dominik and Ezer, Timur and Grabinger, Lisa and Maier, Robert and R\",Proceedings of the 6th European Conference on Software Engineering Education,2025,"In education, recommender systems can provide students with personalized learning materials based on their preferences. When comparing various recommendation algorithms, the main question is, which algorithm provides the most suitable recommendations for each student. Answering this question requires a quantitative evaluation methodology (i.e. a concrete metric) for ranking the results of (even non-deterministic) recommender systems. While there is already literature on this topic, the uniqueness of our approach lies in the application of machine learning: we deploy a likelihood based analysis via Hidden Markov Models named Aiakos. With this strategy, we aim to provide data-driven insights about accuracy and stability of recommendations towards a more reasonable selection of the appropriate recommender system. The training data for the Hidden Markov Models is collected from 80 students. Data from another 26 students is then used to discuss the behavior of our evaluation procedure considering a single recommendation as well as the results from 100 recommendations. Furthermore, the proposed concept allows to be applied to other domains as well.",10.1145/3723010.3723022,https://doi.org/10.1145/3723010.3723022
Integrating Natural Language Processing in Middle School Science Classrooms: An Experience Report,"Katuka, Gloria Ashiya and Chakraburty, Srijita and Lee, Hyejeong and Dhama, Sunny and Earle-Randell, Toni and Celepkolu, Mehmet and Boyer, Kristy Elizabeth and Glazewski, Krista and Hmelo-Silver, Cindy and Mcklin, Tom",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"With the increasing prevalence of large language models (LLMs) such as ChatGPT, there is a growing need to integrate natural language processing (NLP) into K-12 education to better prepare young learners for the future AI landscape. NLP, a sub-field of AI that serves as the foundation of LLMs and many advanced AI applications, holds the potential to enrich learning in core subjects in K-12 classrooms. In this experience report, we present our efforts to integrate NLP into science classrooms with 98 middle school students across two US states, aiming to increase students' experience and engagement with NLP models through textual data analyses and visualizations. We designed learning activities, developed an NLP-based interactive visualization platform, and facilitated classroom learning in close collaboration with middle school science teachers. This experience report aims to contribute to the growing body of work on integrating NLP into K-12 education by providing insights and practical guidelines for practitioners, researchers, and curriculum designers.",10.1145/3626252.3630881,https://doi.org/10.1145/3626252.3630881
Bridging Learnersourcing and AI: Exploring the Dynamics of Student-AI Collaborative Feedback Generation,"Singh, Anjali and Brooks, Christopher and Wang, Xu and Li, Warren and Kim, Juho and Wilson, Deepti",Proceedings of the 14th Learning Analytics and Knowledge Conference,2024,"This paper explores the space of optimizing feedback mechanisms in complex domains such as data science, by combining two prevailing approaches: Artificial Intelligence (AI) and learnersourcing. Towards addressing the challenges posed by each approach, this work compares traditional learnersourcing with an AI-supported approach. We report on the results of a randomized controlled experiment conducted with 72 Master’s level students in a data visualization course, comparing two conditions: students writing hints independently versus revising hints generated by GPT-4. The study aimed to evaluate the quality of learnersourced hints, examine the impact of student performance on hint quality, gauge learner preference for writing hints with versus without AI support, and explore the potential of the student-AI collaborative exercise in fostering critical thinking about LLMs. Based on our findings, we provide insights for designing learnersourcing activities leveraging AI support and optimizing students’ learning as they interact with LLMs.",10.1145/3636555.3636853,https://doi.org/10.1145/3636555.3636853
Comparing Expert and ChatGPT-authored Guidance Prompts,"Bradford, Allison and Li, Weiying and Gerard, Libby and Linn, Marcia C.",,2024,"Students bring a multitude of ideas and experiences to the classroom while they are reasoning about scientific phenomena. They often need timely guidance to refine build upon their initial ideas. In this study we explore the development of guidance prompts to provide students with personalized, real-time feedback in the context of a pedagogically grounded chatbot. In the current version of the tool, guidance prompts are authored by learning scientists who are experts in the content of the items and in Knowledge Integration pedagogy. When students engage with the chatbot, an idea detection model is used to determine the ideas that are present in a student explanation and then the expert-authored guidance prompts are assigned based on rules about which ideas are or are not present in the student explanation. While this approach allows for close attention to and control of the pedagogical intent of each prompt, it is time consuming and not easily generalizable. Further this rule-based approach limits the ways in which students can interact with the chatbot. The work in progress study presented in this paper explores the potential of using generative AI to create similarly pedagogically grounded guidance prompts as a first step towards increasing the generalizability and scalability of this approach. Specifically, we ask: using criteria from the Knowledge Integration Pedagogical Framework, how do ChatGPT 3.5-authored guidance prompts compare to human expert-authored guidance prompts? We find that while prompt engineering can enhance the alignment of ChatGPT-authored guidance prompts with pedagogical criteria, the human expert-authored guidance prompts more consistently meet the pedagogical criteria.",10.1145/3657604.3664669,https://doi.org/10.1145/3657604.3664669
Iterative Student Program Planning using Transformer-Driven Feedback,"Rivera, Elijah and Steinmaurer, Alexander and Fisler, Kathi and Krishnamurthi, Shriram",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"Problem planning is a fundamental programming skill, and aids students in decomposing tasks into manageable subtasks. While feedback on plans is beneficial for beginners, providing this in a scalable and timely way is an enormous challenge in large courses.Recent advances in LLMs raise the prospect of helping here. We utilize LLMs to generate code based on students' plans, and evaluate the code against expert-defined test suites. Students receive feedback on their plans and can refine them.In this report, we share our experience with the design and implementation of this workflow. This tool was used by 544 students in a CS1 course at an Austrian university. We developed a codebook to evaluate their plans and manually applied it to a sample. We show that LLMs can play a valuable role here. However, we also highlight numerous cautionary aspects of using LLMs in this context, many of which will not be addressed merely by having more powerful models (and indeed may be exacerbated by it).",10.1145/3649217.3653607,https://doi.org/10.1145/3649217.3653607
Is ChatGPT the Academic Catalyst We've all been Waiting For?,"Mousa, Raneem Emad and Veilleux, Nanette",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"The excitement around ChatGPT 3.5 underscores its potential to transform various fields in education, including STEM. However, we must approach these claims cautiously. While AI can enhance STEM education, there are ethical concerns and potential inaccuracies linked to unsupervised automated responses. To comprehensively evaluate ChatGPT's influence on STEM, we conducted a controlled experiment that involved answering a question set in mathematics and CS in a time-limited session. To avoid bias, we recruited four groups of math and CS students with similar abilities -each group comprised five students. Two groups utilized ChatGPT, while the other two did not. Students who used ChatGPT were tasked with explaining how and where they employed the tool. Conversely, students who did not use ChatGPT were asked to showcase their problem-solving process. We analyzed the responses from these four groups, alongside the analysis of ChatGPT conversations for those who employed ChatGPT. Performance, confidence level, and completion time of each participant were recorded. Experts in mathematics and CS were then consulted to review participant responses. These experts were subsequently interviewed to gain deeper insights and draw conclusive findings. Our findings show that students who didn't use ChatGPT in Mathematics scored better than those who did, Specifically, ChatGPT provided the correct working process but yielded a wrong final answer due to arithmetic mistakes. Similarly, in programming, ChatGPT led to less elegant code. Our findings provide valuable insights into the benefits and challenges of AI integration in these fields, helping educators and students to adapt to AI advancements.",10.1145/3626253.3635398,https://doi.org/10.1145/3626253.3635398
U.S. Government-Funded Opportunities for CS Educators,"Adams, Joel C. and Bailey, Cynthia and Matthews, Suzanne J. and Tymann, Paul",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"Have you ever thought about spending an academic leave teaching in a different country or advising United States (U.S.) policy-makers on emerging technologies, or spending time at the National Science Foundation (NSF), or working at one of the U.S. service academies? For computer science academics located in the U.S., the federal government offers a variety of opportunities for those interested in such positions, either as an academic leave or as a career change. This panel session explores several of these opportunities, including: American Association for the Advancement of Science (AAAS) Fellowships, Fulbright U.S. Scholars Awards, Jefferson Science Fellowships, NSF rotator opportunities, and U.S. service academy careers. Panelists will describe their experiences in such positions and answer questions from the audience.",10.1145/3641555.3704717,https://doi.org/10.1145/3641555.3704717
Towards a Semantic Representation of Framework Recommendations for Curricular Specifications in Higher Education,B\,Proceedings of the 6th European Conference on Software Engineering Education,2025,"Curricular specifications play an important role in the Higher Education sector and the domain of Computer Science and Software Engineering is characterized by a wide range of education programs with a broad range of topic. Therefore, recommendation frameworks play an important role and their usage is beneficial for a unification of education profiles in a systematic way. This  research is contributing to this development by exploring how a recommendation for the domain of Business Informatics in German speaking countries can be improved by formalizing the recommendations in a semantic model that relies on sophisticated European ontologies in the domain like the European Learning Model (ELM) and related data models. It employs Generative Artificial Intelligence Systems to create semantic models in an experimental way and evaluates the resulting model quality. The results show that a formalization using GenAI has a high potential, but currently also shows deficits in the correctness of the resulting models, requiring human oversight during the model creation.",10.1145/3723010.3723036,https://doi.org/10.1145/3723010.3723036
Generation and Evaluation of a Culturally-Relevant CS1 Textbook for Latines using Large Language Models,"Villegas Molina, Ismael and Montalvo, Audria and Zhong, Shera and Jordan, Mollie and Soosai Raj, Adalbert Gerald",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"In the United States, culturally relevant computing (CRC) is one of the most popular pedagogical implementations for Latin American (Latine) students. Culturally-relevant learning resources are a valuable tool for implementing CRC. However, the traditional method of creation and maintenance of textbooks takes a significant amount of time and effort. Given the duration required for textbook production, the development of culturally-relevant learning resources may become lengthened, as it requires close attention both on the material and the incorporation of cultural referents. In order to accelerate the process, we used the advancement of large language models (LLMs) to our advantage. Through prompt engineering, we created a series of prompts to produce a textbook for an introductory computer science course (CS1) that incorporates Latine culture. This textbook was evaluated on metrics regarding sensibility, correctness, readability, linguistic approachability, appropriateness of examples, and cultural relevance. Overall, the generated textbook was mainly sensible, correct, readable, and linguistically approachable. Code examples were not always appropriate due to the usage of libraries that are not typically used in a CS1 course. The cultural relevance was apparent, but it often included surface-level cultural referents. The main incorporation of culture was through geographical locations and people's names. This suggests that the use of LLMs to generate textbooks may serve as a valuable first step for writing culturally-relevant learning resources. Though this study focuses on Latines, our results and prompts may be applicable for generating culturally-relevant CS1 textbooks for other cultures.",10.1145/3649217.3653600,https://doi.org/10.1145/3649217.3653600
Utilizing ChatGPT in a Data Structures and Algorithms Course: A Teaching Assistant's Perspective,"Jamie, Pooriya and HajiHashemi, Reyhaneh and Alipour, Sharareh",Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems,2025,"Integrating large language models (LLMs) like ChatGPT into computer science education offers transformative potential for complex courses such as data structures and algorithms (DSA). This study examines ChatGPT as a supplementary tool for teaching assistants (TAs), guided by structured prompts and human oversight, to enhance instruction and student outcomes. A controlled experiment compared traditional TA-led instruction with a hybrid approach where TAs used ChatGPT-4o and ChatGPT o1 to generate exercises, clarify concepts, and provide feedback. Structured prompts emphasized problem decomposition, real-world context, and code examples, enabling tailored support while mitigating over-reliance on AI. Results demonstrated the hybrid approach’s efficacy, with students in the ChatGPT-assisted group scoring 16.50 points higher on average and excelling in advanced topics. However, ChatGPT’s limitations necessitated TA verification. This framework highlights the dual role of LLMs: augmenting TA efficiency while ensuring accuracy through human oversight, offering a scalable solution for human-AI collaboration in education.",10.1145/3706599.3720291,https://doi.org/10.1145/3706599.3720291
From,"Lau, Sam and Guo, Philip",Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1,2023,"Over the past year (2022–2023), recently-released AI tools such as ChatGPT and GitHub Copilot have gained significant attention from computing educators. Both researchers and practitioners have discovered that these tools can generate correct solutions to a variety of introductory programming assignments and accurately explain the contents of code. Given their current capabilities and likely advances in the coming years, how do university instructors plan to adapt their courses to ensure that students still learn well? To gather a diverse sample of perspectives, we interviewed 20 introductory programming instructors (9 women + 11 men) across 9 countries (Australia, Botswana, Canada, Chile, China, Rwanda, Spain, Switzerland, United States) spanning all 6 populated continents. To our knowledge, this is the first empirical study to gather instructor perspectives about how they plan to adapt to these AI coding tools that more students will likely have access to in the future. We found that, in the short-term, many planned to take immediate measures to discourage AI-assisted cheating. Then opinions diverged about how to work with AI coding tools longer-term, with one side wanting to ban them and continue teaching programming fundamentals, and the other side wanting to integrate them into courses to prepare students for future jobs. Our study findings capture a rare snapshot in time in early 2023 as computing instructors are just starting to form opinions about this fast-growing phenomenon but have not yet converged to any consensus about best practices. Using these findings as inspiration, we synthesized a diverse set of open research questions regarding how to develop, deploy, and evaluate AI coding tools for computing education.",10.1145/3568813.3600138,https://doi.org/10.1145/3568813.3600138
AI Tools in Matlab Course Education: Instructor Point of View,"Al-Nsour, Rawan",J. Comput. Sci. Coll.,2024,"This work aims to investigate the influence of AI tools, specifically ChatGPT, on assignment submissions for an undergraduate programming course. The study evaluates the variance between MATLAB code submissions supported by ChatGPT and those based solely on traditional classroom resources such as instructor notes, textbooks, and class exercises. By analyzing these differences, the research seeks to highlight the advantages of using AI as an assistant tool, including enhanced efficiency and personalized feedback. However, it also examines the drawbacks, such as potential over-reliance on AI and its impact on achieving students' learning goals. Additionally, the study provides recommendations on how to manage and integrate this new technology effectively to ensure that it complements rather than detracts from the educational experience. Through this comprehensive evaluation, the paper seeks to offer insights into balancing AI assistance with traditional teaching methods to optimize learning outcomes in programming education.",,
Cybersecurity Exercises in the Age of LLMs,"Weiss, Richard and Mache, Jens",J. Comput. Sci. Coll.,2024,"In this tutorial, we will introduce a cybersecurity education framework for developing polymorphic hands-on exercises. Many faculty readily acknowledge the importance of cybersecurity in the Computer Science curriculum, but there are still barriers to integrating it into existing courses. One of those barriers is the fact that in most courses, the current content fills the entire term. Another issues is that faculty don't have time and expertise to create new content that would fit well with their current content and style. The third problem is that exercises created should be resistant to solution by LLMs. We have developed cybersecurity exercises that combine two principles: environment specificity and polymorphism. Environment specificity means that the solutions to the exercise should depend on the local environment (LLMs don't have access to that information). In this context, polymorphism means that they can be easily modified each time that the class is taught.",,
Student-AI Interaction: A Case Study of CS1 students,"Amoozadeh, Matin and Nam, Daye and Prol, Daniel and Alfageeh, Ali and Prather, James and Hilton, Michael and Srinivasa Ragavan, Sruti and Alipour, Amin",Proceedings of the 24th Koli Calling International Conference on Computing Education Research,2024,"Generative artificial intelligence tools (Generative AI), such as ChatGPT, allow users to interact with them in intuitive ways (e.g., conversational) and receive (mostly) good-quality answers. In education, such systems can support students’ learning objectives by providing accessible explanations and examples even when students pose vague queries. But, they also encourage undesired help-seeking behaviors, such as by providing solutions to the students’ homework. Therefore, it is important to better understand how students approach such tools and the potential issues such approaches might present for the learners.In this paper, we present a case study for understanding student-AI collaboration to solve programming tasks in the CS1 introductory programming course. To this end, we recruited a gender-balanced majority non-white set of 15 CS1 students at the University of Houston, a large public university in the US. We observed them solving programming tasks. We used a mixed-method approach to study their interactions as they tackled Python programming tasks, focusing on when and why they used ChatGPT for problem-solving. We analyze and classify the questions submitted by the 15 participants to ChatGPT. Additionally, we analyzed user interaction patterns, their reactions to ChatGPT’s responses, and the potential impacts of Generative AI on their perception of self-efficacy.Our results suggest that, in about a third of the cases, the student attempted to complete the task by submitting the full description of the tasks to ChatGPT without making any effort on their own. We also observed that few students verified their solutions. We discuss the potential implications of these results.",10.1145/3699538.3699567,https://doi.org/10.1145/3699538.3699567
Examples out of Thin Air: AI-Generated Dynamic Context to Assist Program Comprehension by Example,"Mattis, Toni and Krebs, Eva and Rinard, Martin C. and Hirschfeld, Robert","Companion Proceedings of the 8th International Conference on the Art, Science, and Engineering of Programming",2024,"Programmers often benefit from the availability of concrete run-time data alongside abstract source code. However, programmers need to manually exercise the program to reach an interesting state or write code that reproducibly executes a functionality with concrete inputs to be able to observe concrete data. This work aims to automate this process by leveraging generative AI. We present a framework and a preliminary Smalltalk-based prototype allowing programmers to obtain and run examples for the currently viewed source code section from a large language model. Our approach demonstrates how locally hosted LLMs can be fine-tuned and used for such a task with reasonable computational effort while minimizing common problems like hallucinations and out-of-date knowledge. The framework has direct applications in example-based live programming, where it can suggest new examples, and in learning settings where novices need to know how to use certain functionality.",10.1145/3660829.3660845,https://doi.org/10.1145/3660829.3660845
Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models,"Sarsa, Sami and Denny, Paul and Hellas, Arto and Leinonen, Juho",Proceedings of the 2022 ACM Conference on International Computing Education Research - Volume 1,2022,"This article explores the natural language generation capabilities of large language models with application to the production of two types of learning resources common in programming courses. Using OpenAI Codex as the large language model, we create programming exercises (including sample solutions and test cases) and code explanations, assessing these qualitatively and quantitatively. Our results suggest that the majority of the automatically generated content is both novel and sensible, and in some cases ready to use as is. When creating exercises we find that it is remarkably easy to influence both the programming concepts and the contextual themes they contain, simply by supplying keywords as input to the model. Our analysis suggests that there is significant value in massive generative machine learning models as a tool for instructors, although there remains a need for some oversight to ensure the quality of the generated content before it is delivered to students. We further discuss the implications of OpenAI Codex and similar tools for introductory programming education and highlight future research streams that have the potential to improve the quality of the educational experience for both teachers and students alike.",10.1145/3501385.3543957,https://doi.org/10.1145/3501385.3543957
AI Education in German K-10 Computer Science Curricula,"Vo, Gia Minh and Pancratz, Nils",Proceedings of the 18th WiPSCE Conference on Primary and Secondary Computing Education Research,2023,"The growing importance of artificial intelligence (AI) in our daily lives leads to an increasing demand for AI in learning, teaching, and education. Recent developments, such as ChatGPT, have further pushed the significance of AI, garnering media attention and prompting politicians to require stakeholders in education to place a stronger emphasis on AI education in schools. As a result, a growing number of computer science (CS) curricula are expanding to include the topic of AI. This paper aims to contribute to the understanding of AI in K-10 education in Germany by analyzing CS curricula for lower secondary school education across the 16 federal states of Germany. The results indicate that AI-related content is inconsistently addressed in the CS curricula of various federal states, with a noticeable absence of standardized AI competencies for K-10 education. In several federal states, AI-related content is only implicitly addressed from a socio-cultural perspective. To ensure up-to-date education, it is essential to include mandatory AI content in K-10 CS curricula. These contents should be considered holistically by taking into account the technological, socio-cultural, and user-oriented perspectives, in accordance with the Dagstuhl Triangle.",10.1145/3605468.3605471,https://doi.org/10.1145/3605468.3605471
Lessons from Adopting a Competency-based Assessment Approach for an Introductory Programming Module,"Androutsopoulos, Kelly and Heeney, Michael and Smith, Serengul and Ticar, Mae Antonette",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 2,2025,"A major challenge to teaching and assessing a first year undergraduate programming module is that students arrive with different prior programming experience. We address this problem by adopting a competencies-based assessment approach for narrowing the learning gap for less experienced students while still challenging those with more experience. Students can work at different paces and their progress is monitored real-time, allowing for early intervention. We share lessons learned and provide tips to help educators implement this in their modules.",10.1145/3724389.3731257,https://doi.org/10.1145/3724389.3731257
Integrating Data Science for Social Justice: A Tutorial on Developing Non-Traditional Pathways for Non-CS Majors,"Bhattacharya, Sambit and Uma, Ravanasamudram and Deb, Debzani",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"In response to the growing need for socially responsible computer scientists and data scientists, our team is developing a comprehensive data science certificate program specifically tailored for non-computing majors, with a focus on data science for social justice. This program aims to broaden participation in data science and create non-traditional pathways for diverse student populations. Each course in the program is designed to be accessible to non-computing majors, equipping them with the skills to analyze and address social justice issues through data science. Process Oriented Guided Inquiry Learning (POGIL) is employed as an instructional strategy promoting active learning, and real datasets related to social justice are utilized for hands-on activities and assignments, enhancing practical learning experiences. The courses are taught in a synchronous hybrid format, across multiple universities, accommodating both live online and in-person students.This tutorial will equip educators with the tools to incorporate data science for social justice in their courses. Attendees will have access to materials developed for these courses, enabling them to integrate similar content into their own curricula. A key focus is on recent challenges and opportunities created by generative AI. The presenters will share their experiences, course materials, and strategies for introducing computer science through a social justice lens. Participants will share ideas and strategies, which will be collated and made available in a shared repository. This initiative aims to enable educators to train future generations in data science while addressing social justice issues.",10.1145/3641555.3704754,https://doi.org/10.1145/3641555.3704754
Contextual Learning in CS1: Integrating a Chemistry Project to Reinforce Core Programming Concepts,"Qin, Meiying and Kouyoumdjian, Hovig and Schroeder, Jonatan and Zhang, Larry Yueli and Atallah, Jade",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 2,2025,"In an undergraduate CS1 course, we designed two projects to help students apply their learning: one in biology and one in chemistry. In this paper, we focus on the chemistry project, which centers on cheminformatics, the application of computational methods to analyze and interpret chemical data, which are particularly useful in drug discovery. In this project, students filter drug candidates using the PubChem database. The projects received positive feedback, helping students see how coding applies to real-world problems in different scientific fields, understand real-world limitations, and reinforce their programming and problem-solving skills. This multi-context approach ensures a comprehensive understanding of programming concepts and their applications.",10.1145/3724389.3731272,https://doi.org/10.1145/3724389.3731272
"Embedded Ethics in CS: Experiences with Integrating Ethics Assignments in Sophomore, Junior, and Senior Level Courses","Farghally, Mohammed and Seyam, Mohammed and Ellis, Margaret",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"Technical and ethical aspects of Computer Science (CS) are interdependent. Many CS departments teach ethical and social implications of technology in separate standalone courses. However, prior research shows that ethical issues are better taught in tandem with their related technical content as an integral required skill in CS curricula. In this experience report, we share our experience with embedding ethics assignments in 3 CS courses at different levels: a CS2 course in software design and data structures, a CS3 course in data structures and algorithms, and a Software Engineering capstone course, all taught at Virginia Tech (a large public R1 institution) in Spring 2024. Students from the 3 courses were surveyed at the beginning and end of Spring 2024. By comparing results from the pre and post surveys, we found that the embedded assignments for the CS2 and CS3 courses improved students' confidence in their knowledge about how ethical issues may come into play in their career, their confidence in their ability to address ethical issues arising from applying technology in real contexts, and their confidence in communicating and defending their positions on how to address these issues. For all 3 courses, students gave positive feedback on how the assignments were engaging and relevant to the course, and how it improved their ability in raising, and reasoning about, ethical implications of technology. We believe that the practices and results of our experience will be helpful to other CS instructors thinking of injecting ethical content into their technical courses.",10.1145/3724363.3729054,https://doi.org/10.1145/3724363.3729054
Towards Comprehensive Metrics for Programming Cheat Detection,"Vahid, Frank and Pang, Ashley and Denzler, Benjamin",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"Automated assistance for detecting cheating on programs has long been investigated by CS educators, especially with the rise of",10.1145/3626252.3630951,https://doi.org/10.1145/3626252.3630951
"TIPS for Students! A Fair and Equitable Way to Require, Motivate and Reward Creativity and Student-initiated Activities","Wilkin, G. Aaron and Yoder, Jason A. and Daniel, Mitchel J.",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Within education, there is a long-standing tension between the use of standardized grading versus student-centered, experience-based education. In this experience report, we introduce TIPS (The Incentive Points System), a supplementary framework designed to enhance traditional grading by rewarding student creativity and self-directed learning with ''Incentive Points.'' TIPS aims to integrate the benefits of standardized assessment and student-centered education. In TIPS, a mandatory percentage of a course grade is earned through self -initiated, directed, assessed activities, thereby encouraging students to engage deeply with the material, while fostering their intrinsic motivation, personal growth, and meta-cognitive skills. We assert that TIPS can improve fairness and equity in grading by accommodating diverse student backgrounds and abilities. TIPS is versatile, allowing for easy integration into various grading schemes. We describe implementation and student feedback on TIPS over a ten-year period, survey results, and a comparison of two class offerings with and without required Incentive Points. Collectively, these results support our claims.",10.1145/3641554.3701846,https://doi.org/10.1145/3641554.3701846
Contextual Learning in CS1: Integrating a Biology Project to Reinforce Core Programming Concepts,"Qin, Meiying and Atallah, Jade and Schroeder, Jonatan and Zhang, Larry Yueli and Kouyoumdjian, Hovig",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 2,2025,"In an undergraduate CS1 course, we designed two projects to help students apply their learning: one in biology and one in chemistry. In this paper, we focus on the biology project, in which students identify and visualize gene mutations using real BRCA1 gene data. The projects received positive feedback, helping students see how coding applies to real-world problems in different scientific fields, understand real-world limitations, and reinforce their programming and problem-solving skills. This multi-context approach ensures a comprehensive understanding of programming concepts and their applications.",10.1145/3724389.3731273,https://doi.org/10.1145/3724389.3731273
Can ChatGPT Pass a CS1 Python Course?,"Sharpe, James S. and Dougherty, Ryan E. and Smith, Sarah J.",J. Comput. Sci. Coll.,2024,In this paper we determine whether an LLM-ChatGPT in this case-can successfully complete the assignments in our CS1 course as if it were a,,
Digital Conscience: Investigating the State of Ethics in CS Curricula in India,"Parthasarathy, P D and Lakshmi, T G and Indra, R and Spruha, Satavlekar and Joshi, Swaroop",Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 2,2024,"Contemporary computer science graduates enter a world where numerous profound ethical dilemmas confronting society revolve around computing. Navigating the complexities of today’s technological landscape requires a profound consideration of ethical questions. Deliberations on the kinds of data to be gathered or avoided, the ethical dimensions of algorithmic decision-making, and the role of digital platforms in safeguarding democratic principles are at the forefront of discussions. Additionally, addressing biases in large language models (LLMs), ensuring responsible AI practices, and evaluating the technology industry’s contributions to climate change are pivotal aspects.",10.1145/3632621.3671434,https://doi.org/10.1145/3632621.3671434
Demonstration of CFlow: Supporting Semantic Flow Analysis of Students' Code in Programming Problems at Scale,"Zhang, Ashley Ge and Tang, Xiaohang and Oney, Steve and Chen, Yan",,2024,"Introductory programming courses have been growing rapidly, now enrolling hundreds or thousands of students. In such large courses, it can be overwhelmingly difficult for instructors to understand class-wide problem-solving patterns or issues, which is crucial for improving instruction and addressing important pedagogical challenges. In this paper, we propose a technique and system, CFlow, for creating understandable and navigable representations of code at scale. CFlow is able to represent thousands of code samples in a visualization that resembles a single code sample. CFlow creates scalable code representations by (1) clustering individual statements with similar semantic purposes, (2) presenting clustered statements in a way that maintains semantic relationships between statements, (3) representing the correctness of different variations as a histogram, and (4) allowing users to navigate through solutions interactively using semantic filters. With a multi-level view design, users can navigate high-level patterns, and low-level implementations. This is in contrast to prior tools that either limit their focus on isolated statements (and thus discard the surrounding context of those statements) or cluster entire code samples (which can lead to large numbers of clusters---for example, if there are n code features and m implementations of each, there can be m^n clusters).",10.1145/3657604.3664717,https://doi.org/10.1145/3657604.3664717
Designing a CURE for CS1,"Buffardi, Kevin and Brooks, JoAna and Alexander, David",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"Course-based Undergraduate Research Experience (CURE) is a pedagogy for engaging an entire class in the scientific exploration of real research problems with unknown solutions that have impact beyond the classroom. Since CUREs originated in biological sciences, there are unique challenges to adapting the CURE model for computer science. We designed a CURE by aligning its principles with entrepreneurial mindset (EM) and software development practices by applying them in a programming project. This experience report introduces the design and adoption of a CURE project for an introductory programming class (CS1).The CURE project aims to innovate color selection for digital visualizations by facilitating easier interpretation and improved accessibility for people with color vision deficiencies. We designed the",10.1145/3649217.3653573,https://doi.org/10.1145/3649217.3653573
Rethinking Computing Students’ Help Resource Utilization through Sequentiality,"Ko, Shao-Heng and Stephens-Martinez, Kristin",ACM Trans. Comput. Educ.,2025,"Background. Academic help-seeking benefits students’ achievement, but existing literature either studies important factors in students’ selection of all help resources via self-reported surveys or studies their help-seeking behavior in one or two separate help resources via actual help-seeking records. Little is known about whether computing students’ approaches and behavior match, and not much is understood about how they transition sequentially from one help resource to another.Objectives. We aim to study post-secondary computing students’ academic help-seeking approach and behavior. Specifically, we seek to investigate students’ self-reported orders of resource usage and whether these approaches match with students’ actual utilization of help resources. We also examine frequent patterns emerging from students’ chronological help-seeking records in course-affiliated help resources.Context and Study Method. We surveyed students’ self-reported orders of resource usage across 12 offerings of seven courses at two institutions, then analyzed their responses using various help resource dimensions identified by existing works. From two of these courses (an introduction to programming course and a data science course, 11 offerings), we obtained students’ help-seeking records in all course-affiliated help resources, along with code autograder records. We then compared students’ reported orders in these two courses against their actions in the records. Finally, we mined sequences of student help-seeking events from these two courses to reveal frequent sequential patterns.Findings. Students’ reported orders of help resource usage form a progression of clusters where resources in each cluster are more similar to each other by help resource dimensions than to resources outside of their cluster. This progression partially confirms phenomena and decision factors reported by existing literature, but no factor/dimension alone can explain the entire progression. We found students’ actual help-seeking records did not deviate much from their self-reported orders. Mining of the sequential records revealed that help-seeking from course-affiliated human resources led to measurable progress more often than not, and students’ usage of consulting/office hours (mainly run by undergraduate teaching assistants) itself was the best indicator for future usage within the lifespan of the same assignment.Implications. Our results demonstrate that computing students’ help resource selection/utilization is a sophisticated process that should be modeled and analyzed with sufficient awareness of its inherent sequentiality. We identify future research directions through this preliminary analysis, which can lead to a better understanding of computing students’ help-seeking behavior and better resource utilization/management in large-scale instructional contexts.",10.1145/3716860,https://doi.org/10.1145/3716860
"Embedding Technical, Personal and Professional Competencies in Computing Degree Programmes","Prickett, Tom and Crick, Tom and Davenport, James H. and Bowers, David S. and Hayes, Alan and Irons, Alastair",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"Many factors influence computing graduate employment prospects, including human capital, social capital, individual attributes, individual career-building behaviours, perceived employability, and labour market factors. Whilst most computing graduates go on to be beneficially employed, a small minority remain under-employed or unemployed. Computing curricular recommendations increasingly advocate a competency-based approach to bolster graduates' perceived employability. Hence, the discipline is evolving to incorporate competency-based approaches. However, competency-based can mean any of three different types of competency: technical, personal and professional. Technical Competency is the ability to apply acquired content knowledge and skills to develop solutions to unseen problems. Personal Competency is the personal behaviours and interpersonal skills required for success in the modern workplace. Professional Competency is Technical and Personal combined and applied in a real-world context.This position paper provides illustrative examples of how to embed all three kinds of Competency. Based on examples from representative undergraduate computing programmes at UK universities, it provides examples of embedding each kind of competency: Technical Competency (teaching programming through craft computing and approaches for developing cybersecurity competency), Personal Competency (teaching teamwork through project-based learning and creativity via problem-based learning), and Professional Competency (developing work-ready competency using industrial placements, and co-design/co-delivery with industry via degree apprenticeships), providing a valuable foundation and framing for portability and extension in other institutions and jurisdictions. Furthermore, these distinctive types of competency form a helpful taxonomy when considering how to embed competency in computing courses and are candidates for inclusion within future computing curricula guidelines.",10.1145/3649217.3653578,https://doi.org/10.1145/3649217.3653578
ALAN: Assessment-as-Learning Authentic Tasks for Networking,"Minagar, Sepehr and Sakzad, Amin and Tack, Guido and Rudolph, Carsten and Sheard, Judithe",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"In this experience paper, we present ALAN, a framework to automate the generation of authentic assessment tasks in networking courses (NC). Using ALAN, all students in a cohort complete a set of assessment tasks generated from the same skeleton, with each student having their own parameters as input. The way we run ALAN assessments fosters students' self-regulation and peer learning and activates students' engagement in learning through assessment. We present three different ALAN assessments. We finally report on student perceptions and satisfaction and reflect on our experience.",10.1145/3626252.3630774,https://doi.org/10.1145/3626252.3630774
What's in a Social Computing Course: Analyzing Computer and Information Science Syllabi,"Delcourt, Catherine and Venkatagiri, Sukrit and Chandrasekharan, Eshwar",Proceedings of the 6th Annual Symposium on HCI Education,2024,"Social computing systems—such as social media and e-commerce platforms as well as search engines and collaboration software— not only drive vast economic value and societal impact, but are also becoming prominent topics in policy discourse. Although social technology companies heavily recruit students from Computer and Information Science (CS and IS) programs, and social computing is a well-established scholarly field within human-computer interaction (HCI) focused on the social interactions between people mediated through computational systems, little is known about social computing education. Consequently, in this paper we analyzed 25 undergraduate and graduate level courses titled “social computing.” First, as a fast-paced discipline that follows developments in computing as well as related societal implications, we highlight foundational and emergent topics. Second, we map these topics onto the life cycle of social computing systems to highlight gaps in coverage. Third, we map social computing topics to the 2023 ACM CS Curricula Body of Knowledge to provide a framework for introducing social computing concepts into CS and IS curricula. We find that social computing courses require diverse skill sets both within HCI and CS, as well as inter-disciplinary concepts from Sociology, Economics, among others. We conclude with guidelines for designing new social computing courses and discuss ways to critically examine the role of—and the power held by—system builders.",10.1145/3658619.3658623,https://doi.org/10.1145/3658619.3658623
Reimagining CS Courses for High School Students,"Smith, Julie M. and Twarek, Bryan and McGill, Monica M.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"Traditionally, computer science (CS) in the United States has been an elective subject at the high school level. In recent years, however, some school systems have created a CS graduation requirement. Designing a required CS course that meets the needs of anticipated future advancements in the field necessitates exploring the research question, What computing content do high school teachers, college instructors, and computing industry professionals prioritize in a required computer science course for high school students? To better understand what these different groups perceive to be the essential content of a foundational high school CS course, we conducted a series of focus groups. These focus groups explored participants' (n = 21) thinking about what content would be most important to prioritize in a required high school CS course. Transcripts of the focus groups were abductively coded and then analyzed to determine what CS content priorities were identified and what disagreements about priorities exist. We found that participants (1) emphasized CS knowledge and skills, with minimal reference to dispositions, (2) prioritized content similar to that found in current CS standards, (3) developed broad, high-level descriptions of content, (4) identified contextually relevant factors, (5) foregrounded AI both a tool and as a subdomain of CS, and (6) emphasized computational thinking. These findings can inform further research on the design and implementation of a required high school CS course designed to meet the needs of the future as well as to support revisions of CS standards for high school students.",10.1145/3626253.3635554,https://doi.org/10.1145/3626253.3635554
Beyond Functional Correctness: An Exploratory Study on the Time Efficiency of Programming Assignments,"Tao, Yida and Chen, Wenyan and Ye, Qingyang and Zhao, Yao",Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training,2024,"Practical programming assignments are critical parts of programming courses in Computer Science education. Students are expected to translate programming concepts learned from lectures into executable implementations that solve the tasks outlined in the assignments. These implementations are primarily assessed based on their functional correctness, ensuring that students' code produces the expected output when provided with specific inputs.However, functional correctness is not the only metric that evaluates the quality of programs. Runtime efficiency is a metric that is less frequently evaluated in programming courses, yet it holds significant importance in the context of professional software development. To investigate this gap and its potential ramifications, we conducted a large-scale empirical study on the time efficiency of 250 programming assignments that are evaluated solely on functional correctness. The results demonstrate that students' programming assignments exhibit significant variance in terms of execution time. We further identified 27 recurring inefficient code patterns from these assignments, and observed that most of the inefficient patterns can be optimized by automated tools such as PMD, IntelliJ IDEA and ChatGPT. Our findings provide actionable guidelines for educators to enhance the organization and integration of code performance topics throughout the programming course curriculum.",10.1145/3639474.3640065,https://doi.org/10.1145/3639474.3640065
Do Human Beliefs and Traits Influence the Adoption of ChatGPT among Programming Students?,"Batac, Carlo Antonio and Baroja, Marc Jethro and Caballero, Don John Daniel and Coloma, Louis Gabriel and Tan, Lind Matthew and Ebardo, Ryan",Proceedings of the 2024 10th International Conference on Computing and Artificial Intelligence,2024,"Abstract: Increased use of generative artificial intelligence or AI in various academic activities such as programming is a significant milestone in technology diffusion in learning. To bring AI closer to how programmers think, behave, and interact, it is imperative for research to establish a clear connection between various human factors that lead to its adoption. Using a model based on the Theory of Reasoned Action, we positioned human traits of academic stress, risk propensity, neuroticism, and computer self-efficacy as factors that positively influence attitudes toward the use of AI in programming among university students. We further posited that attitude and social norms lead to the behavioral intention to use AI in programming. We used PLS-SEM to analyze responses from 131 programming students who use ChatGPT to accomplish learning tasks. We found that both academic stress and computer self-efficacy influence attitudes toward using AI in programming. While attitude positively influences the behavioral intention to use ChatGPT, we found that risk propensity and neuroticism do not affect attitude, and social norms do not influence behavioral intention. We discuss the implications of our investigation to the industry and the academe.",10.1145/3669754.3669806,https://doi.org/10.1145/3669754.3669806
Integrating AI Tutors in a Programming Course,"Ma, Iris and Krone-Martins, Alberto and Videira Lopes, Cristina",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1,2024,"RAGMan is an LLM-powered tutoring system that can support a variety of course-specific and homework-specific AI tutors. RAGMan leverages Retrieval Augmented Generation (RAG), as well as strict instructions, to ensure the alignment of the AI tutors' responses. By using RAGMan's AI tutors, students receive assistance with their specific homework assignments without directly obtaining solutions, while also having the ability to ask general programming-related questions.  RAGMan was deployed as an optional resource in an introductory programming course with an enrollment of 455 students. It was configured as a set of five homework-specific AI tutors. This paper describes the interactions the students had with the AI tutors, the students' feedback, and a comparative grade analysis. Overall, about half of the students engaged with the AI tutors, and the vast majority of the interactions were legitimate homework questions. When students posed questions within the intended scope, the AI tutors delivered accurate responses 98% of the time. Among the students who used AI tutors, 78% reported that the tutors helped their learning. Beyond AI tutors' ability to provide valuable suggestions, students reported appreciating them for fostering a safe learning environment free from judgment.",10.1145/3649165.3690094,https://doi.org/10.1145/3649165.3690094
Koli Calling 2024: Call for Participation,"Leinonen, Juho",SIGCSE Bull.,2025,"We warmly invite you to attend the 24th Koli Calling International Conference on Computing Education Research (Koli Calling 2024), taking place from November 14-17, 2024, in the beautiful Koli National Park in Eastern Finland.",10.1145/3717402.3717405,https://doi.org/10.1145/3717402.3717405
An Autoethnographic Reflection of Prompting a Custom GPT Based on Oneself,"Lo, Priscilla Y.",Extended Abstracts of the CHI Conference on Human Factors in Computing Systems,2024,"What if you could have a chat with yourself? OpenAI’s introduction of custom GPTs in November 2023 provides an opportunity for non-technical users to create specialized generative artificial intelligence chatbots. Users can write prompts in plain language rather than code to instruct how the system should behave. What can one learn from using non-technical methods to develop a specific chatbot persona? To explore this, I conducted an autoethnography of my experience developing and interacting with a custom GPT based on myself. My findings include a discussion of my experiences throughout the process, and its impact on my personal introspection and understanding of prompt engineering. I summarize first-hand challenges and insights intended to inspire further discussion on the topic of generative AI and chatbots.",10.1145/3613905.3651096,https://doi.org/10.1145/3613905.3651096
Are You Ready to Teach AI in Schools? Teachers' Perspectives of Teaching AI in K-12 Settings,"Addo, Salomey Afua",Proceedings of the 2023 Conference on United Kingdom &amp; Ireland Computing Education Research,2023,"Artificial intelligence (AI) has continually made headlines, even more so with the mass interest in generative AI. The implications of AI on society raises the need for its inclusion in the K-12 computing curriculum. However, little research has been conducted to understand teachers’ preparedness to teach AI concepts in K-12. This exploratory study seeks to understand teachers’ motivation and preparedness to teach AI in schools through the lens of Self Efficacy Theory (SET) and Self Determination Theory (SDT).",10.1145/3610969.3610973,https://doi.org/10.1145/3610969.3610973
Error Messages are Here to Help!,,Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 2,2025,"Programming Error Messages (PEMs) are often misunderstood by students who then miss the opportunity to benefit from them. We have developed and used 'error hunt' lessons using Java, Python, and C PEMs. The activities are supported by videos (images shown below). The materials are targeted at novice programmers.",10.1145/3724389.3731267,https://doi.org/10.1145/3724389.3731267
Evaluating Micro Parsons Problems as Exam Questions,"Wu, Zihan and Smith, David H.",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"Parsons problems are a type of programming activity that present learners with blocks of existing code and requiring them to arrange those blocks to form a program rather than write the code from scratch. Micro Parsons problems extend this concept by having students assemble segments of code to form a single line of code rather than an entire program. Recent investigations into micro Parsons problems have primarily focused on supporting learners leaving open the question of micro Parsons efficacy as an exam item and how students perceive it when preparing for exams.To fill this gap, we included a variety of micro Parsons problems on four exams in an introductory programming course taught in Python. We use Item Response Theory to investigate the difficulty of the micro Parsons problems as well as the ability of the questions to differentiate between high and low ability students. We then compare these results to results for related questions where students are asked to write a single line of code from scratch. Finally, we conduct a thematic analysis of the survey responses to investigate how students' perceptions of micro Parsons both when practicing for exams and as they appear on exams.",10.1145/3649217.3653583,https://doi.org/10.1145/3649217.3653583
Exploring Gender Disparities and Collaborative Learning in IT Education,"Yeom, Soonja and Herbert, Nicole and Ryu, Riseul",Proceedings of the 27th Australasian Computing Education Conference,2025,"Despite efforts to foster gender diversity, women remain underrepresented in Information Technology (IT). Existing research indicates that women often underestimate their abilities in comparison to men. This study investigates this perceived performance gap hypothesis. This study is unique for its extended scope spanning six years and its focus on postgraduate IT students with 39% of women. This study first examines performance disparities between genders in introductory programming. Findings reveal minimal differences, suggesting that women perform comparably to men. However, to encourage broader participation, there is a need for initiatives that enhance the learning environment for women. This study also explores the influence of collaborative learning on performance. No significant improvements in project performance were identified and no significant performance differences were found between genders in group-based projects. The findings, which reveal the intricate interplay among gender, performance, and collaborative learning, are significant for teaching practice, especially at the postgraduate level.",10.1145/3716640.3716645,https://doi.org/10.1145/3716640.3716645
VizProg: Identifying Misunderstandings By Visualizing Students’ Coding Progress,"Zhang, Ashley Ge and Chen, Yan and Oney, Steve",Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,2023,"Programming instructors often conduct in-class exercises to help them identify students that are falling behind and surface students’ misconceptions. However, as we found in interviews with programming instructors, monitoring students’ progress during exercises is difficult, particularly for large classes. We present VizProg, a system that allows instructors to monitor and inspect students’ coding progress in real-time during in-class exercises. VizProg represents students’ statuses as a 2D Euclidean spatial map that encodes the students’ problem-solving approaches and progress in real-time. VizProg allows instructors to navigate the temporal and structural evolution of students’ code, understand relationships between code, and determine when to provide feedback. A comparison experiment showed that VizProg helped to identify more students’ problems than a baseline system. VizProg also provides richer and more comprehensive information for identifying important student behavior. By managing students’ activities at scale, this work presents a new paradigm for improving the quality of live learning.",10.1145/3544548.3581516,https://doi.org/10.1145/3544548.3581516
Our Journey to Student-centered Learning: Lessons and Insights from Transitioning Large-scale Programming Courses,"Faessler, Lukas and Dahinden, Markus",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2,2024,"It is a challenge to replace traditional, lecturer-centered teaching structures with learner-centered ones that adapt dynamically to different requirements. With this poster, we present our experiences in the transition from rigid instructor-centered to dynamic student-centered programming courses with large and diverse student groups and we show some statistics from our current courses.",10.1145/3649405.3659497,https://doi.org/10.1145/3649405.3659497
Facilitating Teens as Ethical Sensemakers of Technology,"Landesman, Rotem and Salac, Jean and Ko, Amy J.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"With the growing awareness of emerging technologies' impacts on teens' lives, families, and communities, rethinking the ways in which we educate and talk about these innovations and their moral and ethical complexities are gaining steam. We present a novel pedagogical intervention that blends techniques from Philosophy for Children (P4C), a pedagogical approach that teaches youth reasoning and argumentative skills, with Youth as Philosophers of Technology, a framework for computing education that foregrounds learning how to decode and unmake tech's relationship with power through artistic, moral and humanistic inquiry, without devaluing core computing practices, such as design, making, coding, and tinkering. We studied this intervention in a summer elective class with 12 students ages 14--18 in the US. Our ongoing data analysis revealed two categories of themes: (1) 'launchpads for ethical sensemaking', namely instances when we observed ethical sensemaking around technology, and (2) 'expressions of ethical sensemaking', namely what students' ethical sensemaking looked like when discussing the ethical implications of technology. We hope to catalyze discussions for both researchers on characterizations of and growth around ethical sensemaking of technology, as well as practitioners on implementations of Youth as Philosophers of Technology and P4C ideas in their classrooms.",10.1145/3626253.3635510,https://doi.org/10.1145/3626253.3635510
"Brief, Just-in-Time Teaching Tips to Support Computer Science Tutors","Cheng, Alan Y. and Tanimura, Ellie and Tey, Joseph and Wu, Andrew C. and Brunskill, Emma",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"As enrollments in computing-related programs continue to rise, computer science departments are increasingly relying on teaching assistants (TAs) to provide additional educational support to students, such as one-on-one tutoring or office hours. Tutoring is more effective with highly trained tutors, but most TAs receive little to no training in pedagogical skills. How might we provide support to TAs working with students one-on-one, especially in online settings? We propose a just-in-time intervention that shows a tutor actionable teaching tips and relevant information right before they begin an online tutoring session with a student. We conducted a crossover experiment (n = 46) where participants engaged in two tutoring roleplays for an introductory computer science programming task and found that participants demonstrated effective instructional strategies for much longer periods of time after receiving the intervention. We discuss the implications of these findings for both educators looking to support tutors and researchers seeking to build technology for tutors.",10.1145/3626252.3630794,https://doi.org/10.1145/3626252.3630794
CryptoEL: A Novel Experiential Learning Tool for Enhancing K-12 Cryptography Education,"Rayavaram, Pranathi and Ukaegbu, Onyinyechukwu and Abbasalizadeh, Maryam and Vellamchetty, Krishna and Narain, Sashank",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"This paper presents an educational tool designed to enhance cryptography education for K-12 students, utilizing Kolb's Experiential Learning (EL) model and engaging visual components. Our tool incorporates the four stages of EL-Concrete Experience, Reflective Observation, Abstract Conceptualization, and Active Experimentation-to teach key cryptographic concepts, including hashing, symmetric cryptography, and asymmetric cryptography. The learning experience is enriched with real-world simulations, customized AI-based conversation agents, video demonstrations, interactive scenarios, and a simplified Python coding terminal focused on cryptography. Targeted at beginners in cybersecurity, the tool encourages independent learning with minimal instructor involvement. An evaluation with 51 middle and high school students showed positive feedback from 93% of participants, who found the simulations, visualizations, AI reflections, scenarios, and coding capabilities engaging and conducive to learning. Comprehension surveys indicated a high understanding of cryptography concepts: hashing (middle school: 89%, high school: 92%), symmetric cryptography (middle school: 93%, high school: 97%), and asymmetric cryptography (middle school: 91%, high school: 94%)",10.1145/3641554.3701926,https://doi.org/10.1145/3641554.3701926
Scaffolding Collaborative Software Design with Serious Games,"Caraco, Serena and Fabros, Melissa and Lojo, Nelson and Fox, Armando",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"An application's architecture is frequently refactored after deployment to accommodate its users' evolving needs. However, we currently lack a repeatable, consistent method to teach high-level collaborative design skills. Drawing on the serious play framework, we advance an existing analog exercise for scaffolding collaborative design using a new system: the LLM-managed application overview. From an instructor prompt, the system generates an overview detailing an entire application using CRC cards -- common industry design aids that forego any code or implementation detail. Students individually edit the cards to redesign the application's architecture, while the system simulates the effects of these edits by updating emulated code metrics and estimating redesign cost. Returning to their teams, students discuss the cost and complexity of their designs before selecting and refining a single solution. By the activity's end, the students will have practiced all the design skills necessary for a months-long cycle of development, without the students or the instructor manually managing any implementation details.",10.1145/3641555.3705242,https://doi.org/10.1145/3641555.3705242
Cracking the Cultural Code: Understanding the Cultural Barriers for Asian International CS Students in the US,"Sthapit, Sandeep and Thomas, Madison and Brock, Janet and Barnes, Tiffany",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"In the field of computer science, cultural assumptions are embedded in programming languages and problem prompts. However, for students studying computer science in a Western country not from a Western culture, these assumptions can create learning barriers. This paper investigates the impact of cultural assumptions on international students studying computer science in a Western country; with a focus on understanding the barriers students face, how they overcome these barriers, and how barriers can be avoided. By performing thematic analysis on semi-structured interviews with 12 international graduate students at North Carolina State University, the authors found six main themes: Barriers, Increased Work, Emotions, Educational Environment, Overcoming Barriers, and Solutions to Barriers. Analyzing these themes provided insight into what barriers international students face and how they can be alleviated. The most common suggestions participants gave for alleviating barriers were more discussions around problem statements. By shedding light on this topic, the authors hope to inform computer science educators and researchers on the importance of creating inclusive and culturally relevant learning environments that accommodate the needs of diverse student populations.",10.1145/3626253.3635567,https://doi.org/10.1145/3626253.3635567
Teaching Students To Use Programming Error Messages,,Proceedings of the ACM Conference on Global Computing Education Vol 2,2023,"Research shows many students struggle to use programming error and warning messages effectively. Instead of using these messages as aids to debug and fix their code, some students have negative emotional reactions to seeing 'angry red text'. Not utilizing programming error and warning messages effectively, or at all, increases the difficulty of learning to program.As compiler messages can vary by programming language and/or development environment, lessons on reading them are not typically included in mainstream educational materials. We believe this gap can be filled and that students can learn to use error messages to their advantage. Further, we believe that teaching students how to read and use error messages can have a significant impact on the learning experience for novice programmers.The goal of this working group is to develop educational materials to teach students to use programming error messages, and evaluate the use of these materials. An additional goal is to investigate the role that large language models may play in the interpretation of error messages in the educational environment. We will produce guidelines for developing educational materials and strategies informed by feedback obtained from the community and our experimentation.",10.1145/3617650.3624950,https://doi.org/10.1145/3617650.3624950
HelpMe: Student Help Seeking using Office Hours and Email,"Wang, Kevin and Lawrence, Ramon",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"Office hours and help sessions provide students with the important opportunity to obtain feedback and guidance while connecting with instructors and peers. However, these out of class help sessions are often underutilized due to problems such as inconvenient times and locations, long wait times, and student misconceptions on their purpose and value. Managing office hours for large classes is difficult for instructors and may result in poor student participation. It is crucial to adopt approaches to manage help sessions more effectively and encourage student attendance. This research examines current problems with help sessions and implements an office hours management system called HelpMe. Interactions in office hours and emails are analyzed to determine the types of questions asked. Student surveys demonstrate a significant change in student perception of office hours, increased engagement, and valuable data on effective practices for deploying office hours.",10.1145/3626252.3630867,https://doi.org/10.1145/3626252.3630867
Learning Assessment for Open Education Learners in the Era of Generative Artificial Intelligence,"Qi, Yuanyi and Wang, Lamei",Proceedings of the 2024 10th International Conference on Frontiers of Educational Technologies,2024,"Generative Artificial Intelligence (AI) tools are now used by students to do their learning assessment, thus impairing the value of such learning assessment. For open education learners who aim to just obtain adult education diplomas, particularly, the cost of learning assessment is becoming increasingly low due to the use of generative AI. How to instructional design and assessment for open education learners in the era of generative AI becomes therefore an issue requiring urgent solutions. From such perspectives as the advantages and disadvantages of generative AI, the learning needs and characteristics of open education learners, and the new characteristics of learning assessment with the use of generative AI, this paper examines the dilemma of instructional design and assessment during the age of generative AI, puts forward the ideas and models for the design of homework for open education learners, and makes learning assessment design proposals with respect to renewing the methods of learning assessment, improving the AI literacy of both teachers and students, etc., with a view to offering some insight for the design of homework in the era of generative AI.",10.1145/3678392.3678405,https://doi.org/10.1145/3678392.3678405
Breaking Stereotypes and Feeding the STEM Pipeline,"Mack, Naja A. and Adeleke, Michael B. and Ballou, Elijah and Davis, Destiny and Ingram, Vincent and Cox, Katlyn",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"Insufficient exposure to computer science and a lack of role models hinder students' pursuit and success in the field. Research suggests that students without early exposure are less likely to enroll in college-level computer science courses and may experience reduced success compared to their peers with prior experience. To address this, CodeBears, a two-week computer science camp, was developed to provide comprehensive exposure, education, and role models for rural and low-income students. CodeBears caters to upper elementary and middle school students, adapting concepts to diverse cultures, challenging stereotypes, and showcasing the diverse backgrounds of computer scientists. This paper outlines the design of CodeBears, examines the experiences of 40 participating students, and highlights engaging lessons using Sphero Bolt, Sphero Rover, Tello Drones, Lego Spike Prime, and Scratch. The camp also collects data on students' favorite activities to gauge their interests and preferences. The discussion focuses on effective strategies for participant recruitment, establishing trust within the target demographic, developing professional programs for facilitators, organizing camp activities, and promoting personal and socially relevant projects. By sharing the challenges and lessons learned, this paper aims to provide insights to researchers and practitioners in similar educational endeavors. Collaboration and knowledge-sharing will drive ongoing improvements in future camps, advancing computer science education.",10.1145/3626252.3630793,https://doi.org/10.1145/3626252.3630793
"Can a Free Tool in an Ebook Platform, Searchable Question Bank, and Summer Workshop Help Instructors Adopt Peer Instruction?","Ericson, Barbara J. and Gu, Xingjian (Lance) and Wu, Zihan and Patel, Shefali and Padiyath, Aadarsh",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Despite evidence of its effectiveness, Peer Instruction (PI) has not been widely adopted by undergraduate computing instructors. In PI, an instructor displays a hard multiple-choice question that students answer individually, then discuss their answer with peers, then answer again, and finally an instructor leads a discussion of the question. Even though the benefits of PI are well documented, it can be difficult to convince computing instructors to move away from passive lectures. Major reasons why instructors do not adopt PI include a lack of awareness, lack of time, and concerns over their ability to cover content. We hypothesized that we could encourage the adoption of PI by creating Peer+, a free tool in an ebook platform, a searchable question bank, and running summer instructor workshops. We offered a three-day in-person summer workshop to a total of 37 instructors in 2022 and 2023. Instructors completed a pre-survey, immediate post-survey, and a follow-up post survey after the fall semester. We also conducted semi-structured interviews with 17 instructors. On the immediate post-survey most (33/37, 89%) instructors reported that they were very likely or likely to use the tool in the fall. However, on the follow-up survey, less than a quarter (6/26, 23%) actually did. The number one reason for not using the tool was a lack of time (18/26, 69%). Notably, all of the instructors who used Peer+ planned to use it again. This work informs efforts to increase the adoption of evidence-based pedagogical approaches in computing.",10.1145/3641554.3701901,https://doi.org/10.1145/3641554.3701901
In Memoriam: Brett Becker,"Smith, Julie M.",SIGCSE Bull.,2025,"The SIGCSE community was saddened by the recent loss of Brett Becker (1976 - 2024). He had been serving as vice-chair of SIGCSE. He was an assistant professor in the School of Computer Science at University College Dublin, founder and chair of the Ireland SIGCSE chapter, and associate editor of ACM TOCE. He was also the inaugural chair of the ACM Global Computing Education conference.",10.1145/3717596.3717599,https://doi.org/10.1145/3717596.3717599
How Humans Communicate Programming Tasks in Natural Language and Implications For End-User Programming with LLMs,"Pickering, Madison and Williams, Helena and Gan, Alison and He, Weijia and Park, Hyojae and Piedrahita Velez, Francisco and Littman, Michael L. and Ur, Blase",Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems,2025,"Large language models (LLMs) like GPT-4 can convert natural-language descriptions of a task into computer code, making them a promising interface for end-user programming. We undertake a systematic analysis of how people with and without programming experience describe information-processing tasks (IPTs) in natural language, focusing on the characteristics of successful communication. Across two online between-subjects studies, we paired crowdworkers either with one another or with an LLM, asking senders (always humans) to communicate IPTs in natural language to their receiver (either a human or LLM). Both senders and receivers tried to answer test cases, the latter based on their sender’s description. While participants with programming experience tended to communicate IPTs more successfully than non-programmers, this advantage was not overwhelming. Furthermore, a user interface that solicited example test cases from senders often, but not always, improved IPT communication. Allowing receivers to request clarification, though, was less successful at improving communication.",10.1145/3706598.3713271,https://doi.org/10.1145/3706598.3713271
LLMS In Education,"Ng, Lynette",XRDS,2024,,10.1145/3688094,https://doi.org/10.1145/3688094
SENSAI: Large Language Models as Applied Cybersecurity Tutors,,Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"The modern educational landscape faces the challenge of maintaining effective, personalized mentorship amid expanding class sizes. This challenge is particularly pronounced in fields requiring hands-on practice, such as cybersecurity education. Teaching assistants and peer interactions provide some relief, but the student-to-educator ratio often remains high, limiting individualized attention. The advent of Large Language Models (LLMs) offers a promising solution by potentially providing scalable and personalized guidance. In this paper, we introduce SENSAI, an AI-powered tutoring system that leverages LLMs to offer tailored feedback and assistance by transparently extracting and utilizing the learner's working context, including their active terminals and edited files. Over the past year, SENSAI has been deployed in an applied cybersecurity curriculum at a large public R1 university and made available to a broader online community of global learners, assisting 2,742 users with hundreds of educational challenges. In total 178,074 messages were exchanged across 15,413 sessions, incurring a total cost of 1,979--comparable to that of a single undergraduate teaching assistant but with a significantly wider reach. SENSAI demonstrates significant improvements in student problem-solving efficiency and satisfaction, offering insights into the future role of AI in education.",10.1145/3641554.3701801,https://doi.org/10.1145/3641554.3701801
Programming Assignment Ungrading as a License to Learn: Implementing Specifications Grading in the Undergraduate Web Development Classroom,"Sampangi, Raghav V. and Poitras, Eric and Barrera Machuca, Mayra D.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"For introductory programming courses, it is crucial to create formative and summarized grading practices that foster growth mindset in students. We explore one way to reimagine and reorient programming assignment grading towards feedback-oriented encouragement for ongoing and continuous learning. This practice of mastery grading encompasses the following key features: (1) students are provided with a comprehensive list of assignment specifications, (2) evaluation of student work is centered on the attainment of specified criteria, employing a nominal scale to denote whether some or all the requirements are met within the deadline, and (3) multiple opportunities are afforded to demonstrate mastery for each specification, without penalties for initial attempts. We share our implementation conducted within an undergraduate first-year web development course, intending it to serve as both a reference and a valuable resource for instructors interested in integrating mastery grading into their own courses.",10.1145/3626253.3635581,https://doi.org/10.1145/3626253.3635581
"Stubents: Videos Created by and for Students, Active Learning Resources in Large and Diverse Computer Science Classrooms","Chen, Yige and Pereira Nunes, Bernardo",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"This paper introduces an innovative pedagogical strategy, employing active learning methodology through peer-reviewed video assignments in a large and diverse computer science (CS) classroom. This approach encourages CS students to create and utilize multimodal learning resources from",10.1145/3649217.3653569,https://doi.org/10.1145/3649217.3653569
AutoPBL: An LLM-powered Platform to Guide and Support Individual Learners Through Self Project-based Learning,"Zhu, Yihao and Ye, Zhoutong and Yuan, Yichen and Tang, Wenxuan and Yu, Chun and Shi, Yuanchun",Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems,2025,"Self project-based learning (SPBL) is a popular learning style where learners follow tutorials and build projects by themselves. SPBL combines project-based learning’s benefit of being engaging and effective with the flexibility of self-learning. However, insufficient guidance and support during SPBL may lead to unsatisfactory learning experiences and outcomes. While LLM chatbots (e.g., ChatGPT) could potentially serve as SPBL tutors, we have yet to see an SPBL platform with responsible and systematic LLM integration. To address this gap, we present AutoPBL, an interactive learning platform for SPBL learners. We examined human PBL tutors’ roles through formative interviews to inform our design. AutoPBL features an LLM-guided learning process with checkpoint questions and in-context Q&amp;A. In a user study where 29 beginners learned machine learning through entry-level projects, we found that AutoPBL effectively improves learning outcomes and elicits better learning behavior and metacognition by clarifying current priorities and providing timely assistance.",10.1145/3706598.3714261,https://doi.org/10.1145/3706598.3714261
Relational Database Courses with CodeRunner in Moodle: Extending SQL Programming Assignments to Client-Server Database Engines,,Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Students practice Data Query, Manipulation, and Definition Language statements in a standard introductory relational database course. When teaching large classes, the teacher needs to review many student solutions. Doing it by hand is laborious. However, this task can be quickly and accurately completed using a learning management system (LMS). Moodle is a widely used LMS that can be enhanced with the CodeRunner plugin to facilitate the evaluation of programming tasks. Unfortunately, a basic setup supports only the embedded database engine SQLite, which often is not the preferred choice for a course of this type. We present an open-source implementation that extends CodeRunner with popular client-server database engines, i.e., Microsoft SQL Server, MySQL, and PostgreSQL. Our method checks the correctness of a student's query in terms of output and validates the query by investigating the parse tree derived from the grammar of a given Structured Query Language (SQL) dialect. We present the system's evaluation results during a database course along with the implementation.",10.1145/3641554.3701830,https://doi.org/10.1145/3641554.3701830
Exploring the Design Space of Cognitive Engagement Techniques with AI-Generated Code for Enhanced Learning,"Kazemitabaar, Majeed and Huang, Oliver and Suh, Sangho and Henley, Austin Z and Grossman, Tovi",Proceedings of the 30th International Conference on Intelligent User Interfaces,2025,"Novice programmers are increasingly relying on Large Language Models (LLMs) to generate code for learning programming concepts. However, this interaction can lead to superficial engagement, giving learners an illusion of learning and hindering skill development. To address this issue, we conducted a systematic design exploration to develop seven cognitive engagement techniques aimed at promoting deeper engagement with AI-generated code. In this paper, we describe our design process, the initial seven techniques and results from a between-subjects study (N=82). We then iteratively refined the top techniques and further evaluated them through a within-subjects study (N=42). We evaluate the friction each technique introduces, their effectiveness in helping learners apply concepts to isomorphic tasks without AI assistance, and their success in aligning learners’ perceived and actual coding abilities. Ultimately, our results highlight the most effective technique: guiding learners through the step-by-step problem-solving process, where they engage in an interactive dialog with the AI, prompting what needs to be done at each stage before the corresponding code is revealed.",10.1145/3708359.3712104,https://doi.org/10.1145/3708359.3712104
Learners Teaching Novices: An Uplifting Alternative Assessment,"Malik, Ali and Woodrow, Juliette and Piech, Chris",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"We propose and carry-out a novel method of formative assessment called Assessment via Teaching (AVT), in which learners demonstrate their understanding of CS1 topics by tutoring more novice students. AVT has powerful benefits over traditional forms of assessment: it is centered around service to others and is highly rewarding for the learners who teach. Moreover, teaching greatly improves the learners' own understanding of the material and has a huge positive impact on novices, who receive free 1:1 tutoring. Lastly, this form of assessment is naturally difficult to cheat---a critical property for assessments in the era of large-language models. We use AVT in a randomised control trial with learners in a CS1 course at an R1 university. The learners provide tutoring sessions to more novice students taking a lagged online version of the same course. We show that learners who do an AVT session before the course exam performed 20 to 30 percentage points better than the class average on several questions. Moreover, compared to students who did a practice exam, the AVT learners enjoyed their experience more and were twice as likely to study for their teaching session. We believe AVT is a scalable and uplifting method for formative assessment that could one day replace traditional exams.",10.1145/3626252.3630887,https://doi.org/10.1145/3626252.3630887
Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,"Liut, Michael and Ly, Anna and Xu, Jessica Jia-Ni and Banson, Justice and Vrbik, Paul and Hardin, Caroline D.",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"In contrast with studies that have identified why students commit academic offences, many educators are familiar with the excuse that an accused student did not know the behavior counted as dishonest. Given the variations in policy and the ways collaboration and code sharing occur in professional and hobbyist spaces, this might be plausible. Mismatches between students' conceptions of academic honesty and course policy can have major consequences, from being kicked out of programs to being too nervous to study with peers. In this work, we investigate what students understand about academic integrity in computer science courses and if there are differences based on university, country, demographic, or online versus in-person courses. We present a study that surveys undergraduate computer science students (N = 1,011) at three universities (Australia, Canada, and the United States of America). The results show that all three institutions take academic integrity seriously, and their students are aware of its importance, but confusion on what is covered under the policies is common. Interestingly, the results also show that course instructors play a huge role as to what students perceive to be a violation of the academic integrity policy at their institution. By understanding student's perspectives on academic integrity, educators can better develop policies and practices that reduce inadvertent and mistaken violations of academic integrity policies.",10.1145/3626252.3630753,https://doi.org/10.1145/3626252.3630753
A Feasibility Study on Automated SQL Exercise Generation with ChatGPT-3.5,"Aerts, Willem and Fletcher, George and Miedema, Daphne",Proceedings of the 3rd International Workshop on Data Systems Education: Bridging Education Practice with Education Research,2024,"SQL is the standard for database query languages and is taught in most introductory database courses. Query languages are illustrated and tested through toy examples: small, accessible, instances of databases. These are not always engaging, but coming up with new examples and questions is time-consuming. Existing research in Computer Science Education has shown that Large Language Models (LLMs) can generate coding exercises. However, this has not been demonstrated for SQL yet but could save teachers much time. In this paper, we study whether it is feasible to have ChatGPT-3.5 generate database schemas and associated SQL questions for teachers through a two-part study. Through a survey of educators, we found that creating a story and database schema for the SQL part is more time-consuming than the questions themselves. In our prompt engineering study, we identified prompts that were successful at creating database schemas, mock data, and exercises. However, although ChatGPT could help reduce the time required to create exams, some participants indicated that they are skeptical about using LLMs.",10.1145/3663649.3664368,https://doi.org/10.1145/3663649.3664368
VisionARy: Exploratory research on Contextual Language Learning using AR glasses with ChatGPT,"Lee, Hyungmin and Hsia, Chen-Chun and Tsoy, Aleksandr and Choi, Sungmin and Hou, Hanchao and Ni, Shiguang",Proceedings of the 15th Biannual Conference of the Italian SIGCHI Chapter,2023,"Language learning is a challenging and time-consuming process, requiring an immersive environment and active usage of the language. However, English as a Foreign Language (EFL) learners often face difficulties in obtaining immersive learning experiences due to one-sided teaching and a lack of real-life English language contexts for practice. To overcome this challenge, various approaches have been proposed that leverage technologies such as mobile-based augmented reality and chatbots. However, these approaches have limitations that hinder full immersion into the language learning environment and fail to adequately contextualize the learning experience. With the recent breakthroughs in large language models and the development of lighter and more powerful AR glasses, we propose VisionARy, the first system that integrates ChatGPT into AR glasses to improve oral language skills and provide a contextualized learning experience. The evaluation results suggest that VisionARy has the potential to be effective and is highly accepted in improving oral language skills, compared to traditional learning methods. Furthermore, our findings provide important insights for the future design of language learning systems.",10.1145/3605390.3605400,https://doi.org/10.1145/3605390.3605400
DBox: Scaffolding Algorithmic Programming Learning through Learner-LLM Co-Decomposition,"Ma, Shuai and Wang, Junling and Zhang, Yuanhao and Ma, Xiaojuan and Wang, April Yi",Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems,2025,"Decomposition is a fundamental skill in algorithmic programming, requiring learners to break down complex problems into smaller, manageable parts. However, current self-study methods, such as browsing reference solutions or using LLM assistants, often provide excessive or generic assistance that misaligns with learners’ decomposition strategies, hindering independent problem-solving and critical thinking. To address this, we introduce Decomposition Box (DBox), an interactive LLM-based system that scaffolds and adapts to learners’ personalized construction of a step tree through a “learner-LLM co-decomposition” approach, providing tailored support at an appropriate level. A within-subjects study (N=24) found that compared to the baseline, DBox significantly improved learning gains, cognitive engagement, and critical thinking. Learners also reported a stronger sense of achievement and found the assistance appropriate and helpful for learning. Additionally, we examined DBox’s impact on cognitive load, identified usage patterns, and analyzed learners’ strategies for managing system errors. We conclude with design implications for future AI-powered tools to better support algorithmic programming education.",10.1145/3706598.3713748,https://doi.org/10.1145/3706598.3713748
Treachery and Deceit: Detecting and Dissuading AI Cheating,"Kerney, William",J. Comput. Sci. Coll.,2025,"Last semester, 75% of the author's data structures students were caught cheating at least once, with Generative AI technologies being the most common means by which they cheated. While it may be tempting to move back to in-person pen-and-paper evaluations to ensure students have retained material, the author has found is possible to detect and discourage the use of cheating via various tricky methods. Finally, the author looks at attempts by students to conceal their use of AI in cheating, and how successful off the shelf AI detection tools are at finding the use of AI in coding assignments before and after being rewritten by hand.",,
How Do Learners With Varying Skills Perceive Misconception Indicators and Feedback?,"Evans, Abigail and Lock, Daniel",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1,2025,"Misconceptions about programming concepts can block learners' progress. Automated feedback for misconceptions is appealing because providing feedback while learners work may help them get unstuck faster. However, a key challenge for automating misconception feedback is that the underlying cause of code patterns suggestive of a misconception can vary greatly by learner, meaning that different learners will have different feedback needs. Existing approaches to automated feedback for task-independent misconceptions favour succinct messages that do not overload users with excessive explanation. Although this approach may work well for learners with relatively shallow misconceptions, it also leaves out learners with deeper conceptual issues who arguably have greater need for additional support. We conducted a qualitative study to investigate how learners perceive misconception indicators and how they make sense of feedback. We find that individual learners can view the same issue very differently and face markedly different challenges in making use of feedback. These findings can be used to inform the design of automated feedback that accounts for learners' varying knowledge and skills.",10.1145/3724363.3729073,https://doi.org/10.1145/3724363.3729073
Artificial Intelligence in Everyday Life 2.0: Educating University Students from Different Majors,"Kasinidou, Maria and Kleanthous, Styliani and Busso, Matteo and Rodas, Marcelo and Otterbacher, Jahna and Giunchiglia, Fausto",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"With the surge in data-centric AI and its increasing capabilities, AI applications have become a part of our everyday lives. However, misunderstandings regarding their capabilities, limitations, and associated advantages and disadvantages are widespread. Consequently, in the university setting, there is a crucial need to educate not only computer science majors but also students from various disciplines about AI. In this experience report, we present an overview of an introductory course that we offered to students coming from different majors. Moreover, we discuss the assignments and quizzes of the course, which provided students with a firsthand experience of AI processes and insights into their learning patterns. Additionally, we provide a summary of the course evaluation, as well as students' performance. Finally, we present insights gained from teaching this course and elaborate on our future plans.",10.1145/3649217.3653542,https://doi.org/10.1145/3649217.3653542
Scaling Academic Decision-Making with NLP: Automating Transfer Credit Evaluations,"Roy, Nimisha and Olufisayo, Omojokun and Tu, Huaijin",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"Manual processes for evaluating external course syllabi for transfer credit in higher education are time-consuming, inconsistent, and prone to bias. This project leverages Natural Language Processing (NLP) and large language models (LLMs) to automate the transfer credit evaluation process. The system processes external syllabi by embedding course content, conducting similarity searches, and providing structured reasoning for each match. Using techniques such as chain-of-thought reasoning and reflection agents, the system generates similarity scores and detailed explanations to support informed, data-driven decision-making by faculty. Validated against faculty decisions, the system promises to significantly improve the efficiency, consistency, and fairness of transfer credit evaluations. Future directions include expanding the system for advanced standing test evaluations and allowing faculty to query specific course components for more targeted analysis.",10.1145/3641555.3705245,https://doi.org/10.1145/3641555.3705245
Integrating Philosophy Teaching Perspectives to Foster Adolescents' Ethical Sensemaking of Computing Technologies,,Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1,2024,"Background: The growing complexity of the impacts of computing technologies on adolescents’ lives requires them to make similarly complex decisions around technology, fueling a rise in education efforts to look at the ethical implications of these advancements with young people. Though prior computing ethics education efforts integrate ethical perspectives, they have rarely drawn from scholarship on how to teach ethics and philosophy. Objectives: We developed a cross-disciplinary pedagogical intervention that blends ethics-focused computing education efforts like Youth as Philosophers of Technology with tools and best practices from Philosophy for Children (P4C), an approach for teaching philosophy to young people. We asked the following research questions: In a secondary computing classroom context, (1) How might adolescent students express ethical sensemaking when engaging with our pedagogical intervention? and (2) What opportunities for ethical sensemaking might our pedagogical intervention facilitate? Methods: We implemented our intervention in a summer academic program in the northwest US for 10 secondary students (age 14-18) from low-income families and who would be the first in their families to pursue a post-secondary education (i.e. first-generation). We then conducted a qualitative analysis of student classwork and instructor reflections using a combination of inductive and deductive coding. Findings: Students expressed their ethical sensemaking by considering multiple perspectives, questioning the status quo, wrestling with dissonance between their principles and actions, and rejecting the good/bad binary. These expressions manifested in three distinct opportunities for ethical sensemaking: when students made connections to their everyday life, engaged in supportive dialogue with their peers, and interacted with instructional scaffolds. Implications: This study indicates the promise of drawing on pedagogies from philosophy when thinking about ethical sensemaking in computing education. Our identification of expressions of and opportunities for adolescents’ ethical sensemaking while using this blended pedagogy advances our understanding of computing ethics education, and offers insights for other ethics education efforts in secondary computing.",10.1145/3632620.3671106,https://doi.org/10.1145/3632620.3671106
Performance Analysis and Interviews of Non-CS-Major Students Sanctioned for Cheating in CS1,"Pang, Ashley and Vahid, Frank",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"College cheating is common, including in computer science (CS) classes like introductory programming (CS1). Much research surveys college students about cheating, but few survey students actually caught cheating, or analyze their performance. We analyzed performance of 24 students sanctioned for cheating on programs in our CS1 over three terms, out of 300+ students, mostly non-CS science and engineering majors. Sanctioned students participated less in lectures (scoring 77% vs. 91%, p = 0.00002), and were less earnest in their completion of the online book's readings (51% vs. 80%, p = 0.0000001) during weeks 1-5. Those findings suggest early disengagement which would correlate with a tendency to cheat, and might also suggest a lack of learning which might help cause cheating. Sanctioned students scored dramatically lower on the earlier midterm exam (61% vs. 83%, p = 0.0001). After being sanctioned with Fs in the course (typically post-midterm), most agreed to an optional later interview to help the professor learn how to prevent cheating, at which point most were quite forthright. Key themes included an inability or unwillingness to devote the time needed to learn programming, a belief that the required CS1 course was not important for non-CS majors, and a disbelief that cheating students would be caught or punished despite warnings. More studies of such experiences may help instructors reduce cheating; in our case, the findings suggest instructors should emphasize relevance, make detection/punishment efforts clear, and detect early disengagement and potentially intervene.",10.1145/3649217.3653614,https://doi.org/10.1145/3649217.3653614
Enhancing Cybersecurity Education with Artificial Intelligence Content,"Brito, Fernando and Mekdad, Yassine and Ross, Monique and Finlayson, Mark A. and Uluagac, Selcuk",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Artificial Intelligence (AI) has become a fundamental tool for cybersecurity researchers and practitioners. It is frequently used to address major security problems such as supply chain attacks, ransomware threats, and social engineering. In this context, integrating AI into cybersecurity workflows requires incorporating AI-driven approaches into the educational training of the cybersecurity workforce. This paradigm shift in academic settings will introduce the necessary skills for cybersecurity professionals to operate modern AI-based systems. Yet, the current cybersecurity curriculum still suffers from the absence of AI resources, particularly the detailed understanding of the appropriate AI mechanisms. Such absence leaves skill gaps for future professionals and practitioners in the industry. To address this, we designed an academic lecture module on AI covering both theory and practice. Then, we taught the module across six cybersecurity courses in our institution. To assess the effectiveness of integrating AI materials into cybersecurity education, we collected data by presenting two surveys before and after the lecture (concluding 81 participants per survey). Specifically, we utilized widely accepted models for unbiased analysis of our data. Our experimental results show positive AI knowledge improvement by 30% of the participants, demonstrating the beneficial impact of the lecture. Then, we observed a high similarity score between the survey responses and the lecture content, reaching 84%. Moreover, our sentiment analysis results reflect positive feedback from the participants with a positive score of 0.50. Overall, our study serves as a reference for instructional designers for developing educational curricula aiming to integrate AI into cybersecurity education.",10.1145/3641554.3701958,https://doi.org/10.1145/3641554.3701958
Integrating Soft Skills Training into your Course through a Collaborative Activity,,Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"Nowadays, employers highly value soft skills, yet many students lack these fundamental abilities. Teaching soft skills involves fostering active student participation and facilitating communication of technical knowledge among peers. This approach presents challenges: (i) creating an engaging learning environment; (ii) ensuring students get timely feedback; (iii) finding an approach that is not too time-consuming for instructors to prepare.The Collaborative Design &amp; Build (CDB) activity, described in this paper, was designed to respond to these challenges. It simulates a real-life scenario, triggering students' interest. The success of this collaborative activity hinges on students working together in a structured chain, where each team builds upon and contributes to the success of the others. This fosters student engagement and accountability as they realize the impact of their actions on the entire chain. This pedagogical approach has already been adopted by four universities abroad. This paper shows how it can be deployed in different courses.Finally, it also discusses how students perceived the activity through four soft skills: collaboration, communication, problem solving and critical thinking. These skills were selected based on their relevance, both in the context of the collaborative activity and in the job market. They are also aligned with the ''4C's of 21st Century skills''. Results show that while students initially struggled with soft skills, consistent practice throughout the semester boosted their confidence, especially in communication. This makes the activity particularly relevant in the classroom, as communication is considered as the most important soft skill for the future.",10.1145/3641554.3701877,https://doi.org/10.1145/3641554.3701877
Comparing the Security of Three Proctoring Regimens for Bring-Your-Own-Device Exams,"Gulati, Rishi and West, Matthew and Zilles, Craig and Silva, Mariana",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"We compare the exam security of three proctoring regimens of Bring-Your-Own-Device, synchronous, computer-based exams in a computer science class: online un-proctored, online proctored via Zoom, and in-person proctored. We performed two randomized crossover experiments to compare these proctoring regimens. The first study measured the score advantage students receive while taking un-proctored online exams over Zoom-proctored online exams. The second study measured the score advantage of students taking Zoom-proctored online exams over in-person proctored exams. In both studies, students took six 50-minute exams using their own devices, which included two coding questions and 8--10 non-coding questions. We find that students score 2.3% higher on non-coding questions when taking exams in the un-proctored format compared to Zoom proctoring. No statistically significant advantage was found for the coding questions. While most of the non-coding questions had randomization such that students got different versions, for the few questions where all students received the same exact version, the score advantage escalated to 5.2%. From the second study, we find no statistically significant difference between students' performance on Zoom-proctored vs. in-person proctored exams. With this, we recommend educators incorporate some form of proctoring along with question randomization to mitigate cheating concerns in BYOD exams.",10.1145/3626252.3630809,https://doi.org/10.1145/3626252.3630809
ICER 2025 Call for Participation,"Morrison, Briana and Montero, Calkin Suero and Porter, Leo and Brown, Neil",SIGCSE Bull.,2025,"We would like to invite you to Charlottesville, Virginia, USA to attend the 21st ICER Conference. The ACM Conference on International Computing Education Research (ICER) will be held 3–6 August 2025 in the Forum Hotel on the beautiful grounds of the University of Virginia. The conference will include an in-person Doctoral Consortium on Sunday, 3 August. Attendees are invited to an opening reception in The Rotunda, the original library designed by Thomas Jefferson (third President of the United States) and centerpiece of the Academical Village on Sunday evening, 5–6:30pm.",10.1145/3732895.3732901,https://doi.org/10.1145/3732895.3732901
Do Embedded Ethics Modules Have Impact Beyond the Classroom?,"Horton, Diane and Liu, David and McIlraith, Sheila A. and Coyne, Steven and Wang, Nina",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"Embedded ethics education integrates ethical considerations into computer sciences courses in support of ethics-informed design, development, and deployment of technology. Scholarly assessment has demonstrated that such modules can influence students' attitudes about the relevance and importance of ethics to their work, as well as their perceived ability to tackle ethical issues in the workplace. In this paper, we report on a study that investigates whether embedded ethics modules have an impact beyond the classroom. Specifically, we examine whether embedded ethics modules influence students to learn more about ethics on their own, whether students are better able to recognize ethical issues when they enter the workplace for an industrial or research work experience, and whether they report that the modules they participated in helped them to navigate the ethical situations they encountered at work. While further assessment is needed to investigate these questions fully, our results suggest that embedded ethics modules can indeed have this kind of positive impact beyond the classroom.",10.1145/3626252.3630834,https://doi.org/10.1145/3626252.3630834
Book Club Model for Engaging with Data Science and Ethics: Using Weapons of Math Destruction,"VanDeGrift, Tammy",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"This experience report describes a book club model for an undergraduate-level Big Data Analytics course. Course learning outcomes included communicating ethical implications of data and models and working collaboratively with other students in crafting solutions by listening and demonstrating. Students read Weapons of Math Destruction by Cathy O'Neil, individually answered reading questions, and collaborated on activities in three class meetings. Students' participation and activity completion rates exceeded 90%, indicating engagement with the book club model. To understand students' experiences with the activities, students' work and survey responses were analyzed. The book club activities expanded students' understanding of bias in data and models, the potential misuse and harm when using and creating software, and how models can target users. In addition to providing activities for a specific book, this paper can serve as a template for using the book club model in any computing course.",10.1145/3626252.3630792,https://doi.org/10.1145/3626252.3630792
A Tool Landscape for Adaptive Learning,"Staufer, Susanne and Bugert, Flemming and Nadimpalli, Vamsi Krishna and R\",Proceedings of the 6th European Conference on Software Engineering Education,2025,"Adaptive learning environments aim to enhance student engagement and learning efficiency by tailoring educational content to individual needs. This paper presents a modular tool landscape designed to extend a learning management system like Moodle with adaptive learning paths based on learner profiles. To this end, the proposed architecture integrates multiple AI-driven tools - like Bayesian networks and Markov models - to generate personalized learning paths. The framework is implemented as a Moodle plugin named Pythia, which facilitates the selection and sequencing of learning elements by analyzing learning styles, completion data, and learning analytics.The main goal of this work is to provide lecturers a modular architecture for an adaptive learning management system that can be used and expanded the way they want it. Therefore, the present work has the following contributions: The architecture with its tools has to be discussed on the basis of flexibility in tool integration. They should be open for extensions, the functionality of the used algorithms should be transparent, and they should offer the possibility of psychological questionnaire integration.",10.1145/3723010.3723028,https://doi.org/10.1145/3723010.3723028
Empowering Computing Students with Large Language Models by Developing an Escape Room Game,"Giacaman, Nasser and Terragni, Valerio",,2025,"In this project, computing students learn to integrate large language models (LLMs) into a software system. Students develop a Java application with a basic graphical user interface (GUI) using JavaFX, gain practical experience with prompt engineering, and learn about the impact of LLM parameters and conversational roles. Students are provided with a Javabased API that connects with OpenAI's GPT model. The project emphasizes teaching students to manage LLM API calls, enhance GUI responsiveness, and improve the user experience all in the context of an AI-powered application. This experience equips them with critical skills in software development and AI application. It prepares them for advanced software development by learning how to create effective LLM prompts to create intelligent and user-friendly applications. We share the experience of using this project and provide guidelines for assessing it in a second-year software engineering undergraduate course, where students' prior programming experience is limited to the prerequisite CS2 course on object-oriented programming. In the case study we present, the project involved developing a riddle-solving escape room, which we called EscAIpe Room.",,
ICER 2024: Call for Participation,"Denny, Paul and Hamilton, Margaret and Porter, Leo and Morrison, Briana",SIGCSE Bull.,2024,Do you know that the 20th ICER Conference will be happening soon? In Australia?The ACM Conference on International Computing Education Research (ICER) will be held at Storey Hall in RMIT University right in the centre of Melbourne.,10.1145/3699853.3699857,https://doi.org/10.1145/3699853.3699857
Developing a Holistic AI Literacy Framework for Children,"Jia, Kaiyue and Leung, Teresa H. M. and Cheung, Ngai Yan Irene and Li, Yixun and Yu, Junnan",ACM Trans. Comput. Educ.,2025,"The increasing prevalence of AI in everyday life has intensified the emphasis on teaching AI literacy to children. However, there is no consensus on the specific knowledge and skills that constitute children’s AI literacy, resulting in varied AI learning materials for young people. We systematically searched for educational practices for children’s AI learning in both formal and informal settings and examined the AI learning content taught to children. Our findings led to the development of a holistic AI literacy framework for children, which contains three high-level dimensions and eight content areas of AI literacy: AI awareness (AI definition, AI application, and AI history), AI mechanics (AI input, learning procedure, and AI output), and AI impacts (AI implication and responsible practice). Theoretically, we contribute a research-based, comprehensive, and current framework for children’s AI literacy, advancing its conceptualization in early life stages. Practically, our framework can guide researchers and practitioners in promoting AI education for the next generation.",10.1145/3727986,https://doi.org/10.1145/3727986
Mocking Temporal Logic,"Gordon, Colin S.",Proceedings of the 2024 ACM SIGPLAN International Symposium on SPLASH-E,2024,"Temporal logics cover important classes of system specifications dealing with system behavior over time. Despite the prevalence of long-running systems that accept repeated input and output, and thus the clear relevance of temporal specifications to training software engineers, temporal logics are rarely taught to undergraduates.    We motivate and describe an approach to teaching temporal specifications and temporal reasoning indirectly through teaching students about mocking dependencies, which is widely used in software testing of large systems (and therefore of more obvious relevance to students), less notationally intimidating to students, and still teaches similar reasoning principles. We report on 7 years of experience using this indirect approach to behavioral specifications in a software quality course.",10.1145/3689493.3689980,https://doi.org/10.1145/3689493.3689980
Untangling School Leaders' Perception of AI Integration in K-12 Education,"Qian, Yingxiao and Tang, Hengtao",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2,2025,"Artificial intelligence (AI) is transforming education, with the potential to revolutionize teaching, learning, and school administration. However, the successful implementation of AI-driven initiatives involves more than simply adopting new technology but requires a thorough understanding of how school leaders perceive AI and their preparedness to integrate it into educational planning and practices. Principals and school leaders play a critical role in supporting effective instruction and student achievement across different content areas, but their needs and challenges, particularly regarding AI integration, are often overlooked. Understanding school leaders' perceptions of AI is vital for successfully implementing AI in schools. This exploratory study employed a qualitative approach to investigate school leaders' perspectives on AI integration in K-12 school settings. Two 90-minute semi-structured focus groups were conducted. Inductive analysis was performed to interpret the qualitative data. The findings highlighted school leaders' perceptions of best practices of AI integration as well as their concerns about AI and the associated ethical dilemma. This collective knowledge of potential solutions for AI integration can help establish a systematic, top-down approach in K-12 school settings.",10.1145/3641555.3705276,https://doi.org/10.1145/3641555.3705276
Experiences from Using Code Explanations Generated by Large Language Models in a Web Software Development E-Book,"MacNeil, Stephen and Tran, Andrew and Hellas, Arto and Kim, Joanne and Sarsa, Sami and Denny, Paul and Bernstein, Seth and Leinonen, Juho",Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1,2023,"Advances in natural language processing have resulted in large language models (LLMs) that can generate code and code explanations. In this paper, we report on our experiences generating multiple code explanation types using LLMs and integrating them into an interactive e-book on web software development. Three different types of explanations -- a line-by-line explanation, a list of important concepts, and a high-level summary of the code -- were created. Students could view explanations by clicking a button next to code snippets, which showed the explanation and asked about its utility. Our results show that all explanation types were viewed by students and that the majority of students perceived the code explanations as helpful to them. However, student engagement varied by code snippet complexity, explanation type, and code snippet length. Drawing on our experiences, we discuss future directions for integrating explanations generated by LLMs into CS classrooms.",10.1145/3545945.3569785,https://doi.org/10.1145/3545945.3569785
Can GPT4 Generate Effective Feedback on Code Readability?,"Su, Xiaotian and Song, Yajie and Messer, Marcus and Savelka, Jaromir and Cutumisu, Maria and Wang, April",Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 2,2025,"Effective feedback is often timely and consistent but, with large cohorts, this is not always achievable. This study explored the potential of GPT4 to generate feedback on code readability for students enrolled in a CS1 Java course. We developed rubrics based on three readability criteria: naming, commenting, and formatting. We defined feedback criteria and incorporated them into GPT4 prompts to guide feedback generation. Results were mixed: while some feedback messages closely aligned with the rubrics, offering valuable insights, others fell short in providing corrective guidance. This highlights the potential and limitations of using LLMs to generate feedback on code readability. Future research could refine these methods to improve feedback consistency and quality.",10.1145/3724389.3730771,https://doi.org/10.1145/3724389.3730771
Exploring Factors Influencing the Satisfaction of Adult Software Engineering Students with Teamwork in Distance Education,"Rahimi, Ebrahim and Passier, Harrie and Stuurman, Sylvia",Proceedings of the 23rd Koli Calling International Conference on Computing Education Research,2024,"Using team-based software development assignments is a prevalent instructional strategy in software engineering (SE) education. Students utilize these development assignments as a vehicle to (co-)learn SE concepts, practice problem-solving, and develop soft skills. The satisfaction of SE students with their teamwork experience in team-based assignments is an important educational and motivational factor that contributes to increased participation in future team-based projects. There is a scarcity of research on the satisfaction of SE students with teamwork in distance and online education specifically for adult learners. This study reports on a case study conducted to identify factors influencing the satisfaction of adult SE graduate students with their teamwork experiences in team-based software design and development assignments at the Open University of the Netherlands (OUNL), a distance education university for adult learners. The self-reflection reports of 29 adult SE students, aged between 25 and 35 years, documented and self-evaluated their experiences with a team-based design and development assignment within a master SE course were analyzed using an open thematic analysis approach. The analysis of the reports revealed six categories of factors that influenced the adult online SE students’ satisfaction with their team-working experience, namely, the attitude of team members, communication, collaboration, team characteristics, tooling and technology, and learning. Additionally, we conducted a literature review to identify any similarities and differences between the results obtained from the literature and those derived from our study on this topic.",10.1145/3631802.3631823,https://doi.org/10.1145/3631802.3631823
Prompt Engineering for Large Language Models to Support K-8 Computer Science Teachers in Creating Culturally Responsive Projects,"Tran, Minh",Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2,2023,"The power of large language models has opened up opportunities for educational use. In computing education, recent studies have demonstrated the potential of these models to improve learning and teaching experiences in university-level programming courses. However, research into leveraging them to aid computer science instructors in curriculum development and course material design is relatively sparse, especially at the K-12 level. This work aims to fill this gap by exploring the capability of large language models in ideating and designing culturally responsive projects for elementary and middle school programming classes. Our ultimate goal is to support K-8 teachers in effectively extracting suggestions from large language models by only using natural language modifications. Furthermore, we aim to develop a comprehensive assessment framework for culturally responsive AI-generated project ideas. We also hope to provide valuable insight into teachers’ perspectives on large language models and their integration into teaching practices.",10.1145/3568812.3603453,https://doi.org/10.1145/3568812.3603453
Case Study 2: Mapping between an E-Voting Curriculum and the DHS/NSA CAE Knowledge Units,"Sanchez, Edwin Antonio and Zheng, Muwei and Bishop, Matt and Zou, Xukai",Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1,2025,"To become a DHS/NSA Center of Academic Excellence in Cyber Defense (CAE-CD), academic institutions must satisfy several specific Knowledge Units (KUs). How they achieve this is up to the institutions. In this case study, we follow the methodology of an earlier work to demonstrate how key parts of an electronic voting (E-voting)-oriented cybersecurity curriculum, proposed by Hostler et al. [4] in 2021, maps into the DHS/NSA KUs supporting the CAE-CD designation, from two aspects: E-voting principle based topics, i.e., from theory and a plug-and-play e-voting system's composing components, i.e., from practice. We grouped CAE-CD KUs into those required as prerequisites, closely related, related/supported, and not covered by the E-voting curriculum. Teachers can then choose which KUs they will use and teach using only the parts of the E-voting-oriented curriculum they deem relevant, and in a depth they find appropriate to their educational objectives, while meeting the requirements of the selected KUs. We conclude with a discussion of how LLMs (Large Language Models) and quantum computing might be added to the E-voting-oriented curriculum.",10.1145/3641554.3701960,https://doi.org/10.1145/3641554.3701960
My Learnings from Allowing Large Language Models in Introductory Computer Science Classes,"Bhalerao, Rasika",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"Many instructors want to allow their students to use large language models (LLMs) in their introductory computer science courses, but they first want to see other instructors' results from doing so before taking on the risk in their own courses. Presented here are the results from allowing students to use LLMs in the second course in a sequence of intensive introductory courses designed to prepare students with a non-computational background for entry into a masters' degree program. We allowed students to use the internet and LLMs (such as ChatGPT or Github Copilot) to help with assignments, with guidelines to avoid plagiarism and encourage learning. We then surveyed students to ask about how they used LLMs, whether they saw others cheating, how they generally used internet-based resources on assignments and exams, and their feedback on the policies. We found that students are overwhelmingly using LLMs (and the internet generally) to learn and code",10.1145/3626253.3635511,https://doi.org/10.1145/3626253.3635511
Exploring the Use of Large Language Models in Requirements Engineering Education: An Experience Report with ChatGPT 3.5,,Proceedings of the XXIII Brazilian Symposium on Software Quality,2024,"Large Language Models (LLMs) are becoming common in educational settings. This trend presents a challenge for teachers, who must focus on teaching the proper usage of LLMs. In the context of Software Engineering (SE), ChatGPT can support various software development tasks. This work reports an experience with students using ChatGPT 3.5 to support the Requirements Engineering (RE) phase. We conducted a two-phase study with 42 students. First, the students elicited requirements for systems using RE techniques. Then, the students used ChatGPT 3.5 to generate requirements for the same systems. Finally, they compared both sets of requirements based on equivalence, innovation, and relevance. On average, 65.26% of the requirements generated by ChatGPT were considered equivalents to the requirements the students had elicited. However, students reported that ChatGPT generates broad and non-specific requirements. Students also reported that ChatGPT 3.5 can foster the requirements elicitation, but it is necessary to establish well-defined prompts for generating requirements.",10.1145/3701625.3701687,https://doi.org/10.1145/3701625.3701687
Using Large Language Models to Enhance Programming Error Messages,"Leinonen, Juho and Hellas, Arto and Sarsa, Sami and Reeves, Brent and Denny, Paul and Prather, James and Becker, Brett A.",Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1,2023,"A key part of learning to program is learning to understand programming error messages. They can be hard to interpret and identifying the cause of errors can be time-consuming. One factor in this challenge is that the messages are typically intended for an audience that already knows how to program, or even for programming environments that then use the information to highlight areas in code. Researchers have been working on making these errors more novice friendly since the 1960s, however progress has been slow. The present work contributes to this stream of research by using large language models to enhance programming error messages with explanations of the errors and suggestions on how to fix them. Large language models can be used to create useful and novice-friendly enhancements to programming error messages that sometimes surpass the original programming error messages in interpretability and actionability. These results provide further evidence of the benefits of large language models for computing educators, highlighting their use in areas known to be challenging for students. We further discuss the benefits and downsides of large language models and highlight future streams of research for enhancing programming error messages.",10.1145/3545945.3569770,https://doi.org/10.1145/3545945.3569770
Building Technological Improvisation Skills through Student-devised Coursework Topics,"Johnson, Colin G.",Proceedings of the ACM Conference on Global Computing Education Vol 1,2023,"The ability of improvise solutions to problems using a variety of technologies is an important, if often tacit, desired outcome from advanced computer science education. This paper will describe experience from three modules at two universities where students design their own assessment topic, based on a set of requirements aligned with the learning outcomes.The paper discusses why these technological improvisation skills are important, and how students can learn to cope with combining a variety variety of techniques, ideas and technologies that don't immediately fit well together. This helps students to build important high-level and meta-cognitive skills, and at a practical level provides students with projects that they can demonstrate to prospective employers after graduation.We discuss how these assessments were presented to students, and how the resulting student activities were aligned with learning objectives. We describe how complex ideas such as added value were explained to students, and how these assignments encouraged students to work on projects of ambition and substance, and to encourage their curiosity.Finally, we discuss some difficulties with this kind of assessment, and how we have endeavoured to tackle these difficulties. These include how such a diversity of assessments were marked fairly and consistently, how students who are struggling with the core module content can engage effectively, and how these kind of assessments can be devised without an excessive burden on teaching staff.",10.1145/3576882.3617917,https://doi.org/10.1145/3576882.3617917
WebGazeTrack: A Web-based Eye Tracking Tool,R\,Proceedings of the 6th European Conference on Software Engineering Education,2025,"Eye tracking provides insight into human cognition and attention, enabling a variety of use cases in different areas of research. However, traditional eye tracking research software suffers from several limitations. First, it lacks native web integration, making it difficult to integrate eye tracking into web applications. Second, due to the first limitation, mapping gaze data to evolving HTML elements in dynamic web environments is challenging. Third, collecting gaze data based on high-precision eye tracking hardware requires the installation of dedicated software. To address these challenges, we present WebGazeTrack, a lightweight, web-based eye tracking tool implemented as a Chrome extension that aims to radically simplify eye tracking research on the web. By using CSS selectors for dynamic AOI definitions and WebUSB for direct hardware communication, WebGazeTrack offers plug-and-play deployment without direct software installation on the host system and native integration into web pages. Currently, the extension supports the Tobii Pro Fusion eye tracker by wrapping the Tobii Pro SDK. It can be used as a standalone Chrome extension or, based on its API, as a foundation for developing custom applications. In this paper, we also propose three specific applications to demonstrate the versatility and potential of our approach.",10.1145/3723010.3723024,https://doi.org/10.1145/3723010.3723024
The Struggles of LLMs in Cross-Lingual Code Clone Detection,,Proc. ACM Softw. Eng.,2025,"With the involvement of multiple programming languages in modern software development, cross-lingual code clone detection has gained traction within the software engineering community. Numerous studies have explored this topic, proposing various promising approaches. Inspired by the significant advances in machine learning in recent years, particularly Large Language Models (LLMs), which have demonstrated their ability to tackle various tasks, this paper revisits cross-lingual code clone detection. We evaluate the performance of five (05) LLMs and, eight prompts (08) for the identification of cross-lingual code clones. Additionally, we compare these results against two baseline methods. Finally, we evaluate a pre-trained embedding model to assess the effectiveness of the generated representations for classifying clone and non-clone pairs. The studies involving LLMs and Embedding models are evaluated using two widely used cross-lingual datasets, XLCoST and CodeNet.  Our results show that LLMs can achieve high F1 scores, up to 0.99, for straightforward programming examples. However, they not only perform less well on programs associated with complex programming challenges but also do not necessarily understand the meaning of “code clones” in a cross-lingual setting. We show that embedding models used to represent code fragments from different programming languages in the same representation space enable the training of a basic classifier that outperforms all LLMs by ∼1 and ∼20 percentage points on the XLCoST and CodeNet datasets, respectively. This finding suggests that, despite the apparent capabilities of LLMs, embeddings provided by embedding models offer suitable representations to achieve state-of-the-art performance in cross-lingual code clone detection.",10.1145/3715764,https://doi.org/10.1145/3715764
RESPECT 2024: Conference Recap,"Pearson, Tamara and Strickland, Carla",SIGCSE Bull.,2024,"The Conference on Research in Equity and Sustained Participation in Engineering, Computing, and Technology is the premier venue for research on equity, inclusion, and justice in computing and computing education. RESPECT 2024, the ninth edition of this conference, was held on May 16-17, 2024 at the Georgia Tech Conference Center and Hotel in Atlanta, Georgia.",10.1145/3699853.3699856,https://doi.org/10.1145/3699853.3699856
Visions of a Discipline: Analyzing Introductory AI Courses on YouTube,"Engelmann, Severin and Choksi, Madiha Zahrah and Wang, Angelina and Fiesler, Casey","Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency",2024,"Education plays an indispensable role in fostering societal well-being and is widely regarded as one of the most influential factors in shaping the future of generations to come. As artificial intelligence (AI) becomes more deeply integrated into our daily lives and the workforce, educational institutions at all levels are directing their focus on resources that cater to AI education. Yet, informal education, including online learning on social media platforms like YouTube, plays an increasingly significant role for both students and the general public. Offering greater accessibility compared to formal education, millions of individuals use YouTube for educational resources on AI today. Due to the substantial societal impact of AI, it is crucial for introductory AI courses to meaningfully address the ethical implications associated with AI. Our work investigates the current landscape of introductory AI courses on YouTube, and the potential for introducing ethics in this context. We qualitatively analyze the 20 most watched introductory AI courses on YouTube, coding a total of 92.2 hours of educational content viewed by close to 50 million people. We find that these introductory AI courses do not meaningfully engage with ethical or societal challenges of AI (RQ1). When defining and framing AI, introductory AI courses foreground excitement around AI’s transformative role in society, over-exaggerate AI’s current and future abilities, and anthropomorphize AI (RQ2). In teaching AI, we see a widespread reliance on corporate AI tools and frameworks as well as a prioritization on a hands-on approach to learning rather than on conceptual foundations (RQ3). In promoting key AI practices, introductory AI courses abstract away entirely the socio-technical nature of AI classification and prediction, for example by favoring data quantity over data quality (RQ4). Given the power of openly available introductory courses to shape enduring beliefs around AI and its field at the onset of a learning journey, we extend our analysis with recommendations that aim to integrate ethical reflections into introductory AI courses. We recommend that introductory AI courses should (1) highlight ethical challenges of AI to present a more balanced perspective, (2) raise ethical issues explicitly relevant to the technical concepts discussed and (3) nurture a sense of accountability in future AI developers.",10.1145/3630106.3659045,https://doi.org/10.1145/3630106.3659045
Towards the Integration of Large Language Models and Automatic Assessment Tools: Enhancing Student Support in Programming Assignments,"Pereira Cipriano, Bruno and Silva, Miguel and Correia, Rodrigo and Alves, Pedro",Proceedings of the 24th Koli Calling International Conference on Computing Education Research,2024,"The rise of Large Language Models (LLMs) has sparked discussion in Computer Science Education (CSE) due to their ability to generate code from text prompts. Students may rely on these tools, neglecting core skills like computational thinking and program design. Thus, it’s crucial to responsibly integrate them into computer science courses.To address this, we integrated an open-source Automatic Assessment Tool with GPT, enabling students to receive LLM assistance on their programming assignments. This tool can be adopted and improved by educators, promoting more responsible integration of LLMs in CSE.",10.1145/3699538.3699588,https://doi.org/10.1145/3699538.3699588
Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language,"Denny, Paul and Kumar, Viraj and Giacaman, Nasser",Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1,2023,"GitHub Copilot is an artificial intelligence tool for automatically generating source code from natural language problem descriptions. Since June 2022, Copilot has officially been available for free to all students as a plug-in to development environments like Visual Studio Code. Prior work exploring OpenAI Codex, the underlying model that powers Copilot, has shown it performs well on typical CS1 problems thus raising concerns about its potential impact on how introductory programming courses are taught. However, little is known about the types of problems for which Copilot does not perform well, or about the natural language interactions that a student might have with Copilot when resolving errors. We explore these questions by evaluating the performance of Copilot on a publicly available dataset of 166 programming problems. We find that it successfully solves around half of these problems on its very first attempt, and that it solves 60% of the remaining problems using only natural language changes to the problem description. We argue that this type of prompt engineering, which we believe will become a standard interaction between human and Copilot when it initially fails, is a potentially useful learning activity that promotes computational thinking skills, and is likely to change the nature of code writing skill development.",10.1145/3545945.3569823,https://doi.org/10.1145/3545945.3569823
Auglets: Intelligent Tutors for Learning Good Coding Practices by Solving Refactoring Problems,"Kumar, Amruth N.",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1,2024,"Code quality is of universal concern among educators. Refactoring code, i.e., revising the structure of a program without changing its behavior is one approach for improving code quality. Numerous software tools have been created to help students refactor the code they write. Only a few software tutors have been reported in literature that help students proactively learn code quality by solving refactoring problems. But they suffer false positive and false negative grading issues because they allow freehand coding. We investigated whether refactoring tutors that do not allow freehand coding could be used to help students learn about non-trivial anti-patterns. We developed and deployed two software tutors for refactoring problems that are based on the principle of",10.1145/3649165.3690119,https://doi.org/10.1145/3649165.3690119
Assessing the Impact of Large Language Models on Cybersecurity Education: A Study of ChatGPT's Influence on Student Performance,"Ohm, Marc and Bungartz, Christian and Boes, Felix and Meier, Michael","Proceedings of the 19th International Conference on Availability, Reliability and Security",2024,"The popularity of chatbots to facilitate day-to-day business, including students and their study exercises, is on the rise. This paper investigates the extent and effects on the academic performance of students that leverage such tools. While many other approaches are hypothesized and discussed, we measure empirically. We recorded and compared the performance of cybersecurity students in weekly exercises and final exams over a period of three years. This allows us to have three groups with varying degrees of ChatGPT influence, namely no access, uncontrolled access, and controlled access. In an anonymous survey, we found that approximately 80% of our students utilize ChatGPT during the weekly assignments in 2023. However, none of them indicated this on their submission, despite it being a mandatory requirement. Through statistical analysis of achieved points in our sample groups, we identified that students perform similarly on the weekly assignments. However, their performance on the final examination deteriorates.",10.1145/3664476.3670446,https://doi.org/10.1145/3664476.3670446
Exploring CS1 Student's Notions of Code Quality,"Izu, Cruz and Mirolo, Claudio",Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1,2023,"Coding tasks combined with other activities such as Explain in Plain English or Parson Puzzles help CS1 students to develop core programming skills. Students usually receive feedback of code correctness but limited or no feedback on their code quality. Teaching students to evaluate and improve the quality of their code once it is functionally correct should be included in the curricula towards the end of CS1 or during CS2. However, little is known about the student's perceptions of code quality at the end of a CS1 course.This study aims to capture their developing notions of code quality, in order to tailor class activities to support code quality improvements. We directed students to think about the overall quality of small programs by asking them to rank a small set of solutions for a simple problem solving task. Their rankings and explanations have been analysed to identify the criteria underlying their quality assessments. The top quality criteria were Performance (64%), Structure (51%), Conciseness (42%) and Comprehensibility (42%). Although fast execution is a key criteria for ranking, their explanations on why a given option was fast were often flawed, indicating students need more support both to evaluate performance and to include readability or comprehensibility criteria in their assessment.",10.1145/3587102.3588808,https://doi.org/10.1145/3587102.3588808
Fostering Teamwork in Software Engineering Projects,"Gutica, Mirela",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2,2024,"Part of computer science disciplines, software engineering (SE) is concerned with the software lifecycle and the rigorous methods and processes required for designing, implementing, modifying and maintaining high-quality software systems. Project-based and experiential learning are core to developing SE competencies and skills. Besides technical competencies, soft skills including adaptability, communication, critical thinking and teamwork are required and highly valued by employers. Several aspects affect the success of a project: the student engagement and participation, the team's dynamics and diversity, the mentoring strategy and the peer feedback process. Important aspects of teamwork are achievement of a high-level of cohesiveness between team members, and effective communication. However, we found that these aspects are impacted by deterrents to diversity and inclusion, and are not always achieved. The purpose of this study is to explore instructional models for teaching SE project courses that foster diversity and inclusion in teamwork, and promote engagement.",10.1145/3649405.3659512,https://doi.org/10.1145/3649405.3659512
ASAG2024: A Combined Benchmark for Short Answer Grading,,Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2,2024,"Open-ended questions test a more thorough understanding compared to closed-ended questions and are often a preferred assessment method. However, open-ended questions are tedious to grade and subject to personal bias. Therefore, there have been efforts to speed up the grading process through automation. Short Answer Grading (SAG) systems aim to automatically score students' answers in examinations. Despite growth in SAG methods and capabilities, there exists no comprehensive short-answer grading benchmark across different subjects, grading scales, and distributions. Thus, it is hard to assess the capabilities of current automated grading methods in terms of their generalizability. In this preliminary work, we introduce the combined ASAG2024 benchmark to facilitate the comparison of automated grading systems. Combining seven commonly used short-answer grading datasets in a common structure and grading scale. For our benchmark, we evaluate a set of recent SAG methods, revealing that while LLM-based approaches reach new high scores, they still are far from reaching human performance. This opens up avenues for future research on human-machine SAG systems.",10.1145/3649409.3691083,https://doi.org/10.1145/3649409.3691083
A Bug's New Life: Creating Refute Questions from Filtered CS1 Student Code Snapshots,"Agarwal, Nimisha and Kumar, Viraj and Raman, Arun and Karkare, Amey",Proceedings of the ACM Conference on Global Computing Education Vol 1,2023,"In an introductory programming (CS1) context, a Refute question asks students for a counter-example which proves that a given code fragment is an incorrect solution for a given task. Such a question can be used as an assessment item to (formatively) develop or (summatively) demonstrate a student's abilities to comprehend the task and the code well enough to recognize a mismatch. These abilities assume greater significance with the emergence of generative AI technologies capable of writing code that is plausible (at least to novice programmers) but not always correct.Instructors must address three concerns while designing an effective Refute question, each influenced by their specific teaching-learning context: (1) Is the task comprehensible? (2) Is the incorrect code a plausible solution for the task? (3) Is the complexity of finding a counter-example acceptable? While the first concern can often be addressed by reusing tasks from previous code writing questions, addressing the latter concerns may require substantial instructor effort. We therefore investigate whether concerns (2) and (3) can be addressed by buggy student solutions for the corresponding code writing question from a previous course offering. For 6 code writing questions (from a Fall 2015 C programming course), our automated evaluation system logged 13,847 snapshots of executable student code, of which 10,574 were buggy (i.e., they failed at least one instructor-supplied test case). Code selected randomly from this pool rarely addresses these concerns, and manual selection is infeasible. Our paper makes three contributions. First, we propose an automated mechanism to filter this pool to a more manageable number of snapshots from which appropriate code can be selected manually. Second, we evaluate our semi-automated mechanism with respect to concerns (2) and (3) by surveying a diverse set of 56 experienced participants (instructors, tutors, and teaching assistants). Third, we use this mechanism to seed a public repository of Refute questions and provide a template to create additional questions using a public resource (CodeCheck).",10.1145/3576882.3617916,https://doi.org/10.1145/3576882.3617916
Leveraging ChatGPT for Adaptive Learning through Personalized Prompt-based Instruction: A CS1 Education Case Study,"Abolnejadian, Mohammad and Alipour, Sharareh and Taeb, Kamyar",Extended Abstracts of the CHI Conference on Human Factors in Computing Systems,2024,"In this research paper, we discuss our attempt to teach high school students introductory programming with Python using a custom learning platform that leverages ChatGPT to generate personalized learning materials based on each student’s educational background. The platform features topics and subtopics, each supported by prompts for Explanation, Example, Exercise, and Exercise Solution, with a context-setting prompt tailored to individual students’ backgrounds while respecting their privacy. The case study brought up compelling insights. Students exhibited heightened engagement, and the lecturers transitioned from being traditional instructors teaching content to becoming mentors who guide students on what to do next, clarifying misunderstandings and addressing potential questions. Furthermore, students gained hands-on programming experience during the learning process, eliminating the traditional post-class experimentation phase. This innovative approach not only enhances traditional CS1 education but also suggests a broader application of Large Language Models (LLMs) for personalized learning across diverse fields, providing tailored instruction and fostering engagement.",10.1145/3613905.3637148,https://doi.org/10.1145/3613905.3637148
Exploring the Innovation Opportunities for Pre-trained Models,"Park, Minjung and Forlizzi, Jodi and Zimmerman, John",Proceedings of the 2025 ACM Designing Interactive Systems Conference,2025,"Innovators transform the world by understanding where services are successfully meeting customers’ needs and then using this knowledge to identify failsafe opportunities for innovation. Pre-trained models have changed the AI innovation landscape, making it faster and easier to create new AI products and services. Understanding where pre-trained models are successful is critical for supporting AI innovation. Unfortunately, the hype cycle surrounding pre-trained models makes it hard to know where AI can really be successful. To address this, we investigated pre-trained model applications developed by HCI researchers as a proxy for commercially successful applications. The research applications demonstrate technical capabilities, address real user needs, and avoid ethical challenges. Using an artifact analysis approach, we categorized capabilities, opportunity domains, data types, and emerging interaction design patterns, uncovering some of the opportunity space for innovation with pre-trained models.",10.1145/3715336.3735753,https://doi.org/10.1145/3715336.3735753
Investigating the Effectiveness of Variations of Micro Parsons Problems,"Wu, Zihan",Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2,2023,"Parsons problems have been used to provide scaffolding for introductory learners. Instead of asking learners to write from scratch, Parsons problems provide blocks of mixed-up code, and ask learners to rearrange them into the correct order. In traditional Parsons problems, each block would contain one or more lines of code. While traditional Parsons problems have been widely used, there is an untapped potential to adapt them to practice to write a single line of code. My research builds upon the design of traditional Parsons problems and introduces micro Parsons problems – problems that focus on assembling code fragments within a single line. The primary goal of my research is to evaluate the effectiveness of variations of micro Parsons problems to support introductory computer science education. Specifically, I aim to investigate the effects of text entry practice versus: 1) micro Parsons problems for creating SQL and Regular Expressions, 2) personalized micro Parsons problems for just-in-time learning after learners make a mistake, and 3) adaptive micro Parsons problems for fading scaffolding as learners’ skill develops.",10.1145/3568812.3603447,https://doi.org/10.1145/3568812.3603447
"Scenario, Role, and Persona: A Scoping Review of Design Strategies for Socially Intelligent AI Agents","Niu, Ruowen and Hu, Jiaxiong and Peng, Siyu and Cao, Caleb Chen and Liu, Chengzhong and Han, Sirui and Guo, Yike",Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems,2025,"As artificial intelligence (AI) agents have often been perceived as social actors, there is a growing expectation for them to demonstrate social intelligence. Social intelligence encompasses the ability of AI agents to align their actions with human intentions and behave in socially and culturally appropriate ways. This study conducts a scoping review to analyze the design strategies employed in current AI agent designs that support the exhibition of social intelligence. Our findings reveal three design strategy themes that interdependently and collectively shape the capabilities and behaviors of AI agents: scenario, role, and persona. These findings provide a structured perspective and actionable insights for designing AI agents that effectively integrate social intelligence into human-AI interactions.",10.1145/3706599.3719762,https://doi.org/10.1145/3706599.3719762
Understanding the Reasoning Behind Students' Self-Assessments of Ability in Introductory Computer Science Courses,"Chen, Melissa and Li, Yinmiao and O'Rourke, Eleanor",Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1,2024,"Although enrollments in introductory computing courses are rising, many students still struggle to learn programming. Previous research has found that students’ perceptions of the programming process may be one factor that contributes to this problem. Students often assess their own programming abilities overly harshly when experiencing low-level programming moments that are considered normal and expected parts of learning to program. For example, many students think they are doing poorly if they need to stop coding to plan. Research has also shown that students who self-assess negatively in these moments tend to have lower self-efficacy, defined as one’s belief in their ability to achieve a particular outcome. In turn, students with lower self-efficacy tend not to persist in their computing studies. While the criteria that students use to assess their ability have been studied extensively, we have a limited understanding of the origins of these criteria and students’ reasons for adopting them. To address this gap, we conducted a total of 36 interviews with seven introductory computer science students throughout an academic quarter. In each interview, we asked students to think aloud and explain their reasoning while filling out a self-assessment survey. Through a qualitative analysis of the data, we identified the most common reasons students gave for negatively assessing their performance, including having high expectations for their abilities and feeling like they cannot overcome a struggle. We also identified common reasons why students do not negatively assess their ability in these moments, including believing an experience is “normal” or feeling like they can learn from or overcome a struggle. These findings contribute valuable new knowledge about the underpinnings of students’ self-assessments of ability, and suggest that interventions that explicitly emphasize best practices and normalize struggles in the programming learning process are needed to increase student self-efficacy and persistence in computing.",10.1145/3632620.3671094,https://doi.org/10.1145/3632620.3671094
Reimagining CS Pathways: High School and Beyond,Computer Science Teachers Association and Institute for Advancing Computing Education and Association for Computing Machinery and Code.org and College Board and CSforALL and Expanding Computing Education Pathways Alliance,,2024,,,
Teaching CS-101 at the Dawn of ChatGPT,"Jacques, Lorraine",ACM Inroads,2023,"Recent news suggests that the advent of AI-generated coding tools signal the end of humans programming. This news should not, however, suggest that students not learn how to program but instead that instructors rethink how they teach programming. Math education has already addressed the challenge of teaching fluency when there is technology for basic tasks by having students use multiple representations, different approaches, and explanations of others' work to emphasize problem-solving, critical thinking, and communication while still teaching basic skills. These approaches can also be applied to computer science education, especially in an introductory course, and with the same benefits.",10.1145/3595634,https://doi.org/10.1145/3595634
Can Students without Prior Knowledge Use ChatGPT to Answer Test Questions? An Empirical Study,"Shoufan, Abdulhadi",ACM Trans. Comput. Educ.,2023,"With the immense interest in ChatGPT worldwide, education has seen a mix of both excitement and skepticism. To properly evaluate its impact on education, it is crucial to understand how far it can help students without prior knowledge answer assessment questions. This study aims to address this question as well as the impact of the question type. We conducted multiple experiments with computer engineering students (experiment group: n=41 to 56), who were asked to use ChatGPT to answer previous test questions before learning about the related topics. Their scores were then compared with the scores of previous-term students who answered the same questions in a quiz or exam setting (control group: n=24 to 61). The results showed a wide range of effect sizes, from -2.55 to 1.23, depending on the question type and content. The experiment group performed best answering code analysis and conceptual questions but struggled with code completion and questions that involved images. However, the performance in code generation tasks was inconsistent. Overall, the ChatGPT group’s answers lagged slightly behind the control group’s answers with an effect size of -0.16. We conclude that ChatGPT, at least in the field of this study, is not yet ready to rely on by students who do not have sufficient background to evaluate generated answers. We suggest that educators try using ChatGPT and educate students on effective questioning techniques and how to assess the generated responses. This study provides insights into the capabilities and limitations of ChatGPT in education and informs future research and development.",10.1145/3628162,https://doi.org/10.1145/3628162
AI as a Learning Tool for Introductory Programming,"Roll, James",J. Comput. Sci. Coll.,2024,"The goal of this assignment is to introduce introductory programming students to using generative AI tools like Claude and ChatGPT to help them in learning introductory programming. Students are shown how they can use AI tools to help explain basic programming concepts, decode cryptic error messages, explain why a program isn't working, and find syntax errors in and suggest fixes. Students are also encouraged to avoid using AI Tools to fully write programs at this point in their education, and introduced to the limitations generative AI tools for programming. This version of the assignment was written for an introductory Java programming course, but could easily be adapted to other programming languages.",,
Adaptable Metrics to Inform Introductory CS,"Garcia, Yuan and Ngo, Jenny and Lin, Florence Rui and Dodds, Zachary",J. Comput. Sci. Coll.,2025,"Metrics have long been used to assess and guide successful software projects. Traditionally these metrics have measured software's professional rather than its educational suitability. This work proposes six adaptable, reproducible pedagogical metrics. With these metrics, we track an Introductory CS course's capstone projects, 2018--2024. The results suggest both year-over-year evolution and a more sudden, LLM-correlated impact on students' relationship with their early computing work. We have begun adapting our curriculum to these signals, and we foresee future refinements and broader applications to metrics-based reproducible curricular assessment.",,
Classifying Course Discussion Board Questions using LLMs,"Zhang, Paul and Jaipersaud, Brandon and Ba, Jimmy and Petersen, Andrew and Zhang, Lisa and Zhang, Michael R.",Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 2,2023,"Large language models (LLMs) can be used to answer student questions on course discussion boards, but there is a risk of LLMs answering questions they are unable to address. We propose and evaluate an LLM-based system that classifies student questions into one of four types: conceptual, homework, logistics, and not answerable. We then prompt an LLM using a type-specific prompt. Using GPT-3, we achieve 81% classification accuracy across the four categories. Furthermore, we achieve 93% accuracy on classifying not answerable questions. This indicates that our system effectively ignores questions that it cannot address.",10.1145/3587103.3594202,https://doi.org/10.1145/3587103.3594202
Online Programming Exams - An Experience Report,,Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1,2023,"When seeking to maximise the authenticity of assessment in programming courses it makes sense to provide students with practical programming problems to solve in an environment that is close to real software development practice, i.e., online, open book, and using their typical development environment. This creates an assessment environment that should afford students sufficient opportunities to evidence what they have learned, but also creates practical challenges in terms of academic integrity, flexibility in the automated grading process, and assumptions surrounding how the student may attempt to solve the problems both in terms of correct and incorrect solutions. In this experience report, we outline two independently observed cohorts of students sitting the same Java programming exam, with different weights, over three years. This is undertaken as a reflective exercise in order to derive a series of recommendations and retrospectively obvious pitfalls to act as guidance for educators considering online programming exams for large (i.e. n &gt; 150) introductory programming courses. After discussing our assessment methodology, we provide 4 high-level observations and centre a set of recommendations around these to aid practitioners in their assessment design.",10.1145/3587102.3588829,https://doi.org/10.1145/3587102.3588829
An Automated Marker for Computer-Human Interaction “MarCHIr”: Assessment of Creative Web Prototypes,"Lottridge, Danielle and Dimalen, Davis and Weber, Gerald",ACM Trans. Comput. Educ.,2025,"Automated assessment is well-established within computer science courses but largely absent from human-computer interaction courses. Automating the assessment of human-computer interaction (HCI) is challenging because the coursework tends not to be computational but rather highly creative, such as designing and implementing interactive prototypes. We meet this challenge by developing an automarker for HCI “MarCHIr” to assess key aspects of web prototypes: visual design, interactivity, and accessibility. MarCHIr automatically compiles web prototypes and analyses them at the pixel level to assess designs using foundational Gestalt visual principles. While computer science student assessments are often personalised with permutations of numbers, we use random assignment of colours to personalise creative prototype assignments at the scale of hundreds of students. Finally, MarCHIr integrates industry accessibility checks to HCI student assessment. We share two years of case study data across two cohorts of university students and reflect on implications for the use of automated assessment within HCI tertiary education.",10.1145/3732788,https://doi.org/10.1145/3732788
Automated Questions About Learners' Own Code Help to Detect Fragile Prerequisite Knowledge,"Lehtinen, Teemu and Sepp\",Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1,2023,"Students are able to produce correctly functioning program code even though they have a fragile understanding of how it actually works. Questions derived automatically from individual exercise submissions (QLC) can probe if and how well the students understand the structure and logic of the code they just created. Prior research studied this approach in the context of the first programming course. We replicate the study on a follow-up programming course for engineering students which contains a recap of general concepts in CS1. The task was the classic rainfall problem which was solved by 90% of the students. The QLCs generated from each passing submission were kept intentionally simple, yet 27% of the students failed in at least one of them. Students who struggled with questions about their own program logic had a lower median for overall course points than students who answered correctly.",10.1145/3587102.3588787,https://doi.org/10.1145/3587102.3588787
Generating Programs Trivially: Student Use of Large Language Models,"Prasad, Siddhartha and Greenman, Ben and Nelson, Tim and Krishnamurthi, Shriram",Proceedings of the ACM Conference on Global Computing Education Vol 1,2023,"Educators have been concerned about the capability of large language models to automatically generate programs in response to textual prompts. However, little is known about whether and how students actually use these tools.In the context of an upper-level formal methods course, we gave students access to large language models. They were told they could use the models freely. We built a Visual Studio Code extension to simplify access to these models. We also paid for an account so students could use the models for free without worrying about cost.In this experience report we analyze the outcomes. We see how students actually do and do not use the models. We codify the different uses they make. Most of all, we notice that students actually do not use them very much at all, and provide insight into the many reasons why not. We believe such experiments can help rebalance some of the public narrative about such tools.",10.1145/3576882.3617921,https://doi.org/10.1145/3576882.3617921
Applying Large Language Models to Enhance the Assessment of Parallel Functional Programming Assignments,"Grandel, Skyler and Schmidt, Douglas C. and Leach, Kevin",Proceedings of the 1st International Workshop on Large Language Models for Code,2024,"Courses in computer science (CS) often assess student programming assignments manually, with the intent of providing in-depth feedback to each student regarding correctness, style, efficiency, and other quality attributes. As class sizes increase, however, it is hard to provide detailed feedback consistently, especially when multiple assessors are required to handle a larger number of assignment submissions. Large language models (LLMs), such as ChatGPT, offer a promising alternative to help automate this process in a consistent, scalable, and minimally-biased manner.This paper explores ChatGPT-4's scalablility and accuracy in assessing programming assignments based on predefined rubrics in the context of a case study we conducted in an upper-level undergraduate and graduate CS course at Vanderbilt University. In this case study, we employed a method that compared assessments generated by ChatGPT-4 against human graders to measure the accuracy, precision, and recall associated with identifying programming mistakes. Our results show that when ChatGPT-4 is used properly (e.g., with appropriate prompt engineering and feature selection) it can improve objectivity and grading efficiency, thereby acting as a complementary tool to human graders for advanced computer science graduate and undergraduate students.",10.1145/3643795.3648375,https://doi.org/10.1145/3643795.3648375
A Comparison of Eye Movement Classifiers,"Ezer, Timur and Engl, Fabian and Grabinger, Lisa and R\",Proceedings of the 6th European Conference on Software Engineering Education,2025,"Eye tracking is a powerful tool for investigating cognitive processes, yet the classification performance of state-of-the-art eye movement classifiers often relies on manually defined thresholds, making them vulnerable when labeling data with varying noise levels. To address this limitation, deep learning approaches promise to replace such manual thresholds using automated and adaptive methods. In recent years, several studies have proposed deep learning models for eye movement classification. However, comparisons of these algorithms are rare. This study fills the research gap by comparing two publicly available neural networks for eye movement classification with the Tobii I-VT algorithm used in the Tobii Pro Lab software. The comparison evaluates classification performance using metrics such as F1-score, Cohen’s Kappa, and Matthew’s Correlation Coefficient. The analysis leverages datasets recorded with Tobii Pro Spectrum and Tobii Pro Fusion eye trackers from two separate studies with sampling frequencies of 300&nbsp;Hz and 250&nbsp;Hz, respectively. Together, these datasets include approximately 5000 eye movements, comprising fixations, saccades, and post-saccadic oscillations. The results provide interesting insights: On the noisier 250&nbsp;Hz dataset, the Tobii I-VT algorithm excels in sample-level evaluation, while deep learning approaches outperform it in event-level saccade detection. In contrast, on the 300&nbsp;Hz dataset, one deep learning model achieves superior performance on the event-level. This work aims to assist researchers in choosing the most suitable eye movement classifier for their datasets, making a significant contribution to the field of eye movement classifier comparisons.",10.1145/3723010.3723023,https://doi.org/10.1145/3723010.3723023
Hacc-Man: An Arcade Game for Jailbreaking LLMs,"Valentim, Matheus and Falk, Jeanette and Inie, Nanna",Companion Publication of the 2024 ACM Designing Interactive Systems Conference,2024,"The recent leaps in complexity and fluency of Large Language Models (LLMs) mean that, for the first time in human history, people can interact with computers using natural language alone. This creates monumental possibilities of automation and accessibility of computing, but also raises severe security and safety threats: When everyone can interact with LLMs, everyone can potentially break into the systems running LLMs. All it takes is creative use of language. This paper presents Hacc-Man, a game which challenges its players to “jailbreak” an LLM: subvert the LLM to output something that it is not intended to. Jailbreaking is at the intersection between creative problem solving and LLM security. The purpose of the game is threefold: 1. To heighten awareness of the risks of deploying fragile LLMs in everyday systems, 2. To heighten people’s self-efficacy in interacting with LLMs, and 3. To discover the creative problem solving strategies, people deploy in this novel context.",10.1145/3656156.3665432,https://doi.org/10.1145/3656156.3665432
A Review of the Role and Impact of Generative Artificial Intelligence on Education,"Yang, Qi",Proceedings of the 2024 7th International Conference on Educational Technology Management,2025,"In order to ensure quality development in the age of intelligence, it is crucial to integrate intelligent technology with education. Artificial Intelligence (AI) and Generative Artificial Intelligence (GAI) are disruptive technologies in the area of education. While online education brings significant advantages in enhancing educational quality, promoting educational equity, and improving educational efficiency, it has also raised concerns among scholars around the world regarding students' moral ethics, cultivation of emotional values, technological dependence, thinking deprivation, privacy, and policy making. Using Cite Space software to analyze more than 50 articles from core journals in the field of educational technology at home and abroad, this paper comprehensively summarizes the role and impact of generative AI in education up to 2023, suggests the limitations of generative AI in empowering education at present, and predicts the direction scholars will tend to research in this field in the future.",10.1145/3711403.3711435,https://doi.org/10.1145/3711403.3711435
ChatGPT-Assisted ABET Accreditation for BSIT Programs,"Wang, Ye Diana",Proceedings of the 25th Annual Conference on Information Technology Education,2024,This talk presents practical strategies for facilitating ABET accreditation for BSIT Programs using ChatGPT as a digital assistant.,10.1145/3686852.3686874,https://doi.org/10.1145/3686852.3686874
Elevating Learning Experiences: Leveraging Large Language Models as Student-Facing Assistants in Discussion Forums,"Mitra, Chancharik and Miroyan, Mihran and Jain, Rishi and Kumud, Vedant and Ranade, Gireeja and Norouzi, Narges",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"Recent advancements in instruction-tuned large language models offer new potential for enhancing students' experiences in large-scale classes. Deploying LLMs as student-facing assistants, however, presents challenges. Key issues include integrating class-specific content into responses and applying effective pedagogical techniques. This study addresses these challenges through retrieval and prompting techniques, focusing on mitigating hallucinations in LLM-generated responses, a crucial concern in education. Furthermore, practical deployment brings further challenges related to student data privacy and computational constraints. This research strives to enhance the quality and relevance of LLM responses while addressing practical deployment issues, with an emphasis on creating a versatile system for diverse domains and teaching styles.",10.1145/3626253.3635609,https://doi.org/10.1145/3626253.3635609
Generating Effective Distractors for Introductory Programming Challenges: LLMs vs Humans,"Hassany, Mohammad and Brusilovsky, Peter and Savelka, Jaromir and Lekshmi Narayanan, Arun Balajiee and Akhuseyinoglu, Kamil and Agarwal, Arav and Hendrawan, Rully Agus",Proceedings of the 15th International Learning Analytics and Knowledge Conference,2025,"As large language models (LLMs) show great promise in generating a wide spectrum of educational materials, robust yet cost-effective assessment of the quality and effectiveness of such materials becomes an important challenge. Traditional approaches, including expert-based quality assessment and student-centered evaluation, are resource-consuming, and do not scale efficiently. In this work, we explored the use of pre-existing student learning data as a promising approach to evaluate LLM-generated learning materials. Specifically, we used a dataset where students were completing the program construction challenges by picking the correct answers among human-authored distractors to evaluate the quality of LLM-generated distractors for the same challenges. The dataset included responses from 1,071 students across 22 classes taught from Fall 2017 to Spring 2023. We evaluated five prominent LLMs (OpenAI-o1, GPT-4, GPT-4o, GPT-4o-mini, and Llama-3.1-8b) across three different prompts to see which combinations result in more effective distractors, i.e., those that are plausible (often picked by students), and potentially based on common misconceptions. Our results suggest that GPT-4o was the most effective model, matching close to 50% of the functional distractors originally authored by humans. At the same time, all of the evaluated LLMs generated many novel distractors, i.e., those that did not match the pre-existing human-authored ones. Our preliminary analysis shows that those appear to be promising. Establishing their effectiveness in real-world classroom settings is left for future work.",10.1145/3706468.3706529,https://doi.org/10.1145/3706468.3706529
Feedback on Feedback: Student’s Perceptions for Feedback from Teachers and Few-Shot LLMs,R\,Proceedings of the 15th International Learning Analytics and Knowledge Conference,2025,"Large language models (LLMs) can be a valuable resource for generating texts and performing various instruction-based tasks. In this paper, we explored the use of LLMs, particularly for generating feedback for students in higher education. More precisely, we conducted an experiment to examine students’ perceptions regarding LLM-generated feedback. This has the overall aim of assisting teachers in the feedback creation process. First, we examine the different student perceptions regarding the feedback that students got without being aware of whether it was created by their teacher or an LLM. Our results reveal that the feedback source has not impacted how it was perceived by the students, except in cases where repetitive content has been generated, which is a known limitation of LLMs. Second, students have been asked to identify whether the feedback comes from an LLM or the teacher. The results demonstrate, that students were unable to identify the feedback source. A small subset of indicators has been identified, that clearly revealed from whom the feedback comes from. Third, student perceptions are analyzed while knowing that feedback has been auto-generated. This examination indicates that generated feedback is likely to be met with resistance. It contradicts the findings of the first examination. This emphasizes the need of a teacher-in-the-loop approach when employing auto-generated feedback in higher education.",10.1145/3706468.3706479,https://doi.org/10.1145/3706468.3706479
Leveraging Large Language Models for Automated Assessment of Elementary Students' Block-Based Narrative Programs,"Gupta, Anisha and Monahan, Robert and Vandenberg, Jessica and Smith, Andy and Elsayed, Rasha and Fox, Kimkinyona and Minogue, James and Oliver, Kevin and Hubbard Cheuoua, Aleata and Ringstaff, Cathy and Mott, Bradford",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2,2024,"Recent years have seen increasing awareness of the need to engage young learners in computational thinking (CT). Integrating digital storytelling, where students create short narratives, and CT offers significant potential for promoting interdisciplinary learning for students; however, it is critical to provide both teachers and students with automated support. A promising approach for enabling support is to leverage advances in Large Language Models (LLMs), which have demonstrated considerable potential for assessing both programming and natural language artifacts. In this work, we investigate the capabilities of LLMs to automatically assess student-created block-based programs developed using a narrative-centered learning environment that engages upper elementary students (ages 9 to 11) in learning CT and physical science through the creation of interactive science narratives. Using the narrative programs created by 28 students, we explore the efficacy of LLMs to assess the programs across two dimensions.",10.1145/3649409.3691089,https://doi.org/10.1145/3649409.3691089
"ChatGPT in IT Education Ecosystem: Unraveling Long-Term Impacts on Job Market, Student Learning, and Ethical Practices","Sakib, Nazmus and Anik, Fahim Islam and Li, Lei",Proceedings of the 24th Annual Conference on Information Technology Education,2023,"The use of ChatGPT in the educational ecosystem has opened up new avenues for learning but also raises questions about its multifarious long-term effects. This scientific study explores how ChatGPT, an AI chatbot, may impact the career prospects of Information Technology and Computer Science graduates in the long term, focusing on job automation and displacement. This study also investigates the enduring impact of ChatGPT on students' attitudes toward learning and developing skills in this education domain while examining ethical practices for incorporating this AI-based aid. This research provides methods to deter unethical actions related to ChatGPT and encourage ethical conduct among students for optimal performance. Moreover, it divulges the impact of ChatGPT on job opportunities, positive outlook, and the pressing necessity for ethical regulations in artificial intelligence use and deployment.",10.1145/3585059.3611447,https://doi.org/10.1145/3585059.3611447
The Journey of LLMs in Education,"He, Zhongxuan",XRDS,2024,,10.1145/3688092,https://doi.org/10.1145/3688092
EIT: Earnest Insight Toolkit for Evaluating Students' Earnestness in Interactive Lecture Participation Exercises,"Miroyan, Mihran and Weng, Shiny and Shah, Rahul and Yan, Lisa and Norouzi, Narges",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"Today's rapidly evolving educational landscape prioritizes active student engagement. Classrooms at scale face particular challenges in fostering meaningful interactions between students and course content. In this study, we introduce EIT (Earnest Insight Toolkit), a tool designed to assess students' engagement within interactive lecture participation exercises-particularly in the context of large-scale hybrid classrooms. We use EIT to conduct a comprehensive assessment of student responses to interactive lecture poll questions. Our objective with EIT is to equip educators with valuable means of identifying at-risk students for enhancing intervention and support strategies and measuring student engagement with course content.",10.1145/3626252.3630838,https://doi.org/10.1145/3626252.3630838
A Comparison of Proctoring Regimens for Computer-Based Computer Science Exams,"Emeka, Chinedu and West, Matthew and Zilles, Craig and Silva, Mariana",Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1,2024,"In this paper, we explore three different methods for administering computer-based tests at scale: (1) a dedicated Computer-Based Testing Center (CBTC), (2) Bring Your Own Device (BYOD) exams proctored in person in the classroom, and (3) BYOD exams proctored online via Zoom. We conducted two randomized crossover experiments to compare pairs of modalities against each other (CBTC vs BYOD-in-person and CBTC vs BYOD-online). We found that testing modality did not impact students' exam performance or students' preparation before exams. However, we observed that students preferred the modalities in which they had recently received the highest scores. Our results indicate that several different modalities can be effectively used to administer testing at scale for CS courses.",10.1145/3649217.3653536,https://doi.org/10.1145/3649217.3653536
Enhancing Formative Feedback at Scale with the Intelligent Feedback Assistant,"Jamal, Rifa and Renzella, Jake",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"Formative feedback spans various domains, from education to businesses and creative endeavours. In educational contexts, feedback enriches students' learning and work quality through reflection. However, providing effective feedback at scale is challenging. Students struggle to engage with feedback, often due to lack of feedback literacy. Recent advancements in Natural Language Processing, a branch of Artificial Intelligence, provides opportunities to evaluate how we can support feedback providers in its quality and scale. This poster paper presents an overview of key feedback challenges, attributes of high quality feedback, and introduces the Intelligent Feedback Assistant (IFA), an innovative NLP-based system designed to assist educators in delivering high-quality feedback. IFA operates as an ensemble of machine learning models and non-AI systems to guide educators in refining their feedback, ensuring it embodies attributes of effective feedback - actionable, specific, justified, and positive. IFA is supportive, not generative, ensuring the feedback provider remains central to the feedback provision process. The tool design, and outcomes of IFA offers a promising path for scaleable, high-quality formative feedback in education and beyond.",10.1145/3626253.3635482,https://doi.org/10.1145/3626253.3635482
Learning Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT &amp; NetLogo Chat,"Chen, John and Lu, Xi and Du, Yuzhou and Rejtig, Michael and Bagley, Ruth and Horn, Mike and Wilensky, Uri",Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems,2024,"Large Language Models (LLMs) have the potential to fundamentally change the way people engage in computer programming. Agent-based modeling (ABM) has become ubiquitous in natural and social sciences and education, yet no prior studies have explored the potential of LLMs to assist it. We designed NetLogo Chat to support the learning and practice of NetLogo, a programming language for ABM. To understand how users perceive, use, and need LLM-based interfaces, we interviewed 30 participants from global academia, industry, and graduate schools. Experts reported more perceived benefits than novices and were more inclined to adopt LLMs in their workflow. We found significant differences between experts and novices in their perceptions, behaviors, and needs for human-AI collaboration. We surfaced a knowledge gap between experts and novices as a possible reason for the benefit gap. We identified guidance, personalization, and integration as major needs for LLM-based interfaces to support the programming of ABM.",10.1145/3613904.3642377,https://doi.org/10.1145/3613904.3642377
Multiple-Choice Question Generation Using Large Language Models: Methodology and Educator Insights,"Biancini, Giorgio and Ferrato, Alessio and Limongelli, Carla","Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization",2024,"Integrating Artificial Intelligence (AI) in educational settings has brought new learning approaches, transforming the practices of both students and educators. Among the various technologies driving this transformation, Large Language Models (LLMs) have emerged as powerful tools for creating educational materials and question answering, but there are still space for new applications. Educators commonly use Multiple-Choice Questions (MCQs) to assess student knowledge, but manually generating these questions is resource-intensive and requires significant time and cognitive effort. In our opinion, LLMs offer a promising solution to these challenges. This paper presents a novel comparative analysis of three widely known LLMs - Llama 2, Mistral, and GPT-3.5 - to explore their potential for creating informative and challenging MCQs. In our approach, we do not rely on the knowledge of the LLM, but we inject the knowledge into the prompt to contrast the hallucinations, giving the educators control over the test’s source text, too. Our experiment involving 21 educators shows that GPT-3.5 generates the most effective MCQs across several known metrics. Additionally, it shows that there is still some reluctance to adopt AI in the educational field. This study sheds light on the potential of LLMs to generate MCQs and improve the educational experience, providing valuable insights for the future.",10.1145/3631700.3665233,https://doi.org/10.1145/3631700.3665233
Exploring ChatGPT’s impact on post-secondary education: A qualitative study,"Rajabi, Parsa and Taghipour, Parnian and Cukierman, Diana and Doleck, Tenzin",Proceedings of the 25th Western Canadian Conference on Computing Education,2023,"As Chat Generative Pre-trained Transformer (ChatGPT) gains traction, its impact on post-secondary education is increasingly being debated. This qualitative study explores the perception of students and faculty members at a research university in Canada regarding ChatGPT’s use in a post-secondary setting, focusing on how it could be incorporated and what ways instructors can respond to this technology. We present the summary of a discussion that took place in a two-hour focus group session with 40 participants from the computer science and engineering departments, and highlight issues surrounding plagiarism, assessment methods, and the appropriate use of ChatGPT. Findings suggest that students are likely to use ChatGPT, but there is a need for specific guidelines, more classroom assessments, and mandatory reporting of ChatGPT use. The study contributes to the emergent research on ChatGPT in higher education and emphasizes the importance of proactively addressing challenges and opportunities associated with ChatGPT adoption and use.",10.1145/3593342.3593360,https://doi.org/10.1145/3593342.3593360
Investigating the Needs of Middle School Educators in Teaching Artificial Intelligence,,Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2,2024,"Widespread and accessible use of artificial intelligence (AI) has escalated dramatically in recent years, with teachers being among those who need to understand, use, and teach these concepts and technologies. However, teachers' access to training and their interest in learning and using AI vary, often due to limited opportunities to attend rigorous, out-of-school training and to receive on-going classroom support. In this work, we report on thematic findings from a contextual analysis of teacher responses to open-ended survey items as well as interviews with them, which informed the design of a customized and relevant professional development (PD) experience for a group of middle school teachers. Our findings have implications for teacher PD in K-12 AI education.",10.1145/3649409.3691082,https://doi.org/10.1145/3649409.3691082
RESPECT 2024: Proceedings of the 2024 on RESPECT Annual Conference,,,2024,"Welcome to RESPECT 2024! The Conference on Research in Equity and Sustained Participation in Engineering, Computing, and Technology is the premier venue for research on equity, inclusion, and justice in computing and computing education. This volume contains the papers presented at RESPECT 2024, the ninth edition of this conference, held on May 16-17, 2024 at the Georgia Tech Conference Center and Hotel in Atlanta, Georgia.As researchers, especially those of us focused on equity, freedom, and justice, our job is to give language to and make meaning of the joy, trauma, and unwavering spirit of the most vulnerable and marginalized among us. We don't do this simply to shed light but to influence change. We stand when others are forced to sit and speak when others are silenced. For many of us, the past several years have rendered our usual tools ineffective, and often we find ourselves seated, scared to stand, and essentially silenced as we search for new language to describe old problems. We increasingly, and rightfully, feel frustrate... powerles... angry. Unfortunately, we sometimes allow these feelings to lead us to inaction. However, as the Black feminist scholar Audre Lorde wrote in her masterpiece, Sister Outsider, anger, directed in productive ways, can be transformative.",,
Mitigating Cold-Start Problems in Knowledge Tracing with Large Language Models: An Attribute-aware Approach,"Guo, Yuxiang and Shen, Shuanghong and Liu, Qi and Huang, Zhenya and Zhu, Linbo and Su, Yu and Chen, Enhong",Proceedings of the 33rd ACM International Conference on Information and Knowledge Management,2024,"Knowledge Tracing (KT) is a crucial research task for dynamically monitoring students' knowledge states, particularly in online education systems. Recently, knowledge tracing has gained significant attention and in-depth research. Most existing methods rely on students' response data for question understanding and modeling, which helps better updating students' knowledge states. Meanwhile, question ID is utilized to indicate and represent questions. However, this presents a challenge when transitioning to new, cold-start questions that few students has answered before. Also, prior work has overlooked the semantic modeling of questions, which could better assist in modeling the transfer of students' knowledge states. In this paper, we explore leveraging the power of Large Language Models (LLMs) to help understand questions for knowledge tracing, which benefits mitigating cold-start and sparse problems and modeling the transfer of students' knowledge states in a sophisticated manner. Specifically, we first design an attribute estimation module to estimate the attribute of the questions (e.g., difficulty, ability requirements, expected response time) by prompting Large Language Models. Subsequently, we have developed a question embedding module that incorporates graph attention network to effectively utilizing these attributes. Extensive experiments on various datasets demonstrate that our model outperforms existing state-of-the-art models and effectively addresses the problems of cold-start and sparsity. In addition, due to the estimation of multiple attributes of the questions, our model exhibits superior interpretability.",10.1145/3627673.3679664,https://doi.org/10.1145/3627673.3679664
How can We Leverage Static Analysis and Large Language Models to Engage Students in Software Quality Improvement,"AlOmar, Eman Abdullah and Mkaouer, Mohamed Wiem",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"Static analysis tools are frequently used to scan the source code and detect deviations from the project coding guidelines. Yet, their adoption is challenged by their high false positive rate, which makes them not suitable for students and novice developers. However, Large Language Models (LLMs), such as ChatGPT, have gained widespread popularity and usage in various software engineering tasks, including testing, code review, and program comprehension. Such models represent an opportunity to reduce the ambiguity of static analysis tools and support their adoption. Yet, the effectiveness of using static analysis (i.e., PMD) to detect coding issues, and relying on LLMs (i.e., ChatGPT) to explain and recommend fix, has not yet been explored. In this talk, we aim to shed light on our experience in teaching the use of ChatGPT to cultivate a bugfix culture and leverage LLMs to improve software quality in educational settings. We share our findings to support educators in teaching students better code review strategies, and to increase students' awareness about LLM and promote software quality in education.",10.1145/3626253.3635356,https://doi.org/10.1145/3626253.3635356
Programmers' Views on IDE Compilation Mechanisms,"Karvelas, Ioannis and Dillane, Joe and Becker, Brett A.",Proceedings of the ACM Conference on Global Computing Education Vol 1,2023,"In this work we investigate the views of novice programmers on three important IDE mechanisms: compilation, error indication, and error message presentation. We utilize two versions of the BlueJ pedagogical programming environment which encapsulate fundamentally different approaches to these mechanisms. This allows us to examine how effective different means of invoking these mechanisms are for novices. We conducted a survey with 305 programmers with different levels of experience who provided rating scores for the individual mechanisms mentioned. Additionally, participants provided suggestions on how these features should be facilitated to assist novices. The present findings serve as evidence regarding the effectiveness and usability of different mechanisms featured within programming environments. These findings can assist designers of pedagogical programming environments in making evidence-based decisions about their products and facilitate the development of environments that can achieve greater efficacy for novices in their first steps of learning.",10.1145/3576882.3617915,https://doi.org/10.1145/3576882.3617915
Understanding Informatics in Continuing Vocational Education and Training Data in Germany,D\,ACM Trans. Comput. Educ.,2024,"Objectives. The purpose of this study is to reveal the importance of informatics in continuing vocational education in Germany. The labour market is a field with diverse data structures and multiple applications, for example connecting jobseekers and trainings or jobs. The labour market heavily relies on vocational education and training and advanced vocational qualification to meet challenges, e.g., digitalization. Study Methods. Since continuing vocational education and training (CVET) is a structurally important lever for the digital transformation of work, this article presents a methodological procedure for content analysis that provides information about the significance of computer science in unregulated continuing education offerings and in formal continuing education regulations. Findings. The question of the extent to which continuing education programs include informaticss topics is investigated, assuming that they can be found in continuing education as cross-cutting topics in a wide variety of thematic contexts. Our results indicating the need for training in computing education. At the same time, computing education offers the highest share of unregulated CVET programs. This could reflect the fact that training and further education regulations in Germany are designed open to technology. Conclusions. We present a novel and unique approach to analyze the importance of informatics and digitalization in CVET advertisements and official regulations for the same.",10.1145/3665932,https://doi.org/10.1145/3665932
Generating Educational Materials with Different Levels of Readability using LLMs,"Huang, Chieh-Yang and Wei, Jing and Huang, Ting-Hao Kenneth",Proceedings of the Third Workshop on Intelligent and Interactive Writing Assistants,2024,"This study introduces the leveled-text generation task, aiming to rewrite educational materials to specific readability levels while preserving meaning. We assess the capability of GPT-3.5, LLaMA-2 70B, and Mixtral 8x7B, to generate content at various readability levels through zero-shot and few-shot prompting. Evaluating 100 processed educational materials reveals that few-shot prompting significantly improves performance in readability manipulation and information preservation. LLaMA-2 70B performs better in achieving the desired difficulty range, while GPT-3.5 maintains original meaning. However, manual inspection highlights concerns such as misinformation introduction and inconsistent edit distribution. These findings emphasize the need for further research to ensure the quality of generated educational content.",10.1145/3690712.3690718,https://doi.org/10.1145/3690712.3690718
Live Session Gamification using PrairieLearn,"Lascelles-Palys, Louis and Lawrence, Ramon",Proceedings of the 26th Western Canadian Conference on Computing Education,2024,"Encouraging students to complete practice questions is challenging, especially with numerous distractions and the capabilities of generative AI. Although there are a variety of techniques and systems for synchronous question answering, these systems are limited in the types of questions that can be asked. Gamification has been applied to help motivate students to practice by using incentives such as badges, bonus marks, and competitions. This work developed an extension to the PrairieLearn system allowing for synchronous question and answer sessions with scoreboards and badge awards as student incentives. A key feature is the capability for automatic grading and including complex questions not easily done by other systems, while still making it fun for students to complete. Student feedback in an upper-year course was very positive with students reporting that it encouraged them to complete the questions.",10.1145/3660650.3660663,https://doi.org/10.1145/3660650.3660663
"AI Mastery May Not Be For Everyone, But AI Literacy Should Be","Hollands, Fiona M. and DiPaola, Daniella and Breazeal, Cynthia and Ali, Safinah",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1,2024,"Despite the abundance of advice from policy bodies, professional associations, advocacy groups, and scholars on how K-12 schools should assimilate AI and provide AI education, practical plans are lacking from K-12 education leaders themselves. Education leaders must make strategic decisions about how to prepare teachers and students for an AI-infused future. Simultaneously, educators need immediate support and guidance on how to manage the arrival of tools that render some existing educational practices obsolete and prompt the need to teach new skills and awareness. Near term, it may be unrealistic to expect all students to master the ability to develop AI applications; universal AI literacy is a more feasible goal. We introduce a set of short-format, modular AI literacy courses and report how they were implemented and affected teachers' and students' knowledge and perceptions of AI. Using an online questionnaire, we collected data from 265 individuals worldwide who accessed the courses, including 190 teachers who implemented them with over 11,800 students. We conducted 17 teacher interviews to gather feedback and to better understand how courses were adapted for local contexts. Teachers reported an increase in their own and their students' knowledge of AI concepts; and increased optimism about the potential benefits of AI to society and their ability to influence the future of AI. Key takeaways are that AI literacy instruction should be designed for adaptability to local contexts and cultures and that steps should be taken to institutionalize the integration of AI literacy into the regular school curriculum.",10.1145/3649165.3690117,https://doi.org/10.1145/3649165.3690117
Reviewing and Revising your Undergraduate CS Major: A Structured Design Process for Creating Distinctive Curricula,"Barnard, Jakob and Braught, Grant and Davis, Janet and Holland-Minkley, Amanda and Schmitt, Karl and Tartaro, Andrea",J. Comput. Sci. Coll.,2025,"Computer science (CS) programs have a variety of reasons for regularly reviewing and revising the curriculum for their undergraduate major. Some of these stem from the rapid pace of change in the discipline and corresponding changes in industry expectations for CS graduates. This has been most recently seen as departments consider how to adjust to advances in generative AI and respond to new international curricular guidelines in the form of CS2023 [1]. Programs also revise their CS major in response to contextual shifts at their institution, such as changes in the size and makeup of the student body, the resources and staffing of a program, assessment results, or new institutional priorities [6]. A shifting student body may come with changes in prior experience with computing and in the professional goals of the students. For smaller programs, staffing changes often affect the balance of expertise within subareas of CS. New institutional priorities such as enabling more study abroad experiences or embedding internship/service-learning into the curriculum can require majors to adjust to both accommodate and support these priorities.",,
Navigating the Application Challenges of ChatGPT in Education: Promoting Responsible Use and Minimizing Mental Risks,"Zhang, Wenting and Zhang, Qiaorong and Cai, Mingming and Wang, Dongqing and Zheng, Yafeng",Proceedings of the 2024 9th International Conference on Distance Education and Learning,2024,"With the wide application of artificial intelligence, especially generative AI like ChatGPT, the era of significant transformation in education has quietly arrived. This article first explores the current applications of ChatGPT in logical learning, language learning, as well as personalized and effective teaching. It then deeply analyzes the challenges brought by the application of ChatGPT in education from three aspects: digital ethics, psychological risks for teachers and students, and educational governance. Based on its potential risks and challenges, effective measures and suggestions are proposed, including improving information literacy education, fully utilizing human-computer collaboration, and establishing clear regulations for the use of ChatGPT. These measures aim to ensure that ChatGPT can maximize its application value in the field of education while minimizing the mental risks.",10.1145/3675812.3675843,https://doi.org/10.1145/3675812.3675843
CT4ALL: Towards Putting Teachers in the Loop to Advance Automated Computational Thinking Metric Assessments in Game-Based Learning,"Troiano, Giovanni M and Cassidy, Michael and Morales, Daniel Escobar and Pons, Guillermo and Abdollahi, Amir and Robles, Gregorio and Puttick, Gillian and Harteveld, Casper",Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems,2025,"Computational thinking (CT) is essential for the 21st century learner. Yet, assessing CT remains challenging. This is particularly challenging in constructionist learning, where individual idiosyncrasies may clash with one-size-fits-all assessments. Tools like Dr. Scratch offer CT metrics that show promise for effective and scalable CT assessments, particularly in constructionist game-based learning (GBL). Prior work has advanced the design of automated CT metrics but hardly included teachers in the process. We extend Dr. Scratch to improve automated CT assessments for GBL and put teachers in the loop to assess its novel features. Specifically, we interviewed seven middle school teachers employing GBL in STEM curricula and asked them to provide feedback on the newly designed CT metrics. Teachers view the new CT metrics positively, underscoring their potential for adaptive CT assessments despite hindrances. We advance automated CT assessments via teacher evaluation toward design-sensitive CT metrics and CT for all.",10.1145/3706598.3713368,https://doi.org/10.1145/3706598.3713368
Prompting Collaboration: Development of an Multidisciplinary Applied AI Minor Program,"Bandi, Ajay and Blackford, Benjamin and Fellah, Aziz and Linville, Diana and Meyer, Trevor C. and Voss, Robert J.",J. Comput. Sci. Coll.,2025,"Artificial Intelligence (AI) has rapidly transformed industries and research, becoming a driving force for technological innovation and development [1]. As AI continues to grow and change, it is reshaping the way we approach problem-solving, decision-making, and creative processes across various sectors. Northwest Missouri State University is developing a new multidisciplinary AI minor open to all undergraduate students on campus. The program is tailored for students from any discipline who want to explore how AI can be utilized and integrated into their fields such as computer science, humanities, business, sciences, healthcare, agriculture, and education, among others. The curriculum integrates topics such as foundational AI concepts, prompt engineering and writing processes, ethical considerations in AI, AI in the workplace, and a capstone project. This program also promotes interdisciplinary collaboration and emphasizes the ethical use of AI.By the end of the program, students will be able to use AI to enhance efficiency and accuracy in tasks, develop and evaluate effective prompts, apply generative AI tools across various input formats, and assess the ethical considerations of AI in real-world applications. The panel members are experts from diverse fields, including management, humanities, technical writing, and computer science. The panel discusses the development of the AI minor curriculum and explores opportunities to extend the AI curriculum by offering AI certificates for undergraduate and graduate online professional students. By attending this panel, the audience will gain valuable insights into developing comprehensive AI programs, fostering cross-disciplinary innovation, and preparing students to use AI ethically and effectively across diverse fields.",,
Can Lexical Sophistication and Cohesion Automatically Differentiate Student Engagement in Socio-technical Platforms?,"Akgun, Mahir and Sharma, Priya and Li, Qiyuan",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1,2024,"This work aims to better analyze student engagement in socio-technical platforms by investigating whether the language students produce in online discussions is an indication of their cognitive engagement in collaborative activities. Primarily, this study evaluates whether a combination of linguistic features related to lexical sophistication and cohesion can capture students' cognitive engagement levels in an online course. We downloaded and annotated posts from the online platform for an undergraduate information sciences and technology course to create the human-coded dataset. Then, we assessed the lexical sophistication and cohesion of human-annotated posts and used lexical sophistication and cohesion indices in multivariate analysis of variance (MANOVA). A subsequent analysis using discriminant function analysis (DFA) suggested that the discriminant functions obtained from the human-annotated posts indicate a distinction between cognitive engagement categories. While the DFA model developed using cohesion indices shows a clear separation between cognitive engagement categories, the model built on lexical sophistication indices provides a partial separation. Study results suggest a promising approach for the application of linguistic features to support the categorization of discourse based on cognitive engagement.",10.1145/3626252.3630800,https://doi.org/10.1145/3626252.3630800
A Comparative Study of Few-Shot vs. Zero-Shot Prompting to Generate Quick and Useful Responses to Students' Periodic Reflections,"Hurley, Ethan and Okyere-Badoo, Joel",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"Our study investigates the effectiveness of leveraging Large Language Models (LLMs), such as GPT-3.5, to generate responses to student reflections. Acknowledging the intensive nature of manually handling reflections, our investigation centers on crafting prompts to automate reflection response generation. Driven by fast and meaningful response generation to student reflections, we explored both Zero-Shot learning (ZSL) and Few-Shot learning (FSL) methodologies. Our research meticulously examined the facets of each approach, highlighting the significance of consistent and meaningful responses.The Few-Shot prompting approach involves creating a fundamental prompt based on reflection questions and desired responses, striving for consistency while facing challenges such as GPT-3.5 computational time and issues related to content",10.1145/3626253.3635400,https://doi.org/10.1145/3626253.3635400
Embracing Social Justice within a Computing Curriculum to Foster Social Change,"Thompson, Gabriella and Dombrowski, Lynn and Smith, Angela D. R.",Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems,2025,"To ensure that technology serves as a tool for empowerment rather than oppression, Human-Computer Interaction (HCI) scholars have examined the ethical considerations of HCI research to explore pathways that inspire social change. In this work, we consider post-secondary education as one such pathway to social change. We engaged in a qualitative content analysis of the course, Introduction to Social Justice Informatics, with 47 students to understand how students developed knowledge of social justice and what sociotechnical tools facilitated their learning. We found that course materials coupled with peer discussion and reflective practice contributed to their development of critical consciousness. We discuss the significance of critical consciousness as a grounding theoretical approach within a social justice computing curriculum and the role of hope within social justice efforts and the workplace. We conclude by providing collectivist design strategies to nurture hope in the workplace.",10.1145/3706598.3713125,https://doi.org/10.1145/3706598.3713125
ASSIST: Automated Feedback Generation for Syntax and Logical Errors in Programming Exercises,"Van Praet, Lucas and Hoobergs, Jesse and Schrijvers, Tom",Proceedings of the 2024 ACM SIGPLAN International Symposium on SPLASH-E,2024,"Introductory programming courses often rely on numerous exercises to help students practice and reinforce their skills. Commonly used automated tests fall short by merely identifying the issues without offering guidance on how to resolve them and manual reviews are too resource-intensive to use in large classes. To address these challenges, we present ASSIST—a tool designed to provide automated, detailed feedback on how to resolve issues in programming exercise submissions with both syntactic and logical errors. ASSIST combines fault-tolerant parsing with fixes based on the context of error nodes to resolve syntactic errors and give feedback. ASSIST feeds this valid program to the Sketch program synthesis tool to determine the needed changes from a set of potential changes induced by rewrite rules, and generates feedback on logic errors based on the needed changes. This dual approach allows ASSIST to offer actionable feedback on both syntax and logic issues in student submissions. We evaluated ASSIST on submissions from an online platform for secondary education. Our findings reveal that, for submissions with syntax errors, ASSIST delivers feedback on all syntax errors in 71% of cases and extends its feedback to cover logical errors in 34% of these submissions. When evaluating all incorrect submissions, ASSIST is able to give feedback on logical errors in 64% of cases. These results indicate that ASSIST can significantly enhance the feedback process in large-scale programming courses, offering a feasible and efficient alternative to current methods.",10.1145/3689493.3689981,https://doi.org/10.1145/3689493.3689981
How Novices Use LLM-based Code Generators to Solve CS1 Coding Tasks in a Self-Paced Learning Environment,"Kazemitabaar, Majeed and Hou, Xinying and Henley, Austin and Ericson, Barbara Jane and Weintrop, David and Grossman, Tovi",Proceedings of the 23rd Koli Calling International Conference on Computing Education Research,2024,"As Large Language Models (LLMs) gain in popularity, it is important to understand how novice programmers use them and the effect they have on learning to code. We present the results of a thematic analysis on a data set from 33 learners, aged 10-17, as they independently learned Python by working on 45 code-authoring tasks with access to an AI Code Generator based on OpenAI Codex. We explore several important questions related to how learners used LLM-based AI code generators, and provide an analysis of the properties of the written prompts and the resulting AI generated code. Specifically, we explore (A) the context in which learners use Codex, (B) what learners are asking from Codex in terms of syntax and logic, (C) properties of prompts written by learners in terms of relation to task description, language, clarity, and prompt crafting patterns, (D) properties of the AI-generated code in terms of correctness, complexity, and accuracy, and (E) how learners utilize AI-generated code in terms of placement, verification, and manual modifications. Furthermore, our analysis reveals four distinct coding approaches when writing code with an AI code generator: AI Single Prompt, where learners prompted Codex once to generate the entire solution to a task; AI Step-by-Step, where learners divided the problem into parts and used Codex to generate each part; Hybrid, where learners wrote some of the code themselves and used Codex to generate others; and Manual coding, where learners wrote the code themselves. Our findings reveal consistently positive trends between learners’ utilization of the Hybrid coding approach and their post-test evaluation scores, while showing consistent negative trends between the AI Single Prompt and the post-test evaluation scores. Furthermore, we offer insights into novice learners’ use of AI code generators in a self-paced learning environment, highlighting signs of over-reliance, self-regulation, and opportunities for enhancing AI-assisted learning tools.",10.1145/3631802.3631806,https://doi.org/10.1145/3631802.3631806
Probeable Problems for Beginner-level Programming-with-AI Contests,"Pawagi, Mrigank and Kumar, Viraj",Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1,2024,"To broaden participation, competitive programming contests may include beginner-level problems that do not require knowledge of advanced Computer Science concepts (e.g., algorithms and data structures). However, since most participants have easy access to AI code-generation tools, these problems often become trivial to solve. For beginner-friendly programming contests that do not prohibit the use of AI tools, we propose Probeable Problems: code writing tasks that provide (1)&nbsp;a problem specification that deliberately omits certain details, and (2)&nbsp;a mechanism to probe for these details by asking clarifying questions and receiving immediate feedback. To evaluate our proposal, we conducted a 2-hour programming contest for undergraduate Computer Science students from multiple institutions, where each student was an active member of their institution’s ACM student chapter. The contest comprised of six Probeable Problems for which a popular code-generation tools (e.g., GitHub Copilot) were unable to generate accurate solutions due to the absence of details. Students were permitted to work individually or in groups, and were free to use AI tools. We obtained consent from 26&nbsp;groups (67&nbsp;students) to use their submissions for research. To determine whether Probeable Problems are suitable for such contests, we analyze the extent to which the code submitted by these groups identifies missing details.",10.1145/3632620.3671108,https://doi.org/10.1145/3632620.3671108
Designing Ethically-Integrated Assignments: It’s Harder Than it Looks,"Brown, Noelle and South, Koriann and Venkatasubramanian, Suresh and Wiese, Eliane S.",Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1,2023,"While the CS education community has successfully incorporated tech-ethics assignments and modules into computing courses, we lack a defined process for instructional design to create these materials from scratch across the curriculum. To enable the development of such a process, we explore two research questions: (1) What specific instructional design challenges emerge when creating ethically-integrated assignments for CS courses? And (2) what strategies might overcome them? We address these questions using Research through Design, a method for critically examining design processes. Applying this method to our own process of creating ethics-integrated CS assignments yielded four key challenges: identifying an ethical context, maintaining a technical focus, eliciting both ethical and technical thinking from students, and making the assignment practical for the classroom. Further, the Research through Design approach revealed process-level insights for addressing these challenges, which can apply across the computing curriculum. This paper also serves as a case study of Research through Design for CS education, highlighting the importance of the instructional design process and the behind-the-scenes challenges and design decisions that go into tech-ethics materials.",10.1145/3568813.3600126,https://doi.org/10.1145/3568813.3600126
Navigating the “Cooked” Data: A Framework for Understanding GenAI's Impact on Academic Writing and Learning,"Mei-seung, Cheng","Proceedings of the 2024 10th International Conference on E-Society, e-Learning and e-Technologies (ICSLT)",2024,"This article explores the integration of Generative AI (GenAI) technologies, such as ChatGPT, Bard, and LaMDA, in academic writing classrooms, examining both their potential to transform learning and the challenges they present. Building on Activity Theory, the study assesses the transformation of students' roles, the writing assistant tool, and the rules and division of labor within the academic community after technology integration. We argue that GenAI, while offering powerful potential for personalized feedback and learning, disrupts traditional educational dynamics. This raises critical questions about student roles, data integrity, and the evolving responsibilities of teachers. We propose eleven research questions to guide future investigations. These questions emphasize the need for a nuanced understanding of how GenAI impacts the learning experience and its implications for academic integrity. We also highlight the ethical considerations surrounding its use. This work aims to contribute to the ongoing conversation surrounding AI in education, promoting a more comprehensive understanding of the opportunities and challenges presented by this transformative technology.",10.1145/3678610.3678630,https://doi.org/10.1145/3678610.3678630
Code Replacement Detection as a Cheating Detection Approach in Programming Classes,"Pang, Ashley and Areizaga, Lizbeth and Denzler, Benjamin and Salloum, Mariam and Vahid, Frank",J. Comput. Sci. Coll.,2025,"Similarity checking has long been the main approach for detecting cheating in programming classes. While still a key approach, similarity checking has increasing limitations, due to more ways for students to copy code from online solutions, low-cost contractors, and artificial intelligence code writing tools - - in such cases, a student may copy a program that is not similar to a program from any classmate. However, the rise in use of program auto-graders, version control, and other tools that capture a student's program history provides new cheating detection approach opportunities. One approach detects when a student's program history includes a code replacement - - an instance where a student's code at one time is followed by new code that is clearly an entirely different program. We manually examined program histories for 5 labs in our CS1 class, for 50 random students per lab, and found code replacement prevalence of 12%, with half not turning up in the similarity checker. Detecting code replacement, and from-the-start solution copying, may become important complements to similarity checking, to catch and preferably prevent cheating in programming classes.",,
A RAG-based Feedback Tool to Augment UML Class Diagram Learning,"Ardimento, Pasquale and Bernardi, Mario Luca and Cimitile, Marta and Scalera, Michele",Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems,2024,"This paper introduces an advanced functionality designed to facilitate the learning of UML class diagram construction. Built upon an integrated Retrieval Augmented Generation Large Language Model, the functionality provides enriched feedback by leveraging accumulated knowledge. The functionality is implemented in an existing tool named UML Miner, a Visual Paradigm plugin that captures and analyzes student-generated UML diagrams by applying process mining techniques. By offering personalized feedback and continuous support during modeling, the tool aims to enhance learning outcomes and students' engagement.",10.1145/3652620.3687784,https://doi.org/10.1145/3652620.3687784
Creative Coding as Method and Goal in a Gender Diverse First-Year Seminar,"Gulley, Paige",SIGCAS Comput. Soc.,2024,"FIERCE (Fostering Inclusion by Engaging in Real-world Computing Education) is a first-year academic program for gender diverse students entering UMass's computer science or informatics degree program. In response to feedback that students wanted to be exposed to more actual programming prompts in addition to the more theoretical content which was the focus of the previous year's seminar, this year's seminar is focused on Creative Coding.",10.1145/3656021.3656027,https://doi.org/10.1145/3656021.3656027
Exploring Disparities in Student and Practitioner Perceptions of Skill Proficiency with SE Gap Awareness,"Gruber, Sean and Govan, Grace and Brown, Chris",,2024,"Software engineering (SE) is constantly changing and evolving, increasing the gaps in knowledge and skills that students need to become productive software engineers in industry. To address the gaps in SE education, this paper introduces SE Gap Awareness--an online platform to increase awareness of gaps from industry professionals using gamification and provide resources to help users improve on SE skills. We conducted a preliminary evaluation by engaging with practitioners to identify gaps they perceive in SE education and perform a user study to students' self-assessment of gaps and usage of our system. Our findings show students rank their skills higher than practitioners in soft, hard, and coding skills, and found SE Gap Awareness useful for increasing awareness of gaps and exploring resources concerning deficient skills. Based on our initial tool and evaluation, we provide implications for future systems to mitigate gaps in SE education.",10.1145/3657604.3664684,https://doi.org/10.1145/3657604.3664684
"Revolutionizing Student Engagement and Enrollment through Personalized, AI-Driven Dialog Systems in Higher Education","Fox, Alexander and Stoner, Joshua and Wang, Jingwen",Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2,2024,"In this era of digital transformation, approaches for enhancing student engagement and enrollment are critical for higher education institutions. This study introduces AcademiBot, a novel AI-driven college dialog system designed to provide personalized assistance to students and serve as a strategic marketing tool for higher institutions. AcademiBot leverages advanced Large Language Models (LLMs) and customized datasets to revolutionize colleges-students interactions by offering accurate, human-like responses to students' inquiries. The system employs two interfaces: AcademiBot-Web, a web-based GUI, and AcademiBot-VR, an immersive virtual reality environment. This dual-interface approach caters to address various user preferences, ensuring a versatile and captivating user experience. The evaluation results demonstrate AcademiBot's effectiveness in providing timely and accurate information, significantly improving user interaction in a digital context.",10.1145/3626253.3635414,https://doi.org/10.1145/3626253.3635414
HCAI Block Model: A competence model for Human Centred Artificial Intelligence at K-12,"Conway, Brian and Nolan, Keith and Quille, Keith",Proceedings of the 2024 Conference on Human Centred Artificial Intelligence - Education and Practice,2024,"Artificial Intelligence (AI) is becoming a common topic within the computing K-12 curricula worldwide. While much of the focus of research is on the use of Generative AI in and for education, AI as a core subject area is still gaining popularity, with much of this research focusing on content and tools that effectively support the teaching of AI. However, as we grow as a field, there is a need currently unmet to provide foundations (in the form of a block model as there exists for programming) to allow researchers to build strong pedagogies and methodologies from, and even a base to design activities and content. Compounding this, as ethics and its relationship to AI in the K-12 classroom grows stronger, there is a further need to provide scaffolding to educators and researchers not only on traditional AI concepts, but also on how they link with ethical knowledge, skills and dispositions. In this paper, the Human Centered Artificial Intelligence (HCAI) Block Model is developed and introduced. This is a competence-based model to guide effective teaching and learning of Human Centered Artificial Intelligence, as well as research in the K-12 space. The HCAI Block model’s foundation is developed/adapted from the programming Block model and has been adapted and developed using two lenses. The first was through the data science lens through interaction with Computational Thinking 2.0 and competency-based learning. The second lens was through a human-centred lens. The outcome was a ground-up K-12 model where traditional and technical AI concepts have been developed from the start, integrating ethical considerations and human-centred approaches.",10.1145/3701268.3701273,https://doi.org/10.1145/3701268.3701273
Feedback on Student Programming Assignments: Teaching Assistants vs Automated Assessment Tool,"Kristiansen, Nynne Grauslund and Nicolajsen, Sebastian Mateos and Brabrand, Claus",Proceedings of the 23rd Koli Calling International Conference on Computing Education Research,2024,"Existing research does not quantify and compare the differences between automated and manual assessment in the context of feedback on programming assignments. This makes it hard to reason about the effects of adopting automated assessment at the expense of manual assessment. Based on a controlled experiment involving N=117 undergraduate first-semester CS1 students, we compare the effects of having access to feedback from: i) only automated assessment, ii) only manual assessment (in the form of teaching assistants), and iii) both automated as well as manual assessment. The three conditions are compared in terms of (objective) task effectiveness and from a (subjective) student perspective. The experiment demonstrates that having access to both forms of assessment (automated and manual) is superior both from a task effectiveness as well as a student perspective. We also find that the two forms of assessment are complementary: automated assessment appears to be better in terms of task effectiveness; whereas manual assessment appears to be better from a student perspective. Further, we found that automated assessment appears to be working better for men than women, who are significantly more inclined towards manual assessment. We then perform a cost/benefit analysis which leads to the identification of four equilibria that appropriately balance costs and benefits. Finally, this gives rise to four recommendations of when to use which kind or combination of feedback (manual and/or automated), depending on the number of students and the amount of per-student resources available. These observations provide educators with evidence-based justification for budget requests and considerations on when to (not) use automated assessment.",10.1145/3631802.3631804,https://doi.org/10.1145/3631802.3631804
Adopting an Agile Approach for Reflective Learning and Teaching,"Leist, Eleanor and Lee, Jaejoon",Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training,2024,"Software engineering is concerned with how best to create software in ways that promote sustainable development and maximise quality. We have been largely successful at transferring software engineering knowledge into the industry, however, many challenges in software engineering training remain. A key amongst these is how best to teach practical engineering approaches along with the theoretical concepts behind them.This paper describes our experience of adopting an agile approach for reflective learning and teaching within the context of our Software Systems Engineering module, aimed at addressing challenges identified with previous efforts to promote reflective practice. Our study attempts to strengthen the use of reflective learning approaches for our current cohort, as well as introducing reflective teaching practices, whereby we examine our teaching approach in order to improve its efficiency and effectiveness. Our analysis of student response to the module shows that it was very well-received by the students, and we were able to collect ample evidence from feedback to support this. Most of our approaches resulted in positive feedback and contributed to improvements in teaching quality, however, we also identified some key aspects in our method that could still benefit from refinement, such as the need for explicit links between learning outcomes and workshop activities, and intuitive design of feedback questions, along with feedback collection frequency. We plan to incorporate these additional updates into the revision of the module for the next academic year, and to continue collecting and analysing feedback data for further enhancement.",10.1145/3639474.3640055,https://doi.org/10.1145/3639474.3640055
Chances and Challenges of Chatgpt and Similar Models for Education in M&amp;S,"Tolk, Andreas and Barry, Philip and Loper, Margaret L. and Rabadi, Ghaith and Scherer, William T. and Yilmaz, Levent",Proceedings of the Winter Simulation Conference,2024,"This position paper summarizes the inputs of a group of experts from academia and industry presenting their view on chances and challenges of using ChatGPT within Modeling and Simulation education. The experts also address the need to evaluate continuous education as well as education of faculty members to address scholastic challenges and opportunities while meeting the expectation of industry. Generally, the use of ChatGPT is encouraged, but it needs to be embedded into an updated curriculum with more emphasis on validity constraints, systems thinking, and ethics.",,
AI-Generated Code Not Considered Harmful,"Kendon, Tyson and Wu, Leanne and Aycock, John",Proceedings of the 25th Western Canadian Conference on Computing Education,2023,"Recent developments in AI-generated code are merely the latest in a series of challenges to traditional computer science education. AI code generators, along with the plethora of available code on the Internet and sites that facilitate contract cheating, are a striking contrast to the heroic notion of programmers toiling away to create artisanal code from whole cloth. We need not interpret this to mean that more, potentially automated, policing of student assignments is necessary: automated policing of student work is already fraught with complications and ethical concerns. We argue that instructors should instead reconsider assessment design in their pedagogy in light of recent developments, with a focus on how students build knowledge, practice skills, and develop processes. How can these new tools support students and the way they learn, and support the way that computer scientists will work in the years to come? This is an opportunity to revisit how computer science is taught, how it is assessed, how we think about and present academic integrity, and the role of the computer scientist in general.",10.1145/3593342.3593349,https://doi.org/10.1145/3593342.3593349
Identifying Secondary School Students' Misconceptions about Machine Learning: An Interview Study,"Marx, Erik and Witt, Clemens and Leonhardt, Thiemo",Proceedings of the 19th WiPSCE Conference on Primary and Secondary Computing Education Research,2024,"Since students are familiar with machine learning (ML)-based applications in their everyday lives, they already construct mental models of how these systems work. This can result in misconceptions that influence the learning of correct ML concepts. Therefore, this study investigates the misconceptions students hold about the functionality of ML-based applications. To this end, we conducted semi-structured interviews with five students, focusing on their understanding of facial recognition and ChatGPT. The interviews were analyzed using an inductively developed code system and qualitative content analysis. This process identified six key misconceptions held by students: “Programmed Behavior,” “Exactness,” “Data Storage,” “Continuous Learning,” “User-trained Model,” and “Autonomous Data Acquisition”. These misconceptions include the notion that AI learns continuously during application, or that training data is saved and reused later. This paper presents the identified misconceptions and discusses their implication for the design and evaluation of effective learning activities in the context of ML.",10.1145/3677619.3678114,https://doi.org/10.1145/3677619.3678114
Jupybara: Operationalizing a Design Space for Actionable Data Analysis and Storytelling with LLMs,"Wang, Huichen Will and Birnbaum, Larry and Setlur, Vidya",Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems,2025,"Mining and conveying actionable insights from complex data is a key challenge of exploratory data analysis (EDA) and storytelling. To address this challenge, we present a design space for actionable EDA and storytelling. Synthesizing theory and expert interviews, we highlight how semantic precision, rhetorical persuasion, and pragmatic relevance underpin effective EDA and storytelling. We also show how this design space subsumes common challenges in actionable EDA and storytelling, such as identifying appropriate analytical strategies and leveraging relevant domain knowledge. Building on the potential of LLMs to generate coherent narratives with commonsense reasoning, we contribute Jupybara, an AI-enabled assistant for actionable EDA and storytelling implemented as a Jupyter Notebook extension. Jupybara employs two strategies—design-space-aware prompting and multi-agent architectures—to operationalize our design space. An expert evaluation confirms Jupybara’s usability, steerability, explainability, and reparability, as well as the effectiveness of our strategies in operationalizing the design space framework with LLMs.",10.1145/3706598.3713913,https://doi.org/10.1145/3706598.3713913
Development and Utilization of AI-Enabled Automatic Programming Problem Generator Using the CodeRunner Plugin of Moodle,"Serato, Jay Vince Donoso and Sta. Romana, Cherry Lyn",Proceedings of the 2024 10th International Conference on Education and Training Technologies,2024,"Programming instructors provide various kinds of problems that suit their current topics of programming. With the use of Learning Management Systems (LMS) such as Moodle, teachers can create and store their problems in problem banks using a question plugin CodeRunner. However creating and validating programming problems takes significant time and creative effort. With instructors dealing multiple programming languages, it would need mastery not only to solve the problem but also to use a specific language. This paper presents an automation of the programming problem generation using AI. This is effectively an improvement of the CodeRunner plugin of Moodle that allows programming instructors to generate problem descriptions, answers, and testcases of different programming topics in various programming languages with a few clicks. To address the issue of difficulty control, an additional feature is placed to generate an easier or harder problem than what is currently generated. The evaluation of the improved tool showed that the problems generated with AI are similar, correct, and practical that matches the human-generated problems.",10.1145/3661904.3661921,https://doi.org/10.1145/3661904.3661921
A Case for Bayesian Grading,"Zilles, Craig and Zhao, Chenyan and Chen, Yuxuan and Matthews, Evan Michael and West, Matthew",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1,2024,"Academic integrity continues to be an issue in education. Students' grades are often computed using a collection of evidence that varies in its trustworthiness (e.g., a proctored exam can be trusted more than an out-of-class programming project) due to practical constraints. When a student cheats, their trusted and less trustworthy scores are inconsistent, which presents instructors a choice between rewarding the cheating behavior and the burden of investigating / making cheating allegations.In this position paper, we propose that Bayesian inference might be a useful tool in assigning grades derived from trusted and less trusted evidence. Rather than compute grades by performing arithmetic on both trusted and untrusted assessments, we instead try to infer a latent variable, the student's mastery of the course material, from these observed performances and their potential for cheating. Key to this approach is that grades can be assigned that discount suspicious work without needing to explicitly make a cheating allegation. A logical conclusion of this approach is that the needed amount of trusted assessments for a given student depends on how inconsistent are their trusted and untrusted assessments.",10.1145/3649165.3703624,https://doi.org/10.1145/3649165.3703624
Coding4Therapy: Enhancing Cognitive and Socio-emotional Skills in Children with ADHD,"Toto, Bianca and Joyner, David A.",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1,2024,"This paper examines the theoretical foundation and practical applications of an online intervention for children ages 5-11 with ADHD. Coding4Therapy integrates informal coding education with therapeutic goals, filling the gaps between and within existing educational, pharmacological, and non-pharmacological treatment. Coding4Therapy seeks to improve cognitive and socio-emotional functioning and promote equitable STEM outcomes through personalized courses with multifaceted instruction. This intervention builds on research highlighting the benefits of early STEM engagement, alternative therapies, gamification, and online learning, resulting in a replicable methodology and accessible application.",10.1145/3649165.3690124,https://doi.org/10.1145/3649165.3690124
Artificial Intelligence Policy: What Computing Educators and Students Should Know,"Bailey, Cynthia",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1,2024,"Catalyzed by the release of ChatGPT by OpenAI in November 2022, policymakers worldwide have launched a surge of activity surrounding artificial intelligence (AI). The legal and policy frameworks emerging from this concentrated period of attention may shape AI governance for decades to come. This keynote will examine the implications of these global AI policy debates for computing educators and their students.  Drawing on the speaker's dual experience as a computing educator and AI policy adviser within the United States Senate, this presentation will explore the developing threads of AI policy that educators should integrate into their curricula to prepare students for an evolving socio-technical landscape.  The talk will present an overview of significant AI policy developments, including the European Union's AI Act, the over 120 AI-related bills currently pending in the United States Congress, and the United Arab Emirates' launch of a state-of-the-art open-source AI model. These examples will be contextualized within the history of how the current active regulatory stance diverges from prior approaches to technologies like the internet and social media, and consider the potential implications of this shift.  Equally important to understanding how AI policy is evolving is understanding why. Many legislative efforts are driven by concerns about AI's potential to exacerbate societal harms, such as election misinformation, cybersecurity threats, nonconsensual sexual imagery, weapons development, data privacy violations, intellectual property appropriation, labor market disruptions, and algorithmic biases. Coupled with these concerns is a widespread skepticism toward the tech industry's capacity for responsible self-governance. This context underscores the need for computing educators to engage students on issues of policy, ethics, and justice throughout the curriculum, to cultivate future professionals who can earn public trust and who appreciate the role of governments in establishing balance between innovation and safety guardrails. Finally, the talk will offer reflections on the experience of serving as a technical adviser to policymakers, and advocate for computing educators to consider public service engagement on AI policy as a compelling career trajectory for themselves and their students.",10.1145/3649165.3699863,https://doi.org/10.1145/3649165.3699863
"Am I Wrong, or Is the Autograder Wrong? Effects of AI Grading Mistakes on Learning","Li, Tiffany Wenting and Hsu, Silas and Fowler, Max and Zhang, Zhilin and Zilles, Craig and Karahalios, Karrie",Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1,2023,"Errors in AI grading and feedback often have an intractable set of causes and are, by their nature, difficult to completely avoid. Since inaccurate feedback potentially harms learning, there is a need for designs and workflows that mitigate these harms. To better understand the mechanisms by which erroneous AI feedback impacts students’ learning, we conducted surveys and interviews that recorded students’ interactions with a short-answer AI autograder for “Explain in Plain English” code reading problems. Using causal modeling, we inferred the learning impacts of wrong answers marked as right (false positives, FPs) and right answers marked as wrong (false negatives, FNs). We further explored explanations for the learning impacts, including errors influencing participants’ engagement with feedback and assessments of their answers’ correctness, and participants’ prior performance in the class. FPs harmed learning in large part due to participants’ failures to detect the errors. This was due to participants not paying attention to the feedback after being marked as right, and an apparent bias against admitting one’s answer was wrong once marked right. On the other hand, FNs harmed learning only for survey participants, suggesting that interviewees’ greater behavioral and cognitive engagement protected them from learning harms. Based on these findings, we propose ways to help learners detect FPs and encourage deeper reflection on FNs to mitigate the learning harms of AI errors.",10.1145/3568813.3600124,https://doi.org/10.1145/3568813.3600124
Humans or Machines for Teaching: Trust and Preferences among University Students,"Asgari, Mohsen and Mannila, Linda and Tsai, Fong-Chun and Str\",Proceedings of the 2024 16th International Conference on Education Technology and Computers,2025,"Recent developments in artificial intelligence (AI) have generated discussions around and expectations for its impact in education. In a society where AI plays an increasing role, a basic understanding for the technology and its potential is considered crucial. Still, many educators feel apprehensive towards the use of AI in education, which naturally affects students’ opportunities to learn about and use AI-supported solutions. Users’ preference and trust in relation to these tools also becomes important when integrated in education. Bringing light on students’ perceptions of AI might help educators to better understand the value of such applications. The present study aims to provide insight into how university students perceive AI in general and, more particularly, the idea of having a machine performing tasks that have traditionally been handled by a teacher or a teaching assistant. The results are based on 140 Swedish and Taiwanese university students’ responses to an online questionnaire. Our results indicate that the students have quite positive perceptions of AI: they might still not feel very competent in AI, but show a large interest in the topic and are positive about its consequences for society. Nevertheless they also see potential drawbacks of the technology. As a whole, our findings indicate that Swedish and female students tend to prefer human interactions over AI-supported tools for learning.",10.1145/3702163.3702166,https://doi.org/10.1145/3702163.3702166
ChatScratch: An AI-Augmented System Toward Autonomous Visual Programming Learning for Children Aged 6-12,"Chen, Liuqing and Xiao, Shuhong and Chen, Yunnong and Song, Yaxuan and Wu, Ruoyu and Sun, Lingyun",Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems,2024,"As Computational Thinking (CT) continues to permeate younger age groups in K-12 education, established CT platforms such as Scratch face challenges in catering to these younger learners, particularly those in the elementary school (ages 6-12). Through formative investigation with Scratch experts, we uncover three key obstacles to children’s autonomous Scratch learning: artist’s block in project planning, bounded creativity in asset creation, and inadequate coding guidance during implementation. To address these barriers, we introduce ChatScratch, an AI-augmented system to facilitate autonomous programming learning for young children. ChatScratch employs structured interactive storyboards and visual cues to overcome artist’s block, integrates digital drawing and advanced image generation technologies to elevate creativity, and leverages Scratch-specialized Large Language Models (LLMs) for professional coding guidance. Our study shows that, compared to Scratch, ChatScratch efficiently fosters autonomous programming learning, and contributes to the creation of high-quality, personally meaningful Scratch projects for children.",10.1145/3613904.3642229,https://doi.org/10.1145/3613904.3642229
Supplement to CSEC 2017: Foundational Cybersecurity Content and Instructional Guidance for Secondary and Postsecondary Cybersecurity Education,"Bishop, Matt and Cerrone, Beth and Dai, Jun and Dark, Melissa and Daugherty, Jenny and Huff, Philip and Tang, Cara and Tucker, Cindy",,2025,"This curriculum project involved a review of the Cybersecurity Curricula 2017 (CSEC 2017) guidelines and recommendation of learning outcomes that support foundational collegiate-level courses and upperlevel high school cybersecurity offerings, comparable to Advanced Placement (AP) content. The primary goal of this document is to provide a foundational cybersecurity education framework that can be implemented by both post-secondary institutions and high schools. These guidelines aim to bridge the gap between secondary and post-secondary education in cybersecurity to support broad transferability across institutions and ensure continuity for students.",,
Nemobot: Crafting Strategic Gaming LLM Agents for K-12 AI Education,"Wang, Yuchen and Guo, Shangxin and Ling, Lin and Tan, Chee Wei",,2024,"Artificial intelligence (AI) permeates modern society and is poised for further integration across various domains. However, there exists a notable deficiency in equipping K-12 students with foundational AI understanding. This paper introduces a novel learning framework that leverages large language models (LLMs) and strategic gaming to teach K-12 students about the inner workings of AI. The framework consists of a chatbot programming and testing IDE that enables K-12 students to construct AI from scratch, engage in strategic gameplay to generate instant training data, and improve the AI heuristics with a data-driven learning mechanism. With a tiered curriculum catering to diverse proficiency levels and fostering synchronous collaboration, this framework efficiently adapts learning experiences to suit various groups of students, thereby facilitating learning at scale. Preliminary experiments validate the feasibility and vast potential of this approach, promising to revolutionize AI education in K-12 education.",10.1145/3657604.3664671,https://doi.org/10.1145/3657604.3664671
Assessing Student Perceptions of Co-Teaching in a 3rd-Year Computer Science Course,"Attarwala, Abbas and Raigoza, Pablo",J. Comput. Sci. Coll.,2024,"In this research, the effects of various teaching methodologies such as solo teaching, parallel coordinated teaching (PCT), and sequential teaching (SEQT) on student perceptions in a third-year programming language course at Boston University (BU) are studied. PCT and SEQT, as variants of co-teaching, contrast with the independent approach of solo teaching. This research uses student evaluation data to analyze eight distinct evaluative questions, including areas such as fairness in grading, stimulation of student's interest in the course material, and overall instructor ratings. These eight questions are analyzed using student course evaluations across the three aforementioned teaching methodologies to determine if there are statistically significant differences in perceptions. The results show that consistent instructor presence throughout the semester, as seen in solo teaching and PCT scenarios, significantly enhances student perceptions of fairness and overall satisfaction. In contrast, SEQT, which involves instructor changes in the middle of the semester, is associated with less favorable student evaluations. The study highlights the importance of instructor consistency and the potential disruptions caused by changing instructors mid-course.",,
Toward Personalised Learning Experiences: Beyond Prompt Engineering,"Kruis, Joost and Pera, Maria Soledad and Napel, Zo\",Proceedings of the 23rd Annual ACM Interaction Design and Children Conference,2024,"We discuss the foundation of a collaborative effort to explore AI’s role in supporting (teachers and) children in their learning experiences. We integrate principles of educational psychology, AI, and HCI, and align with best practices in education while undertaking a human-centered focus on design and development that puts the student at the centre and keeps the expert-in-the-loop. Initially, we study assessment items—questions or tasks tied to a learning target. These items vary in complexity, serve as indicators of students’ grasp of specific concepts and spotlight areas where support may be needed. This preliminary analysis will help us outline a framework to guide the design and evaluation of AI technology for K-12 education. Such a framework would ensure that assessment item generation technology goes beyond the current one-dimensional approach by incorporating multifaceted, adaptable perspectives that consider the variegated landscape of learners’ needs, subject matter complexities, and pedagogical goals.",10.1145/3628516.3659367,https://doi.org/10.1145/3628516.3659367
Evaluating the Quality of LLM-Generated Explanations for Logical Errors in CS1 Student Programs,"Balse, Rishabh and Kumar, Viraj and Prasad, Prajish and Warriem, Jayakrishnan Madathil",Proceedings of the 16th Annual ACM India Compute Conference,2023,"When students in CS1 (Introductory Programming) write erroneous code, course staff can use automated tools to provide various types of helpful feedback. In this paper, we focus on syntactically correct student code containing logical errors. Tools that explain logical errors typically require course staff to invest greater effort than tools that detect such errors. To reduce this effort, prior work has investigated the use of Large Language Models (LLMs) such as GPT-3 to generate explanations. Unfortunately, these explanations can be incomplete or incorrect, and therefore unhelpful if presented to students directly. Nevertheless, LLM-generated explanations may be of adequate quality for Teaching Assistants (TAs) to efficiently craft helpful explanations on their basis. We evaluate the quality of explanations generated by an LLM (GPT-3.5-turbo) in two ways, for 30&nbsp;buggy student solutions across 6&nbsp;code-writing problems. First, in a study with 5&nbsp;undergraduate TAs, we compare TA perception of LLM-generated and peer-generated explanation quality. TAs were unaware which explanations were LLM-generated, but they found them to be comparable in quality to peer-generated explanations. Second, we performed a detailed manual analysis of LLM-generated explanations for all 30&nbsp;buggy solutions. We found at least one incorrect statement in 15/30 explanations (50%). However, in 28/30 cases (93%), the LLM-generated explanation correctly identified at least one logical error. Our results suggest that for large CS1 courses, TAs with adequate training to detect erroneous statements may be able to extract value from such explanations.",10.1145/3627217.3627233,https://doi.org/10.1145/3627217.3627233
"Large Language Models and Introductory Lab Exercises: Susceptibility, Resistance, and Potential","Chamberlain, Devin and Levine, David B. and Pitcairn, Abigail and Snow, Nicholas and Sweeney, Benjamin",J. Comput. Sci. Coll.,2025,"Three student personas were created, each representing a way in which current students interact with AI tools such as ChatGPT when completing introductory computer science assignments. Four undergraduate students assumed the role of each of the personas in turn and two semesters worth of current assignments were completed in each persona. The results and experiences were then analyzed to determine aspects of the assignments that made it more (or less) difficult to complete them using the AI tools, with an eye towards whether small changes in phrasing or requirements might result in significant changes in this metric.Three of the main takeaways were that LLMs are more difficult for students to use when assignments 1) consist of many small steps, 2) make use of external code libraries, or 3) involve spatial reasoning.Finally, the student/persona experiences helped to generate a list of opportunities for instructors to proactively include the use of AI tools in current assignments without sacrificing any of the current learning objectives.The initial phase involved labs from one institution and used only one AI tool, but follow-up work involving the use of other tools and labs from other institutions validated those core conclusions. A student survey (as well as other published literature) also validated the choice of personas.",,
Towards a Theory of Humanistic Computing and How to Teach It,"Sollazzo, Anna and Cutts, Quintin",Proceedings of the 24th Koli Calling International Conference on Computing Education Research,2024,"Early in the field’s development, it was argued that to belong in the Digital Humanities (DH) one must know how to ‘build’—to code. Despite this stated focus, little work has addressed the specific computing needs of DH or the best approaches to teaching computing in that context. The grand challenge of DH is the epistemological dissonance between its constituent domains. Modern computing, anchored as it has become in the knowledge-cultures of science and engineering, is built around assumptions and priorities which often oppose those of humanistic inquiry. Correspondingly, there is an argument that to undertake meaningful humanistic work in a digital space, it is necessary to develop a distinct practice of computing which is aligned with humanistic values. What precisely this paradigm of ‘humanistic computing’ entails, however, is not well defined. The aim of this paper is twofold. Using interviews with DH computing instructors to augment limited existing literature, it first looks to understand the specificity of DH computing education—in terms of both key competencies and areas of interest, and the characteristics and challenges of DH students as a learner group. Second, it aims to establish a working definition of humanistic computing. Taken together, these findings will support the development of a computing curriculum tailored to the Digital Humanities.",10.1145/3699538.3699559,https://doi.org/10.1145/3699538.3699559
Integrating ChatGPT in Cybersecurity Education: Use Cases and Implications,"Hamdan, Basil",J. Comput. Sci. Coll.,2024,"This paper examines the integration of ChatGPT into cybersecurity courses, emphasizing practical applications and ethical considerations within educational settings. Through use case in malware development and web application security, the study explores ChatGPT's dual role in cybersecurity education. It addresses ethical AI behavior, challenges in contextual awareness, and the risks associated with AI-generated content misuse. This paper aims to provide educators with insights to navigate the complexities of AI-enhanced cybersecurity education effectively.",,
Mathematical Considerations in Two-Year Computing Degrees: The Evolution of Math in Curricular Guidelines,"Servin, Christian and Hawthorne, Elizabeth K. and Postner, Lori and Tang, Cara and Tucker, Cindy S.",Proceedings of the 24th Annual Conference on Information Technology Education,2023,"Incorporating mathematics in computing has been a subject of ongoing deliberation within computing curriculum recommendations spanning several decades. Depending on the specific computing area or program, there is a variation in the advocated number of math contact hours. For instance, two-year programs like community colleges require many math hours due to curriculum alignment and agreements with four-year colleges. In other cases, the regional workforce and the career opportunities provided by local industry partners influence a degree program’s math courses/topics. The debate surrounding the appropriate number of math contact hours in computing programs has persisted over the years and has yet to be a definitive solution. Curricular guidelines such as ACM/IEEE-CS/AAAI CS 2023 and Information Technology 2017 have proposed math education based on competencies and workforce perspectives. Specifically, the former now recommends a tailored math background based on the knowledge area within computer science. This approach allows for a more flexible structure of knowledge units, encompassing specific topics, learning outcomes, and competencies. This paper explores various approaches and solutions proposed in the first two years of computing education programs to address challenges and gaps in computing education. It also highlights the short-term and long-term challenges computing programs and educators face.",10.1145/3585059.3611441,https://doi.org/10.1145/3585059.3611441
GPT-3 vs Object Oriented Programming Assignments: An Experience Report,"Cipriano, Bruno Pereira and Alves, Pedro",Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1,2023,"Recent studies show that AI-driven code generation tools, such as Large Language Models, are able to solve most of the problems usually presented in introductory programming classes. However, it is still unknown how they cope with Object Oriented Programming assignments, where the students are asked to design and implement several interrelated classes (either by composition or inheritance) that follow a set of best-practices. Since the majority of the exercises in these tools' training dataset are written in English, it is also unclear how well they function with exercises published in other languages.In this paper, we report our experience using GPT-3 to solve 6 real-world tasks used in an Object Oriented Programming course at a Portuguese University and written in Portuguese. Our observations, based on an objective evaluation of the code, performed by an open-source Automatic Assessment Tool, show that GPT-3 is able to interpret and handle direct functional requirements, however it tends not to give the best solution in terms of object oriented design. We perform a qualitative analysis of GPT-3's output, and gather a set of recommendations for computer science educators, since we expect students to use and abuse this tool in their academic work.",10.1145/3587102.3588814,https://doi.org/10.1145/3587102.3588814
Framing AI Literacy for K-12 Education: Insights from Multi-Perspective and International Stakeholders,"Mannila, Linda and Hallstr\",Proceedings of the 27th Australasian Computing Education Conference,2025,"National and international policy documents emphasize the need for AI-related competencies “for all”, but there is little clarity on what these competencies should include, and determining what non-experts need to know remains a challenge. AI literacy has become a widely discussed topic in this context, often referring to a set of skills that empower individuals to critically evaluate AI, communicate and collaborate effectively with AI systems, and utilize AI as a tool across diverse contexts, including online environments, homes, schools, and workplaces. However, what AI literacy looks like in practice depends on factors such as age, level of education, and individual background. In this article, we frame AI literacy based on a qualitative analysis of the views of 33 international experts from various disciplines on what AI literacy in K-12 education should encompass. This analysis builds on existing AI literacy frameworks, with a focus on understanding and critically evaluating AI’s role in daily life, recognizing and using AI, and designing AI solutions for everyday problems. The findings show that experts emphasize a wide range of knowledge, skills, and attitudes, highlighting the importance of multiple perspectives when exploring this emerging field.",10.1145/3716640.3716650,https://doi.org/10.1145/3716640.3716650
Assessing the impact of hints in learning formal specification,,Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training,2024,"Background: Many programming environments include automated feedback in the form of hints to help novices learn autonomously. Some experimental studies investigated the impact of automated hints in the immediate performance and learning retention in that context. Automated feedback is also becoming a popular research topic in the context of formal specification languages, but so far no experimental studies have been conducted to assess its impact while learning such languages. Objective: We aim to investigate the impact of different types of automated hints while learning a formal specification language, not only in terms of immediate performance and learning retention, but also in the emotional response of the students. Method: We conducted a simple one-factor randomised experiment in 2 sessions involving 85 BSc students majoring in CSE. In the 1st session students were divided in 1 control group and 3 experimental groups, each receiving a different type of hint while learning to specify simple requirements with the Alloy formal specification language. To assess the impact of hints on learning retention, in the 2nd session, 1 week later, students had no hints while formalising requirements. Before and after each session the students answered a standard self-reporting emotional survey to assess their emotional response to the experiment. Results: Of the 3 types of hints considered, only those pointing to the precise location of an error had a positive impact on the immediate performance and none had significant impact in learning retention. Hint availability also causes a significant impact on the emotional response, but no significant emotional impact exists once hints are no longer available (i.e. no deprivation effects were detected). Conclusion: Although none of the evaluated hints had an impact on learning retention, learning a formal specification language with an environment that provides hints with precise error locations seems to contribute to a better overall experience without apparent drawbacks. Further studies are needed to investigate if other kind of feedback, namely hints combined with some sort of self-explanation prompts, can have a positive impact in learning retention.",10.1145/3639474.3640050,https://doi.org/10.1145/3639474.3640050
How Beginning Programmers and Code LLMs (Mis)read Each Other,"Nguyen, Sydney and Babe, Hannah McLean and Zi, Yangtian and Guha, Arjun and Anderson, Carolyn Jane and Feldman, Molly Q",Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems,2024,"Generative AI models, specifically large language models (LLMs), have made strides towards the long-standing goal of text-to-code generation. This progress has invited numerous studies of user interaction. However, less is known about the struggles and strategies of non-experts, for whom each step of the text-to-code problem presents challenges: describing their intent in natural language, evaluating the correctness of generated code, and editing prompts when the generated code is incorrect. This paper presents a large-scale controlled study of how 120 beginning coders across three academic institutions approach writing and editing prompts. A novel experimental design allows us to target specific steps in the text-to-code process and reveals that beginners struggle with writing and editing prompts, even for problems at their skill level and when correctness is automatically determined. Our mixed-methods evaluation provides insight into student processes and perceptions with key implications for non-expert Code LLM use within and outside of education.",10.1145/3613904.3642706,https://doi.org/10.1145/3613904.3642706
Grading Programming Assignments by Summarization,"Dong, Dong and Liang, Yue",Proceedings of the ACM Turing Award Celebration Conference - China 2024,2024,"Grading programming assignments manually is a big burden for instructors who teach programming languages for university students due to complexity and subjectivity. The black test approach adopted by online judge systems can only outputs either an answer is correct or incorrect. This study proposes a Large Language Model (LLM) approach to automatically grade answers from students for programming assignments. A LLM mode formed by coder-decoder architecture is utilized to generate summarization from source code, then the summarization is compared to the textual assignment description by semantic similarity. Finally, the output is converted to five-score rating. CodeBERT and a Transformer model serve as coder and decoder respectively. The semantic similarity is computed by MiniLM-L6. The validation test shows that the accuracy of the suggested approach reaches 0.92.",10.1145/3674399.3674426,https://doi.org/10.1145/3674399.3674426
Improving Effectiveness of Programming Assignments with Real-time Formative Feedback,"Baimetov, Ilya",Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 2,2023,"This PhD research explores the problem of building an effective ITS-like system for providing real-time formative feedback for programming assignments given to college/university students. Such system would maximize learning outcomes while minimizing the effort from the tutor to construct such system.It proposes an approach to building such a system and assessing its effectiveness, as well as outlines topics for future research.",10.1145/3587103.3594145,https://doi.org/10.1145/3587103.3594145
Students' Perceptions and Intentions Regarding ChatGPT Usage in Higher Education,"Chan, Shiau Wei and Norhisham, Nur Intan Shahira and Ismail, Fadillah and Ahmad, Md Fauzi","Proceedings of the 2024 10th International Conference on E-Society, e-Learning and e-Technologies (ICSLT)",2024,"The adoption of new technologies such as ChatGPT has opened up the potential to elevate education to the next level. However, several issues have arisen with ChatGPT, including concerns related to academic integrity and the challenge of distinguishing between AI-generated and human-generated content. Thus, this study aimed to investigate students' perceptions and intentions regarding the use of ChatGPT in higher education. A total of 320 undergraduate students were selected from the Faculty of Technology Management and Business (FPTP) at Universiti Tun Hussein Onn Malaysia (UTHM). The random sampling method was employed in this study, with a population size of 1976 students. Data were collected through a questionnaire, and statistical analysis was conducted using SPSS software. The findings of this research reveal that students' perception of ChatGPT usage is moderate, while their intention to use ChatGPT is interpreted at a high level. Furthermore, a positive correlation between students' intentions and perceptions toward ChatGPT was discovered. This study is crucial for understanding students' perceptions and intentions to optimize their benefits and comprehend their risks to students, organizations, and ethics.",10.1145/3678610.3678625,https://doi.org/10.1145/3678610.3678625
Helping Students Understand the Code’s Behavior and Purpose by Leveraging Concreteness Fading and Comics,"Suh, Sangho and Hassan, Mohammed",Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2,2023,"The ability to reason about the general purpose and behavior of code, rather than simply focusing on specific inputs and outputs, is an essential skill to teach to novice programmers. However, effectively teaching this skill can be a challenging task. In light of recent research on using concreteness fading and comics for teaching programming, we aim to develop a tool that employs a gradual transition from concrete to abstract code representations and investigate whether it enhances students’ ability to recognize patterns and foster the development of associated programming skills, such as code tracing and writing.",10.1145/3568812.3603491,https://doi.org/10.1145/3568812.3603491
Designing an AI Literacy Transformational Game for Families,"Yang, Ellia and Ogan, Amy and Hammer, Jessica and Solyst, Jaemarie",Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 2,2024,,10.1145/3632621.3671433,https://doi.org/10.1145/3632621.3671433
"Do I Have a Say in This, or Has ChatGPT Already Decided for Me?","Padiyath, Aadarsh",XRDS,2024,"It's not just about LLMs, it's about us too.",10.1145/3688090,https://doi.org/10.1145/3688090
A Comparative Study of Gender Differences in the Utilization and Effectiveness of AI-Assisted Learning Tools in Programming Among University Students,"Maurat, John Ivan Curbano and Isip, Elsie Villareal and Lumabas, Aileen Gail Regala",Proceedings of the 2024 International Conference on Artificial Intelligence and Teacher Education,2025,"This comparative study examines gender differences in the use and efficacy of AI-assisted learning tools for programming among university students. A survey-based methodology was used to collect data from a varied sample of students across different academic years, ensuring representation from diverse demographic groups. The study sought to investigate the frequency of AI tool use and students' assessments of their efficacy in learning programming fundamentals. Notably, the findings reveal that students overwhelmingly prefer ChatGPT as the primary AI tool for learning programming concepts, with 312 mentions, making it the most popular and presumably the most useful tool among respondents. Following ChatGPT, Blackbox AI was the second most mentioned, with 74 students highlighting its utility. Gemini, Co-pilot, Assistguru, and Amazon Code Whisperer followed in popularity, with varying levels of student engagement and perceived usefulness. The study also found a substantial positive association (r = 0.296, p &lt; 0.05) between AI tool usage frequency and perceived effectiveness in programming education, indicating the potential benefits of increased interaction with AI tools. Gender disparities in tool preferences were identified, with male students showing a preference for specific instruments over their female counterparts. Despite these differences, there was little variation in the overall perceived efficacy of AI technology between genders. Furthermore, first-year students exhibited the highest frequency of AI tool usage, particularly on a weekly basis, emphasizing the importance of early exposure on usage patterns throughout students' academic careers. These findings underscore the necessity of considering gender preferences and demographics when developing and implementing AI-powered educational systems. The study recommends individualized approaches to enhance inclusivity and effectiveness in programming education, aiming to inform future advancements in educational technology and pedagogy.",10.1145/3702386.3702392,https://doi.org/10.1145/3702386.3702392
The Evolution of Computer Science at the University Level,"Shein, Esther",Commun. ACM,2025,Combining computer science with arts disciplines may be the wave of the future for education.,10.1145/3701223,https://doi.org/10.1145/3701223
Tartare: Automatic Generation of C Pointer Statements and Feedback,,Proceedings of the 26th Australasian Computing Education Conference,2024,"This paper addresses the difficulties students face when learning and practicing pointers (i.e., variables storing the memory address of another variable as its value) in a computer programming class. To improve their understanding and practice, we have developed Tartare, an automatic C pointer statement and feedback generator. By creating statements with automatic feedback, students are given the opportunity to practice at will, each time on a different instance. In addition, if the statement must be done remotely and accounts in the final grade, Tartare discourages academic dishonesty since each student faces their own statement to solve. This paper describes the techniques implemented in Tartare, relying on a pattern template-based approach. The statement variety of Tartare is evaluated. Finally, current limitations and further improvements are discussed. We believe our approach for Tartare can be transposed for automatic exercises generation in various other fields.",10.1145/3636243.3636264,https://doi.org/10.1145/3636243.3636264
Nurturing Code Quality: Leveraging Static Analysis and Large Language Models for Software Quality in Education,"AlOmar, Eman Abdullah",ACM Trans. Comput. Educ.,2025,"Large Language Models (LLMs), such as ChatGPT, have become widely popular for various software engineering tasks, including programming, testing, code review, and program comprehension. However, their impact on improving software quality in educational settings remains uncertain. This article explores our experience teaching the use of Programming Mistake Detector (PMD) to foster a culture of bug fixing and leverage LLM to improve software quality in the classroom. This article discusses the results of an experiment involving 155 submissions that carried out a code review activity of 1,658 rules. Our quantitative and qualitative analyses reveal that a set of PMD quality issues influences the acceptance or rejection of the issues, and design-related categories that take longer to resolve. Although students acknowledge the potential of using ChatGPT during code review, some skepticism persists. Further, constructing prompts for ChatGPT that possess clarity, complexity, and context nurtures vital learning outcomes, such as enhanced critical thinking, and among the 1,658 issues analyzed, 93% of students indicated that ChatGPT did not identify any additional issues beyond those detected by PMD. Conversations between students and ChatGPT encompass five categories, including ChatGPT’s use of affirmation phrases like “certainly” regarding bug fixing decisions, and apology phrases such as “apologize” when resolving challenges. Through this experiment, we demonstrate that code review can become an integral part of the educational computing curriculum. We envision our findings to enable educators to support students with effective code review strategies, increasing awareness of LLMs, and promoting software quality in education.",10.1145/3722229,https://doi.org/10.1145/3722229
Report on the Second International Workshop on DataSystems Education (DataEd '23),"Miedema, Daphne and Aivaloglou, Efthimia and Amer-Yahia, Sihem and Fletcher, George and Mior, Michael and Taipalus, Toni",SIGMOD Rec.,2024,"This report summarizes the outcomes of the second international workshop on Data Systems Education: Bridging Education Practice with Education Research (DataEd '23). The workshop was held in conjunction with the SIGMOD '23 conference in Seattle, USA on June 23, 2023. The aim of the workshop was to provide a dedicated venue for presenting and and discussing data management systems education experiences and research by bringing together the database and the computing education research communities to share findings, to crosspollinate perspectives and methods, and to shed light on opportunities for mutual progress in data systems education. The program featured two keynote talks, eight research paper presentations, and a discussion session. In this report, we present the workshop's main results, observations, and emerging research directions.",10.1145/3703922.3703932,https://doi.org/10.1145/3703922.3703932
Automated Program Repair for Introductory Programming Assignments via Bidirectional Refactoring,"Xie, Linna and Li, Chongmin and Pei, Yu and Zhang, Tian and Pan, Minxue",Proceedings of the 5th ACM/IEEE International Workshop on Automated Program Repair,2024,"The development of programming education has given rise to automated program repair techniques tailored for introductory programming assignments (IPAs). Despite the promising performance of mainstream automated feedback generation systems, they still struggle to handle scenarios where there is",10.1145/3643788.3648017,https://doi.org/10.1145/3643788.3648017
Video Versus Source Code Lab Solutions,"McGowan, Aidan and Anderson, Neil and Sage, Paul and Galway, Leo and Adhikari, Janak and Trombino, Giuseppe",Proceedings of the 8th Conference on Computing Education Practice,2024,"Traditionally university programming modules have been delivered using a blend of lectures, tutorials, and practical lab sessions. Although the lab sessions offer valuable hands-on practice, they are constrained by time, limited individualised pacing, and insufficient feedback opportunities. The solutions for the labs are normally provided as static source code, with students reviewing their attempts against the model answer. The use of video-based solutions for lab exercises has the potential to enhance flexibility and interactivity for the lab. This study explores the attitudes, experiences, and impact of the wholesale provision of video-based lab solutions in improving the student performance of a cohort of postgraduate novice programmers. It reports high student engagement with the video solutions with a clear preference for a dynamic build-up style. It also identifies separate engagement styles with the videos as well as overall improvement in module averages compared to previous cohorts. The findings highlight the potential of video-based lab solutions to enhance student learning in programming modules and adds to the literature in a relatively under-researched area and presents potential of further adoption and adaption in programming and other engineering disciplines.",10.1145/3633053.3633056,https://doi.org/10.1145/3633053.3633056
Supercharging Python Scripting Education with ChatGPT! - How I Use ChatGPT in my Advanced Python Scripting Class,"Kwan, Pak",J. Comput. Sci. Coll.,2024,"In recent years, the integration of artificial intelligence (AI) technologies into education has emerged as a promising approach to enhance student learning experiences and outcomes. This tutorial aims to explore how ChatGPT [1] can be effectively utilized to teach advanced Python scripting at the college level. Through interactive demonstrations, discussions, case study and hands-on activities, participants will gain insights into the potential applications of ChatGPT in the classroom and learn practical strategies for integrating this cutting-edge technology into their curriculum.",,
Data-driven Contribution-based Disciplinary Assessment System,"Xu, Ke and Yi, Hanxiao and Xu, Zichen and Wu, Dan",Proceedings of the ACM Turing Award Celebration Conference - China 2024,2024,"A scientific disciplinary assessment system is crucial for nurturing high-quality disciplines within Computer Science. Computer Science Education (CSE) emphasizes the need for a scientific and comprehensive assessment method that guides the development of the discipline, with a particular focus on practical contributions. However, traditional assessment systems tend to prioritize the theoretical outcomes. Moreover, data expansion demands significant effort and time from educational professionals, making it challenging to conduct a thorough evaluation of the disciplines. To tackle these issues, we introduce a data-driven, contribution-based disciplinary assessment system. This system takes into account both theoretical and practical contributions to provide a holistic evaluation. Our proposed system employs a contribution-based assessment approach to establish a correct evaluative direction, steering discipline construction to align with societal needs. It also incorporates intelligent algorithms and a Large Language Model (LLM), leveraging their substantial computational power in the evaluation process. This integration alleviates the workload of educational professionals by automating the collection and analysis of information. The paper outlines a detailed implementation plan that integrates contribution evaluation theory with intelligent technologies, aiming to foster the ongoing advancement of CSE education.",10.1145/3674399.3674423,https://doi.org/10.1145/3674399.3674423
Novice Perceptions on Effective Elements of PostgreSQL Error Messages,"Taipalus, Toni and Grahn, Hilkka and Ritonummi, Saima and Siitonen, Valtteri and Vartiainen, Tero and Zhidkikh, Denis",ACM Trans. Comput. Educ.,2025,"SQL compiler error messages are the primary way users receive feedback when they encounter syntax errors or other issues in their SQL queries. Effective error messages can enhance the user experience by providing clear, informative, and actionable feedback. Despite the age of SQL compilers, it still remains largely unclear what contributes to an effective SQL error message. With 2,052 answers yielded by 165 participants for qualitative analysis, this study is an attempt to understand what novices perceive as effective elements in SQL error messages. The results uniformly indicate that communicating the precise error position, articulating what is wrong in the query with clear natural language, and showing hints on how to fix the error are perceived as the most effective elements for error recovery. These insights have potential to be utilized in providing more effective error messages in SQL compilers and SQL learning environments, and for guiding generative AI for enhanced error messages in order to minimize frustration caused by cryptic error messages, improving learning and adoption, and reducing debugging time.",10.1145/3732790,https://doi.org/10.1145/3732790
Using Grammar Masking to Ensure Syntactic Validity in LLM-based Modeling Tasks,"Netz, Lukas and Reimer, Jan and Rumpe, Bernhard",Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems,2024,"Low-code development platforms (LCDPs) are becoming increasingly important in industry, which confronts us in academic teaching with the challenge of educating students in the basic principles, critical engagement, and evaluation of LCDPs. This leads us to the question, how to teach the usage of different LCDPs during an university course. The short time frame of university-level courses makes it challenging to teach more than only one LCDP. In our teaching approach, students use two different LCDPs and create a web-application with both of them. Firstly, we require the students to define a target application with common modeling languages, next they use the first LCDP, at about half the time they switch to the second LCDP and present their findings of the differences in methodology and development processes at the end. We discuss this approach, show survey results from the participants, and explain lessons learned. This concept allows students critical engagement with LCDPs and model-driven software engineering. Supervisors get an insight into the learnability of each LCDP and how novices adapt to different domain-specific languages and their notations.",10.1145/3652620.3687805,https://doi.org/10.1145/3652620.3687805
Leveraging Large Language Models for Analysis of Student Course Feedback,"Wang, Zixuan and Denny, Paul and Leinonen, Juho and Luxton-Reilly, Andrew",Proceedings of the 16th Annual ACM India Compute Conference,2023,"This study investigates the use of large language models, specifically ChatGPT, to analyse the feedback from a Summative Evaluation Tool (SET) used to collect student feedback on the quality of teaching. We find that these models enhance comprehension of SET scores and the impact of context on student evaluations. This work aims to reveal hidden patterns in student evaluation data, demonstrating a positive first step towards automated, detailed analysis of student feedback.",10.1145/3627217.3627221,https://doi.org/10.1145/3627217.3627221
Computer Science Curricula 2023,"Kumar, Amruth N. and Raj, Rajendra K. and Aly, Sherif G. and Anderson, Monica D. and Becker, Brett A. and Blumenthal, Richard L. and Eaton, Eric and Epstein, Susan L. and Goldweber, Michael and Jalote, Pankaj and Lea, Douglas and Oudshoorn, Michael and Pias, Marcelo and Reiser, Susan and Servin, Christian and Simha, Rahul and Winters, Titus and Xiang, Qiao",,2024,,,
PLAID: Supporting Computing Instructors to Identify Domain-Specific Programming Plans at Scale,"Jain, Yoshee and Demirtas, Mehmet Arif and Cunningham, Kathryn Irene",Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems,2025,"Pedagogical approaches focusing on stereotypical code solutions, known as programming plans, can increase problem-solving ability and motivate diverse learners. However, plan-focused pedagogies are rarely used beyond introductory programming. Our formative study (N=10 educators) showed that identifying plans is a tedious process. To advance plan-focused pedagogies in application-focused domains, we created an LLM-powered pipeline that automates the effortful parts of educators’ plan identification process by providing use-case-driven program examples and candidate plans. In design workshops (N=7 educators), we identified design goals to maximize instructors’ efficiency in plan identification by optimizing interaction with this LLM-generated content. Our resulting tool, PLAID, enables instructors to access a corpus of relevant programs to inspire plan identification, compare code snippets to assist plan refinement, and facilitates them in structuring code snippets into plans. We evaluated PLAID in a within-subjects user study (N=12 educators) and found that PLAID led to lower cognitive demand and increased productivity compared to the state-of-the-art. Educators found PLAID beneficial for generating instructional material. Thus, our findings suggest that human-in-the-loop approaches hold promise for supporting plan-focused pedagogies at scale.",10.1145/3706598.3713832,https://doi.org/10.1145/3706598.3713832
CPVis: Evidence-based Multimodal Learning Analytics for Evaluation in Collaborative Programming,"Zhang, Gefei and Ji, Shenming and Li, Yicao and Tang, Jingwei and Ding, Jihong and Xia, Meng and Sun, Guodao and Liang, Ronghua",Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems,2025,"As programming education becomes more widespread, many college students from non-computer science backgrounds begin learning programming. Collaborative programming emerges as an effective method for instructors to support novice students in developing coding and teamwork abilities. However, due to limited class time and attention, instructors face challenges in monitoring and evaluating the progress and performance of groups or individuals. To address this issue, we collect multimodal data from real-world settings and develop CPVis, an interactive visual analytics system designed to assess student collaboration dynamically. Specifically, CPVis enables instructors to evaluate both group and individual performance efficiently. CPVis employs a novel flower-based visual encoding to represent performance and provides time-based views to capture the evolution of collaborative behaviors. A within-subject experiment (N=22), comparing CPVis with two baseline systems, reveals that users gain more insights, find the visualization more intuitive, and report increased confidence in their assessments of collaboration.",10.1145/3706598.3713353,https://doi.org/10.1145/3706598.3713353
Prompting for Comprehension: Exploring the Intersection of Explain in Plain English Questions and Prompt Writing,"Smith, David H. and Denny, Paul and Fowler, Max",,2024,"Learning to program requires the development of a variety of skills including the ability to read, comprehend, and communicate the purpose of code. In the age of large language models (LLMs), where code can be generated automatically, developing these skills is more important than ever for novice programmers. The ability to write precise natural language descriptions of desired behavior is essential for eliciting code from an LLM, and the code that is generated must be understood in order to evaluate its correctness and suitability. In introductory computer science courses, a common question type used to develop and assess code comprehension skill is the 'Explain in Plain English' (EiPE) question. In these questions, students are shown a segment of code and asked to provide a natural language description of that code's purpose. The adoption of EiPE questions at scale has been hindered by: 1) the difficulty of automatically grading short answer responses and 2) the ability to provide effective and transparent feedback to students. To address these shortcomings, we explore and evaluate a grading approach where a student's EiPE response is used to generate code via an LLM, and that code is evaluated against test cases to determine if the description of the code was accurate. This provides a scalable approach to creating code comprehension questions and enables feedback both through the code generated from a student's description and the results of test cases run on that code. We evaluate students' success in completing these tasks, their use of the feedback provided by the system, and their perceptions of the activity.",10.1145/3657604.3662039,https://doi.org/10.1145/3657604.3662039
NotePlayer: Engaging Computational Notebooks for Dynamic Presentation of Analytical Processes,"Ouyang, Yang and Shen, Leixian and Wang, Yun and Li, Quan",Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology,2024,"Diverse presentation formats play a pivotal role in effectively conveying code and analytical processes during data analysis. One increasingly popular format is tutorial videos, particularly those based on Jupyter notebooks, which offer an intuitive interpretation of code and vivid explanations of analytical procedures. However, creating such videos requires a diverse skill set and significant manual effort, posing a barrier for many analysts. To bridge this gap, we introduce an innovative tool called NotePlayer, which connects notebook cells to video segments and incorporates a computational engine with language models to streamline video creation and editing. Our aim is to make the process more accessible and efficient for analysts. To inform the design of NotePlayer, we conducted a formative study and performed content analysis on a corpus of 38 Jupyter tutorial videos. This helped us identify key patterns and challenges encountered in existing tutorial videos, guiding the development of NotePlayer. Through a combination of a usage scenario and a user study, we validated the effectiveness of NotePlayer. The results show that the tool streamlines the video creation and facilitates the communication process for data analysts.",10.1145/3654777.3676410,https://doi.org/10.1145/3654777.3676410
,"Smith, Julie M. and Wallace, Charles and Scharlau, Bruce",,,,,
More than Model Documentation: Uncovering Teachers' Bespoke Information Needs for Informed Classroom Integration of ChatGPT,"Tan, Mei and Subramonyam, Hari",Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems,2024,"ChatGPT has entered classrooms, circumventing typical training and vetting procedures. Unlike other educational technologies, it placed teachers in direct contact with the versatility of generative AI. Consequently, teachers are urgently tasked to assess its capabilities to inform their use of ChatGPT. However, it is unclear what support teachers have and need and whether existing documentation, such as model cards, provides adequate direction for educators in this new paradigm. By interviewing 22 middle- and high-school ELA and Social Studies teachers, we connect the discourse on AI transparency and documentation with educational technology integration, highlighting the information needs of teachers. Our findings reveal that teachers confront significant information gaps, lacking clarity on exploring ChatGPT’s capabilities for bespoke learning tasks and ensuring its fit with the needs of diverse learners. As a solution, we propose a framework for interactive model documentation that empowers teachers to navigate the interplay between pedagogical and technical knowledge.",10.1145/3613904.3642592,https://doi.org/10.1145/3613904.3642592
Public Computing Intellectuals in the Age of AI Crisis,"Connolly, Randy",ACM Trans. Comput. Educ.,2024,"The belief that AI technology is on the cusp of causing a generalized social crisis became a popular one in 2023. While there was no doubt an element of hype and exaggeration to some of these accounts, they do reflect the fact that there are troubling ramifications to this technology stack. This conjunction of shared concerns about social, political, and personal futures presaged by current developments in AI presents the academic discipline of computing with a renewed opportunity for self-examination and reconfiguration. This position article endeavors to do so in four sections. The first section explores what is at stake for computing in the narrative of an AI crisis. The second section articulates possible educational responses to this crisis and advocates for a broader analytic focus on power relations. The third section presents a novel characterization of academic computing’s field of practice, one which includes not only the discipline’s usual instrumental forms of practice but reflexive practice as well. This reflexive dimension integrates both the critical and public functions of the discipline as equal intellectual partners and a necessary component of any contemporary academic field. The final section will advocate for a conceptual archetype—the Public Computer Intellectual and its less conspicuous but still essential cousin, the Almost-Public Computer Intellectual—as a way of practically imagining the expanded possibilities of academic practice in our discipline, one that provides both self-critique and an outward-facing orientation toward the public good. It will argue that the computer education research community can play a vital role in this regard. Recommendations for pedagogical change within computing to develop more reflexive capabilities are also provided.",10.1145/3703162,https://doi.org/10.1145/3703162
SIGITE '24: Proceedings of the 25th Annual Conference on Information Technology Education,,,2024,,,
Emerging Technologies in K–12 Education: A Future HCI Research Agenda,"Van Mechelen, Maarten and Smith, Rachel Charlotte and Schaper, Marie-Monique and Tamashiro, Mariana and Bilstrup, Karl-Emil and Lunding, Mille and Graves Petersen, Marianne and Sejer Iversen, Ole",ACM Trans. Comput.-Hum. Interact.,2023,"This systematic mapping review sheds light on how emerging technologies have been introduced and taught in various K–12 learning settings, particularly with regard to artificial intelligence (AI), machine learning (ML), the internet of things (IoT), augmented reality (AR), and virtual reality (VR). These technologies are rapidly being integrated into children's everyday lives, but their functions and implications are rarely understood due to their complex and distributed nature. The review provides a rigorous overview of the state of the art based on 107 records published across the fields of human-computer interaction, learning sciences, computing education, and child–computer interaction between 2010 and 2020.&nbsp;The findings show the urgent need on a global scale for inter- and transdisciplinary research that can integrate these dispersed contributions into a more coherent field of research and practice. The article presents nine discussion points for developing a shared agenda to mature the field. Based on the HCI community's expertise in human-centred approaches to technology and aspects of learning, we argue that the community is ideally positioned to take a leading role in the realisation of this future research agenda.",10.1145/3569897,https://doi.org/10.1145/3569897
Does Every Computer Scientist Need to Know Formal Methods?,,Form. Asp. Comput.,2024,"We focus on the integration of Formal Methods as mandatory theme in any Computer Science University curriculum. In particular, when considering the ACM Curriculum for Computer Science, the inclusion of Formal Methods as a mandatory Knowledge Area needs arguing for why and how does every computer science graduate benefit from such knowledge. We do not agree with the sentence “While there is a belief that formal methods are important and they are growing in importance, we cannot state that every computer science graduate will need to use formal methods in their career.” We argue that formal methods are and have to be an integral part of every computer science curriculum. Just as not all graduates will need to know how to work with databases either, it is still important for students to have a basic understanding of how data is stored and managed efficiently. The same way, students have to understand why and how formal methods work, what their formal background is, and how they are justified. No engineer should be ignorant of the foundations of their subject and the formal methods based on these.In this article, we aim at highlighting why every computer scientist needs to be familiar with formal methods. We argue that education in formal methods plays a key role by shaping students' programming mindset, fostering an appreciation for underlying principles, and encouraging the practice of thoughtful program design and justification, rather than simply writing programs without reflection and deeper understanding. Since integrating formal methods into the computer science curriculum is not a straightforward process, we explore the additional question: what are the tradeoffs between one dedicated knowledge area of formal methods in a computer science curriculum versus having formal methods scattered across all knowledge areas? Solving problems while designing software and software-intensive systems demands an understanding of what is required, followed by a specification and formalizing a solution in a programming language. How to do this systematically and correctly on solid grounds is exactly supported by formal methods.",10.1145/3670795,https://doi.org/10.1145/3670795
Evaluating Micro-Insertion as a Method for Teaching Responsible Computing: Results from a Randomized Controlled Experiment,"Brown, Noelle and Nurollahian, Sara and Wiese, Eliane S.",ACM Trans. Comput. Educ.,2025,"While there have been many calls for teaching ethics and responsible computing, it is unclear how responsible computing instruction and technical learning interact. Some instructors even hesitate to include ethics in their courses, fearing it might distract students from learning technical computing content. An approach called micro-insertion offers a path to teaching responsible computing while teaching technical content. Micro-insertion situates technical problems in real-world contexts, with frequent, minimally invasive discussions of potential harms of a computing professional’s technical choices. We conducted a between-subjects laboratory study where 82 post-secondary student participants were randomly assigned to one of two instructional conditions to learn a computing topic. The technical-only condition received traditional instruction, while the micro-insertion condition learned the same technical material contextualized within a real-world scenario with potential broader ethical or social impacts. Our study design included a pre-test, instruction intervention, immediate post-test, and a 2-week delayed post-test. Each test included both technical and contextualized questions, and the instructional time was the same across both conditions. The study revealed no statistically significant differences in learning outcomes between the two conditions. Participants in both conditions improved in solving problems presented both abstractly and contextualized with a real-world narrative. Thus, we did not find evidence that our responsible computing intervention distracted participants from learning the technical topics. Further, participants in the technical-only condition could correctly respond to contextualized questions, suggesting that students might be able to engage with responsible computing micro-insertions without targeted instruction. To more deeply understand students’ reasoning, we conducted follow-up interviews with 13 of the participants. The interviews revealed that participants in both conditions perceived to have learned about responsible computing from the study. However, the depth and quality of participants’ engagement with real-world issues varied significantly, with many only superficially addressing the context and many relying on their own personal experiences as their source of knowledge. We, therefore, encourage future studies to investigate other approaches to responsible computing education to determine which approach results in more meaningful consideration of social and ethical issues and whether that detracts from or supports technical learning.",10.1145/3719017,https://doi.org/10.1145/3719017
Exploring the Frontiers of Machine Learning in Education,"Li, Jiayi",XRDS,2024,,10.1145/3688077,https://doi.org/10.1145/3688077
A Chatbot Won't Judge Me: An Exploratory Study of Self-disclosing Chatbots in Introductory Computer Science Classes,"Goddard, Quinn and Moton, Nathan and Hudson, Jonathan and He, Helen Ai",Proceedings of the 26th Western Canadian Conference on Computing Education,2024,"Students in introductory Computer Science (CS) courses sometimes struggle with learning course content, but feel these struggles are uniquely theirs. To foster a more inclusive CS culture and normalize challenges in the learning process, we designed a conversational agent (“chatbot”) that self-discloses information about the chatbot’s own imaginary struggles with learning course material. Inspired by previous work in the mental health domain where humans reciprocated disclosure when a chatbot disclosed sensitive information, our goal was to promote student self-disclosure of learning challenges and to help students feel less alone. To inform design, we first conducted three focus groups with CS students on themes of identity and belonging. Based on these findings, we designed a self-disclosing chatbot (“Mibi”) and deployed it in a pilot summer course (40 students) and a larger course (460 students) in the fall semester of 2023. Our work is the first real-world deployment of a chatbot in higher education for promoting student wellbeing, rather than assisting with practical course content. We highlight findings from this exploratory study, sharing how students engaged with Mibi, where it succeeded, where it has room to grow, and how that can inform future iterations of this promising new classroom companion for student mental health.",10.1145/3660650.3660662,https://doi.org/10.1145/3660650.3660662
Leveraging ChatGPT for SQL Learning: An Interactive Approach,"Huang, Ching-yu and Wang, Paolien",J. Comput. Sci. Coll.,2024,"In today's data-driven world, SQL proficiency is essential for data analysts, software developers, and database fields. However, traditional SQL learning methods often rely heavily on classroom lectures and textbooks, resulting in repetitive activities where students tackle the same exercises and questions. This approach can be inefficient, hindering student learning as instructors must individually address syntax errors and runtime issues, limiting their ability to assist all students effectively. Additionally, student engagement and comprehension may suffer, particularly for those with weak foundations who heavily depend on instructor guidance.",,
"ChatGPT: To Use or Not to Use, That is the Question: Panel Discussion","Cerkez, Paul S. and Hummel, Joseph Edward and Mejias, Marlon and Pruitt, William",J. Comput. Sci. Coll.,2023,"ChatGPT, from OpenAI (AI - artificial intelligence), and the many similar Large Language Models (LLM) appear to have taken the world by storm with some for it, some against it. In simple terms, these products are a great tool for the experienced domain user, however, precisely because of their capability, there is a lot of controversy surrounding student's use.",,
CURRICULUM MATTERS,"Goldweber, Mikey",ACM Inroads,2024,How to Read the CS2023 Report,10.1145/3676561,https://doi.org/10.1145/3676561
English Composition Image Automatic Scoring Based on Multi-modal Large Language Models,"Wang, Xiaohui and Yu, Ruijie and Zhang, Yu and Xu, Yanyan",Proceeding of the 2024 International Conference on Artificial Intelligence and Future Education,2025,"Large language models (LLMs) bring significant opportunities in the field of education evaluation. Nowadays, most existing LLMs are introduced to generate reasonable scores for electronic and structurized documents. However, such systems require huge efforts for manual typewriting or advanced optical character recognition techniques. To this end, this work directly processes the scanning copy of English composition with multi-modal LLMs. Specifically, this research aims to utilize multi-modal LLMs for automated essay scoring (AES) and evaluate its reliability and accuracy. We take the English composition images of 1,511 tenth-grade examinees in a standardized test environment as the research objects for automated scoring, and explore the performance of the multi-modal LLM GPT-4o in evaluating composition image data. The study compares the consistency of the composition image scores of GPT-4o under zero-shot and two-shot prompts with the scores of the marking experts, and verifies them through multiple indicators such as the exact agreement coefficient, Pearson correlation coefficient, Coefficient of determination, Root Mean Square Error, and the probability that the GPT-4o score falls within a given confidence interval. Especially, comparing the scores given by experts, the R-square of the GPT-4o scoring reaches 0.66. The results show that GPT-4o has the ability to learn from two samples through prompt, can quickly adapt and provide high-quality and personalized evaluations for examinees, and can provide valuable support for human scoring.",10.1145/3708394.3708437,https://doi.org/10.1145/3708394.3708437
"The Promise and Peril of ChatGPT in Higher Education: Opportunities, Challenges, and Design Implications","Park, Hyanghee and Ahn, Daehwan",Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems,2024,"A growing number of students in higher education are using ChatGPT for various educational purposes, ranging from seeking information to writing essays. Although many universities have officially banned the use of ChatGPT because of its potential harm and unintended consequences, it is still important to uncover how students leverage ChatGPT for learning, what challenges emerge, and how we can make better use of ChatGPT in higher education. Thus, we conducted focus group workshops and a series of participatory design sessions with thirty students who have actively interacted with ChatGPT for one semester in university and with other five stakeholders (e.g., professors, AI experts). Based on these, this paper identifies real opportunities and challenges of utilizing and designing ChatGPT for higher education.",10.1145/3613904.3642785,https://doi.org/10.1145/3613904.3642785
Generating CS1 Coding Questions using OpenAI,"Naringrekar, Pranjal Dilip and Akhmetov, Ildar and Stroulia, Eleni",Proceedings of the 25th Western Canadian Conference on Computing Education,2023,"In CS1, to assess student knowledge, instructors prepare exam questions that often include code snippets. Due to the significant amount of time and effort required to create high-quality exam questions, instructors often only produce a single version of the exam. This results in all students receiving the same set of questions, which raises the possibility of plagiarism. In this paper, we propose a tool that allows computing science educators to generate a number of variations of a given code snippet, where the pedagogical intent of the code remains the same, but the code is mutated.",10.1145/3593342.3593348,https://doi.org/10.1145/3593342.3593348
“It’s Weird That it Knows What I Want”: Usability and Interactions with Copilot for Novice Programmers,"Prather, James and Reeves, Brent N. and Denny, Paul and Becker, Brett A. and Leinonen, Juho and Luxton-Reilly, Andrew and Powell, Garrett and Finnie-Ansley, James and Santos, Eddie Antonio",ACM Trans. Comput.-Hum. Interact.,2023,"Recent developments in deep learning have resulted in code-generation models that produce source code from natural language and code-based prompts with high accuracy. This is likely to have profound effects in the classroom, where novices learning to code can now use free tools to automatically suggest solutions to programming exercises and assignments. However, little is currently known about how novices interact with these tools in practice. We present the first study that observes students at the introductory level using one such code auto-generating tool, Github Copilot, on a typical introductory programming (CS1) assignment. Through observations and interviews we explore student perceptions of the benefits and pitfalls of this technology for learning, present new observed interaction patterns, and discuss cognitive and metacognitive difficulties faced by students. We consider design implications of these findings, specifically in terms of how tools like Copilot can better support and scaffold the novice programming experience.",10.1145/3617367,https://doi.org/10.1145/3617367
Designing Technology to Support the Hospital Classroom: Preliminary Findings,"Rasberry, Nadra and Essandoh, Joshua and Do, Ethan and Ogbonnaya-Ogburu, Ihudiya Finda",Companion Publication of the 2024 Conference on Computer-Supported Cooperative Work and Social Computing,2024,"Hospital teachers are state-employed educators who provide K-12 instruction to children in the hospital. We conducted research to understand how technology is used in hospital classrooms, an area which has been relatively underexplored. We conducted semi-structured interviews with five hospital teachers to understand their experience of using technology in and outside the classroom. Our findings revealed that hospital teachers often rely on older curricula given the changing education atmosphere; learning is often assessed through in-classroom observations of mastery; and technology and internet use by students is often restricted, which may inhibit opportunities to use AI and other technical resources in the classroom. We contribute a deeper understanding of technology use in the hospital classroom.",10.1145/3678884.3681856,https://doi.org/10.1145/3678884.3681856
Some theories from abroad for AI interaction literacy.,"Waite, Jane",Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research,2024,"I have become rather ‘het up’ about the use of AI applications in teaching and learning. I am worried that the digital divide will widen rather than narrow with the increasing use of this technology. A question that bothers me is,",10.1145/3689535.3689563,https://doi.org/10.1145/3689535.3689563
Roles of ChatGPT in virtual teaching assistant and intelligent tutoring system: opportunities and challenges,"Chen, Shunxing and Xu, Xiaoshu and Zhang, Huanhuan and Zhang, Yunfeng",Proceedings of the 2023 5th World Symposium on Software Engineering,2023,"Artificial Intelligence (AI), specifically the Generative Pre-trained Transformer 4 (GPT-4), or ChatGPT, promises to revolutionize Virtual Teaching Assistants (VTAs) and Intelligent Tutoring Systems (ITS). This advanced language model fosters enhanced student engagement and personalized, adaptive learning experiences. However, amidst the substantial benefits, several critical challenges encompassing response reliability, data privacy, algorithmic biases, and interpretability necessitate deliberate scrutiny. The proposed study aims to examine the opportunities and hurdles inherent to the deployment of ChatGPT in the educational landscape. With a focus on high-quality, Google Scholar, Scopus, and Web of Science-indexed literature, the review encompasses a comprehensive exploration of empirical studies, theoretical perspectives, and practical implications related to ChatGPT. Through this literature review, we will shed light on the dynamic intersection of AI and education. The elucidation of nuanced implications will empower educators, policymakers, and AI developers to make informed decisions and devise effective strategies, thereby facilitating an optimized integration of ChatGPT into the educational ecosystem.",10.1145/3631991.3632024,https://doi.org/10.1145/3631991.3632024
"The use of ChatGPT to generate Summative Feedback in Programming Assessments that is Consistent, Prompt, without Bias and Scalable","McGowan, Aidan and Anderson, Neil and Smith, Christopher",Proceedings of the Cognitive Models and Artificial Intelligence Conference,2024,"ABSTRACTThis paper explores the automated integration of ChatGPT into the feedback process for a large-scale and complex university programming assignment. It aims to explore the feasibility of using ChatGPT to facilitate prompt, efficient, and valued feedback to students. The study presents case studies illustrating the use of the ChatGPT API in generating feedback through an automated tool (AutoFeed) developed by the researchers. The findings report on the advantages as well as the limitations of employing Prompt Engineering for this purpose.",10.1145/3660853.3660863,https://doi.org/10.1145/3660853.3660863
Gamification of a BPMN Modeling Course: an Analysis of Effectiveness and Student Perception,"Garaccione, Giacomo and Coppola, Riccardo and Ardito, Luca and Torchiano, Marco",Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement,2024,"Background. Gamification, i.e. the use of game-like elements in non-recreational contexts for increasing user participation and interest, has been adopted several times for Software Engineering activities for both practitioners and learners. There is, however, little evidence in the literature about applications of gamification to the discipline of Process Modeling, and even fewer experience reports are available about the use of gamified tooling in education. Aims. Our research aims at filling this current gap by applying BIPMIN, a tool that employs gamification of Business Process Modeling Notation (BPMN), in the practical sessions of an Information Systems course, to assess whether gamification leads to improvements in the students’ BPMN knowledge and their commitment in performing the exercises. Method. All the exercises of the course were performed with a gamified tool, that embedded means to evaluate automatically the students’ efforts in terms of completeness, syntax errors, and semantic errors. We analyzed the improvements over time during the course and compared the results obtained at the end of the year with those obtained by students of the previous edition, to assess whether gamification leads to higher grades. Results. The grades of BPMN-related exercises were higher if gamified concepts were applied. Students managed to have a solid grasp of modeling fundamentals around halfway through the course, and no evident reduction in productivity or results is measured when the most difficult BPMN concepts are introduced. Conclusions. The application of Gamification to an entire Information Systems course appears beneficial for process modeling education, with higher grades, favorable student reception, and positive learning effects as students keep interacting with the gamified tool.",10.1145/3674805.3686683,https://doi.org/10.1145/3674805.3686683
Teaching Refactoring to Improve Code Quality with ChatGPT: An Experience Report in Undergraduate Lessons,,Proceedings of the XXIII Brazilian Symposium on Software Quality,2024,"Refactoring presents a complex computational challenge, and its learning is intricate, requiring a solid foundation in computational thinking, programming and object-oriented concepts. Moreover, making students realize the importance and benefits of refactoring is also challenging. To address this complexity, we introduce a refactoring teaching method based on Generative Artificial Intelligence (GAI), incorporating single-loop and double-loop learning principles, focusing on fostering deeper and critical learning. We used ChatGPT, a GAI-based tool, and conducted an eight-week mixed-methods study involving 23 computer science undergraduate students. The study involved applying four distinct projects extracted from GitHub, where participants were tasked with identifying code smells and performing the necessary refactoring to improve code quality. The primary focus was on identifying both the positive and negative aspects of the method, as well as delineating the computational thinking characteristics developed during the process. The results indicate that the use of ChatGPT facilitated the learning of refactoring, contributing to the development of numerous computational thinking skills, especially problem formulation, decomposition, and abstraction. Thus, this paper contributes a GAI-based teaching method along with evidence on how it helps students develop refactoring skills.",10.1145/3701625.3701681,https://doi.org/10.1145/3701625.3701681
Varying Program Input to Assess Code Reading Skills,"Albluwi, Ibrahim and Hriez, Raghda and Lister, Raymond",ACM Trans. Comput. Educ.,2025,"Explain-in-Plain-English (EiPE) questions are used by some researchers and educators to assess code reading skills. EiPE questions require students to briefly explain (in plain English) the purpose of a given piece of code, without restating what the code does line-by-line. The premise is that novices who can explain the purpose of a piece of code have higher code-reading skills than those who can trace the code but cannot see its high-level purpose. However, using natural language in EiPE questions poses challenges. Students (especially those whose first language is not English) may struggle to convey their understanding of the code unambiguously. Also, grading responses written in natural language is time-consuming, requires the design of a rubric, and is difficult to automate. We propose a new code reading question type that addresses these issues with EiPE questions. Given a piece of code involving repetition (in the form of iteration or recursion), the student is asked to provide the output for a set of inputs, where the output for some of these inputs cannot be determined using code tracing alone and requires higher-level code comprehension. In empirical evaluations, using CS1 exams, think-aloud interviews with students, and interviews with instructors, we found that assessments of code reading skills using the new question type are highly consistent with the assessments using EiPE questions, yet are more reliable. These results put forward the proposed question type as another way to assess high-level code-reading skills without the issues associated with expressing in natural language or grading responses expressed in natural language.",10.1145/3737884,https://doi.org/10.1145/3737884
'I'm Categorizing LLM as a Productivity Tool': Examining Ethics of LLM Use in HCI Research Practices,"Kapania, Shivani and Wang, Ruiyi and Li, Toby Jia-Jun and Li, Tianshi and Shen, Hong",Proc. ACM Hum.-Comput. Interact.,2025,"Large language models are increasingly applied in real-world scenarios, including research and education. These models, however, come with well-known ethical issues, which may manifest in unexpected ways in human-computer interaction research due to the extensive engagement with human subjects. This paper reports on research practices related to LLM use, drawing on 16 semi-structured interviews and a survey with 50 HCI researchers. We discuss the ways in which LLMs are already being utilized throughout the entire HCI research pipeline, from ideation to system development and paper writing. While researchers described nuanced understandings of ethical issues, they were rarely or only partially able to identify and address those ethical concerns in their own projects. This lack of action and reliance on workarounds was explained through the perceived lack of control and distributed responsibility in the LLM supply chain, the conditional nature of engaging with ethics, and competing priorities. Finally, we reflect on the implications of our findings and present opportunities to shape emerging norms of engaging with large language models in HCI research.",10.1145/3711000,https://doi.org/10.1145/3711000
Integrated Coding Environment for Programming Exercise,"Murai, Kiyohiro and Watanobe, Yutaka",Proceedings of the 2023 4th Asia Service Sciences and Software Engineering Conference,2024,"Programming education has become important due to the recent development of ICT. However, there are some barriers for beginners to learn programming. The first is a technical problem that construction of an execution environment is not easy. The second is the lack of graders for solving programming and algorithmic problems. The third is that learners cannot receive sufficient reviews. The fourth is that it is not easy to grasp the learning status of learners. This paper proposes an environment called Integrated Coding Environment to solve these problems. So far, the functional and architectural interactions of online learning services have not been sufficiently discussed. In addition, there is not enough discussion on how to systematically interact with online learning services in the learner's workflow. This paper describes the environment designed to support this workflow, focusing on the comprehensive components it contains and their interactions. The environment has been implemented and utilized, and experiences in its operation are also discussed.",10.1145/3634814.3634822,https://doi.org/10.1145/3634814.3634822
Students'perception of the use of AI Detector System by faculty members in determining the originality of submitted academic requirements,"Angeles, Chito Naorbe and Samson, Brylle Dimaano and Mama, Bai Rafsan Zahna Ibad and Luriaga, Ronnie Lucero and Delizo, John Pierre Demata and Ching, Michelle Renee Domingo","Proceedings of the 2024 8th International Conference on E-Commerce, E-Business, and E-Government",2024,"Recent studies revealed an overwhelming concern about the misuse of generative Artificial Intelligence (AI) tools by students in completing academic requirements. The detection of AI-generated content using the naked eye was perceived to be difficult, hence the need for more accurate, reliable, and effective detection methods. As a countermeasure, educators are turning to AI content detectors and plagiarism checkers to ascertain the originality of submitted school requirements, raising concerns from students regarding the accuracy and reliability of these tools and the ethical implications and negative consequences of misclassification of genuinely original works as machine-generated outputs. By employing a holistic case study approach, the authors attempted to determine the perceptions of selected university students on the use of AI detection systems by faculty members in checking the originality and novelty of their academic outputs. Through the lenses of various normative ethical theories, the authors also analyzed the ethical issues and concerns raised by selected students to better understand their sentiments and the factors they believe could influence the faculty members' intention to adopt this emerging technology. The results of the study revealed that students have mixed attitudes and perceptions toward the faculty's intention to use AI detectors. While students perceived it as a means to encourage independent learning and critical thinking, they also expressed valid concerns regarding fairness, accuracy, and reliability, the impact on teacher-student trust, and the responsible use of the technology, among others. The participants also acknowledged the influence of other faculty members and the students' increasing dependence on AI as possible enablers of technology adoption while technological limitations, the teachers’ lack of technological skills, and age as perceived barriers. From an ethical view, the findings of the study highlighted the importance of transparency, fairness, privacy, and the need for a policy to regulate AI use.",10.1145/3675585.3675587,https://doi.org/10.1145/3675585.3675587
Beyond Text-to-Text: An Overview of Multimodal and Generative Artificial Intelligence for Education Using Topic Modeling,"Heilala, Ville and Araya, Roberto and H\",Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing,2025,"Generative artificial intelligence (GenAI) can reshape education and learning. While large language models (LLMs) like ChatGPT dominate current educational research, multimodal capabilities—such as text-to-speech and text-to-image—are less explored. This study uses topic modeling to map the research landscape of multimodal and generative AI in education. An extensive literature search yielded 4175 articles. Employing a topic modeling approach, latent topics were extracted, resulting in 38 interpretable topics organized into 14 thematic areas. Findings indicate a predominant focus on text-to-text models in educational contexts, with other modalities underexplored, overlooking the broader potential of multimodal approaches. The results suggest a research gap, stressing the importance of more balanced attention across different AI modalities and educational levels. In summary, this research provides an overview of current trends in generative AI for education, underlining opportunities for future exploration of multimodal technologies to fully realize the transformative potential of artificial intelligence in education.",,https://doi.org/10.1145/3672608.3707764
An Evidence-based Workflow for Studying and Designing Learning Supports for Human-AI Co-creation,"Gmeiner, Frederic and Conlin, Jamie Lynn and Tang, Eric Handa and Martelaro, Nikolas and Holstein, Kenneth",Extended Abstracts of the CHI Conference on Human Factors in Computing Systems,2024,"Generative artificial intelligence (GenAI) systems introduce new possibilities for enhancing professionals’ workflows, enabling novel forms of human–AI co-creation. However, professionals often struggle to learn to work with GenAI systems effectively. While research has begun to explore the design of interfaces that support users in learning to co-create with GenAI, we lack systematic approaches to investigate the effectiveness of these supports. In this paper, we present a systematic approach for studying how to support learning to co-create with GenAI systems, informed by methods and concepts from the learning sciences. Through an experimental case study, we demonstrate how our approach can be used to study and compare the impacts of different types of learning supports in the context of text-to-image GenAI models. Reflecting on these results, we discuss directions for future work aimed at improving interfaces for human–AI co-creation.",10.1145/3613905.3650763,https://doi.org/10.1145/3613905.3650763
InsProg: Supporting Teaching Through Visual Analysis of Students’ Programming Processes,"Zhong, Hongyan and Niu, Jun and Li, Junjie",Proceedings of the 2024 International Conference on Advanced Visual Interfaces,2024,"Teachers commonly assess students’ knowledge mastery through their submitted programming assignments. However, programming is a dynamic process that involves editing and debugging, and this evaluation may overlook the actual abilities exhibited by students during the programming process. Therefore, understanding students’ programming processes becomes crucial for teachers to grasp their programming abilities. While previous studies have focused on students’ programming processes, they predominantly concentrate on the evolution of source code content for individual student, neglecting a comprehensive analysis and visual representation of the entire programming pathway, including the debugging process. In this paper, we propose InsProg, a novel visual analysis system for programming process. By collecting students’ keystroke data and source code snapshots, InsProg not only enables teachers to trace students’ complete programming processes, but it also provides insights into their editing progress and the correctness of their solutions in two-dimensional coordinates. Preliminary experimental results demonstrate that InsProg effectively visualizes students’ programming processes, facilitating teachers’ efficient assessment of students’ programming abilities. This offers valuable support for teachers in assisting with programming instruction.",10.1145/3656650.3656668,https://doi.org/10.1145/3656650.3656668
From Feedback to Formative Guidance: Leveraging LLMs for Personalized Support in Programming Projects,"Ghoochani, Fatemeh and Scharfenberger, Jonas and Funk, Burkhardt and Doublan, Raoul and Jakharabhai Odedra, Mayur and Etsiwah, Bennet","Adjunct Proceedings of the 33rd ACM Conference on User Modeling, Adaptation and Personalization",2025,"Large Language Models (LLMs) offer scalable opportunities to personalize feedback in education, yet their trustworthiness and effectiveness remain underexplored. We present a study conducted in an introductory programming and data science course with approximately 1,400 first-year university students. A subset of these students received both peer and LLM-generated feedback on their individual programming projects. Our results show that 56% of students preferred the LLM feedback, and 52% could not reliably distinguish it from human-written feedback. Student ratings suggest that LLM feedback is perceived as helpful, constructive, and relevant, though it often lacks personalized depth and motivational nuance. These findings underline the potential of LLMs to support scalable, personalized education, while pointing to key areas for responsible improvement. Based on these insights, we outline the future roadmap for the course in which LLM-generated feedback supports students in their learning journey but also instructors through monitoring student performance and helping to allocate instructional resources more effectively. Given limited human resources this approach enables personalized instructor feedback to be scaled to a large group of students.",10.1145/3708319.3733808,https://doi.org/10.1145/3708319.3733808
EAAI-24 Blue Sky Ideas in Artificial Intelligence Education from the AAAI/ACM SIGAI New and Future AI Educator Program,"Neumann, Marion and Rosenthal, Stephanie and Stevens, Justin and Lugo, Rachel and Agnew, William and Wein, Shira",AI Matters,2025,"The 14th Symposium on Educational Advances in Artificial Intelligence (EAAI-24), cochaired by Marion Neumann and Stephanie Rosenthal, continued the tradition of the AAAI/ACM SIGAI New and Future AI Educator (NFAIED) Program to support the training of early-career university faculty, secondary school faculty, and future educators (PhD candidates or postdocs who intend a career in academia).This paper is a collection of the",10.1145/3715920.3715922,https://doi.org/10.1145/3715920.3715922
How to Deal with Students' Conceptions: Conceptual Change Texts on Artificial Intelligence,"Rabe, Anna and Kreinsen, Moritz and Grospietsch, Finja and Schulz, Sandra",Proceedings of the 18th WiPSCE Conference on Primary and Secondary Computing Education Research,2023,"The aim of this study is to develop conceptual change texts (CCTs) on Artificial Intelligence (AI), which are supposed to transform the common everyday conceptions of students on AI into scientifically correct conceptions in a meaningful way. In a first step, we qualitatively examined existing research findings on students’ conceptions on AI in order to identify relevant conceptions. Further, we developed a test instrument that included both scientific conceptions and the identified student conceptions on AI and investigated students’ agreement with these conceptions. A CCT was created for the student conception with the most agreement, testing the effect of conceptual change as a learning process by conducting a pre- and post-test design. After the intervention, first indications for a conceptual change were uncovered.",10.1145/3605468.3609781,https://doi.org/10.1145/3605468.3609781
Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems,"Prabhudesai, Snehal and Kasi, Ananya Prashant and Mansingh, Anmol and Das Antar, Anindya and Shen, Hua and Banovic, Nikola",Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems,2025,"Despite recognizing that Large Language Models (LLMs) can generate inaccurate or unacceptable responses, universities are increasingly making such models available to their students. Existing university policies defer the responsibility of checking for correctness and appropriateness of LLM responses to students and assume that they will have the required knowledge and skills to do so on their own. In this work, we conducted a series of user studies with students (N=47) from a large North American public research university to understand if and how they critically engage with LLMs. Our participants evaluated an LLM provided by the university in a quasi-experimental setup; first by themselves, and then with a scaffolded design probe that guided them through an end-user auditing exercise. Qualitative analysis of participant think-aloud and LLM interaction data showed that students without basic AI literacy skills struggle to conceptualize and evaluate LLM biases on their own. However, they transition to focused thinking and purposeful interactions when provided with structured guidance. We highlight areas where current university policies may fall short and offer policy and design recommendations to better support students.",10.1145/3706598.3713714,https://doi.org/10.1145/3706598.3713714
Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems,"Ko, Eunhye Grace and Nanayakkara, Shaini and Huff, Earl W",Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems,2025,"As generative AI (GenAI) becomes increasingly ubiquitous, it is crucial to equip users, particularly vulnerable populations like older adults (65+), with the knowledge to understand its benefits and potential risks. Older adults often face greater reservations about adopting emerging technologies and require tailored literacy support. Using a mixed methods approach, this study examines strategies for delivering GenAI literacy to older adults through a chatbot named Litti, evaluating its impact on their Al literacy (knowledge, safety, and ethical use). The quantitative data showed a trend toward improved AI literacy, though the results were not statistically significant. However, the qualitative interviews revealed diverse levels of familiarity with generative AI, along with a strong desire to learn more. Qualitative findings also show that although Litti provided a positive learning experience, it did not significantly enhance participants’ trust or sense of safety regarding GenAI. This exploratory case study highlights the challenges and opportunities in designing AI literacy education for the rapidly growing older adult population.",10.1145/3706599.3720032,https://doi.org/10.1145/3706599.3720032
Automated Generation and Tagging of Knowledge Components from Multiple-Choice Questions,"Moore, Steven and Schmucker, Robin and Mitchell, Tom and Stamper, John",,2024,"Knowledge Components (KCs) linked to assessments enhance the measurement of student learning, enrich analytics, and facilitate adaptivity. However, generating and linking KCs to assessment items requires significant effort and domain-specific knowledge. To streamline this process for higher-education courses, we employed GPT-4 to generate KCs for multiple-choice questions (MCQs) in Chemistry and E-Learning. We analyzed discrepancies between the KCs generated by the Large Language Model (LLM) and those made by humans through evaluation from three domain experts in each subject area. This evaluation aimed to determine whether, in instances of non-matching KCs, evaluators showed a preference for the LLM-generated KCs over their human-created counterparts. We also developed an ontology induction algorithm to cluster questions that assess similar KCs based on their content. Our most effective LLM strategy accurately matched KCs for 56% of Chemistry and 35% of E-Learning MCQs, with even higher success when considering the top five KC suggestions. Human evaluators favored LLM-generated KCs, choosing them over human-assigned ones approximately two-thirds of the time, a preference that was statistically significant across both domains. Our clustering algorithm successfully grouped questions by their underlying KCs without needing explicit labels or contextual information. This research advances the automation of KC generation and classification for assessment items, alleviating the need for student data or predefined KC labels.",10.1145/3657604.3662030,https://doi.org/10.1145/3657604.3662030
Developing a Modular Cloud-Based Kubernetes Powered Framework for Scalable Cybersecurity Education,"Selikow, Ryder and Berol, Nate and Cook, Jack and Weiss, Richard and Mache, Jens",Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2,2024,"We explore building a Kubernetes-powered, cloud-based cybersecurity education platform and framework named 'EDURange Cloud'. It allows instructors to efficiently design and host their own cybersecurity competitions and exercises. The benefits of this system include enhanced security through isolated instances, cost-effective scaling that adjusts resources based on demand, and the agility to deploy or update challenges rapidly. Originally focused primarily on hosting Capture The Flag (CTF) competitions, the scope of EDURange Cloud will include support for cybersecurity demos and other educational exercises. This evolution will allow for a broader range of educational opportunities within the platform.EDURange Cloud was created as a distributed cloud alternative to the existing EDURange software, leveraging the power of Kubernetes to create an efficient and highly modular cybersecurity education framework. In addition to providing better load balancing and achievement tracking, EDURange Cloud extends the existing project by enabling full GUI desktop environments that are also much more easily customizable compared to command-line restricted exercises. The continued development of this platform could provide a new format for a wide range of hands-on exercises, going beyond just cybersecurity.",10.1145/3649409.3691088,https://doi.org/10.1145/3649409.3691088
Exploring How Multiple Levels of GPT-Generated Programming Hints Support or Disappoint Novices,"Xiao, Ruiwei and Hou, Xinying and Stamper, John",Extended Abstracts of the CHI Conference on Human Factors in Computing Systems,2024,"Recent studies have integrated large language models (LLMs) into diverse educational contexts, including providing adaptive programming hints, a type of feedback focuses on helping students move forward during problem-solving. However, most existing LLM-based hint systems are limited to one single hint type. To investigate whether and how different levels of hints can support students’ problem-solving and learning, we conducted a think-aloud study with 12 novices using the LLM Hint Factory, a system providing four levels of hints from general natural language guidance to concrete code assistance, varying in format and granularity. We discovered that high-level natural language hints alone can be helpless or even misleading, especially when addressing next-step or syntax-related help requests. Adding lower-level hints, like code examples with in-line comments, can better support students. The findings open up future work on customizing help responses from content, format, and granularity levels to accurately identify and meet students’ learning needs.",10.1145/3613905.3650937,https://doi.org/10.1145/3613905.3650937
The Effect of ChatGPT: Student Perspective and Performance Achievement,"Hsin, Wen-Jung",J. Comput. Sci. Coll.,2024,"ChatGPT, introduced in November 2022, has rapidly used in various educational systems, prompting the U.S. Department of Education to explore the role of Artificial Intelligence (AI) in teaching and learning. This paper focuses on the impact of AI, particularly ChatGPT, in Computer Science education from the student's perspective and student's performance achievement. Specifically, a study in a Computer Networking course encouraged students to use ChatGPT for learning-related questions, followed by a post-exam survey to evaluate its impact on their learning. Both student feedback and performance achievement indicate that ChatGPT has made a positive impact in their learning in the Computer Networking course.",,
SPLASH-E '24: Proceedings of the 2024 ACM SIGPLAN International Symposium on SPLASH-E,,,2024,"Welcome to the SPLASH-E 2024, the SPLASH community's annual symposium on software engineering and programming languages in education!    Programming courses play a central role in most computer science curricula: the decision of what programming language to use and how to teach impacts many following courses. It is therefore important that the programming language community and the CS education community engage in regular discourse about teaching practice, teaching languages, teaching philosophy and teaching practicalities. We are happy that SPLASH-E continues to host this conversation year after year.",,
Gamifying Business Process Modeling Education: A Longitudinal Study,"Garaccione, Giacomo and Coppola, Riccardo and Ardito, Luca",Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering,2024,"Gamification, the practice consisting of adapting game elements and features in non-recreational contexts to increase user motivation and interest, has become increasingly common in recent years in the different fields of Software Engineering such as development, requirements definition, testing, and education. Among the different educational fields to which gamification has been applied, process modeling is currently not much explored: there are few examples of game-like approaches used for teaching process modeling, and such examples have yet to be applied for the duration of an entire course to assess possible benefits. We thus describe the use of BIPMIN, a platform that implements elements regularly used in gamified tools such as levels, avatars, and leaderboards, in an Information Systems course, where students used the tool to perform practical BPMN modeling exercises over the whole duration of the course to get feedback on their modeling strategies. The students’ opinions have been gathered in the form of an end-of-course questionnaire and have been analyzed following the Straussian grounded theory approach to assess the general sentiment regarding usability, appreciation, and possible issues and improvement areas of the tool. The gathered results are encouraging, as they show that the tool has been well received and that its features that help student understanding the reasons behind their errors have been perceived as helpful for learning and improving BPMN modeling.",10.1145/3661167.3661272,https://doi.org/10.1145/3661167.3661272
A Comparative Analysis of Large Language Models for Code Documentation Generation,"Dvivedi, Shubhang Shekhar and Vijay, Vyshnav and Pujari, Sai Leela Rahul and Lodh, Shoumik and Kumar, Dhruv",Proceedings of the 1st ACM International Conference on AI-Powered Software,2024,"This paper presents a comprehensive comparative analysis of Large Language Models (LLMs) for generation of code documentation. Code documentation is an essential part of the software writing process. The paper evaluates models such as GPT-3.5, GPT-4, Bard, Llama2, and StarChat on various parameters like Accuracy, Completeness, Relevance, Understandability, Readability and Time Taken for different levels of code documentation. Our evaluation employs a checklist-based system to minimize subjectivity, providing a more objective assessment. We find that, barring StarChat, all LLMs consistently outperform the original documentation. Notably, closed-source models GPT-3.5, GPT-4, and Bard exhibit superior performance across various parameters compared to open-source/source-available LLMs, namely Llama 2 and StarChat. Considering the time taken for generation, GPT-4 demonstrated the longest duration by a significant margin, followed by Llama2, Bard, with GPT-3.5 and StarChat having comparable generation times. Additionally, file level documentation had a considerably worse performance across all parameters (except for time taken) as compared to inline and function level documentation.",10.1145/3664646.3664765,https://doi.org/10.1145/3664646.3664765
Research on the Construction of Intelligent Programming Platform Based on AI-generated Content,"Wu, Hao and Fa, Daidong and Wu, Xiaoling and Tan, Weijun and Chang, Xiwen and Gao, Ying and Weng, Jinta",Proceedings of the 15th International Conference on Education Technology and Computers,2024,"Programming education can play an important role in cultivating students' higher-order thinking ability and enhancing the competitiveness of an intelligent society. However, a series of problems still exist: the lack of high-quality programming teachers, the low degree of personalization, and the insufficient learning interaction. This study constructs a novel programming learning model based on AI-generated content technology under the guidance of constructivism learning theory and cognitive load theory. The model divides programming learning into the process of learning program development, personalized context creation, learning chain of thought execution and practice exercises, and real-time interaction throughout the process. On this basis, the platform alleviates the shortage of teachers through intelligent programming assistants, realizes personalized programming learning through learning analytics and customized learning settings, as well as using real-time interaction throughout the whole process to change the status quo of insufficient interaction. Compared with traditional programming learning and practice methods, AIGC-based programming learning platforms can provide a more personalized learning experience and more timely learning interactions, which can effectively enhance learners' interest and learning quality.",10.1145/3629296.3629298,https://doi.org/10.1145/3629296.3629298
"Gender Bias in Self-Perception of AI Knowledge, Impact, and Support among Higher Education Students: An Observational Study",,ACM Trans. Comput. Educ.,2025,,10.1145/3721295,https://doi.org/10.1145/3721295
ICIEAI '24: Proceedings of the 2024 2nd International Conference on Information Education and Artificial Intelligence,,,2024,,,
Mining Topics towards ChatGPT Using a Disentangled Contextualized-neural Topic Model,"Wang, Rui and Liu, Xing and Wang, Yanan and Chang, Shuyu and Yao, Yuanzhi and Huang, Haiping",Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining,2025,"Mining topics relevant to the advanced AI dialogue system, such as ChatGPT, from short-length posts on social media poses several challenges for existing topic-mining approaches. Firstly, Bag-Of-Words approaches, including probabilistic topic models and their embedding-based variants, may struggle to extract interpretable topics due to insufficient word co-occurrence. Secondly, contextualized based approaches, built on the autoencoding framework, often yield entangled topic spaces, resulting in the mixing of irrelevant words into topics. To address these limitations, we propose a novel Dis entangled Contextualized-neural Topic Model (DisCTM) based on textual representation learning. DisCTM leverages a pre-trained transformer language model to incorporate word sequence information and deal with the sparsity in short text. Additionally, it employs a topic disentangling mechanism to decorrelate dimensions of the latent topic space, effectively separating semantically irrelevant words into different topics. Extensive experiments have been conducted on three publicly available text corpora, and the results demonstrate the effectiveness of DisCTM in extracting high-quality topics, as measured by topic coherence and diversity metrics.",10.1145/3701551.3703534,https://doi.org/10.1145/3701551.3703534
ICETM '24: Proceedings of the 2024 7th International Conference on Educational Technology Management,,,2024,,,
Using Large Language Models To Diagnose Math Problem-solving Skills At Scale,"Jin, Hyoungwook and Kim, Yoonsu and Park, Yeon Su and Tilekbay, Bekzat and Son, Jinho and Kim, Juho",,2024,"Personalized feedback, tailored to students' needs and prior knowledge, is essential for fostering mathematical problem-solving skills. However, personalized feedback is often limited to one-to-one tutoring or small classrooms as it requires instructors' in-depth diagnosis of cognitive processes employed in students' answers. We propose a large language model (LLM) pipeline that diagnoses students' problem-solving skills from their answers at scale in elementary school math word problems. Based on prior literature and an interview with a math education expert, we developed PERC, a framework composed of four problem-solving stages that students can follow: Parse, Extract, Retrieve, and Combine. The framework facilitates diagnosis by externalizing students' step-by-step problem-solving processes and allowing our pipeline to analyze each stage individually. Our LLM pipeline diagnoses each stage by (1) generating rubrics and (2) comparing students' answers with the rubrics. We fine-tuned our LLM pipeline with 71 math problem-rubric pairs and 128 problem-answer-grade triplets collected from elementary school students. We evaluated our pipeline's diagnosis accuracy against vanilla GPT-3.5 and vanilla GPT-4 with automatic and expert evaluations. The results showed the potential of our approach in improving the end-to-end diagnosis accuracy of LLMs, and expert evaluation provided specific aspects that should be improved.",10.1145/3657604.3664697,https://doi.org/10.1145/3657604.3664697
Assessing ChatGPT’s Code Generation Capabilities with Short vs Long Context Programming Problems,"Shuvo, Uddip Acharjee and Dip, Sajib Acharjee and Vaskar, Nirvar Roy and Al Islam, A. B. M. Alim","Proceedings of the 11th International Conference on Networking, Systems, and Security",2025,"This study assesses the code generation capabilities of ChatGPT using competitive programming problems from platforms such as LeetCode, HackerRank, and UVa Online Judge. In a novel approach, we contrast ChatGPT’s performance on concise problems from LeetCode against more complex, narrative-driven problems from Codeforces. Our results reveal significant challenges in addressing the intricate narrative structures of Codeforces, with difficulties in problem recognition and strategic planning in extended contexts. While initial code accuracy for LeetCode problems stands at 72%, it drops to 31% for complex Codeforces problems using Python. Additionally, we explore the impact of targeted instructions aimed at enhancing performance, which increased LeetCode accuracy to 73.53% but saw a decrease in Codeforces performance to 29%. Our analysis further extends across multiple programming languages, examining if iterative prompting and specific feedback can enhance code precision and efficiency. We also delve into ChatGPT’s performance on challenging problems and those released post its training period. This research provides insights into the strengths and weaknesses of AI in code generation and lays groundwork for future developments in AI-driven coding tools.",10.1145/3704522.3704535,https://doi.org/10.1145/3704522.3704535
Applying LLM-Powered Virtual Humans to Child Interviews in Child-Centered Design,"Li, Linshi and Cai, Hanlin",Proceedings of the 24th Interaction Design and Children,2025,"In child-centered design, directly engaging children is crucial for deeply understanding their experiences. However, current research often prioritizes adult perspectives, as interviewing children involves unique challenges such as environmental sensitivities and the need for trust-building. AI-powered virtual humans (VHs) offer a promising approach to facilitate engaging and multimodal interactions with children. This study establishes key design guidelines for LLM-powered virtual humans tailored to child interviews, standardizing multimodal elements including color schemes, voice characteristics, facial features, expressions, head movements, and gestures. Using ChatGPT-based prompt engineering, we developed three distinct Human–AI workflows (LLM-Auto, LLM-Interview, and LLM-Analyze) and conducted a user study involving 15 children aged 6 to 12. The results indicated that the LLM-Analyze workflow outperformed the others by eliciting longer responses, achieving higher user experience ratings, and promoting more effective child engagement.",,https://doi.org/10.1145/3713043.3731551
ChatGPT-Proofing a Web Development Course,"Wang, Ye Diana",Proceedings of the 24th Annual Conference on Information Technology Education,2023,"This talk discusses an effective and efficient process that a BSIT program has undergone for transitioning to the new ABET Student Outcomes and some preliminary results, which may benefit other computing programs in preparation for an ABET accreditation visit in 2019 or beyond.",10.1145/3585059.3611424,https://doi.org/10.1145/3585059.3611424
RESPECT 2025: Designing an Accessible Future for Equitable Computer Science,"Blaser, Brianna",SIGCSE Bull.,2025,"The ACM SIGCSE Conference on Research on Equity and Sustained Participation in Engineering, Computing, and Technology (RESPECT) 2025 will be held 14–16 July at the New Jersey Institute of Technology in Newark, NJ, USA. The theme for this year is Designing an Accessible Future for Equitable Computer Science. 2025 marks the fiftieth anniversary of the Individuals with Disabilities in Education Act, landmark legislation in the United States developed to ensure students with disabilities receive a free, appropriate public education. When we began planning the conference, we envisioned an opportunity to reflect on disability inclusion.",10.1145/3732895.3732900,https://doi.org/10.1145/3732895.3732900
CLASSROOM VIGNETTES: Experiencing Efficiency of Algorithms and Implementations,"Walker, Henry M.",ACM Inroads,2024,,10.1145/3649509,https://doi.org/10.1145/3649509
Co-Designing AI literacy for K-12 Education,"Mannila, Linda",Proceedings of the 19th WiPSCE Conference on Primary and Secondary Computing Education Research,2024,"Today’s children are the first generation to grow up with AI as a natural part of their daily lives; to benefit from the opportunities AI brings, but also to face AI-related risks such as privacy invasion, exposure to biased or harmful content, manipulation through personalized advertisements, and potential dependency on AI for decision-making. Consequently, AI literacy is becoming an essential component of modern education. AI, however, is both an unfamiliar topic and a moving target due to fast development. Determining what non-experts need to know about AI is therefore not straightforward, and the answer varies based on the educational context and level. This keynote begins by exploring the challenges of introducing AI literacy in K-12 education, drawing on insights from previous computing-related K-12 curricular reforms. It then presents a four-stage process of co-creating AI lesson plans with students, teachers, and teacher trainers in Finland. Finally, we discuss the lessons learned and future ideas for AI in K-12 education.",10.1145/3677619.3678716,https://doi.org/10.1145/3677619.3678716
Pedagogical Implications of Parser Combinators in Programming Languages Courses: A Comparative Study,"Attarwala, Abbas and Raigoza, Pablo",J. Comput. Sci. Coll.,2024,"This paper recounts the experience of teaching parser combinators in a programming language course using OCaml at both Boston University and California State University, Chico. The main focus is on how parser combinators are introduced when teaching parsing to students who are new to functional programming. Techniques such as boxes and color coding are employed to simplify the understanding of the concepts. Furthermore, teaching course evaluation data are presented to compare course outcomes, contrasting semesters when parser combinators were not used with those when they were incorporated into the teaching. Reflections and feedback from students provide insight into the effectiveness of these teaching methods. Additionally, a two-tailed Welch t-test is conducted on the teaching course evaluation data to assess the impact of using parser combinators.",,
Instructional Approaches Complementing the Use of Generative Artificial Intelligence in Higher Education,"Beaton, Catherine and Weeden, Elissa and Zilora, Stephen",Proceedings of the 25th Annual Conference on Information Technology Education,2024,"The explosion of generative artificial intelligence (AI) has created a level of chaos in higher education as both students and faculty try to determine its utility and how best to incorporate it into the learning process. Students may view generative AI as a means to an end of achieving a perfect grade, skipping important elements of the learning process, or they may view it as an opportunity to expand their creative efforts. Faculty may view it as a tool students use to circumvent plagiarism detection, may feel it potentially minimizes the role of faculty in the classroom, or they may view it as an opportunity to avail of a supplement to existing activities and assignments. Ultimately, faculty are faced with maintaining academic integrity and reinforcing the need and importance of the learning process. This paper explores the combination of three approaches: peer-supported incremental learning, master/apprentice model, and growth mindset as a way for faculty to guide appropriate student use of generative AI, while also maintaining the integrity of the learning process.",10.1145/3686852.3687075,https://doi.org/10.1145/3686852.3687075
ICAIE '24: Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education,,,2024,,,
Three Student-Centered Approaches to Integrate ChatGPT in the Online Classroom: Effective eLearning (Special Series),"Dyer, Thomas and Steele, John and Mandernach, Jean",ELearn,2023,"In response to the advent of AI technologies like ChatGPT in academia, educators should not merely react with plagiarism policies but proactively integrate such tools to enhance learning. By cultivating AI literacy, integrating AI into assignments for interactive learning, and leveraging it for idea generation, we can prepare students for a digitally advanced future, promoting critical thinking and digital literacy while ensuring thoughtful use of technology to support student growth.",10.1145/3609266.3594546,https://doi.org/10.1145/3609266.3594546
Charting the Future of AI in Project-Based Learning: A Co-Design Exploration with Students,"Zheng, Chengbo and Yuan, Kangyu and Guo, Bingcan and Hadi Mogavi, Reza and Peng, Zhenhui and Ma, Shuai and Ma, Xiaojuan",Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems,2024,"Students’ increasing use of Artificial Intelligence (AI) presents new challenges for assessing their mastery of knowledge and skills in project-based learning (PBL). This paper introduces a co-design study to explore the potential of students’ AI usage data as a novel material for PBL assessment. We conducted workshops with 18 college students, encouraging them to speculate an alternative world where they could freely employ AI in PBL while needing to report this process to assess their skills and contributions. Our workshops yielded various scenarios of students’ use of AI in PBL and ways of analyzing such usage grounded by students’ vision of how educational goals may transform. We also found that students with different attitudes toward AI exhibited distinct preferences in how to analyze and understand their use of AI. Based on these findings, we discuss future research opportunities on student-AI interactions and understanding AI-enhanced learning.",10.1145/3613904.3642807,https://doi.org/10.1145/3613904.3642807
Simulating Climate Change Discussion with Large Language Models: Considerations for Science Communication at Scale,,,2024,"Large language models (LLMs) have shown promise in simulating public opinions on social issues. These models can be leveraged in educational simulations that allow students to acquire information and feedback from multiple perspectives. In this research, we investigate the potential of using LLMs (specifically GPT-4) to generate open-ended responses about climate change within a science communication simulation. We prompt GPT-4 to role-play as different personas with various demographics (race/ethnicity, gender, age, income, political affiliations, and ability status) and levels of concern about climate change. We find that GPT-4 is capable of representing multifaceted perspectives around climate change's impact and solutions. However, the model may exaggerate narratives for certain personas based on political affiliations, gender, and concern levels. Such exaggeration may lead to homogeneous narratives that do not fully represent the simulated personas. Our findings highlight the affordances and challenges of applying LLMs to simulating public opinions and enriching educational experiences.",10.1145/3657604.3662033,https://doi.org/10.1145/3657604.3662033
Newly Created Assignments and The First Repository Effect on Inter-Semester Plagiarism,"Adkins, Keith and Joyner, David A.",,2024,"The Internet---for all of its benefits---makes it easy for students to share assignments. This creates a serious problem for academic institutions. Common mitigation tactics include discouraging students from sharing their work and routinely checking for and removing solutions shared online. While these strategies can be successful in many cases, they are not always sufficient. In our experience, it can be a challenge if either students or hosting sites refuse to remove solutions. Pursuing legal options can be both time consuming and costly. One approach taken to combat this is to routinely create new coding assignments, but this can still require a significant time commitment. It is worth exploring if this effort is worthwhile.In this paper, we present an empirical study based on data that we collected over five semesters while addressing plagiarism within our large online computer science graduate program. We compare plagiarism rates between two courses: one integrating new assignments and the other continuing to reuse older assignments.In this study, we explore the benefits derived from introducing new assignments to counter plagiarism, and how long these benefits last. We then explore the trends that publicly shared solutions have on plagiarism rates, and what those trends tell us about the value of implementing new assignments. Lastly, we explore the effects that the process of detection and intervention have on the frequency of misconduct.We observed that the benefits gained by introducing new assignments faded quickly. Additionally, we observed that proactively seeking the removal of publicly shared solutions may be ineffective unless all solutions are removed. Lastly, we observed that early detection and notification to students results in reduced misconduct over time.Our observations underscore the notion that a single solution posted publicly can swiftly erode the advantages gained from creating new assignments to help reduce plagiarism. This raises questions about whether the advantages of introducing new assignments outweigh benefits gained through reusing and refining assignments over time. More mature and well-developed assignments tend to lend themselves to robust, experience-backed rubrics and dynamic autograders which deliver a pedagogical benefit that may outweigh the integrity benefits of frequently developing new assessments.",10.1145/3657604.3662043,https://doi.org/10.1145/3657604.3662043
A Self-Efficacy Theory-Based Study on the Teachers’ Readiness to Teach Artificial Intelligence in Public Schools in Sri Lanka,"Rajapakse, Chathura and Ariyarathna, Wathsala and Selvakan, Shanmugalingam",ACM Trans. Comput. Educ.,2024,"Objectives. This article explores teacher readiness for introducing artificial intelligence (AI) into Sri Lankan schools, drawing on self-efficacy theory. Similar to some other countries, Sri Lanka plans to integrate AI into the school curriculum soon. However, a key question remains: Are teachers prepared to teach this advanced technical subject to schoolchildren? Assessing teacher readiness is crucial, as it is intricately linked to the overall success of this initiative and will inform the development of appropriate policies.Participants. This study surveyed over 1,300 Sri Lankan public school teachers who teach Information and Communication Technology (ICT) using the snowball sampling approach. The respondents represent approximately 20% of the total ICT teacher population in Sri Lanka. Their readiness to teach AI was assessed using a general teacher self-efficacy scale specifically developed based on the well-established Self-Efficacy Theory. While key demographic factors like gender, education level and educational background were also collected, their impact analysis is not included in this article.Study Method. The study was conducted based on the premise that teachers’ readiness to teach AI hinges on their self-efficacy towards teaching AI in the classroom. This premise was substantiated through a review of existing research, and a conceptual model of teachers’ self-efficacy for AI instruction was developed. To assess this model, a nationwide survey targeting school ICT teachers was conducted. The questionnaire used in the survey was based on existing research on evaluating teacher self-efficacy. Data analysis, focusing on testing and validating the conceptual model, primarily employed the PLS-SEM approach.Findings. This study identified several key findings: (1) Teachers generally reported low self-efficacy regarding their ability to teach AI; (2) Teachers’ self-efficacy was most influenced by their emotional and physiological states, as well as their imaginary experiences related to teaching AI; (3) Surprisingly, mastery experiences had a lesser impact on their self-efficacy for teaching AI; and (4) Neither vicarious experiences (observing others teach AI) nor verbal persuasion had a significant impact on teachers’ self-efficacy. Additionally, the study revealed that the teachers’ own level of expertise in AI, along with their social capital, is insufficient to deliver a standard AI curriculum.Conclusions. The analysis of the results found that Sri Lankan teachers currently lack the readiness to teach AI in schools effectively. Potential lapses in certain sources of self-efficacy were also identified. It further revealed the need for a more systemic approach to teacher professional development. Therefore, the study recommends further research exploring the potential of incorporating a socio-technical systems perspective into the government’s teacher training initiatives.",10.1145/3691354,https://doi.org/10.1145/3691354
CURRICULAR SYNCOPATIONS: A Modest Individual/Group Exercise on Current Events in Computing,"Walker, Henry M.",ACM Inroads,2024,,10.1145/3701301,https://doi.org/10.1145/3701301
Do We Need to Write? Researching Perceptions of Disciplinary Writing Importance and Skills in an Advanced Computer Science Course,"von Briesen, Elizabeth",J. Comput. Sci. Coll.,2023,"Our research explores perceptions related to writing in the computer science discipline. It is a common misconception that this skill is not important in the field, and we are motivated to dispel that notion and assist students in gaining experience and confidence in their disciplinary writing skills. To that end, we surveyed undergraduate students at the start and end of term in our Artificial Intelligence course, an advanced computer science elective. Students wrote two blogs-like items, one each for audiences with and without technical knowledge of the field, and also produced technical documentation related to two programming assignments. We found that on average, students agreed that writing in the discipline is important, and that they have some confidence in their writing abilities across audiences. While we did not find a statistically significant difference between perceptions at the start and end of the term, our overall results and open-ended feedback indicate that students find writing in the field to be important, and that there is strong interest in further curricular enhancements in this area.",,
Member Spotlight: Ismaila Sanusi,"Smith, Julie M. and Wallace, Charles and Sanusi, Ismaila",SIGCSE Bull.,2024,"Ismaila Sanusi is a Doctoral Researcher, Faculty of Science, Forestry and Technology, School of Computing, at the University of Eastern Finland.",10.1145/3643836.3643842,https://doi.org/10.1145/3643836.3643842
Can metacognition predict your success in solving problems? An exploratory case study in programming,,Proceedings of the 24th Koli Calling International Conference on Computing Education Research,2024,"Metacognition has been recognized as an essential skill for academic success and for performance in solving problems. During learning or problem-solving, metacognitive skills facilitate a range of cognitive and affective processes, leading collectively to improved performance. This study explores the predictive potential of metacognition in the second introductory programming course. A two-dimensional model has been proposed, consisting of metacognitive awareness and metacognitive behavior. To evaluate the predictive capacity of metacognition empirically, an exploratory case study with 194 participants from two institutions was conducted in the second introductory programming course. A latent approach was employed to examine the associations between metacognition and performance in object-oriented programming. Our findings indicate that both metacognitive dimensions have a positive effect on programming. Likewise, the results of the structural equation modeling show that 27% of variance in programming performance is explained by metacognitive behavior. Following the results, metacognition has the potential to be considered as one of the important predictors of performance in introductory programming.",10.1145/3699538.3699593,https://doi.org/10.1145/3699538.3699593
"Routine, Twisty, and Queer: Pasts and Futures of Games Programming Pedagogy with No and Low Code Tools","Cox, Daniel and Murray, John and Salter, Anastasia",Proceedings of the 20th International Conference on the Foundations of Digital Games,2025,"This paper traces a history of platforms targeting no-code and low-code audiences. It connects historical moments addressing accessibility challenges related to computer programming up through the more recent adoption of generative AI in game engines. Across these moments, this paper identifies communities that claimed authoring platforms, establishing their identity by rejecting other, potentially more efficient or expressive options. We argue these community dynamics have shaped the evolution of current game development platforms. By contextualizing current efforts in pedagogy as part of larger shifts in computer programming and game engine practice, we present a better understanding of the origins of platforms targeting no and low code audiences as rooted in earlier pivots in computer programming and community engagement. These “twisty” and often queer adaptations aimed at smaller communities have led to major changes in how game development has evolved for larger audiences. We close on considerations of the uncertain futures and pedagogical implications of AI-generated code and visual scripting, as game engines increasingly serve as the primary interface between creators and their work.",10.1145/3723498.3723817,https://doi.org/10.1145/3723498.3723817
EduCHI '24: Proceedings of the 6th Annual Symposium on HCI Education,,,2024,,,
Themes in the Declared Use of Generative Artificial Intelligence in Assessment,"Maguire, Joseph and English, Rosanne and Cao, Qi and Seow, Chee Kiat",Proceedings of the 9th Conference on Computing Education Practice,2025,"Generative Artificial Intelligence use by students completing assessments has been an area of concern for academics. Some educators believe such use will undermine all assessment, while others think it has the potential to revolutionise assessments. This has resulted in some institutions and educators adopting various approaches to control the use of Generative Artificial Intelligence However, much of this is taking place without fully appreciating how students are already making use of such tools. In this paper a practice where an existing assessment is presented with the addition that students are not prevented from using Generative Artificial Intelligence but must declare and explain such use. These declarations and explanations are considered to better understand how students approached the assessment and how it could be refined in future.",10.1145/3702212.3702217,https://doi.org/10.1145/3702212.3702217
"Making Software Development More Diverse and Inclusive: Key Themes, Challenges, and Future Directions","Hyrynsalmi, Sonja M. and Baltes, Sebastian and Brown, Chris and Prikladnicki, Rafael and Rodriguez-Perez, Gema and Serebrenik, Alexander and Simmonds, Jocelyn and Trinkenreich, Bianca and Wang, Yi and Liebel, Grischa",ACM Trans. Softw. Eng. Methodol.,2025,"Introduction: Digital products increasingly reshape industries, influencing human behavior and decision-making. However, the software development teams developing these systems often lack diversity, which may lead to designs that overlook the needs, equal treatment or safety of diverse user groups. These risks highlight the need for fostering diversity and inclusion in software development to create safer, more equitable technology.Method: This research is based on insights from an academic meeting in June 2023 involving 23 software engineering researchers and practitioners. We used the collaborative discussion method 1-2-4-ALL as a systematic research approach and identified six themes around the theme “challenges and opportunities to improve Software Developer Diversity and Inclusion (SDDI).” We identified benefits, harms, and future research directions for the four main themes. Then, we discuss the remaining two themes, AI &amp; SDDI and AI &amp; Computer Science education, which have a cross-cutting effect on the other themes.Results: This research explores the key challenges and research opportunities for promoting SDDI, providing a roadmap to guide both researchers and practitioners. We underline that research around SDDI requires a constant focus on maximizing benefits while minimizing harms, especially to vulnerable groups. As a research community, we must strike this balance in a responsible way.",10.1145/3711904,https://doi.org/10.1145/3711904
When Fine-Tuning LLMs Meets Data Privacy: An Empirical Study of Federated Learning in LLM-Based Program Repair,,,2025,,10.1145/3733599,https://doi.org/10.1145/3733599
Computer Science Undergraduate Programs in Australia,"Hamilton, Margaret and Hol, Ana and Richardson, Joan and McGovern, James",ACM Inroads,2024,,10.1145/3644816,https://doi.org/10.1145/3644816
Evaluation of e-learning platforms using artificial intelligence (AI) robots: Are the AI robots consistent,"Chan, Victor K. Y.",Proceedings of the 7th International Conference on Education and Multimedia Technology,2023,"This article aims to explore the consistency between a few popular generative AI robots in the evaluation of e-learning platforms. The three robots adopted in the study were GPT-4, Sage, and Dragonfly, which were requested to award rating scores to the six major dimensions, namely (1) features and capabilities, (2) ease of use and customization, (3) cost, (4) security, (5) customer support, and (6) scalability, of 10 to 20 currently most popular e-learning platforms. For each of the three robots, the minimum, the maximum, the range, and the standard deviation of the rating scores for each of the six dimensions were computed across all the e-learning platforms. The rating score difference for each of the six dimensions between any pair of robots was calculated for each platform. The mean of the absolute value, the minimum, the maximum, the range, and the standard deviation of the differences for each dimensions between each pair of robots were calculated across all platforms. Finally, a Cronbach alpha coefficient of the rating scores was computed for each of the six dimensions between all the three robots across all the e-learning platforms. The computational results were to reveal whether the three robots accorded discrimination in evaluating each dimension across the platforms and whether there was consistency between the three robots in evaluating each dimension across the platforms. Among some auxiliary results, it was found that the evaluation by the three robots was severely inconsistent for the two dimensions cost and security, inconsistent to a lesser extent for the dimension scalability, and consistent for the remaining three dimensions.",10.1145/3625704.3625744,https://doi.org/10.1145/3625704.3625744
What Is Programming?,"Nicolajsen, Sebastian and Brabrand, Claus",Commun. ACM,2025,&nbsp;... and what is programming in the age of artificial intelligence?,10.1145/3713068,https://doi.org/10.1145/3713068
Report from the Summer School on Software Engineering andArtificial Intelligence,"Parra, Esteban and Aponte, Jairo",SIGSOFT Softw. Eng. Notes,2025,"This report summarizes the curriculum and academic outcomes of the Summer School on Software Engineering and Artificial Intelligence (AI) held at the Universidad de Los Andes in Bogot´a, Colombia. The summer school offered an in-depth introduction to the fields of Machine Learning (ML), Artificial Intelligence (AI), and Natural Language Processing (NLP); their role and applications in Software Engineering (SE) and the software development process. The feedback we received from the participants indicates that the program successfully enhanced their knowledge and the skills needed for them to navigate the role of AI in the current landscape of software engineering.The students of the summer school were engaged in the development of a full software system using AI-based tools as part of the development process. We found that the project was successful in providing the students with experience regarding how to incorporate AI-based tools as part of their software development process but not all students showed the same level of proficiency when leveraging AI tools.",10.1145/3709616.3709620,https://doi.org/10.1145/3709616.3709620
ISAIE '24: Proceedings of the 2024 International Symposium on Artificial Intelligence for Education,,,2024,,,
Building Bridges in Computer Networks: A Nifty Assignment for Cross-Language Learning and Code Refactoring,"Akhmetov, Ildar and Schmidt, Logan W.",Proceedings of the 26th Western Canadian Conference on Computing Education,2024,"This nifty assignment is designed to introduce students to fundamental networking concepts, such as the client—server model, sockets, and network protocols, through hands-on experience with cross-language programming and code refactoring. The assignment targets students without a prior background in computer science. By engaging students with starter code in C, Python, and Java, the assignment facilitates the understanding of protocols across different programming languages and emphasizes the importance of code reusability and refactoring. Students are tasked with extending server functionality to include custom commands and are encouraged to use AI tools for code development. This approach aims to prepare students for the evolving pedagogical landscape where AI-assisted development plays a significant role in software engineering practices.",10.1145/3660650.3660665,https://doi.org/10.1145/3660650.3660665
ICETC '24: Proceedings of the 2024 16th International Conference on Education Technology and Computers,,,2024,,,
Integrating ChatGPT in Project Management Education: Benefits and Challenges in the Academic Environment,,Proceedings of the XXIII Brazilian Symposium on Software Quality,2024,"CONTEXT: Teaching project management is complex, and students often do not feel engaged or motivated. Professors can use many initiatives to improve the teaching and learning process. Tools like ChatGPT, when integrated into education, have generated considerable interest due to their potential to enrich students’ learning experiences. GOAL: This paper analyzes the impacts of using ChatGPT as a complementary tool in teaching Project Management in the Software Engineering course, highlighting its benefits and challenges. METHOD: We performed an exploratory study to identify the effects of using ChatGPT in teaching project management, evaluating learning, productivity, teamwork, student perceptions, and future expectations. RESULTS: The results indicate that ChatGPT contributed to improving content comprehension, developing critical skills, accelerating production, improving collaboration and communication, and increasing student engagement. However, challenges related to misuse and dependence on the tool were also identified. CONCLUSION: The integration of ChatGPT in teaching project management has shown promise, promoting a richer and more collaborative learning experience. The insights obtained provide directions for future implementations and research on the use of AI in project management education.",10.1145/3701625.3701684,https://doi.org/10.1145/3701625.3701684
Towards Open Natural Language Feedback Generation for Novice Programmers using Large Language Models,"Koutcheme, Charles",Proceedings of the 22nd Koli Calling International Conference on Computing Education Research,2022,"Automated feedback on programming exercises has traditionally focused on correctness of submitted exercises. The correctness has been inferred, for example, based on a set of unit tests. Recent advances in the area of providing feedback have suggested relying on large language models for building feedback. In this poster, we present an approach for automatically constructed formative feedback, written in natural language, that builds on two streams of research: (1) automatic program repair, and (2) automatically generating descriptions of programs. Building on combining these two streams, we propose a new approach for constructing written formative feedback on programming exercise submissions.",10.1145/3564721.3565955,https://doi.org/10.1145/3564721.3565955
Disruptors in Educational Technology: A Futurespective Case Study of UK Computing Academics,"Crick, Tom and Prickett, Tom and Anderson, Emma and Watson, Ian and Chitare, Neeranjan and Vasiliou, Christina",Proceedings of the 2023 Conference on United Kingdom &amp; Ireland Computing Education Research,2023,"The COVID-19 pandemic forced extensive experimentation in how education has been – and may be – delivered worldwide. The increasing use of and dependency on educational technology for diverse aspects of learning, teaching and assessment has been felt across all disciplines, including computing. Similarly, we have seen an explosion in the use and application of AI tools in education, potentially being as significant a disruptor and a catalyst for change as the pandemic itself. This single UK institutional pilot study critically explores how technology may be employed to support computing students in the face of this emerging ongoing disruption.",10.1145/3610969.3611127,https://doi.org/10.1145/3610969.3611127
Human-AI Collaboration in a Student Discussion Forum,"Laney, Mason and Dewan, Prasun",Companion Proceedings of the 29th International Conference on Intelligent User Interfaces,2024,"The recent public releases of AI tools such as ChatGPT have forced computer science educators to reconsider how they teach. These tools have demonstrated considerable ability to generate code and answer conceptual questions, rendering them incredibly useful for completing CS coursework. While overreliance on AI tools could hinder students’ learning, we believe they have the potential to be a helpful resource for both students and instructors alike. We propose a novel system for instructor-mediated GPT interaction in a class discussion board. By automatically generating draft responses to student forum posts, GPT can help Teaching Assistants (TAs) respond to student questions in a more timely manner, giving students an avenue to receive fast, quality feedback on their solutions without turning to ChatGPT directly. Additionally, since they are involved in the process, instructors can ensure that the information students receive is accurate, and can provide students with incremental hints that encourage them to engage critically with the material, rather than just copying an AI-generated snippet of code. We utilize Piazza—a popular educational forum where TAs help students via text exchanges—as a venue for GPT-assisted TA responses to student questions. These student questions are sent to GPT-4 alongside assignment instructions and a customizable prompt, both of which are stored in editable instructor-only Piazza posts. We demonstrate an initial implementation of this system, and provide examples of student questions that highlight its benefits.",10.1145/3640544.3645215,https://doi.org/10.1145/3640544.3645215
BlueAI: Designing Artificial Intelligence for Environment Science and Climate Change Learning Experiences for K12 Students,"Dogan, Gulustan and Sahin, Elif and Wilkinson, Catherine Fay and Moody, Amelia K. and Song, Yang",J. Comput. Sci. Coll.,2024,"The subject of teaching artificial intelligence (AI) in K-12 settings is rapidly expanding and will significantly affect computer education. While AI is currently a required part of computing curricula at universities, there are unique challenges in incorporating AI into K-12 education. The goal of BlueAI is to prepare K-12 educators to use game-based lessons to teach computational thinking, AI, and computer science skills that will interest children while incorporating important environmental and marine science subjects. We conducted assessments where we taught lessons at two different schools, and presented our findings.",,
ICEDS '24: Proceedings of the 2024 5th International Conference on Education Development and Studies,,,2024,,,
Navigating the IT Skills Gap: Cultivating Job-Ready Graduates,"Herbert, Nicole and Herbert, David and Gray, Tony",Proceedings of the 26th Australasian Computing Education Conference,2024,"The perpetual misalignment between the skill sets of Information Technology (IT) graduates and evolving demands of industry remains an ongoing concern. Reports indicate that IT graduates often lack the practical job-readiness that industry requires, prompting an examination of potential solutions. Work-integrated learning and experiential learning have emerged as promising solutions. In 2023, an innovative approach to job-readiness was pioneered by incorporating these approaches into an on-campus internship tailored for non-cognate international postgraduate IT students. This internship cultivates industry insight, technical proficiency, lifelong learning, and personal branding, all impacting on a graduate's employability. This practitioner paper unveils the design, encountered challenges, and lessons learned with the aim to facilitate the adoption of similar initiatives by other institutions, particularly those in regions with limited access to industry internships for postgraduate IT students.",10.1145/3636243.3636251,https://doi.org/10.1145/3636243.3636251
Analyzing the Contents of AI Benchmarks using Python,"Nicholson, Bill",J. Comput. Sci. Coll.,2024,"Generative AI models are often evaluated through the use of benchmarks. These benchmarks consist of thousands of question/answer challenges across a wide variety of topics and sources. Some benchmarks are derived from Internet sources such as WikiHow.com. Some are composed by researchers and some are generated by AI. In this tutorial, we will make a deep dive into several popular benchmark datasets to learn more about contents and structure. We will create Python projects to analyze reading level, sentence structure, word frequency, and other metadata. The author's Materials can be found here: https://github.com/nicomp42/CCSCMW2024",,
Youth as Advisors in Participatory Design: Situating Teens’ Expertise in Everyday Algorithm Auditing with Teachers and Researchers,,Proceedings of the 24th Interaction Design and Children,2025,"Research on children and youth’s participation in different roles in the design of technologies is one of the core contributions in child-computer interaction studies. Building on this work, we situate youth as advisors to a group of high school computer science teacher- and researcher-designers creating learning activities in the context of emerging technologies. Specifically, we explore algorithm auditing as a potential entry point for youth and adults to critically evaluate generative AI algorithmic systems, with the goal of designing classroom lessons. Through a two-hour session where three teenagers (16–18 years) served as advisors, we (1) examine the types of expertise the teens shared and (2) identify back stage design elements that fostered their agency and voice in this advisory role. Our discussion considers opportunities and challenges in situating youth as advisors, providing recommendations for actions that researchers, facilitators, and teachers can take to make this unusual arrangement feasible and productive.",10.1145/3713043.3728849,https://doi.org/10.1145/3713043.3728849
The Institute of Coding Accreditation Standard: Exploring the Use of a Professional Skills Framework to Address the UK Skills Gap,"Bowers, David S. and Hayes, Alan and Prickett, Tom and Crick, Tom and Streater, Kevin and Sharp, Chris",Proceedings of the 2023 Conference on United Kingdom &amp; Ireland Computing Education Research,2023,"Computing comprises a broad spectrum of subjects and specialisms, with a rich variety of undergraduate courses (including Computer Engineering, Computer Science, Cybersecurity, Information Systems, Information Technology and Software Engineering) offered by universities worldwide. This breadth presents challenges for employers considering employing computing graduates and hence desiring to know both the topics studied and the skills/competencies accumulated by graduates to be able to make appropriate job offers. Small to medium enterprises (SMEs) may not have the resources to provide graduate training programmes, and therefore need ‘work-ready’ graduates. This paper explores and evaluates the feasibility of benchmarking students’ achievements against an industry-led skills framework, Skills for the Information Age (SFIA), to distinguish between what graduates know, have done or are competent in. The approach taken was evolutionary prototyping, informed by expert review. The work generated an accreditation standard that could be implemented or used as a model to enhance an existing accreditation standard. In contrast to academic approaches to competency-based education, or abstract notions of generic skills, this work focused on defining an output standard expressed in terms of employer needs and expectations captured in the SFIA skills framework. We show how a course meeting the proposed standard would satisfy the UK benchmarks for an undergraduate computing degree. By badging SFIA knowledge and competencies, such a course would enhance its learning outcomes, offering clarity for employers and career benefits to students.",10.1145/3610969.3611121,https://doi.org/10.1145/3610969.3611121
Exploration of Multi-round Dialogue Function of International Chinese Education Robot Based on LLM,"Lian, Weichen and Xu, Juan",Proceedings of the 2023 International Conference on Information Education and Artificial Intelligence,2024,"In the process of international Chinese language education, issues such as the shortage of Chinese language teachers and insufficient input and output for Chinese learners are common. To enable learners to effectively engage in input and output activities based on their learning levels, this article attempts to integrate educational robot technology into the field of international Chinese education. Firstly, the article explains the form and function of robots; Then, based on the characteristics of robot technology, large language models, and multi-turn dialogue systems, it proposes the use of educational robots equipped with large language models specific to international Chinese education to assist learners. This research uses LangChain to connect a local Chinese resource library with a large language model, exploring the practical effects of educational robots equipped with this multi-turn dialogue function in international Chinese education, and compares it with the dialogue effects of general large language models. Finally, the article concludes with a summary and future outlook.",10.1145/3660043.3660191,https://doi.org/10.1145/3660043.3660191
Evaluating the Pedagogical Impact of Large Language Models on Programming Skills in Data Science Programs in Higher Education,"Crocetti, Giancarlo and Bak, Seonwoo and Vautor-Laplaceliere, Daena D. and Noory, Naqib A.",J. Comput. Sci. Coll.,2024,"The integration of GenAI (GenAI), such as large language models (LLMs), in education has raised the question of how it will alter the students' training and learning outcomes. To better understand the phenomenon, this empirical study explores whether college students find GenAI tools helpful in advancing their skills, particularly Python programming proficiency.",,
AIFE '24: Proceeding of the 2024 International Conference on Artificial Intelligence and Future Education,,,2024,,,
A Paradigm Shift in Teaching Machine Learning to Sustainable City Management Master Students,"Domingues, Ines and Rasteiro, Deolinda Maria Lopes Dias",Proceedings of the 2024 16th International Conference on Education Technology and Computers,2025,"Teaching machine learning (ML) to students with diverse backgrounds, such as those in the Master in Sustainable City Management program, presents unique challenges. Traditional programming-based approaches can be daunting for students unfamiliar with coding. Initially, software tools like RapidMiner, Weka, and Orange Data Mining were employed to simplify the learning process. However, this method often fell short in conveying deep ML concepts, which often resulted in a superficial understanding. With the advent of user-friendly coding aids like ChatGPT, a transition to Python-based instruction was implemented. Additionally, the incorporation of active learning strategies has further enhanced student engagement and understanding. This shift has shown to improve comprehension and practical skills, evidenced by higher median and maximum grades on the evaluation tool, a final project. A multiple linear regression analysis suggested that performance in “Big Data” significantly predicts grades on the Artificial Intelligence module, and the teaching approach has a marginally significant impact. Subjective analysis by the professor, also proved a better grasp of the concepts by the students.",10.1145/3702163.3702448,https://doi.org/10.1145/3702163.3702448
ICETT '24: Proceedings of the 2024 10th International Conference on Education and Training Technologies,,,2024,,,
Structured Chain-of-Thought Prompting for Code Generation,"Li, Jia and Li, Ge and Li, Yongmin and Jin, Zhi",,2025,,10.1145/3690635,https://doi.org/10.1145/3690635
Leveraging Language Models and Automatic Summarization in Online Programming Learning Environments,"Areces, Carlos and Benotti, Luciana and Bulgarelli, Franco and Echeveste, Emilia and Finzi, Nadia",Commun. ACM,2024,,10.1145/3653323,https://doi.org/10.1145/3653323
ACMSE '24: Proceedings of the 2024 ACM Southeast Conference,,,2024,"We are pleased to welcome you to the 2024 ACM Southeast Conference (ACMSE 2024) sponsored by ACM and the College of Computing and Software Engineering (CCSE) at Kennesaw State University, Marietta, Georgia, USA. ACMSE 2024 continues the ACM Southeast Conference tradition of participation in all areas of computing disciplines. We hope this conference will be an excellent opportunity to share current and future hot research trends amongst researchers from around the world.",,
Studying the effect of AI Code Generators on Supporting Novice Learners in Introductory Programming,"Kazemitabaar, Majeed and Chow, Justin and Ma, Carl Ka To and Ericson, Barbara J. and Weintrop, David and Grossman, Tovi",Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,2023,"AI code generators like OpenAI Codex have the potential to assist novice programmers by generating code from natural language descriptions, however, over-reliance might negatively impact learning and retention. To explore the implications that AI code generators have on introductory programming, we conducted a controlled experiment with 69 novices (ages 10-17). Learners worked on 45 Python code-authoring tasks, for which half of the learners had access to Codex, each followed by a code-modification task. Our results show that using Codex significantly increased code-authoring performance (1.15x increased completion rate and 1.8x higher scores) while not decreasing performance on manual code-modification tasks. Additionally, learners with access to Codex during the training phase performed slightly better on the evaluation post-tests conducted one week later, although this difference did not reach statistical significance. Of interest, learners with higher Scratch pre-test scores performed significantly better on retention post-tests, if they had prior access to Codex.",10.1145/3544548.3580919,https://doi.org/10.1145/3544548.3580919
"How we taught AI concepts, workflows, and ethics to 200 schoolchildren","Kahila, Juho and Arkko, Eetu and Lin, Anssi",Proceedings of the 23rd Koli Calling International Conference on Computing Education Research,2024,"The proliferation of artificial intelligence (AI) based technology, when coupled with a scarcity of learning tools and pedagogical frameworks for AI education, risks increased inequality among children and youth. This poster presents our approach to instructing fundamental AI concepts, societal impacts, and ethics to Finnish schoolchildren through workshops implemented in spring 2023. These workshops engaged 213 students across twelve schools, where children actively designed, implemented, and shared their own AI applications.",10.1145/3631802.3631844,https://doi.org/10.1145/3631802.3631844
Exploring The Potential of Chatbots to Provide Mental Well-being Support for Computer Science Students,"Kumar, Harsh and Yu, Kunzhi and Chung, Andrew and Shi, Jiakai and Williams, Joseph Jay",Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2,2023,"Computer Science students are affected by a number of stressors, such as competition, which make it difficult for them to manage their mental well-being and mood. Students are often reluctant to use existing resources for support because they are difficult to access or perceived as ineffective. Conversational agents have shown potential to provide accessible and effective support to improve well-being. In this work, we explore the problem space to identify contexts in which chatbots could be beneficial for students and investigate how different types of chatbot could supplement existing resources provided by universities.",10.1145/3545947.3576285,https://doi.org/10.1145/3545947.3576285
AI Competencies for non-computer science students in undergraduate education: Towards a competency framework,,Proceedings of the 23rd Koli Calling International Conference on Computing Education Research,2024,"Artificial Intelligence (AI) has been increasingly applied in various societal areas such as medicine, education, and science. For example, through the generation of more accurate medical diagnoses to support patients’ treatment, more content personalization to provide adaptive learning for students and more accurate predictions for future climate changes. Consequently, there is an increasing demand for professionals from different fields with AI competencies. These future professionals need preparation during their undergraduate education to deal with the remarkable AI breakthroughs in their domains and to understand, use, and help with the responsible development of these technologies. However, to address AI to non-computer science students in undergraduate education, it is necessary to thoroughly investigate the core AI competencies essential to these students acquire in order to prepare them effectively. Based on this, the objective of the research is to develop a framework with core AI competencies that can be adopted in future work to inform AI education for this target audience. Therefore, towards the AI competency framework for non-computer science students in undergraduate education, as an initial part of the process, we conducted semi-structured interviews with professionals working in the intersection of AI and other domains. The objective of the interviews was to qualitatively investigate the AI competencies considered suitable for incorporation into the undergraduate education curricula of non-computer science students from these professionals’ points of view. In this work, we present the results of these interviews and the list of core AI competencies for non-computer science students in undergraduate education according to these professionals. In summary, this list encompasses different perspectives, varying from basic AI competencies related to AI definition, history, and capabilities to more complex theoretical knowledge and practical skills regarding data and machine learning. The list also includes responsible AI competencies, covering AI’s social, ethical, and legal aspects.",10.1145/3631802.3631829,https://doi.org/10.1145/3631802.3631829
Exploring Knowledge Tracing in Tutor-Student Dialogues using LLMs,"Scarlatos, Alexander and Baker, Ryan S. and Lan, Andrew",Proceedings of the 15th International Learning Analytics and Knowledge Conference,2025,"Recent advances in large language models (LLMs) have led to the development of artificial intelligence (AI)-powered tutoring chatbots, showing promise in providing broad access to high-quality personalized education. Existing works have studied how to make LLMs follow tutoring principles, but have not studied broader uses of LLMs for supporting tutoring. Up until now, tracing student knowledge and analyzing misconceptions has been difficult and time-consuming to implement for open-ended dialogue tutoring. In this work, we investigate whether LLMs can be supportive of this task: we first use LLM prompting methods to identify the knowledge components/skills involved in each dialogue turn, i.e., a tutor utterance posing a task or a student utterance that responds to it. We also evaluate whether the student responds correctly to the tutor and verify the LLM’s accuracy using human expert annotations. We then apply a range of knowledge tracing (KT) methods on the resulting labeled data to track student knowledge levels over an entire dialogue. We conduct experiments on two tutoring dialogue datasets, and show that a novel yet simple LLM-based method, LLMKT, significantly outperforms existing KT methods in predicting student response correctness in dialogues. We perform extensive qualitative analyses to highlight the challenges in dialogueKT and outline multiple avenues for future work.",10.1145/3706468.3706501,https://doi.org/10.1145/3706468.3706501
Design Heuristics for GenAI Educational Platforms,"Owen, Violet and Parkman, Seren and Lindley, Joseph and Rubegni, Elisa",Proceedings of the 24th Interaction Design and Children,2025,"The proliferation of Generative AI (GenAI) has created a need for effective tools and strategies that teach young people how to use and think about these technologies. This paper presents work in progress extending a successful trial of an AI-focused constructionist learning package, which included a proprietary GenAI tool, lesson plans, and supplementary teaching resources. To explore the scalability of this approach, we interviewed education practitioners. In these discussions they reflected on findings from the initial trial to identify potential challenges and opportunities for broader implementation. From these insights, we propose a set of design heuristics for designing scalable GenAI education platforms.",,https://doi.org/10.1145/3713043.3731499
NotebookGPT – Facilitating and Monitoring Explicit Lightweight Student GPT Help Requests During Programming Exercises,"George, Samuel D and Dewan, Prasun",Companion Proceedings of the 29th International Conference on Intelligent User Interfaces,2024,"The success of GPT with coding tasks has made it important to consider the impact of GPT and similar models on teaching programming. Students’ use of GPT to solve programming problems can hinder their learning. However, they might also get significant benefits such as quality feedback on programming style, explanations of how a given piece of code works, help with debugging code, and the ability to see valuable alternatives to their code solutions. We propose a new design for interacting with GPT called Mediated GPT with the goals of (a) providing students with access to GPT but allowing instructors to programmatically modify responses to prevent hindrances to student learning and combat common GPT response concerns, (b) helping students generate and learn to create effective prompts to GPT, and (c) tracking how students use GPT to get help on programming exercises. We demonstrate a first-pass implementation of this design called NotebookGPT.",10.1145/3640544.3645234,https://doi.org/10.1145/3640544.3645234
With Great Power Comes Great Responsibility: The Role of Software Engineers,"Betz, Stefanie and Penzenstadler, Birgit",ACM Trans. Softw. Eng. Methodol.,2025,"The landscape of Software Engineering evolves rapidly amidst digital transformation and the ascendancy of AI, leading to profound shifts in the role and responsibilities of Software Engineers. This evolution encompasses both immediate changes, such as the adoption of Large Language Model-based approaches to coding, and deeper shifts driven by the profound societal and environmental impacts of technology. Despite the urgency, there persists a lag in adapting to these evolving roles. This roadmap article proposes 10 research challenges to develop a new generation of Software Engineers equipped to navigate the technical and social complexities as well as ethical considerations inherent in their evolving profession. Furthermore, the challenges target role definition, integration of AI, education transformation, standards evolution, and impact assessment to equip future Software Engineers to skillfully and responsibly handle the obstacles within their transforming discipline.",10.1145/3715112,https://doi.org/10.1145/3715112
ARCS Model for Exploring the Enhancement of Learning Motivation and Engagement through AIGC Technology in Computer Graphics Courses,"Wu, Chih-Hung and Liou, Guang-Mei",Proceedings of the 2024 8th International Conference on Education and Multimedia Technology,2024,The purpose of this study is to apply the Keller ARCS Motivation Model theory to the,10.1145/3678726.3678745,https://doi.org/10.1145/3678726.3678745
Exploring the Impact of Intervention Methods on Developers’ Security Behavior in a Manipulated ChatGPT Study,"Serafini, Raphael and Yardim, Asli and Naiakshina, Alena",Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems,2025,"Increased AI use in software development raises concerns about AI-generated code security. We investigated the impact of security prompts, insecure AI suggestion warnings, and the use of password storage guidelines (OWASP, NIST) on the security behavior of software developers when presented with insecure AI assistance. In an online lab setting, we conducted a study with 76 freelance developers who completed a password storage task divided into four conditions. Three conditions included a manipulated ChatGPT-like AI assistant, suggesting an insecure MD5 implementation. We found a high level of trust in AI-generated code, even when insecure suggestions were presented. While security prompts, AI warnings, and guidelines improved security awareness, 32% of those notified about insecure AI recommendations still accepted weak implementation suggestions, mistakenly considering it secure and often expressing confidence in their choice. Based on our results, we discuss security implications and provide recommendations for future research.",10.1145/3706598.3713989,https://doi.org/10.1145/3706598.3713989
The Future of Learning: Large Language Models through the Lens of Students,"Zhang, He and Xie, Jingyi and Wu, Chuhao and Cai, Jie and Kim, Chanmin and Carroll, John M.",Proceedings of the 25th Annual Conference on Information Technology Education,2024,"As Large-Scale Language Models (LLMs) continue to evolve, they demonstrate significant enhancements in performance and an expansion of functionalities, impacting various domains, including education. In this study, we conducted interviews with 14 students to explore their everyday interactions with ChatGPT. Our preliminary findings reveal that students grapple with the dilemma of utilizing ChatGPT’s efficiency for learning and information seeking, while simultaneously experiencing a crisis of trust and ethical concerns regarding the outcomes and broader impacts of ChatGPT. The students perceive ChatGPT as being more “human-like” compared to traditional AI. This dilemma, characterized by mixed emotions, inconsistent behaviors, and an overall positive attitude towards ChatGPT, underscores its potential for beneficial applications in education and learning. However, we argue that despite its human-like qualities, the advanced capabilities of such intelligence might lead to adverse consequences. Therefore, it’s imperative to approach its application cautiously and strive to mitigate potential harms in future developments.",10.1145/3686852.3687069,https://doi.org/10.1145/3686852.3687069
Toward Data Sovereignty: Justice-oriented and Community-based AI Education,"Moudgalya, Sukanya Kannan and Swaminathan, Sai",Proceedings of the 2024 on RESPECT Annual Conference,2024,"Just as food sovereignty is the innate right of all individuals, we argue that data sovereignty should also be treated similarly. We take a critical approach and have leaned on Indigenous scholarship that focuses on rights, control, and power related to data sovereignty. Peoples of the world should have access to, have ownership of, and be decision-making stewards of their own communities' data. We discuss the importance of data sovereignty, implications of a possible 'data apartheid', and ways to possibly achieve data sovereignty in this paper. We present examples of justice-oriented and community-based AI education to serve as starting points.",10.1145/3653666.3656107,https://doi.org/10.1145/3653666.3656107
A comprehensive survey and visual analysis of AIGC education and teaching,"Liu, Xianghong and Li, Haoyu",Proceedings of the 2024 International Conference on Intelligent Education and Computer Technology,2024,"To comprehensively understand the research landscape of Artificial Intelligence-Generated Content applications in educational scenarios. This study employs the CiteSpace visual bibliometric tool to conduct a quantitative analysis of 366 publications related to AIGC in education and teaching. The findings indicate that research on AIGC in education and teaching focuses primarily on three aspects. The connotation and characteristics of AIGC in education, the educational threats posed by AIGC, and the application scenarios of AIGC in education and teaching. It is evident that education researchers need to address the potential crises introduced by AIGC, actively explore strategies and models suited for various educational scenarios based on its functional characteristics and adapt to contemporary needs.Dominant typeAdvantages and characteristicsPersonalized learning supportAIGC can conduct one-on-one open-ended question-and-answer sessions with usersteacher instructional assistanceGenerative AI can assist teachers in lesson preparation and teaching[4]timely feedback evaluationProvide immediate feedback to learners to help them identify and correct mistakes in their learning.Multi-dimensional educational interactionExtending into the cyberspace that facilitates human-machine-human interaction.educational resource sharingEfficiently create personalized and cross-modal educational resources based on different resources[5].",10.1145/3687311.3687340,https://doi.org/10.1145/3687311.3687340
RePurr: Automated Repair of Block-Based Learners’ Programs,"Schweikl, Sebastian and Fraser, Gordon",Proc. ACM Softw. Eng.,2025,"Programming is increasingly taught using dedicated block-based                                                                programming environments such as Scratch. While the use of blocks                                                                instead of text prevents syntax errors, learners can still make                                                                semantic mistakes implying a need for feedback and help. Since                                                                teachers may be overwhelmed by help requests in a classroom, may not                                                                have the required programming education themselves, and may simply                                                                not be available in independent learning scenarios, automated hint                                                                generation is desirable. Automated program repair can provide the                                                                foundation for automated hints, but relies on multiple assumptions:                                                                (1) Program repair usually aims to produce localized patches for                                                                fixing single bugs, but learners may fundamentally misunderstand                                                                programming concepts and tasks or request help for substantially                                                                incomplete programs.                                                                (2) Software tests are required to guide the search and to localize                                                                broken statements, but test suites for block-based programs are                                                                different to those considered in past research on fault localization                                                                and repair: They consist of system tests, where very few tests are                                                                sufficient to fully cover the code. At the same time, these tests                                                                have vastly longer execution times caused by the use of animations                                                                and interactions on Scratch programs, thus inhibiting the                                                                applicability of metaheuristic search.                                                                (3) The plastic surgery hypothesis assumes that the code necessary                                                                for repairs already exists in the codebase. Block-based programs                                                                tend to be small and may lack this necessary redundancy.                                                                In order to study whether automated program repair of block-based                                                                programs is nevertheless feasible, in this paper we introduce, to                                                                the best of our knowledge, the first automated program repair                                                                approach for Scratch programs based on evolutionary search.                                                                Our RePurr prototype includes novel refinements of fault                                                                localization to improve the lack of guidance of the test suites,                                                                recovers the plastic surgery hypothesis by exploiting that a                                                                learning scenario provides model and student solutions as                                                                alternatives, and uses parallelization and accelerated executions to                                                                reduce the costs of fitness evaluations.                                                                Empirical evaluation of RePurr on a set of real learners' programs                                                                confirms the anticipated challenges, but also demonstrates that the                                                                repair can nonetheless effectively improve and fix learners'                                                                programs, thus enabling automated generation of hints and feedback                                                                for learners.",10.1145/3715786,https://doi.org/10.1145/3715786
May We Consult ChatGPT in Our Human-Computer Interaction Written Exam? An Experience Report After a Professor Answered Yes,,Proceedings of the XXII Brazilian Symposium on Human Factors in Computing Systems,2024,"Using ChatGPT in education presents challenges for evaluating students. It requires distinguishing between original ideas and those generated by the model, assessing critical thinking skills, and gauging subject mastery accurately, which can impact fair assessment practices. The Human-Computer Interaction course described in this experience report has enabled consultation with textbooks, slides and other materials for over five years. This experience report describes reflections regarding using ChatGPT as a source of consultation in a written HCI exam in 2023. The paper describes experiences with analysis of the types of questions ChatGPT was able to solve immediately without mediation and the types of questions that could benefit from ChatGPT’s assistance without compromising the assessment of higher-level learning outcomes that professors want to analyse in teaching HCI. The paper uses Bloom’s taxonomy to analyse different questions and abilities to be evaluated and how they can be solved solely by using ChatGPT. The paper discusses questions that need mediation, previous lived experience in class and understanding of the knowledge acquired in class that cannot be answered directly by copying and pasting questions into ChatGPT. The discussions can raise reflections on the learning outcomes that can be assessed in HCI written exams and how professors should reflect upon their experiences and expectations for exams in the age of growing generative artificial intelligence resources.",10.1145/3638067.3638100,https://doi.org/10.1145/3638067.3638100
Investigating Youth AI Auditing,"Solyst, Jaemarie and Peng, Cindy and Deng, Wesley Hanwen and Pratapa, Praneetha and Ogan, Amy and Hammer, Jessica and Hong, Jason and Eslami, Motahhare","Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency",2025,"Youth are active users and stakeholders of artificial intelligence (AI), yet they are often not included in responsible AI (RAI) practices. Emerging efforts in RAI largely focus on adult populations, missing an opportunity to get unique perspectives of youth. This study explores the potential of youth (teens under the age of 18) to engage meaningfully in RAI, specifically through AI auditing. In a workshop study with 17 teens, we investigated how youth can actively identify problematic behaviors in youth-relevant ubiquitous AI (text-to-image generative AI, autocompletion in search bar, image search) and the impacts of supporting AI auditing with critical AI literacy materials with guided discussion about AI ethics and an auditing tool. We found that youth can contribute quality insights, shaped by their specialized knowledge (e.g., hobbies and passions), lived experiences (e.g., social identities), and age-related knowledge (e.g., understanding of fast-moving trends). We discuss how empowering youth in AI auditing can result in more responsible AI, support their learning through doing, and lead to implications for including youth in various participatory RAI processes.",10.1145/3715275.3732142,https://doi.org/10.1145/3715275.3732142
Alan's Speakeasy - An Ecosystem for the Evaluation of Conversational Agents,,Companion Proceedings of the ACM on Web Conference 2025,2025,"Conversational artificially intelligent agents have received increasing attention in recent years. For many use cases, evaluating such agents requires a human-in-the-loop approach. In this demo paper, we present Alan's Speakeasy, a Web-based ecosystem for the evaluation of conversational agents.",10.1145/3701716.3715165,https://doi.org/10.1145/3701716.3715165
"Guiding Students in Using LLMs in Supported Learning Environments: Effects on Interaction Dynamics, Learner Performance, Confidence, and Trust","Kumar, Harsh and Musabirov, Ilya and Reza, Mohi and Shi, Jiakai and Wang, Xinyuan and Williams, Joseph Jay and Kuzminykh, Anastasia and Liut, Michael",Proc. ACM Hum.-Comput. Interact.,2024,"Personalized chatbot-based teaching assistants can be crucial in addressing increasing classroom sizes, especially where direct teacher presence is limited. Large language models (LLMs) offer a promising avenue, with increasing research exploring their educational utility. However, the challenge lies not only in establishing the efficacy of LLMs but also in discerning the nuances of interaction between learners and these models, which impact learners' engagement and results. We conducted a formative study in an undergraduate computer science classroom (N=145) and a controlled experiment on Prolific (N=356) to explore the impact of four pedagogically informed guidance strategies on the learners' performance, confidence and trust in LLMs. Direct LLM answers marginally improved performance, while refining student solutions fostered trust. Structured guidance reduced random queries as well as instances of students copy-pasting assignment questions to the LLM. Our work highlights the role that teachers can play in shaping LLM-supported learning environments.",10.1145/3687038,https://doi.org/10.1145/3687038
Exploring the Impact of ChatGPT in Engineering Education: A Mixed Methods Study at the Military Technological College in Muscat.,"Al Badi, Amal and Al handhali, Khulood and Alsalmi, Sumaiya and Al-Zadjali, Ozear and AlYarobi, Shihab and Alshibli, Abdullah",Proceedings of the 2024 8th International Conference on Digital Technology in Education (ICDTE),2024,"This study aimed to explore the perspectives of students on the impact of ChatGPT on their engineering education. It also aimed to investigate the need for guidelines for the use of ChatGPT by students in higher education institutions. The research followed mixed-methods research design. A total of 1310 students affiliated with the Military Technological College in Muscat, Oman, responded to the questionnaire. Additionally, 6 students participated in a focus group discussion to get an in-depth understanding of their views on the use of ChatGPT in engineering education. The study's findings showed that Students’ perspectives on the impact of ChatGPT on their overall learning experience was high. Also, the findings showed that explicit guidelines should be established to ensure the responsible and ethical use of AI technologies in educational contexts. Finally, the study has established some guidelines for AI use in higher education institutions.",10.1145/3696230.3696252,https://doi.org/10.1145/3696230.3696252
Automated Generation of Challenge Questions for Student Code Evaluation Using Abstract Syntax Tree Embeddings and RAG: An Exploratory Study,"Boubaker, Anis and Fang, Ying",Proceedings of the 2024 7th International Conference on Educational Technology Management,2025,"This paper presents an exploratory study on detecting learning gaps in student-submitted code by generating automated challenge questions. The proposed method compares the abstract syntax trees (ASTs) of student code with those of class-taught examples using embeddings and retrieval-augmented generation (RAG). The approach identifies the most structurally deviant sections of student code and generates challenge questions targeting advanced, un-taught coding techniques, such as function pointers and variadic functions. The evaluation, conducted on real-world C programming assignments, demonstrates the effectiveness of the selection process and the quality of generated questions. This work highlights the potential for using structural analysis and automated challenge questions generation to improve student assessment in coding education.",10.1145/3711403.3711450,https://doi.org/10.1145/3711403.3711450
Examining the Behavior of LLM Architectures within the Framework of Standardized National Exams in Brazil,,"Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society",2025,,,
Beyond the Textbook: A Study of ChatGPT Patterns of Use Perceptions and Experiences Among Students in Higher Education,"Mohd A'seri, Muhamad Safwan and Mahmud, Malissa Maria and Yaacob, Yazilimiwati and Ahmad, Rozaini and Nagasundram, Usha and Mustamam, Nur Izzati",Proceedings of the 2024 16th International Conference on Education Technology and Computers,2025,"This study investigates the utilization pattern, perception, and experience of Higher Education Institutes (HEIs) students towards the ChatGPT application in an academic context. It employs a quantitative approach utilizing a questionnaire as the research instrument. The study sample was selected using a simple random sampling method from Sunway University and Sunway College in Kuala Lumpur, Malaysia. The survey participants, enrolled in General Studies Subjects (MPU) during their short semester between September and December 2023, were selected using a simple random sampling method. Out of 150 students who received the survey via Google Forms, 119 provided complete responses suitable for analysis. The research primarily focused on calculating mean scores to assess three key dimensions: its use patterns of ChatGPT, perceptions and experiences among students towards its adoption in educational contexts. A descriptive analysis was conducted to determine student frequency and percentage values for ChatGPT usage. At the same time, mean scores were utilized to evaluate higher education institutes (HEIs) students' perceptions and experiences with the application in an academic context. This descriptive analysis revealed a spectrum of responses that ranged from low to very high levels across these dimensions. The findings of this study offer extensive insight into the current incorporation and perception of ChatGPT within Higher Education Institutions (HEIs), showcasing the diverse range of engagement and acceptance levels among students.",10.1145/3702163.3702179,https://doi.org/10.1145/3702163.3702179
IT Higher Education Teachers and Trust in AI-Enabled Ed-Tech: Implications for Adoption of AI in Higher Education,"Aladi, Clement Chimezie",Proceedings of the 2024 Computers and People Research Conference,2024,"The integration of Artificial Intelligence (AI) in higher education encounters a myriad of inhibiting factors, notably the conspicuous absence of transparency, reliability issues, and ethical concerns. This problem has substantially impeded the assimilation of generative AI-enabled Educational Technology (Ed-Tech) within the higher education domain, unlike other fields such as finance, health, and management. The prevailing sentiment among higher education practitioners remains wavering, with differing opinions on whether to permit AI comprehensively, impose complete restrictions, or allow minimal integration into academic courses. This pilot study endeavors to elucidate the nuanced determinants influencing cognitive trust of Information Technology (IT) Higher Education instructors in AI-enabled educational Technology. The implications of this trust, or lack thereof, on the broader adoption of AI in higher education, constitute a focal point of investigation in this scholarly investigation.",10.1145/3632634.3655852,https://doi.org/10.1145/3632634.3655852
PANEL: WORKFORCE IMPLICATIONS OF LEARNED PASSIVITY,"Van Slyke, Craig and Mansour, Joseph and Joseph, Damien and Sumner, Mary and Zaza, Sam",Proceedings of the 2025 Computers and People Research Conference,2025,"Employers face a daunting challenge: They need self-motivated, adaptable Information Systems (IS) workers who are willing to take on challenges, but in an atmosphere where apathy and timidity seem to be gaining ground. From employers lamenting their need for employees with greater critical thinking skills, to students’ unwillingness to troubleshoot even the smallest problem in the classroom, the issue may be attributable to what we call “learned passivity”, a term we propose to describe the belief that waiting, rather than taking action, will lead to favorable outcomes. This could have roots in the classroom, with grave implications for career failure in the workplace. Faculty have long complained that students are not willing to help themselves [3]. This phenomenon is often attributed to “learned helplessness”. But learned helplessness, which occurs when an individual faces repeated failures believed to be beyond their control, does not accurately capture the current phenomenon, nor does it have the same causes. Rather, with learned passivity, there is greater (perceived) utility in doing nothing. Because IS is characterized by constant adaptation and complex problem solving, learned passivity is a particularly pernicious problem for this field, and IS educators run the risk of enabling a pipeline of passivity from the classroom to the workplace. The emerging concept of learned passivity requires further consideration because it gives voice and adds context to a number of concerns that educators and employers have had regarding perceived shortcomings among graduates and new hires. In this panel, we will explore what leads to learned passivity, its negative consequences for career readiness and progression, and how IS faculty can mitigate its effects.",10.1145/3716489.3732273,https://doi.org/10.1145/3716489.3732273
Detecting Automatic Software Plagiarism via Token Sequence Normalization,,Proceedings of the IEEE/ACM 46th International Conference on Software Engineering,2024,"While software plagiarism detectors have been used for decades, the assumption that evading detection requires programming proficiency is challenged by the emergence of automated plagiarism generators. These generators enable effortless obfuscation attacks, exploiting vulnerabilities in existing detectors by inserting statements to disrupt the matching of related programs. Thus, we present a novel, language-independent defense mechanism that leverages program dependence graphs, rendering such attacks infeasible. We evaluate our approach with multiple real-world datasets and show that it defeats plagiarism generators by offering resilience against automated obfuscation while maintaining a low rate of false positives.",10.1145/3597503.3639192,https://doi.org/10.1145/3597503.3639192
Authoring Worked Examples for JAVA Programming with Human AI Collaboration,"Hassany, Mohammad and Ke, Jiaze and Brusilovsky, Peter and Lekshmi Narayanan, Arun Balajiee and Akhuseyinoglu, Kamil",Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing,2024,"Worked examples are among the most popular types of learning content in programming classes. However, instructors rarely have time to provide line-by-line explanations for a large number of examples typically used in a programming class. In this paper, we explore and assess a human-AI collaboration approach to authoring worked examples for Java programming. We introduce an authoring system for creating Java worked examples that generates a starting version of code explanations and presents it to the instructor to edit if necessary. We also present a study that assesses the quality of explanations created with this approach.",10.1145/3605098.3636160,https://doi.org/10.1145/3605098.3636160
Evolving Cybersecurity Education: An Analysis of the GenCyber Teacher Academy's Progression from 2022 to 2023 and Beyond,"Radday, Elizabeth A. and Mekni, Mehdi and Page, Liberty and Sula, Ardiana and Brown, Laura",J. Comput. Sci. Coll.,2024,"The GenCyber Teacher Academy (GTA) stands as a pioneering professional development initiative, empowering Connecticut's high school educators in diverse STEM fields to explore and integrate cybersecurity concepts into their teaching. The inaugural 2022 edition facilitated inquiry-based learning and collaborative discourse on GenCyber Cybersecurity Concepts. However, program evaluation uncovered areas for curriculum enhancement. This paper delineates the evaluation process, curriculum revisions, and their implementation outcomes. Findings demonstrate that the revised 2023 GTA fostered improved teacher engagement with modules, enhancing their ability to integrate cybersecurity principles while prioritizing online safety. Notably, the revised GTA fortified the sustainable GenCyber Teacher Academy Teaching and Learning Community, bolstering a network of educators and practitioners destined to collectively mold Connecticut's cybersecurity landscape.",,
Innovative Career-Focused Curriculum for Computer Science and Information Technology,"Huang, Ching-yu",J. Comput. Sci. Coll.,2024,"Undergraduate students from disadvantaged backgrounds often lack guidance when it comes to selecting college majors and exploring career paths. As a result, they may be unprepared for internships or job searches during their freshman or sophomore years. Many choose majors like computer science or information technology because of the promising job market, but they may not fully understand the types of jobs, roles, and skills required in these fields.",,
Choosing Our Computing Birthplace: VSCode vs Colab as GenEd IDEs,"Miller, Elena and Shaw, Katy and Dodds, Zachary",J. Comput. Sci. Coll.,2023,"First impressions are important. The initial environment in which our computing students express themselves helps shape their foundational understanding of what computing is, what it's for, and who participates. This work distills experiences and insights from offering Comp1 and Comp21 with two different IDEs: Microsoft's VSCode and Google's Colab. We identify and describe several axes along which we compare our students' experience of these two. This effort has changed the way we offer Comp1, a degree requirement of all students at our institution, and Comp2, an optional follow-up course, required by some computationally-themed programs.",,
Improving Student Motivation through an Alternative Grading System,"Mattfeld, Ryan Stephen",J. Comput. Sci. Coll.,2023,"The traditional grading system has significant shortcomings in effectiveness and reliability. In addition, the traditional grading system encourages extrinsic motivation in students rather than intrinsic motivation. This reliance on external goals and factors for motivation tends to increase students' anxiety and inclination to cheat. This problem is a growing concern as students gain access to new tools which make cheating quicker and easier. Several ideas for alternatives to the traditional grading system include contract grading, mastery grading, specifications grading, and ungrading. In this study, an alternative grading system combining many of these concepts was applied to three sections of an upper level computer science elective course. To evaluate the effectiveness of this system, questions from the Motivated Strategies for Learning Questionnaire (MSLQ) were asked in a pre- and post- term survey. Statistically significant improvements were found in Self-Efficacy and Learning Performance, Task Value, and Control of Learning Beliefs. These findings support the idea that alternative grading systems may be an effective course adjustment to improve student motivation and learning in an upper level computer science course.",,
ICETC '23: Proceedings of the 15th International Conference on Education Technology and Computers,,,2023,,,
The Linguistics of Programming,"Gordon, Colin S.","Proceedings of the 2024 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software",2024,"Research in programming languages and software engineering are broadly concerned with the study of aspects of computer programs: their syntactic structure, the relationship between form and meaning (semantics), empirical properties of how they are constructed and deployed, and more. We could equally well apply this description to the range of ways in which linguistics studies the form, meaning, and use of natural language. We argue that despite some notable examples of PL and SE research drawing on ideas from natural language processing, there are still a wealth of concepts, techniques, and conceptual framings originating in linguistics which would be of use to PL and SE research. Moreover we show that beyond mere parallels, there are cases where linguistics research has complementary methodologies, may help explain or predict study outcomes, or offer new perspectives on established research areas in PL and SE. Broadly, we argue that researchers across PL and SE are investigating close cousins of problems actively studied for years by linguists, and familiarity with linguistics research seems likely to bear fruit for many PL and SE researchers.",10.1145/3689492.3689806,https://doi.org/10.1145/3689492.3689806
Lawyer Up! Joint Introductory Computer Science and Law Courses,"Beck, Shannon and Goines, Timothy and Biller, Jeffrey",J. Comput. Sci. Coll.,2024,"Courses typically focus on a single discipline, limiting exposure to cross-disciplinary topics. To address this, we designed an interdisciplinary two-course set within our undergraduate Honors program: an introductory computing course and an introductory law course. This initiative breaks down barriers between computing and law, enabling students to integrate both disciplines and foster a comprehensive understanding of complex issues. The Computer Science (CS) course covers introductory programming and principles, while the Law course surveys American Law and basic legal reasoning. Initially, the topics are independent but they strongly converge in the term's second half. Students explore the intersection of CS and Law through discussions, debates, guest speakers, and a cross-disciplinary project. Conducted for two years at the United States Air Force Academy (USAFA), this report shares our curriculum and experiences, aiming to inspire wider adoption of our inter-departmental model.",,
On Transdisciplinary Research through Data Science and Engineering Education,"Kim, Junwhan",Proceedings of the 2024 16th International Conference on Education Technology and Computers,2025,"This paper explores the role of Data Science and Engineering (DSE) education in fostering transdisciplinary research and innovation. By combining data science’s analytical capabilities with the infrastructure-building focus of data engineering, DSE offers powerful tools for addressing complex challenges across diverse fields such as finance, agriculture, law, and engineering. However, researchers outside traditional DSE domains often lack the expertise to manage and leverage data effectively. To bridge this gap, we have developed four courses—data science, data engineering, advanced DSE, and vision AI—at the University of the District of Columbia, designed to equip students from various disciplines with the necessary skills to apply DSE techniques in their respective fields. This paper highlights the research conducted by students in these courses, emphasizing the importance of transdisciplinary collaboration in advancing scientific discovery and technological innovation.",10.1145/3702163.3702465,https://doi.org/10.1145/3702163.3702465
AI for Education (AI4EDU): Advancing Personalized Education with LLM and Adaptive Learning,"Wen, Qingsong and Liang, Jing and Sierra, Carles and Luckin, Rose and Tong, Richard and Liu, Zitao and Cui, Peng and Tang, Jiliang",Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,2024,"Recent advanced AI technologies, especially large language models (LLMs) like GPTs, have significantly advanced the field of data mining and led to the development of various LLM-based applications. AI for education (AI4EDU) is a vibrant multi-disciplinary field of data mining, machine learning, and education, with increasing importance and extraordinary potential. In this field, LLM and adaptive learning-based models can be utilized as interfaces in human-in-the-loop education systems, where the model serves as a mediator among the teacher, students, and machine capabilities, including its own. This perspective has several benefits, including the ability to personalize interactions, allow unprecedented flexibility and adaptivity for human-AI collaboration and improve the user experience. However, several challenges still exist, including the need for more robust and efficient algorithms, designing effective user interfaces, and ensuring ethical considerations are addressed. This workshop aims to bring together researchers and practitioners from academia and industry to explore cutting-edge AI technologies for personalized education, especially the potential of LLMs and adaptive learning technologies.",10.1145/3637528.3671498,https://doi.org/10.1145/3637528.3671498
The October 2024 Issue,"Uhlig, Steve",SIGCOMM Comput. Commun. Rev.,2025,"This October 2024 issue contains three technical papers, one of which is of a rather educational nature and can be considered both an educational contribution and a technical paper.",10.1145/3717512.3717513,https://doi.org/10.1145/3717512.3717513
Building babyGPTs: Youth engaging in data practices and ethical considerations through the construction of generative language models,"Morales-Navarro, Luis and Noh, Daniel J. and Kafai, Yasmin",Proceedings of the 24th Interaction Design and Children,2025,"As generative language models (GLMs) have gained popularity, youth are increasingly using them in their everyday lives. As such, most research has centered on supporting youth as users of GLM-powered systems. However, we know little of how to engage youth in the design of these models. Building on the rich legacy of child-computer interaction research that positions youth as designers of computing systems, we explore how to support young people in designing GLMs. Through a case study of three teenagers (ages 14–15) building a babyGPT screenplay generator, we illustrate how the team developed a model while engaging in artificial intelligence/machine learning-relevant data practices and addressing ethical issues. This paper contributes a case study that demonstrates the feasibility of engaging youth in building GLMs.",,https://doi.org/10.1145/3713043.3731525
Stage Wizard: Enhancing Tangible Storytelling with Multimodal LLMs,"Han, Kuntong and Tang, Keyang and Wang, Meng","Proceedings of the Nineteenth International Conference on Tangible, Embedded, and Embodied Interaction",2025,"This paper introduces a pipeline that integrates multimodal large language models (LLMs) for tangible storytelling, featuring flexible materials generation, intuitive hands-on performance, and easy finalization. The design system enables teachers, parents, and children to create stage elements through natural language interactions and generate paper-cut style images. These elements can be easily fabricated using standard printing paper and assembled into a reconfigurable cardstock stage, allowing children to craft various plotlines through manipulation. The storytelling process can be directly recorded as a short film or transformed into an elaborate storybook using styled image filters and refining LLMs. By introducing the role of the stage in both the design and manipulation processes, this pipeline offers intuitive guidance and affordance for free but organized creation. The flexibility introduced by LLMs supports educators in diverse course design and children in self-expression. Without the requirement for specific hardware, the system also has the potential to be applied more broadly in less developed areas.",10.1145/3689050.3704429,https://doi.org/10.1145/3689050.3704429
ICFET '24: Proceedings of the 2024 10th International Conference on Frontiers of Educational Technologies,,,2024,,,
Boosting Large Language Models with Socratic Method for Conversational Mathematics Teaching,"Ding, Yuyang and Hu, Hanglei and Zhou, Jie and Chen, Qin and Jiang, Bo and He, Liang",Proceedings of the 33rd ACM International Conference on Information and Knowledge Management,2024,"With the introduction of large language models (LLMs), automatic math reasoning has seen tremendous success. However, current methods primarily focus on providing solutions or using techniques like Chain-of-Thought to enhance problem-solving accuracy. In this paper, we focus on improving the capability of mathematics teaching via a Socratic teaching-based LLM (SocraticLLM), which guides learners toward profound thinking with clarity and self-discovery via conversation. We collect and release a high-quality mathematical teaching dataset, named SocraticMATH, which provides Socratic-style conversations of problems with extra knowledge. Also, we propose a knowledge-enhanced LLM as a strong baseline to generate reliable responses with review, guidance/heuristic, rectification, and summarization. Experimental results show the great advantages of SocraticLLM by comparing it with several strong generative models. The codes and datasets are available on https://github.com/ECNU-ICALK/SocraticMath.",10.1145/3627673.3679881,https://doi.org/10.1145/3627673.3679881
The European AI Tango: Balancing Regulation Innovation and Competitiveness,,Proceedings of the 2023 Conference on Human Centered Artificial Intelligence: Education and Practice,2023,"In the past few years, the EU has shown a growing commitment to address the rapid transformations brought about by the latest Artificial Intelligence (AI) developments by increasing efforts in AI regulation. Nevertheless, despite the growing body of technical knowledge and progress, the governance of AI-intensive technologies remains dynamic and challenging. A mounting chorus of experts have been sharing their reservations regarding an overemphasis on regulation in Europe. Among their core arguments is the concern that such an approach might hinder innovation within the AI arena. This concern resonates particularly strongly compared to the United States and Asia, where AI-driven innovation appears to be surging ahead, potentially leaving Europe behind. The current contribution is a position paper emphasising the need for balanced AI governance to foster ethical innovation, reliability, and competitiveness of European technology. This paper only explores recent AI regulations and upcoming European laws relevant to the topic to ensure conciseness while underscoring Europe’s role in the global AI landscape. The authors analyse European governance approaches and their impact, especially on SMEs and startups, offering a comparative view of global regulatory efforts. We address the complexities of creating a comprehensive, human-centred AI master’s programme for higher education and the importance of ethical AI education. Finally, we discuss how Europe can seize opportunities to promote ethical and reliable AI progress through education, fostering a balanced approach to regulation and enhancing young professionals’ understanding of ethical and legal aspects.",10.1145/3633083.3633161,https://doi.org/10.1145/3633083.3633161
Unfolding Programming: How to Use AI Tools in Introductory Computing Courses,"Servin, Christian and Karichev, Nadia V. and Pagel, Myshie",Proceedings of the 25th Annual Conference on Information Technology Education,2024,"Artificial Intelligence (AI) generative tools, commonly referred to as AI-based tools, have become integral in various computing domains, including education. The widespread adoption of these tools has raised concerns among educators, spanning from issues related to plagiarism and comprehension gaps to potential threats to student identity. Consequently, educators are grappling with how to adapt their courses and incorporate AI technologies into their curriculum and pedagogical approaches. In addition to navigating challenges associated with AI regulations, educators face the compounded difficulty of addressing post-pandemic issues, such as students displaying diminished effort and professionalism in the classroom. The convergence of these two challenges creates a complex scenario that intertwines technical and professional considerations. Within the Computer Science Fundamentals course, commonly referred to as CS 1, the learning process revolves around comprehending programming through a sequential understanding of steps, as each concept builds upon the preceding one. This investigation centers on the CS 1 curriculum within an American two-year program, commonly known as a community college. The objective is to address a problem by leveraging an AI tool within team settings. The study assesses both problem-solving capabilities and the effectiveness of teamwork, providing recommendations to guide students in the proper utilization of AI tools. The emphasis is on fostering contextual relevance and collaborative work within the generative learning process.",10.1145/3686852.3687073,https://doi.org/10.1145/3686852.3687073
Addressing Academic Misconduct in the Age of ChatGPT: Strategies and Solutions,"Wang, Jin and Cornely, Pierre-Richard",Proceedings of the 2023 7th International Conference on Education and E-Learning,2024,"ChatGPT, developed by OpenAI, has emerged as a pivotal advancement in the realm of artificial intelligence, boasting capabilities that extend from answering factual queries to engaging in nuanced dialogue. While ChatGPT offers transformative potential across various sectors, its integration into the educational domain presents unique challenges—most notably, an escalation in the prevalence and complexity of academic misconduct. Students have begun to exploit this technology to complete assignments, fabricate essays, and even cheat during examinations, thereby undermining the core principles of educational integrity. This paper aims to offer a comprehensive examination of the academic implications of ChatGPT, focusing on the ethical dimensions and the evolving forms of misconduct enabled by this technology. Through a thorough review of existing literature, case studies, and expert opinions, we propose a multifaceted strategy for institutions to effectively combat this emergent form of academic dishonesty, aiming to strike a balance between technological advancement and academic integrity.",10.1145/3637989.3638014,https://doi.org/10.1145/3637989.3638014
ICDTE '24: Proceedings of the 2024 8th International Conference on Digital Technology in Education (ICDTE),,,2024,,,
On the Applicability of Language Models to Block-Based Programs,"Griebl, Elisabeth and Fein, Benedikt and Oberm\",Proceedings of the 45th International Conference on Software Engineering,2023,"Block-based programming languages like SCRATCH are increasingly popular for programming education and end-user programming. Recent program analyses build on the insight that source code can be modelled using techniques from natural language processing. Many of the regularities of source code that support this approach are due to the syntactic overhead imposed by textual programming languages. This syntactic overhead, however, is precisely what block-based languages remove in order to simplify programming. Consequently, it is unclear how well this modelling approach performs on block-based programming languages. In this paper, we investigate the applicability of language models for the popular block-based programming language SCRATCH. We model SCRATCH programs using n-gram models, the most essential type of language model, and transformers, a popular deep learning model. Evaluation on the example tasks of code completion and bug finding confirm that blocks inhibit predictability, but the use of language models is nevertheless feasible. Our findings serve as foundation for improving tooling and analyses for block-based languages.",10.1109/ICSE48619.2023.00199,https://doi.org/10.1109/ICSE48619.2023.00199
PaperWave: Listening to Research Papers as Conversational Podcasts Scripted by LLM,"Yahagi, Yuchi and Chujo, Rintaro and Harada, Yuga and Han, Changyo and Sugiyama, Kohei and Naemura, Takeshi",Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems,2025,"Listening to audio content, such as podcasts and audiobooks, is one way for people to engage with knowledge. Listening affords people more mobility than reading by seeing, thereby broadening their learning opportunities. This study explores the potential applications of large language models (LLMs) to adapt text documents to audio content and addresses the lack of listening-friendly materials for niche content, such as research papers. LLMs can generate scripts of audio content in various styles tailored to specific needs, such as full-content duration or speech types (monologue or dialogue). To explore this potential, we developed PaperWave as a prototype that transforms academic paper PDFs into conversational podcasts. Our two-month investigation, involving 11 participants (including the authors), employed an autobiographical design, a field study, and a design workshop. The findings highlight the importance of considering listener interaction with their environment when designing document-to-audio systems.",10.1145/3706599.3706664,https://doi.org/10.1145/3706599.3706664
SQL Puzzles: Evaluating Micro Parsons Problems With Different Feedbacks as Practice for Novices,"Wu, Zihan and Ericson, Barbara J.",Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems,2024,"This paper investigates using micro Parsons problems as a novel practice approach for learning Structured Query Language (SQL). In micro Parsons problems learners arrange predefined code fragments to form a SQL statement instead of typing the code. SQL is a standard language for working with relational databases. Targeting beginner-level SQL statements, we evaluated the efficacy of micro Parsons problems with block-based feedback and execution-based feedback compared to traditional text-entry problems. To delve into learners’ experiences and preferences for the three problem types, we conducted a within-subjects think-aloud study with 12 participants. We found that learners reported very different preferences. Factors they considered included perceived learning, task authenticity, and prior knowledge. Next, we conducted two between-subjects classroom studies to evaluate the effectiveness of micro Parsons problems with different feedback types versus text-entry problems for SQL practice. We found that learners who practiced by solving Parsons problems with block-based feedback had a significantly higher learning gain than those who practiced with traditional text-entry problems.",10.1145/3613904.3641910,https://doi.org/10.1145/3613904.3641910
SA '23: SIGGRAPH Asia 2023 Educator's Forum,,,2023,,,
"A Pleasant Surprise: A Classic Assignment and an Offbeat Assessment for PDC, HPC, and Related KU Coverage","Rosasco, Nicholas S. and Paxson, Andrew and Hawk, Ethan",J. Comput. Sci. Coll.,2024,"This paper presents an assignment that when paired with a discussion or other follow-up can be used to increase and diversify computer science knowledge unit coverage. The knowledge units are taken from the CS2013 and related documents from ACM/IEEE. This guidance to the teaching community notes the criticality of educating students on parallel, distributed, and high performance computing. Information on available, modular resources for addressing these areas in the classroom is presented. Additionally, integrating undergraduate writing expectations into a topics course is discussed.",,
Instructional Guidance,,Supplement to CSEC 2017: Foundational Cybersecurity Content and Instructional Guidance for Secondary and Postsecondary Cybersecurity Education,2025,"This curriculum project involved a review of the Cybersecurity Curricula 2017 (CSEC 2017) guidelines and recommendation of learning outcomes that support foundational collegiate-level courses and upperlevel high school cybersecurity offerings, comparable to Advanced Placement (AP) content. The primary goal of this document is to provide a foundational cybersecurity education framework that can be implemented by both post-secondary institutions and high schools. These guidelines aim to bridge the gap between secondary and post-secondary education in cybersecurity to support broad transferability across institutions and ensure continuity for students.",,
ICBDE '24: Proceedings of the 2024 7th International Conference on Big Data and Education,,,2024,,,
SelfGauge: An Intelligent Tool to Support Student Self-assessment in GenAI-enhanced Project-based Learning,"Zheng, Chengbo and Huang, Zeyu and Ma, Shuai and Ma, Xiaojuan",Adjunct Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology,2024,"Project-based learning (PBL) involves students tackling real-world problems and creating artifacts. With the rise of generative AI (GenAI) tools, assessing students in GenAI-enhanced PBL is challenging. To address this, we designed SelfGauge, a tool that supports student self-assessment by analyzing their GenAI usage and project artifacts. It helps students define criteria, seek feedback, and reflect on their performance, promoting continuous self-improvement.",10.1145/3672539.3686338,https://doi.org/10.1145/3672539.3686338
REFERENT: Transformer-Based Feedback Generation Using Assignment Information for Programming Course,"Heo, Jinseok and Jeong, Hohyeon and Choi, Dongwook and Lee, Eunseok",Proceedings of the 45th International Conference on Software Engineering: Software Engineering Education and Training,2023,"Students require feedback on programming assignments to improve their programming skills. An Automated feedback generation (AFG) technique proposes to provide feedback-corrected submissions for incorrect student programming submissions in programming courses. However, these techniques are limited as they rely on the availability of correct submissions as a reference to generate feedback. In situations where correct submissions are not available, they resort to using mutation operators, which can lead to a search space explosion problem. In this work, we propose REFERENT, Transformer-based feedback generation using assignment information. REFERENT uses transfer learning on a pre-trained model with data from students' submission history from the past assignment. To generate assignment-related feedback, we use a title, tag, assignment description, and test case as assignment information. REFERENT can generate feedback without a reference program in limited resources. We conducted a preliminary study to confirm the effectiveness of REFERENT and the feasibility of using assignment information. REFERENT generated feedback for 32.7% of incorrect submissions without reference programs and that its performance increased up to 50.7% when reference programs were used. We also check whether the submission history, assignment information, and repair knowledge of open-source software help generate feedback.",10.1109/ICSE-SEET58685.2023.00035,https://doi.org/10.1109/ICSE-SEET58685.2023.00035
ACM SIGCOMM '24: Proceedings of the ACM SIGCOMM 2024 Conference,,,2024,,,
